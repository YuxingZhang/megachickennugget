does connectivity neural network number synapses per neuron complexity problems measured entropy theory would suggest functions implemented using circuit low connectivity eg using two input network learns problem examples using local learning rule prove entropy problem lower bound connectivity network
describe family learning algorithms recurrent connected network like machine presence noise these networks learn synaptic connection basis correlations locally each describe version supervised learning network analog activation functions demonstrate unsupervised competitive learning approach weight important role describe experiments reinforcement noise used search procedure identify above described elements learning techniques level these chosen implementation vlsi have designed cmos test chip rules speed up learning about over equivalent simulation due parallel analog computation weights use processes generating random noise components test chip noise neuron adaptive each these components into neuron network finally point out techniques area both design show algorithm study implemented systems
paper backpropagation method general network containing feedback connections network model considered consists neurons each could fully could have feedback connections weights but between stochastic descent algorithm applied under certain constraint each weight matrix network state every input
artificial neural network developed patterns function neuron generalized weights transfer functions nonlinear following adaptation learning rule learning rule generalized resulting learning weights neural network first developed spatial patterns thus generalized temporal patterns tested using set input patterns derived speech signals showing robust classification model
complexity computational capacity multi feedforward neural networks neural networks special functions circuit complexity known results complexity theory applied special instance neural network circuits particular classes functions implemented circuits about learning complexity problems problem computational capacity class multi networks dynamics considered results presented higher order structures between programming capacity shown made fixed point structure random higher order phase transitions shown
visual cortex orientation selective cells two rules have similar orientation many different observed local region several orientation models these constraints found their using rate orientation change measure models compared experimental results
investigate behavior different learning algorithms networks neuron like units test cases use simple pattern problems such problem detection problems algorithms considered either machine learning rule based backpropagation errors propose analyze generalized rule linear threshold units find performance given learning algorithm depends type units used particular networks units quite generally exhibit significantly better learning behavior than corresponding demonstrate weight structure problem lead increase learning speed
being able number neurons simultaneously important study functional networks real neurons using several neurons approach response properties sets therefore related neurons do necessary signals generated these different neurons paper problem signals such based upon their classification signals case spikes
much experimental study real neural networks classification neural signals ie action experimental most classification task single well neurons time those sampling many single neurons simultaneously classification paper describe three approaches problem each designed neural but real time first present two classification using neural network matching approach these two compared simple matching implementation analysis real neural signals simple matching better solution problem than either neural network approach
based data have developed computer simulation cortex capable spatial temporal patterns cortical activity under variety conditions using simple type learning rule cortical dynamics model simulations capable cortical representations different input patterns basis these representations interaction distributed highly between neurons have shown different representations minimal following learning these representations input reconstruction representation following partial original training stimulus further have demonstrated degree cortical representations different stimuli instance similar input patterns generate cortical representations discrimination while inputs generate representations both features important stimuli
connection machine allows neural network simulations use simple data control structures two approaches described allow parallel computation models nonlinear functions parallel models weights parallel propagation models activation error each approach allows models structure dynamic model implemented each approach over same number provide performance comparison
artificial neural networks capable accurate recognition simple speech such paper two more difficult set set words set difficult because difficult because timing word recognition time technique based dynamic programming set recognition improved attention recognition better than both implemented single layer perceptron
potential information processing within single discussed paper current knowledge about activity firing threshold conditions required similarity nodes along single circuit model low presented response single frequency circuit filter
paper analyze convergence behavior number neuronal plasticity models recent research suggests neuronal behavior adaptive particular memory within neuron associated synaptic weights achieve learning number adaptive neuronal models have been proposed three specific models paper model sutton model recent model paper conditions convergence position convergence rate convergence these models they applied classical simulation results presented analysis
new neural network classifier propose classification problem into coding theory problem noisy input vector feature space into internal representation code space error space input feature vector its class two classes codes give high performance matrix code length sequence code show number classes neuron system linear significantly more than using type memory classifier
various simulations cortical have like phase transitions respect key parameters demonstrate such transitions array models related array models classical phase transitions describe state behavior may but changes behavior key system parameters through critical values
associated forward structures show biological neurons role similar two elements equivalent circuit provide more neuron than they have such low power current they could used neural networks observed properties simple circuits containing include action threshold behavior over synaptic inputs synaptic weights temporal memory network connectivity based activity firing signal outputs firing rate input current transfer functions simple artificial neurons inputs outputs have been measured correlated input
propose learning rules recurrent neural networks high order interactions between neurons designed networks exhibit desired associative memory function retrieval information sequences information complexity
report study relationship between eeg amplitude values unit spike output cortex relationship takes form curve describes output input curve using nonlinear regression described its maximum value measurements made both neurons cortex these neurons known form negative feedback both classes cells described same parameters curve region data model other existing neural nets being discussed signal processing particular relationship efficiency neural computation
brain theory need two approaches measurements well synthetic computer simulations generate hypothesis structures neural paper research second line described model associative basic control tasks conditions conditions studied such units hierarchical general brain
interaction set sufficient many cases explain complex responses classes biological systems stimuli shown generalization allows efficient implementation effective algorithms conditions examples processing techniques presented paper applications simulated behavior path planning pattern analysis clustering design optimization
cortex neurons have provided new evidence connections between associated firing probability these cells produce large part additional synaptic noise but area ie number above per amplitude about per these data information processing connections discussed effects sequential effects underlying connections net effect parallel sum individual
neural network model associative memory generalization two state neurons neurons set values two classes neuron input output developed convergence stable states st class continuous second class rules neurons information capacity networks second class found order network neurons generalization sum learning rule developed well
computer has been designed implemented allow analyze behavior simulated neural networks connectivity computer implemented system results experiments discussed allows user construct neural networks containing connection have been studied including more activation points non variable path class important due its ability implement time dependent goal processing neural networks
describe method higher order neural networks under transformations input space each unit set constraints weights particular structure network network using such architecture its invariant performance independent values weights assume learning rules used form network network usually eg average input case higher order networks perform useful functions still exhibit derive weight constraints scale several these transformations report results simulation studies
information retrieval neural network procedure network most map estimate unknown information allows class probability distributions neural network explicitly learning algorithms neural network search most designed statistical true probability distribution developed example applications theory highly nonlinear back propagation learning algorithm networks field discussed
process sensory data sensory brain areas information about both among learned cues without would without would cues would have constructed model cortex large number parameters such two step firing necessary conditions long term synapses three types short long long sparse connectivity between layer ii cortex nonlinear have tested model its ability learn difference sensory cues biological characteristics model produce multiple each input such way different cell firing activity model both similarity difference particular probabilistic al properties synapses give probabilistic levels combination activity local layer single layer ii cells time firing spatial patterns out against relatively firing rate using rules stable layer ii cell spatial firing patterns learned cues multiple simulated input patterns ie those many features give firing patterns many layer cortex yields highly layer cell spatial layer ii cell similarity among similar inputs same time those synapses learning process cell firing strong cell specific local cells firing cells have these cells their recurrent synapses layer these synapses combination those still active response cells among even similar cues empirical computer simulation have shown after training initial spatial layer ii cell firing responses similar cues similarity cues such response equal than research part under under input cell firing eg two cues give response patterns more cell firing patterns after among even similar patterns so cues input give output responses less than difference response measured respect its input reduced near zero response structure between even similar cues other hand similarity response mechanism mapping quite input cues response patterns category therefore use statistical metric information value measure value produced simulation network
efficient using current large connection networks more than connections requires these networks exhibit high degree real neural networks exhibit significant yet most network models have paper connectivity simple associative network using theory several techniques based theory presented improve network face sparse local structures discussed potential problems information distributed
many connectionist learning models implemented using gradient descent least error function output signal present model particular back propagation using power small error metric large maximum metric while standard backpropagation model results implementation back propagation described several experiments show different values may various different values may appropriate reduction effects noise modeling input space more clusters modeling statistics particular domain more way may more eg speech vision
describe new learning procedure networks nonlinear units learning codes allow activity vectors represented activity vectors hidden way test whether code accurate representation vector hidden vector difference between original vectors called reconstruction error learning procedure minimize error learning procedure has two first original vector second average original vector vector learning procedure changes each weight amount product activity difference synaptic activity two procedure much implement than methods like back propagation simulations simple networks show usually good set codes analysis shows certain cases performs gradient descent reconstruction error
paper movement control based two signal processing higher stage neural network model array motor pattern network uses sensory input pattern evaluate their performance outputs produced includes recurrent thus capable self activity these outputs motor local feedback systems called motor control individual control thus achieved two adaptive network array feedforward motor set local feedback systems these into movements
describe two neural computing first feedback used implement associative image second perceptron like learning algorithm implemented
previous work nets continuous inputs generative construct convex decision regions two layer hidden layer arbitrary decision regions three layer two hidden here demonstrate two layer classifiers trained back propagation form both convex decision regions such classifiers robust train provide good performance simple decision regions complex decision regions required convergence time long performance often better than nearest neighbor classifiers three neural net classifiers presented provide more training under such two use fixed weights first two similar classifiers estimate probability density functions using feature map classifier uses both unsupervised supervised training provides good performance supervised training such speech recognition much training data available architecture classifier used implement neural net nearest neighbor classifier
inverse matrix considered optimization have demonstrated problem solved highly simple neuron like analog network matrix based concept neural network designed implemented hardware network solving linear equation efficiently features circuit potential speed due parallel processing against parameters
use highly developed system their environment neural system well four representation architecture search knowledge system addition design architecture goal system feedback its environment analysis neural networks target tracking neurons within region connections between sensory inputs motor outputs analysis suggested these neurons selective temporal patterns sensory input through type filter stimulus connectivity response patterns cells nature response suggest function cells may stimulus source its has been computed
information capacity sparse distributed memory type neural networks under approximations used here shown total information these systems number connections network constant same type models independent particular model order model approximations same analysis used show sequences patterns addition time connections allows retrieval context dependent temporal patterns used correlated patterns
recently many model have been proposed both learning given network function due information learning updates these networks need introduce performance measures addition information capacity evaluate different networks define such plasticity network information vector probability network these analytically compare different networks
interest neural networks neural less work has been performed using neural networks process point neural networks therefore best potential speed parallel make neural net number interesting explore paper discuss our work demonstrate certain applications neural networks achieve significantly higher numerical accuracy than more conventional techniques particular prediction future values time series performed high accuracy analyze neural net able do process show large class functions may backpropagation neural net two network uses functional approximation perform either interpolation signal processing applications processing applications neural nets therefore use quite methods perform their tasks here useful approach neural network neural networks well studied functional approximation
new distributed neural information processing model proposed explain response characteristics system more data model motion cells cell signals multiple synapses neurons exhibit varying dynamics model application concept neural networks description allows us behavior neurons whose characteristics according their properties
general mapping optimization problems into systems differential equations associated artificial neural networks presented comparison made optimization using gradient search methods performance measure time initial state target state simple example dynamical systems representing artificial neural network methods would faster than those representing time more optimization problem using computer simulations problem version problem activity measurements simulations gradient based systems typically times faster than systems based current neural network optimization methods
information optimization principle proposed development each processing stage perceptual network principle maximum information states signal transformation each stage information output signal values stage about input signals values stage certain constraints presence processing noise being information rate provide principle simple model cases derive its discuss implementation show principle may lead relevant neural features such maps map orientation spatial temporal signal correlations possible connection between information principle principle minimum entropy suggested
discrete model average memory capacity associative compared means good random dimension different vectors memory capacity found much than upper bound two dimensions average has about capacity corresponding memory same number neurons coding effective capacity memory capacity due stable states much same way stable states another nonlinear process here called label selection take net gives sensitive memory improved use transformation application implemented
has been interest neural like processing systems example two parallel distributed processing discussed parallel distributed systems connectionist models neural nets value systems multiple context systems artificial attention parallel systems implemented hardware paper simple neural like systems based multiple context other well known systems length sequence prediction finite state machines machines presents sequence prediction results new
paper discuss special useful connectionist neural networks such applications pattern recognition classification three chip described hybrid connection matrix analog connection matrix connection digital best chip common feature distribution processing power data minimize data movement distributed computation chip conventional node complexity figure graph node complexity size conventional computer simple nodes each few but processing power complex node neural network distributed computation region many simple fixed local data after
have studied fixed point analog neural network network feedback initial conditions resulting fixed points show associative memory network leads network includes analog time delay have shown delay symmetric networks introduce conditions related presence connections delay network
class neural networks whose performance signal space environment neural networks perform between two more constraint sets desired convergence easily network either form number patterns network order number input hidden neurons output neurons take two states trained easily converge iteration more generally convergence exponential rate convergence improved use type network number neurons hidden layer manner network data trained ie directly analytically
present paper results theory large scale dynamical systems order develop theory field model neural networks our approach view such networks many single neurons our results terms properties individual neurons terms properties structure neural networks neural networks address include asymptotic stability exponential stability estimates trajectory bounds estimates domain stable stability neural networks under
binary synaptic matrix chip has been developed neural networks matrix chip array long channel binary connection elements implemented cmos process neurons synaptic chip multi chip synaptic network large size alternative long channel connection elements series cmos test obtain synaptic connections although require additional processing steps they area performance synaptic chip neuron system associative memory test application discussed
vlsi neural network described initial architecture array through design computation discussed parallel development hybrid neural network learning reported network along neuron technique extended synapses network update time using technique time through array
novel network type introduced uses unit length vectors local variables example its applications associative memory nets defined their performance real systems corresponding such models eg networks limit have their feedback path
have developed neural network consists off used function related log likelihood function codes more general signal problems connections network types networks vlsi implementation experimental results convergence stability network have been found structure network used distributed representation data while units
general method backpropagation algorithms networks recurrent higher order networks introduced propagation activation these networks determined differential equations error signal associated differential equation method introduced applying recurrent generalization feedforward backpropagation network method extended case higher order networks constrained dynamical system training memory feature adaptive algorithms adaptive equation has simple product form experiments suggest learning networks recurrent connections continuous makes new approach more implementation vlsi
many optimization models neural networks need constraints space outputs using energy methods upon state neural network method quadratic energy constraints existing optimization energy has recently but constraint conditions other neural model multiple constraints paper present basic differential method constraints apply constraints over time using neurons estimate basic differential method differential version method numerical analysis prove differential equations locally converge constrained minimum examples applications differential method include analog problem problem
error propagation nets have been shown able learn variety tasks input pattern output pattern paper presents these nets time varying patterns three possible architectures example nets applied problem speech coding time sequence speech data net another use dynamic nets gives better signal noise ratio than achieved using nets
have several neural network processing models order determine these models would scale first have understanding representations define general structure derive relationships among their parameters size set size computed capacity schemes well measurements memory distributed connectionist system
study distributed memory systems has produced number models work well limited domains recently application such systems problems has been difficult because their simulation computational complexity recent development capacity feedforward architectures has way application such systems complex pattern recognition problems such problems features describe environment thus significant pattern environment often non current work high density memory systems their network discuss general learning algorithm such high density its application point sets finally introduce extension method learning probability distributions non point sets
have developed training control systems based artificial neural systems applications rule set experts difficult used rules information actions takes constructed networks rules behavior them function they trained set possible training provided either under direct system using network training data performs tasks demonstrate these methods have trained network through simulated
ability obtain three dimensional structure visual motion important human non human using parallel processing model current work biological visual system might solve problem might about understanding solution
self multi networks time sequential neural firing cells each layer provides unsupervised capture patterns presented previous layer patterns complexity network higher levels capture pattern set
general method product representation described distributed representation method allows fully distributed representation structures structures well those non local fully special cases reduce existing cases connectionist representations data product representation these few existing examples fully distributed representations structures representation larger structures represented complex representations generate multiple parallel continuous structures continuous patterns values variables analysis structures associative leads optimal distributed representations algorithm learning them
paper explore spatial neural networks under assumptions what individual cells mechanism properties neural nets relevant image modeling pattern analysis spatial stochastic two dimensional image fields first approach develop random neural network model based upon simple probabilistic assumptions whose studied means discrete simulation investigate random networks using approach theory general product form networks neural network described network nodes moving node node represent connections between nodes terms probabilities obtain solution model under different time each node results distribution network function network arrival pattern compared measures obtained simulation approach
patterns temporal context important such tasks speech recognition motion detection propose architecture time its representation temporal context state nodes contrast approach architecture represent time example these demonstrate architecture inputs temporal feature standard back propagation model experiments motion detection word discrimination illustrate novel features system finally discuss possible architecture
propose new scheme construct neural networks patterns new scheme has several novel features focus attention important patterns order most important first less important training use information measure instead error function multi perceptron like architecture decision made according tree structure learned new scheme expected self perform well large scale problems
efficient method self associative proposed together applications robot systems proposed input output first algorithm self proposed hardware new neural network part recognition robot system demonstrated
networks simple analog neuron like properties have been compute good solutions variety optimization problems paper presents neural net solution problem local wide area network problem described terms energy function analog computational network simulation results performance neural computation presented
number using after sound through auditory system although has been achieved area useful speech recognition has been either single multiple channel coding evidence suggests necessary would natural speech system temporal other found natural implemented presented here computational model using artificial neural networks natural artificial model presents series advantages implementation such systems first hardware constraints power size processing taken into account together development neural structures defined second model natural neurons necessary close mapping necessary functions processing like functions could implemented more efficiently local model allows function through parametric variety experiments those user system real time more fit condition auditory system
family networks designed signal processing applications presented information sparse code sequences basis binary signals generalized synaptic connectivity matrix binary values addition high capacity associative memory resulting neural networks used implement general functions such code filtering code mapping code code code
paper presents artificial neural network concept networks individual form point processes form information between neurons type most other models typically continuous discrete value networks each processing unit time signal firing other units presents significant implementation advantages our model neurons interaction present firing neurons networks such neurons global exhibit multiple arbitrary initial states energy minimization learning make network converge multi dimensional constraints such networks directly represent problems sequences
paper describes approach dimensional object recognition complex log mapping combined distributed associative memory system objects changes scale information database used object version object estimate changes scale system response noise several experiments using real scale images presented show our approach
paper presents model adaptive constructed adaptive information processing elements first paper describes model second its significant adaptive properties using computer simulation examples among these properties network model elements single reinforcement channel provides same positive negative reinforcement signal adaptive elements network same time multiple input multiple output multiple sequential networks network elements hidden their outputs directly environment
potential adaptive networks learn rules model human performance studied natural artificial systems new inputs ie they generalize like networks learn deterministic task variety alternative individual solutions analysis constraints using networks minimal number hidden units shows minimal sufficient explain predict human performance few solutions found both minimal adaptive networks further analysis human network initial conditions may provide important constraints generalization new technique call learning described finding appropriate initial conditions
propose principle training unsupervised feedforward neural network based upon ability input data network outputs describe algorithm used train either linear nonlinear networks certain types examples applications problems image coding feature detection analysis presented
reinforcement based connectionist architecture learns associative maps continuous locations positive negative do outputs relevant current goal combined compared current location produce error vector vector through motor perceptual mapping network produce action vector leads system do locations locations demonstrated simulated robot target task
class fast supervised learning algorithms presented they use local representations multiple scales resolution approximate functions continuous model algorithms learn more than back propagation while often generalization furthermore most traditional function approximation methods algorithms well use real time adaptive signal processing adaptive systems such linear predictive coding adaptive linear kalman filter new algorithms capable efficiently structure non linear systems algorithm applied prediction
optimization techniques applied problem learning feedforward neural networks addition superior convergence properties optimization techniques such method significantly more efficient than backpropagation algorithm these results based experiments performed small learning problems noisy real learning problem hand recognition
classifier systems machine learning systems algorithm learning mechanism although they inputs neural networks their structure representation learning mechanisms those neural network same domains result might these two types machine learning different two taken together prove instead classifier systems neural networks equivalent paper demonstrated through description transformation procedure map classifier systems into neural networks behavior several used neural network required order make transformation work these their discussed paper practical these results their
work new method called self neural network algorithm its use system task algorithm network neuron functions weights compared back propagation algorithm time series results shows more accurate model less training data algorithm applied generalized classifier
introduce learning algorithm neural networks binary linear threshold elements existing algorithms reduce learning process minimizing cost function over weights our method internal representations determined correct set internal representations weights found local learning rule tested our learning algorithm four problems combined
address question network expected generalize random training examples chosen arbitrary probability distribution future test examples same distribution among our results following bounds appropriate sample network size assume show random examples feedforward network linear threshold functions nodes weights so least examples has confidence network future test examples same distribution fully connected feedforward nets hidden layer learning algorithm using than random training examples distributions examples consistent appropriate weight choice least fixed time find weight choice more than future test examples
new training called introduced tasks network learn pattern set based examples human input network consists two trained experts better applied learning set comparison training much higher levels performance achieved networks much coding schemes much furthermore possible set up network so consistent
paper means using knowledge network determine relevance individual units both understanding networks behavior its performance basic idea train network certain performance criterion compute measure relevance input hidden units most critical performance automatically least relevant units technique used networks units information improve learning performance first learning hidden units generalization behavior networks terms minimal rules
concept stochastic machine decision making pattern classification probability network states function network energy probability particular energy may associated probabilities making certain because stochastic nature complexity high therefore such networks used practice paper suggest way into deterministic network call network equivalent but has forward structure low complexity required conditions under such given learning algorithm based gradient method provided backpropagation algorithm
required filtering minimum error noise present highly non gaussian experiments performed determine whether correct could provided single input multi layer perceptron trained back propagation found multi layer perceptron input output node nodes first hidden layer nodes second hidden layer could trained provide than samples network trained relatively high signal noise ratio used linear filter reduced probability error network similar used current designed noise provided similar performance
large recent work artificial neural nets uses trained back propagation algorithm described et al algorithm large complex problems such speech recognition iterations may convergence even small data sets paper show training problem nonlinear dynamic system solved using extended kalman algorithm although computationally complex kalman algorithm usually few iterations describe algorithm compare back propagation using examples
paper provides analysis recurrent backpropagation algorithm number new results main algorithm convergence network stable fixed point order error signals show experiment analysis condition behavior next advantages over standard backpropagation algorithm stable fixed points corresponding input patterns makes appropriate many function learning inverse problems
scaling generalization have key current studies supervised learning examples neural networks such many training patterns training problem given size represent useful training theoretical practical several rules have been obtained empirical studies but few results paper study generalization possible case perceptron networks learning functions task chosen function ie input units number useful properties find many networks learning large difficult tasks simple domain numerical results even understanding achieved
improved learning significant reduction computation time during supervised phase described based role neuron artificial neural systems prior work has neuron non linear processing other hand source information processing knowledge work role neuron extended its learning phase function such parameter during learning both synaptic weights neuronal so capture knowledge within training set method allows each neuron update its local algorithm has been applied type problems such problem resulting significant required number training
has proposed method minimal simple representations during learning back propagation networks approach used number hidden units construct representation appropriate problem thus improve generalization ability back propagation networks method suggests involves terms error function paper introduce minimal networks idea compare two possible weight search space these compared both simple problems speech recognition problem general constrained search does minimize number hidden units required expected increase local
paper problem weights set linear filters model cells so ensemble information cells output values about their input values given statistical properties ensemble input vectors information rate average mutual information between input output several models role processing noise biological them described simple models input signal values space time correlated cells resulting optimization process include cells cells sensitive temporal input signal
number learning models have recently been proposed temporal continuous time models these models like most adaptive network models terms frequency activation useful neuronal firing rates more evaluate neuronal model may develop model discrete information point out many functions properties neuronal processing learning may ways nature information coding properties neuron systems compared terms activation computing temporal proposed sutton both more stable more system these models terms coding our has been us further connections between real time models learning biological circuit models underlying learning memory
paper show neural networks speech recognition constructed hidden structure previously trained networks performance resulting larger nets found good performance nets approach learning times would necessary larger networks allows learning large time delay neural networks constructed applying these training techniques achieved recognition performance
results speaker speech recognition reported method neural networks speech recognition used recognition systems property variable resolution time frequency domains used speech model human auditory system
propose new neural network model its learning algorithm proposed neural network consists four input hidden output output hidden output multiple using proposed pattern information learning algorithm possible learn analog data obtain smooth outputs using neural network have developed speech system speech parameter have natural speech high accuracy
connectionist model uses temporal information speech signal recognition rates transitions uses adaptive method transition each system uses spatial temporal representations through delay uses parametric temporal representations transition classification through node activation transition networks visual motion cells tested data its training
space environment has construct small system called performed well human have constructed three layer back propagation connectionist network learns well does suggests connectionist network perform task knowledge automatically study internal representations constructed network may give processes human brain
discuss paper architectures probabilistic rule parallel manner using theoretical basis recently introduced information models our non neural learning algorithm theory rule exact nature two particular models finally work through example our approach database rules inference network compare networks performance theoretical specific problems
application neural networks signals multiple environment considered study large part fact system conventional filter performance relative signals large near far problem furthermore near far problem complex practical use based multi layer considered simple robust alternative solution used performance neural net particular decision regions neural networks back propagation algorithm version used train neural net sampling technique introduced reduce number simulations necessary evaluate performance neural nets examples considered proposed neural net significantly conventional
study performance perceptron frequency sensitive competitive learning network measurements performance neural network classifiers compared nearest neighbor maximum likelihood classifiers our results indicate problem neural network classifiers relatively changes network noise level training data while problem traditional algorithms these simple neural classifiers neural networks show potential improved performance
new class neural network early visual processing described call neural analog layer network consists two levels through feedback connections lower level two dimensional map visual features input activity over larger scales function time upper layer activity layer local form contrast using network local these local back layer using available output network network dynamics cluster features multiple scales function time used variety early visual processing tasks such high points along line detection points perceptual multiple scales path long range motion shape representations invariant location orientation scale small visual field
propose parallel network simple find spatial changes within regions
neural network layer back propagation network designed task following takes images range input output direction should order training has been using simulated images test indicate network real under certain field conditions developed perform task network trained under various conditions novel adaptive system capable its processing conditions hand
most complex control tasks based systems conventional systems face computational introduced parallel problems new computer architectures based human brain high speed solutions processing paper applications artificial neural networks problem pattern recognition
neural network applied problem using propagation network learning algorithm forward network trained similar addition two new methods make training effective recognition accuracy higher than conventional methods analysis connection weights trained networks hierarchical structure strategy trained networks makes high recognition accuracy possible our results suggest neural networks effective recognition
used train neural network task whether given network feedforward net binary image input hidden layer single unit output layer weights according backpropagation algorithm into through use binary performance function training set network structure best order true
vision based controller path based connectionist architecture implemented video series robot sensory motor maps cortex internal representations four simple units representing both dynamic sensory motor environment previously reported work first learned direct model system during extended practice used model hand visual has been extended two ways first now learns inverse differential addition direct allows hand directly visual target without need search now much more difficult problem presence
computing inverse dynamics robot active area research control learn inverse dynamics training neural network measured response input network temporal measured output vector train network data measured first two direct ii through randomly generated sample trajectories test generalization new trajectory compare its output measured network shown generalize mean weights network terms filters used conventional control theory
has representations space its used so visual auditory stimuli visual field view present models computer simulations these structures address various problems map space auditory sensory problem motor system these maps compare results biological data
have previously developed simple model visual cortex model provides common framework variety activity dependent biological studied computational results together now following inputs specific each eye locally correlated their firing within cells form cortical interactions into correlations within each eye correlations between more cortex positive correlation over yields almost cortex most features model analytically through decomposition into linear stability analysis allows prediction other features biological parameters
modeling studies memory based neural networks both selective synaptic required efficient information et al have tested assumption cortical structure brain long term memory high frequency activation synapses increase synaptic known long term many known requires et al et al mechanism reduction synaptic could has yet been demonstrated studied associative interactions between inputs same trees cells field found low frequency input does change synaptic either increase associative associative upon whether correlated second high frequency input synaptic firing sufficient activity thus associative associative capable information covariance between inputs present address present address computational covariance synaptic
discrimination model based described simulations produce activity across observed field decision states information here stable rather than point stable states computing models analysis simulations show non linear determined input appropriate inputs higher particular model provides framework between input output cortex
present new hypothesis key role sensory information system paper explore idea function simple related behavior eye movements generated minimize image retina during movements system point view statistical estimation theory our results suggest transfer function often feature system should during movements further suggest these changes under direct control cortex propose experiments test hypothesis
its environment generating fields small fields resulting objects objects basis sequence images whose temporal spatial properties timing its position relative objects its environment these timing position during object discrimination have developed simulation self generated fields so position timing paper describes finite simulation system presents field measurements being used simulation
recently proposed model explain sensory maps could resolution through have extended model general case polynomial schemes response function polynomial same order further demonstrated system finally suggested mechanism sensory representation stimuli resolution far separation
new learning algorithm recurrent analog neural networks introduced network nodes may programming network vector independent patterns stability patterns rates convergence may patterns product allows learning may spatial patterns neural activity cortex during predict pattern recognition behavior experiments these during through decision point their selection input pattern
visual system learns true direction pattern motion using local capable component motion orientation moving feedforward network model similar model presented input patterns each randomly moving particular direction input layer units component direction speed curves similar those neurons visual area area network trained many such patterns most weights units second layer solve problem eg show same direction curve pattern direction selective neurons first area
analyze model selective cells based recent data show its computation motion direction robust against noise speed
have developed general simulation system modeling neural networks implemented under designed support simulations many levels use both applied network modeling simulation models examples current models developed under system include cortex pattern well more abstract connectionist simulations
consider layer node input neural network whose nodes compute linear threshold functions their inputs show complete whether weights three nodes network so produce output consistent given set training examples extend result other simple networks result suggests those training algorithms cannot computational simple networks suggests given training problem finding appropriate network input problem left problem extend our result nodes non linear functions such
hidden markov models used speech recognition they sequential speech signal trained choice model their another these models their power now connectionist approach classification problems have been successfully tested speech recognition problems sequential nature speech signal difficult machine paper hidden markov model defined shown particular perceptron feedback input units considered general form such markov models
machine has been introduced means perform global optimization objective functions using simulated paper consider its free memory provide bounds its performance context show machines ability local order use constant associative pattern retrieval noisy rule each pattern used along machines dynamics machines noisy input patterns fixed points whose rule due machines finite probability state results apply machine net binary threshold elements model they provide network case best case bounds networks performance allow polynomial time studies design parameters
describe recent results development distributed representations variable data structures work certain types data structures now represented fixed analog vectors simple performed using type pattern neural networks another these representations self similar limit many interesting new about basis discussed
learning parallel self context free capable length due its tree representation scheme system capable its performance through training examples
human activation connectionist has systems nodes perform patterns activation paper demonstrate simple network performed activation over weights learned distributed thus account provided relationship between distributed connectionist approaches
time delay response neurons network present stability criterion based local stability analysis symmetric delay networks show example dynamics non symmetric delay network
research artificial neural networks has generally architectures systems natural exhibit both their elements patterns behavior complex dynamic environment may provide into design artificial neural networks paper describe neural network simulated controller variety stable different varying activity single cell natural its design
new optimization strategy mean field presented its application map noisy range images derived experimentally
research involves method finding global constraint networks process but most instead determined locally units each update thus processing unit level two practical processing way processing areas network while good areas stable processing areas long constraints ie does after number result method determined but global more than systems comparison machine et al made finally implementation method computationally
introduce optimization approach solving problems computer vision multiple levels our objective functions include vision problems graph matching problems graph matching terms constrained optimization use analog neural networks perform optimization method perceptual model matching experimental results shown
distributed connectionist system neural network complex dynamical properties energy its component leads better understanding model suggests ways its dynamics order improve performance difficult cases
describe adaptive network learns transition function sequential system observations its behavior two state representations examples system behavior its dynamics main paper transition functions noisy state representations data during training while sequences transitions response input dynamics both nets based adaptive theory give results experiment learned behavior system even number
present model human elements simulation model shows four signal processing features whose basis evidence furthermore does model parallel signal processing way means elements what features design useful filter process images obtain better understanding auditory system
describe firing circuits implement analog neural networks synaptic weights uses time neural neuron neuron their state variable control time thus achieved small circuit cell vlsi chip set design uses cmos
paper describes cmos artificial neuron circuit directly derived channel model neural has low power small principal work include high performance more accurate neuron need higher density practical neural network
sparse sensory data well known problem computer vision paper describes experimental analog vlsi chip smooth interpolation sparse depth data node network designed cmos successfully tested network second order energy circuit directly model reconstruction addition chip provide gaussian like images
analog fully parallel implementation class recurrent neural networks wide variety based proposed while contrast data adaptation mean input network well processing sensory information feature memory system network global function thus achieve stable addition model function analog adaptive circuit
digital two dimensional self feature maps presented method based classification using technique weight vector approximation produce network discussed over effective binary weights applied using conventional number image recognition tasks including recognition object described
design fully analog version self feature map neural network has been several parts design feature map algorithm circuit solutions various required performance effects measured design part speech recognition system circuits implement both activation weight learning analog weight values provided weight fully analog implementation requires order less area than hybrid version developed
have test chip cmos perform supervised learning manner similar machine patterns presented per second chip learns solve problem few have demonstrated do unsupervised competitive learning functions chip components performance
discuss synthetic these based field effect structures using standard cmos these small presence objects they direction field
speech recognition artificial problem input continuous patterns desired output may words text most approach speech recognition based stochastic models stochastic model theoretical system whose internal state output series transformations probabilistic application speech recognition unknown patterns sound they outputs stochastic system information about classes patterns structure these probabilities their most type known hidden markov model several approach has been so describe shape has way temporal order together both hierarchical nature speech structure algorithms respect model recognition model fit significant example data learning theoretical eg many system speech signal first described sequence vectors cross equivalent rate per second pattern sequence corresponding discrete states model each vectors distribution state but independent another states after systems relationship between states speech but most properties speech assume important most approaches pattern recognition theory level parameters models usually using estimation method so likelihood data given model right do form model appropriate data but parameter method speech recognition discrimination between classes words hmm recognition algorithm designed find best input terms model current states lead current state better dynamic programming may lead current state much than best current state search method important many hand current input connectionist neural network approaches strong types process used they new processing mechanisms used usually than those methods but theory what computed instance more difficult structures have been proposed temporal structure connectionist approaches speech network whose inputs speech data would have internal state necessary information about input output would accurate early could training networks their dynamics difficult what internal state should methods training fixed points recurrent non networks has train various types network full state feedback recurrent connections self hidden output units but even so theory such non linear filters other systems whole time frequency amplitude array resulting initial analysis input network require label output example performance et al report multi speaker small word recognition tasks approach those best hmm techniques available same data temporal position trained into network patterns random fixed time et al use either networks across time network single small network internal delay time delay neural network recurrent output so training using backpropagation problem may finite response non linear filter reported results discrimination better than those hmm system same data system position its has constructed demonstrated large word continuous speech systems neural network but implemented algorithms more current digital signal map technique unsupervised adaptive constrained its points non linear low dimensional space learning vector technique used initial advantages nearest neighbor method training among other types network have been applied speech interesting class based correlations weight vectors product but points radial basis function theory developed multi dimensional interpolation shown many forward networks used advantage difficult find useful points define first non linear transformation linear output transformation weights found methods fast points using methods based backpropagation related methods include potential functions kernel methods network much form comparison theory stochastic model neural network approaches speech recognition perform speech way like algorithm have state states model state include information about distribution possible states given pattern so far state transition function update distribution current speech input whether such internal representation behavior learned recurrent network stochastic model based algorithms have present temporal sequences discrimination based training techniques may make significant difference performance would area have most finding non linear transformations data take us space related parameters more relevant than auditory eg resulting transformation could set feature should posterior probabilities states directly applying stochastic model neural network approach class models networks able capture between speech words instance yet have structure makes algorithms models based examples particular unknown patterns future systems need described allow high performance systems large their adaptation characteristics each new user speech recognition stochastic model based methods work best present but current systems generally far even higher level processing minimal predict next systems based combination connectionist theory techniques speech knowledge used rather soft way structure should long have been making theory stochastic processes
map like representation sound source direction used interest computed difference sound level present models computer simulations two level difference processing known make several predictions
pattern well defined biological neural network neuron network many inputs these inputs network produce multiple output patterns three simple mechanisms cells active synaptic response properties individual neurons response properties neurons network function modulation discussed
multiple sensory inputs make synaptic many motor neurons these hidden units several different used constraints construct model local dynamical networks trained experimentally derived input output patterns using recurrent back propagation units model include synapses multiple synaptic time properties hidden units simulations those model data support distributed rather than representations local these results explain local
traditional neural coding known stimuli average neural responses face task short spike train information about unknown time varying stimulus here present neural code point view algorithms real time stimulus reconstruction based single sample spike train these methods applied design analysis experiments movement sensitive neuron visual system far first instance direct neural code has been
most complex internal states responses its environment therefore interest neural basis these states upon work neural basis have developed artificial neural network behavior simulated demonstrate artificial many characteristics behavior natural
brain map cortex map has been shown experimentally use dependent present neural network simulation competitive dynamics underlying cortical plasticity analysis receptive field properties model neurons during simulations cortical section
well known neural responses particular brain regions but general have been developed structure brain map nature associated computation parallel maps quite similar brain maps computation distributed across multiple paper discuss relationship between maps these suggest similar might apply maps brain
model cortex minimal known shown function memory using previously developed theory network has neurons local feedback set nonlinear long range connections using local like learning rule higher order synapses long range connections system learns amplitude patterns observed visual cortex rule derived more general algorithm recurrent analog networks analytically memory continuous sequences capacity components node network
firing patterns cells visual cortex exhibit responses range furthermore neurons many highly long cells have similar orientation investigate two basic network architectures either nearest neighbor global feedback interactions non local feedback role initial dynamic stability
has been known many specific regions cortex correlated activity while system has been focus much work similar behavior has recently been observed visual cortex have developed models both visual cortex observed properties these networks using these models have behavior single cell properties network architectures discuss idea cortex may architecture cortex whole these patterns may important neuronal activity during sensory processing
computational model development specific eye brain circuits model self map network uses local rules constrained various simulations development maps described
level individual neurons cells inputs present model effects network neural like elements changes individual elements do their ability signal noise same changes cell network such elements do improve signal detection performance network whole show result used computer simulation behavior account effect signal detection performance human subjects
study networks spiking neurons spikes process state cell determined firing rate limit high firing rates our model studied find spiking results several new features such noise between off states cells probability description network dynamics terms energy account spikes allows us network parameters such synaptic weights against experiments real synapses synaptic response network dynamics suggests novel dynamical learning mechanism
paper presents results simulation spatial relationship between principal objective modeling between proposed cortex suggested experiments more mapping results suggest several features circuit may using techniques but patterns techniques more accurate representation region cortex
visual cortex orientation selective simple cells may instead test single neuron model learns receptive fields upon noise input orientation upon model learn receptive fields upon environment thus new experiments receptive field may provide into plasticity simple cells model suggests cells single spatial frequency may more spatial frequency orientation dependent effects than observed
spiking neurons threshold used study frequency signals through networks firing correlations between cells input layer found signals under certain dynamical conditions level activity each cell source synaptic input average produced synaptic input threshold firing correlations between cells input layer could signal present close threshold firing between cells initial could effect propagation signals case neurons could analog elements linear input output
properties model neuron taken work model neuron several active including dynamics set first order differential equations set internal parameters model rate time study parameter set input neuron fixed while each internal parameter left fixed study input frequency while internal parameters system left fixed resulting output firing rate rate model neuron studied out much more sensitive modulation certain current parameters than plasticity per amount current due activation would suggest has been recently observed experimentally current may more important focus neural plasticity than synaptic
solutions information equation connection three layer feedforward neural net visual information processing presented results receptive fields feature cells maximum equation first derived equation connection mechanism has been changes receptive field conditions different explicitly
neural net conventional pattern classifiers gaussian nearest neighbor standard back propagation adaptive back propagation feature map learning vector binary decision tree implemented computer compared using two speech recognition two artificial tasks error rates equivalent almost tasks but classifiers memory training time classification time nearest neighbor classifiers trained but required most memory tree classifiers provided classification but complex back propagation classifiers typically required long training times memory these results suggest classifier selection should often more practical memory computation training classification times than error rate work research practical characteristics neural network
well known learning algorithm applied fixed data size upper bound number model generalize well because amount hardware neural network typically dimensionality its inputs high performance network large input patterns paper several techniques problem discussed context word recognition task
based speaker dependent continuous speech recognition system ie feedforward artificial neural network into hidden markov model hmm approach shown maximum map probabilities could thus probability estimator hmms using information input have been able improve performance over corresponding performance simple maximum likelihood even map probabilities estimated without context recognition words continuous speech so improved use several original scheme necessary performance shown here word recognition performance simple discrete density hmm system better methods used estimate probabilities
two approaches neural net classifiers hidden markov model hmm speech both improve speech pattern discrimination while temporal processing advantages approach used neural nets provide second stage discrimination following small task radial basis function rbf back propagation neural nets reduced error rate rbf classifier larger task neural net classifiers reduce error rate they gaussian gaussian mixture neighbor classifiers another approach neural nets low level feature based single rbf neural net classifiers gaussian mixture classifiers performance across using single node work research hmm speech recognition neural net discrimination sequence second stage classifier node segmentation figure second stage discrimination system recognition based each node second stage classifier weights each node provide improved discrimination
present number time delay neural network based architectures multi speaker recognition use speech two four compare performance various architectures against recognition rate single speaker series leads highly multi network architecture capable speaker recognition task speaker dependent rate addition its high recognition rate so called architecture learns without direct speech particular speaker using internal models other
neural network approaches pattern recognition use discrimination based training method show have output layer perceptron provide correct probability distributions error criterion probability based result equivalent maximum mutual information training has been used successfully improve performance hidden markov models speech recognition network constructed perform recognition given stochastic model based classifier obtain discrimination based training parameters models examples include hmm based word call
neural networks knowledge speech speaker independent speech recognition system knowledge input coding output coding output constraints temporal speech hidden output units input level back propagation sequences learning algorithm networks local self strategy demonstrated several experiments particular discrimination task application speech theory hypothesis improved generalization
effects parameter hardware constraints self feature map algorithm performance measured error rate speech recognition system algorithm part processing system parameters weight connection adaptation distance measures circuit approximations include characteristics process experiments using word database demonstrated performance weight competitive nature algorithm constraints makes fully analog circuit implementation circuits have been following constraints through simulation
speech recognition presence noise information available visual speech signals previous using these visual speech signals improve speech recognition systems have combined visual speech information level using rules paper demonstrate alternative approach visual speech information training feedforward neural networks map visual signal corresponding short term spectral amplitude signal information directly combined significant demonstrated recognition noise signals these results compared performance well other pattern matching estimation algorithms
patterns present signal make based parameters use neural network signals directly without input such network invariant features may chosen input pattern
paper describes neural network algorithm performs temporal pattern matching real time trained line single requires single training each class changes noise signals low noise presence non gaussian noise makes use context outputs bayesian probability estimates algorithm has been problem signal detection classification connection machine within signals noise uncertainty
our develop neural system invariant learning recognition objects introduce here new architecture called network constructed adaptive synapses upon our existing system processes them into view ie invariant position orientation scale network learns transitions between these graph like structure network object recognition evidence over multiple object
describe model two dimensional image independent their orientation position scale model called efficiently between object each its component features fixed invariant transformation features objects weights connectionist network using such transformations complexity features each layer network multiple objects parallel implementation described along experimental results networks ability invariant manner
maps provide general method two dimensional but images give such maps good objects them maps easily long feature vectors recognition associative memory these properties maps suggest role them early visual direction sensitive neurons visual cortex view
have constructed two system single human eye artificial eye signals generated two rate motion information visual analysis its process similar response eye learns system model changes its structure performance environment eye example robust sensory system performs significant use
achieve high rate image data while high quality image good image model efficient way represent specific data each image introduced based knowledge characteristics interactions between them human visual system parallel architecture image data markov random field image model interactions between number filter proposed
paper use model neural network motor learning presented neural network do nearest neighbor early paper their nearest neighbor network local model network local model set nearest network design equivalent local regression network architecture represent smooth nonlinear functions yet has simple training rules single global network has been used motor learning simulated simulated machine
scheme has been used basis implementation associative memory system part learning control concept degree local generalization area interpolation fixed paper algorithm self variable generalization based
performance network studied introduced into weights after training has been found reduced generalization loss weight considered but weight
given set input output training samples describe procedure time sequence weights dynamic neural network model arbitrary input output process input output mapping problem optimal control problem performance function time varying weights solve resulting nonlinear two point value problem yields training rule performance chosen rule out continuous time generalization product rule suggested associative learning curves new technique presented
nonlinear neural framework called generalized network proposed able solve parallel distributed manner systems nonlinear equations method applied general nonlinear optimization problem demonstrate three most important optimization algorithms generalized reduced gradient quadratic programming methods study results dynamic view optimization problem model optimization thus significantly practical problems optimization problem gain
present novel recurrent connectionist network architecture learns perform complex sequential input word time our networks learn do role recognition networks make predictions every point time previous predictions arrival new our networks their rules input sequence words into these networks generalize input has been ways common language
structure human yet highly constrained through combination connectionist modeling analysis develop computational basis nature present connectionist architecture performs multiple sequences introduce novel additional clustering clustering provides interesting alternative both iterative processes such our resulting model efficient because processes parallel using forward
order single layer network easily learns deterministic finite state machine version neural net state machine connected through common error term analog memory combination neural net neural net finite state machine given able top through gradient descent learning rule derived common error function hybrid network learns use actions memory learn simple
present application back propagation networks recognition minimal data required but architecture network highly constrained designed task input network consists images method has error rate about rate provided us
propose new way construct large scale neural network recognition neural network consists parts small scale networks trained small number network output small scale networks process these recognition rate total system those small scale networks our results indicate proposed method effective large scale network without loss recognition performance
order presence location domains sequences system based neural network hidden layer trained back propagation designed efficiently identify such domains few regions low research new sequence database evaluate performance obtained low rates rate
present two connectionist architectures rules uses backpropagation learning other competitive learning although they developed same rules two their learning
consider robot actions resulting states task construct internal model its environment model allow predict its actions what sequences actions take particular goal states have studied problem have designed algorithm explore structure finite state algorithm representation environment called update graph have developed connectionist implementation update graph using highly network architecture back propagation learning strategy random network algorithm simple problems network has additional stochastic suggests update graph representation do traditional
present general method neural network design based algorithm technique network learning rules networks architecture connectivity learning rule parameters networks various such learning speed generalization connectivity approach model independent describe system backpropagation learning rule experiments several small problems have been each case has produced networks perform significantly better than randomly generated networks its initial population computational our approach discussed
sparse distributed memory associative memory model based properties high dimensional binary address spaces algorithms search technique high dimensional spaces processes memory hybrid above two systems memory uses algorithm its locations correlations between data example presented data memory specific features data well memory information architecture designed ability system scale up real world problems
have developed dynamic information neural network learning systems new make use spatial size information applied these study back propagation learning simple have obtained new into dynamics learning process
goal work has been identify neuronal elements cortical most support learning nonlinear associative maps show particular network learning algorithm based locally receptive fields maps cortical hardware gives variety features cortical whose learning
paper present upper bounds learning rates hybrid models combination both self supervised learning using radial basis functions receptive field representations hidden units learning performance such networks nearest neighbor improved upon individual receptive field factor present results optimal values such factors present new algorithm receptive field method more hidden units regions input space function output better learning number patterns hidden units small
neurons sum up their inputs non linear way simulations suggest distributed non during learning small tree up right areas their input spaces report show abstract highly tree quadratic transfer function associated each self using single global reinforcement perform binary classification tasks procedure well solving difficult classification task well back propagation does faster furthermore does error gradient but uses statistical scheme moving models reinforcement signal
faster supervised learning dynamical nonlinear neural networks presented concept computation changes networks response due system parameters using solution single set constructed linear equations lower bound per learning iteration over conventional methods energy gradient number neurons network
new form deterministic machine learning procedure presented efficiently train network between input vectors according criterion new technique directly free energy these mean field represent probability criterion free energy being learning procedure although conventional deterministic learning higher order feature network new mean field mutual information objective function important higher order feature without direct
new learning algorithm learning choice internal recently introduced many algorithms reduce learning process minimizing cost function over weights our method internal representations determined algorithm search procedure space internal representations adaptation weights eg using learning rule
problem connectionist control network during learning present approach weights prediction distribution values mean standard these weight distributions weight updates function both mean standard each connection network function error signal stochastic rule weights information their their uncertainty prediction such information useful policy size complexity network new nodes example during problem solving present network two nodes node measured its shown number problems networks find minimal architectures reduce computational complexity increase efficiency representation learning interaction
work new method called self neural network algorithm its performance back propagation signal separation application problem two signals data signal speech signal through channel signals using supervised learning made them algorithm its network during training shown much than network faster trained free network design
simple method training dynamical behavior neural network derived training problem discrete time networks arbitrary feedback algorithm back propagation error function using gradient based method but optimization out hidden part state space either instead addition weight space computational results presented simple dynamical training problems requires response signal time steps
selective sampling form search increase ability connectionist network generalize based information previous samples network may trained data regions domain unknown cases distribution known cost points target distribution compared cost them classification approach its problem training network power system analysis selective sampling studied analytically results experimentally
class unsupervised algorithms competitive algorithms traditional view given case propose view competitive adaptation fit simple probability such set data points maximum likelihood fit model type suggests form relative probability input each investigate application soft competitive model radial basis function function interpolation show soft model give better performance additional computational cost
method analog vectors continuous feedback model proposed analog vectors mean vectors whose components real vectors set network network model consists layer neurons layer hidden neurons propose learning algorithm results well their stability simulation results method
have used information derive class practical optimal schemes size neural network weights network several expected better generalization training examples required improved speed learning classification basic idea use second information make between network complexity training set error experiments methods real world application
have both analytically simulations rate convergence long times backpropagation learning networks without hidden units our basic finding units using standard transfer function convergence error large most networks hidden units other transfer functions may lead polynomial rate convergence our presented here focus more our empirical measurements convergence rate numerical simulations our results
development image segmentation system real time image processing applications apply classical decision analysis segmentation classification task use supervised training derive classifier our system set examples particular classification problem study test connectionist method against two statistical methods gaussian maximum likelihood classifier first second degree polynomial classifiers solution real world image segmentation problem taken research classifiers derived using three methods performance classifiers training data set well test images measured
multi layer trained classification trees two different techniques have recently given data time both methods capable arbitrary non linear classification first consider important between multi layer classification trees theoretical basis technique over other performed number empirical three real world problems power system power system prediction speaker independent cases even linear trees multi layer perceptron performed well better than trained classification trees performance
have empirical study number parameters weights feedforward net generalization performance two experiments reported use simulated data sets well parameters such signal noise ratio continuous data second train network vector real speech samples each case use back propagation train feedforward net multiple class pattern classification problem report results these studies show application cross validation techniques overfitting
learning dynamics back propagation algorithm complexity constraints standard least mean cost function shown loss generalization performance due using such complexity constraints furthermore energy hidden representations weight distributions observed compared during learning made results terms linear non linear effects gradient descent learning algorithm
properties cluster multiple back propagation networks compared performance single network underlying idea effect within cluster performance networks trained perform same input output mapping following training cluster computing average outputs generated individual networks output cluster used desired output during training back individual networks comparison single network cluster multiple generalization significant cluster advantage simple single cluster time but cannot them time
recent many have use markov random fields computer vision they applied example sparse noisy depth data output visual process early vision processes label paper show applying mean field theory those models class neural networks obtained those networks speed up solution models method computer vision
analysis finite precision computational neural network pattern classifier via probabilistic approach presented even negative results perceptron show following positive results given pattern vectors each represented distributed high probability perceptron perform possible binary patterns moreover resulting neural network requires small memory would required complete patterns further perceptron algorithm takes high probability other methods such linear programming takes case indicate connections vlsi circuit theory random matrices
within context learning perceptron algorithm shown learn arbitrary space time probability distribution examples taken over unit here accuracy parameter fast standard approaches solution linear programming problem constraints dimensions distribution independent learning proposed distribution function learned may chosen these may more real world learning than under perceptron algorithm shown distribution independent learning algorithm show distributions classes dimension including convex sets class convex sets
decision making tasks common yet difficult address supervised learning methods accurate model underlying dynamical system these tasks sequential decision problems solved dynamic programming paper reinforcement learning terms sequential decision framework shows learning algorithm similar implemented adaptive used sutton further developed sutton into framework adaptive neural networks significant functions required solving sequential decision problems
experimental evidence has shown analog neural networks particular their performance does significantly precision limited analog neurons limited precision compute weighted threshold functions into regions neural networks set threshold values although they binary neural networks weights made number without hardware time weights made while time constant multiple hardware small polynomial binary neurons used time increase larger constant multiple hardware increase larger polynomial symmetric function computed constant depth size function computed constant depth size neural networks neural networks related model analog neural networks limited precision
comparison algorithms minimize error functions train trajectories recurrent networks complexity off these algorithms related time independent suggested causal algorithms possible activation dynamics adaptive neurons fast compared behavior learned standard continuous time recurrent backpropagation used example
paper suggests statistical framework parameter estimation problem associated unsupervised learning neural network network performs feature dimensionality reduction
introduce cost function learning forward neural networks function internal representation addition weights learning problem two simple search internal representations back propagation limit frequency solutions better algorithm than back propagation weights hidden units same ie every learning step
mechanism eye movements images during motion system forward inputs outputs system visual feedback used directly computation system motor learning perform has proposed model gain using image information retina have designed tested analog vlsi version adaptive model
long term goal our development analog network based vlsi early vision algorithms demonstrate experimental circuit noisy sparse depth data using detection circuit computing zero using two different demonstrate our algorithms analog cmos vlsi these circuits small real time environment
distributed neuron synapses have been active area using single well cmos distributed neuron synapses call matrices between each these provide small area units network various possible network network two networks indicate number units per layer including input layer weights analog form synaptic weights resolution their full scale value due other parameters like gain shape
cmos containing cross array synapses have been fully parallel implementation neural networks synapses based hybrid digital analog design chip data weights two compute weighted outputs synapses exhibit resolution their transfer characteristics neuron hardware four has been investigate performance feedback networks optimization problem solving study net problem net have been implemented hardware networks ability obtain near solutions real time has been demonstrated
paper whether analog perform constrained optimization constrained optimization circuits designed using differential method these circuits time varying constraints example circuits include quadratic programming circuit constrained
paper present novel implementation used back propagation neural net learning algorithm connection machine general parallel computer implementation about per second main used nearest neighbor techniques developed here easily extended implement other algorithms neural nets other parallel have higher degree connections among their
mapping back propagation mean field theory learning algorithms computer described architecture these applications close find learning rates given array
short account given various neural network properties work early work statistical via parallel distributed processing memory learning pattern recognition described
describe computational model development specific eye brain circuits model self map network uses local rules constrained determined various simulations development eye brain maps described particular simulations experiments
feature selective cells visual cortex several hierarchical maps stimulus features like position visual space orientation order describe their spatial structure their development investigate self neural network model based feature map algorithm model map dimension mapping high dimensional feature space two dimensional such similarity between features feature into spatial corresponding feature selective cells model able several spatial structure cortical maps visual cortex
development cortex according previously proposed formulation self neural networks three types visual two models model considered model considered addition model shows spatial patterns model patterns shows single behavior compare simulated results observed results spatial patterns models those
simple classical models well known models long range interactions pattern given generate many properties orientation visual cortex
biological complexity neuronal computation here demonstrate synapses cells may give two novel self response synaptic input first basis relationships between synaptic cell may small subset its input space second same mechanisms may produce clusters synapses across space type self may significant presence nonlinear
experiments computational modeling have shown modulation may associative memory function cortex have shown synaptic between cells within cortex while input connections tested computational model cortex selective applied during learning associative memory performance
have scheme reduce complexity dynamical systems class includes most neural models reduction based transformations variables high level original system techniques system system
main point paper stochastic neural networks have structure quite field theory neural network derived show such description
self recurrent feature networks studied dynamical systems theory parameter multiple limit networks perform principal component analysis
present new way derive dynamics formulation used obtain both standard novel neural net dynamics optimization problems demonstrate derive standard descent dynamics well introduce computational attention mechanism
network provides simple model associative memory neuronal structure model based highly artificial assumptions use two state neurons response neurons what neurons real biological neurons address question two steps first show simple model neuron capture relevant features neuron spiking ie wide range spiking distribution intervals second construct associative memory these neurons together solution large fully connected network shows solution neurons short than critical solutions different associative solutions
simple architecture algorithm analytically associative memory analog patterns continuous sequences same network described matrix network weights given patterns units capacity node network weights unit per two per component each sequence four per function special system approach states trajectories unsupervised supervised learning algorithms pattern classification such competitive learning easily implemented architecture into recurrent network higher order weights used model cortex rule hierarchical sensory motor control networks may constructed cortical these network network performance being application problem real time recognition
show analytically stability two dimensional neural networks depends local connection various network critical time delay continuous time networks present phase dynamics discrete time networks
de fully recurrent networks dynamic systems dynamics perform sequences generate trajectories several problems first convergence state space second learned fixed points trajectories stable finally might fixed points trajectories do patterns paper introduce new energy function presents solutions these problems present efficient gradient descent algorithm directly stability fixed points trajectories size shape corresponding results simulation small memory
development learning algorithms generally based upon minimization energy function compute gradient energy function respect various parameters neural architecture eg synaptic weights neural principle requires solving system nonlinear equations each parameter model computationally new neural learning time dependent nonlinear presented concept fast global computation networks response systems parameters time conditions functions discussed algorithm presented equations solved ie forward time along nonlinear dynamics neural networks makes real time applications hardware implementation temporal learning
activity large networks biological artificial neural units may useful mechanism coding information single perceptual object within data set consider dynamics large array simple under variety connection schemes particular interest robust phase results sparse scheme each randomly subset its
paper studies dynamical neural systems negative feedback nonlinear delay differential equations these systems stable fixed point stable limit certain parameters shown their frequency robust parameter noisy property makes these systems good both parametric noise sense state variable more time near fixed point than would noise case noise variable ie system has memory finally shown distribution rather than fixed delay fixed point solution
show simple system its critical point spatial characteristics signals such objects visual field temporal correlation functions individual suggest firing neurons should described unit length such models exhibit critical dynamics over range show these spike measure interaction using simulations small clusters cells correlations among spike obtained large cells predictions these dynamic correlations predict spatial suggest novel representation object temporal correlations may relevant recent experiments neural firing visual cortex
multi neural networks have recently been proposed nonlinear prediction system modeling although modeling time invariant nonlinear systems neural networks temporal has so far been applying them signals such speech paper present network architecture called hidden control neural network modeling signals generated nonlinear dynamical systems time approach taken here allow mapping implemented multi neural network change time function additional control input signal network trained using algorithm based back propagation segmentation algorithms estimating unknown control together networks parameters approach applied several tasks including modeling time varying nonlinear systems speaker independent recognition connected word accuracy
work describe new method time time artificial neural networks automatically input units weighted gaussian input over time allows learning rules derived same way used weights our results classification task compare well results obtained et al same task
present new neural network model processing temporal patterns model neural model general delay model arbitrary weight kernels show model model temporal learning rule derived related existing models temporal processing
goal has been construct supervised artificial neural network learns unknown mapping result network combination backpropagation proposed called network network used focus supervised backpropagation network network has advantage being able response input patterns containing new information simulation results show network classical maximum likelihood method estimation discrete dynamic nonlinear transfer function
study representation patterns temporal neural networks distribution signal certain class such systems simple understanding temporal computation possible novel functional allows study asymptotic network behavior through statistical analysis present both retrieval quality capacity compare them simulation results
work computational learning theory over time eg system time varying have extended learning provide framework algorithm concept over time given framework memory based algorithms have derived sample complexity results determine example tracking have used similar framework tracking algorithms have derived bounds error rates specific concept classes
present large continuous speech recognition system based predictive neural networks system uses neural networks speech measures used stage algorithm perform continuous speech recognition system speech speech system word accuracy tasks several simple hmms tested found accuracy speed improved use hidden control inputs predictive approach
neural network architecture designed word words sequences architecture tested three sets studies first highly generated network trained limited number words network performance transfer set low error rate second study network trained identify words speech transfer test error rate correct words word study used output classifier input word word network error rate transfer test set task these studies provide first step words connected neural network
previous work has shown ability estimate probabilities hidden markov models hmms advantages speech recognition system both hmms best discrimination ability multiple sources evidence features temporal context without assumptions distributions statistical paper presents results speaker dependent language database results support previously reported probability estimation continuous speech recognition additional approach use nonlinear hmms while shown more hmm still several approach generalized take account time correlation between observations without assumptions about noise
through use neural network classifiers feature selection have achieved high accuracy speaker independent recognition category segmentation performed location allows us measure features specific locations signal such important information classification performed forward neural network recognition accuracy test set neural network classifiers used tracking category segmentation our research has been extended recognition between database achieved first choice retrieval work has continuous classifier does classification
neural prediction model speech recognition model based pattern prediction its speaker independent recognition experiments paper presents improvement model its application large speech recognition based units improvement involves
research particular form neural network described has patterns class labels speaker parameters method training network speaker parameters particular speaker based supervised network unsupervised describe experiments using approach word recognition based whole word hidden markov models results indicate improvement over speaker independent performance data performance close achieved data
novel unsupervised neural network dimensionality reduction presented its connection methods discussed leads new statistical synaptic equations learning neurons dimensionality reduction principle based features demonstrated using recognition experiment compared feature using back propagation network
paper describe several our work based approach our framework report our study use multi layer detection classification outputs network compare network performance other classifiers our performed within set experiments independent speaker database our system accuracy
language natural efficient means among role our important address human machine through language paper describe our recent moving speech recognition into language understanding report development system called application have used basis research language understanding
paper results focus use computing techniques various problems speech recognition first results use feedforward nets units classification word recognition speaker adaptation
have been performance matching sample task gain into processes mechanisms uses during natural signals paper describes novel neural network architecture called network have developed account performance network information multiple about accuracy contrast standard backpropagation network performed about accuracy
signal processing biological neurons signals neurons increase capacity signal suggested threshold neurons high threshold low threshold firing signal firing signal network neurons line signal processing input signal mapping firing intervals output network thus specific firing intervals network provides filtering timing original signal
using unsupervised learning procedure network trained ensemble images same two dimensional object different each network object produce output set parameters have high mutual information parameters output other network given ensemble training patterns parameters two network position orientation size whole object them after training network other using fact predictions made its two two networks trained mixture images two objects they cluster training cases basis objects position orientation size
model based neural vision system presented here position three dimensional objects two images scene described terms shape line derived scenes their structure recurrent neural matching network problem corresponding line right left images scene description generated second neural network against models model quality solutions convergence speed both improved using mean field approximations
second order architecture presented here scale invariant processing images input units new architecture has complexity weights weights usually required order invariant architecture reduction complexity due use discrete frequency information simulations show other neural network architectures
previous work feedforward network area like input layer units rule develop area like second layer units solve problem pattern motion present study work more complex et al neurons large receptive fields visual area sensitive different receptive field location movement network like second layer trained tested patterns layer units learn specific position independent position dependent direction within their receptive fields
paper presents neural network approach problem problem finding correct between possible non iterative many mapping two layer forward architecture developed learn code nonlinear complex mapping using back propagation learning rule training set important technique constraints such explicitly constraints learned more more accurate than existing methods approach successfully tested several shown net generalize its learned mapping cases its training set advantages over algorithm discussed shown performance superior
neural network model motion segmentation visual cortex described model motion signals motion contrast filter filter long range motion mechanisms motion competitive control such motion motion capture motion total model system motion system computed parallel both systems generate representation three dimensional visual form present use motion segmentation problems local movements problem complex moving shape into global motion signal
exact structure motion computation therefore sensitive noise work describe shape representation based gaussian computed directly motion without computation exact depth map show sense three points motion two three four rate significantly above simple rbf net has been trained perform same task
problem sampling natural images using array linear filters optimization information capacity constrained noise levels individual channels long range array low signal noise optimal filter characteristics bound states equation signal role potential resulting optimal filters similar those observed visual cortex cells lower observed scale natural images role
visual system limited noise processing between cells brain fact may close optimal here design optimal signal estimates time varying retina based signals show first stage optimal signal processing involves cell output through linear filter characteristics determined signal noise filter general fact first stage visual signal processing task low output first stage filter response cell first stage signal processing recent data relevant make parameter free predictions cell response experiment far first predictive theory neural dynamics
retina response off cells reduced movement receptive field through computer simulation model takes into account their properties show interactions between four neuron types two two may change sensitive model shows four neuron circuit account previously observed movement sensitive cell allows prediction temporal pattern activity change sensitive cells
adaptation allows vision functional between time even time their response limited log units mechanism underlying found along domain neural network feedback cells level equivalent circuit three different channels feedback used model behavior simulation interactions between feedback sensitive curves along domain provided mechanism during response
have designed tested dimensional analog cmos vlsi chip real time chip natural filtering properties networks implement scheme similar difference proposed our chip zero associated difference two exponential functions across zero above threshold reported simulations indicate technique extend well two dimensions
visual motion detection model retina computational architecture used early have designed chip correlation model report dimensional field motion scene real time using analog vlsi techniques have successfully tested chip using standard process
present neural network architecture capable non linear network dynamic parallel linear maps non linear using recurrent form back propagation algorithm control achieved control task parameters mean quadratic cost function computed across trajectory along performance constraint approach demonstrated control task difficult conditions show network yields performance while within response constraints
describe real time robot system based three vlsi neural network these grid path planning nearest classifier using range data sensory motor associative network dynamic
neural network problem training artificial neural networks real time perform difficult tasks back propagation network uses inputs video paper describes training techniques allow learn under control human response new using these techniques has been trained variety including single off up per
propose new parallel hierarchical neural network model motor learning control both trajectory control method our previous neural network control model using feedback error learning scheme furthermore two hierarchical control apply model derived using matrix related minimum change trajectory other related minimum motor change trajectory human dynamics level joint generated therefore inverse model problem combination these control feedback error learning problem finally efficiency parallel hierarchical neural network model shown learning experiments using artificial computer simulations
have used neural network compute images effects iterative methods effective but require computation time have instead trained neural network perform equivalent resulting significant speed up have hardware using both analog digital networks both small error compared iterative results neural network generalized solution problem include patterns its training set have experimentally approach system
present new connectionist planning method interaction unknown environment world model constructed using gradient descent optimal actions respect future reinforcement planning applied two steps network gradient descent chain world models so optimal reinforcement may obtained method demonstrated application task
sutton introduced grid task example temporal difference planning dynamical programming paper effects coding input stimulus self supervised learning particular form hidden unit representation performance
results class architectures systems based dynamic programming methods architectures error reinforcement learning time planning into single process world learned forward model world describe show results two architectures using task results shown simple system simultaneously learns error learns world model optimal using world model show architectures based learning use
present algorithm based reinforcement state learning techniques solve control problems particular have simple learning scheme called learning weights associative search either such system desired possible trajectory improve learning rate variable reinforcement scheme negative reinforcement values whether normal furthermore simulated scheme learning system same state negative reinforcement value examples studied these learning schemes have demonstrated high learning rates therefore may prove useful learning
paper class neuron based learning systems dynamic control adaptive range coding inputs provide binary range vectors describe system state these vectors input neuron like processing elements output generated these neurons system state new inputs reinforcement signals environment various intervals neural weights well range output goal future reinforcement environment experiments show neural receptive fields learning dynamical control observed performance method approaches adaptive range coding
feedforward network mapping required control unknown stochastic nonlinear dynamical system training based novel approach stochastic approximation backpropagation method applied control into system time varying environment
work three problems reinforcement learning adaptive control non between environment line learning based system adaptive algorithm described based system two fully recurrent networks may learn parallel problems parallel learning adaptive described systems combined vector adaptive previous have been
response circuit underlying initial response consists three cells distributed representations its have several neuronal properties system using neural network models backpropagation learning algorithm constrained known characteristics order test model have compared models responses various responses similar
neural network simulations system have been developed uses complex simulation networks account spatial distribution cells well range stochastic firing each neuron addition motor neuron firing patterns sequences simulation training against both motor neuron firing patterns trained networks firing patterns these motor neuron firing patterns during such networks provide both analysis first use
three dimensional structures have been predicted using neural networks forward neural network trained class but using backpropagation learning network generated structure information form binary distance constraints binary distance between two distance between them less than certain threshold distance distance constraints predicted trained neural network generate using descent minimization approach
computer describe application hybrid machine learning algorithm task important sequences system inference rules provide correct method class sequences known map domain theory into neural network provide training examples using samples neural networks learning algorithm domain theory so these sequences our procedure general method knowledge into artificial neural networks present experiment value so
complex real time control systems task has solution traditional methods have neural networks successfully systems paper means use develop appropriate training order network architectures provide estimates classification accuracy these networks new samples recent work applying neural nets adaptive control active system presented
study has demonstrated artificial neural networks used sources using high frequency data have taken novel approach using research source information depth focus characteristics rather than feature classifier between have found have potential applications feature classifier future studies these techniques should applied data new results study should part system
artificial neural network trained pattern particular future backpropagation errors algorithm used relationship between desired output variables variables into data future would have made less than trained able predict
neural network algorithms have useful recognition individual their recognition accuracy has been limited accuracy underlying segmentation algorithm conventional rule based segmentation algorithms noisy problem these often cannot yet cannot present here neural network algorithm simultaneously system algorithm has several novel features uses supervised learning algorithm backpropagation but able take position independent information self units competitive information demonstrate ability hand
dimensionality set face images subjects reduced via network features do features used previous face recognition systems such between elements rather they whole face features call given layer back propagation networks trained input features state automatically provide sufficient basis several among training set network human compared found networks more than do
has biological good making but machines have ability neural network trained human performed well set images using fully connected back propagation network hidden units input back propagation trained produce values networks average error rate compared errors those
paper neural system following two functions generalization information derived training data knowledge form neural network rules relative each part trained neural network paper gives method automatically rules trained neural network prove proposed neural system neural system has been developed
analog neural networks feedback used implement take networks networks used class nonlinear error codes such networks construct capable more codes consider several networks analyze their performance terms coding theory consider such networks vlsi
et al connectionist theory well based assumption well measured negative energy corresponding connectionist state lower level connectionist network few general connectionist but construct higher level network equivalent function most relevant global lower level network paper extend product representation fully representations objects like lower level network show example power new technique parallel distributed structure processing
network trained back propagation map form representation networks performance over several simulations training sets both expression network trained language generate representation representation presented network trained other language generate appropriate
previous paper clustering connectionist model produced parallel processing account certain paper show addition second power model present examples non language require rule least depth four structure models input able these examples two steps
higher order recurrent neural network architecture learns generate after being trained these networks dynamical systems yields two interesting first learning process new form inference phase transition small weight limit behavior network phase transition networks capacity arbitrary length second study resulting previously while architecture find minimal finite consistent given problem architecture does capable generating dynamics paper hypothesis capacity non linear dynamical systems
competitive learning unsupervised algorithm input patterns into clusters neural net framework each cluster represented processing unit input pattern present simple extension algorithm allows construct discrete distributed representations discrete representations useful because they relatively analyze their information measured distributed representations useful because they explicitly similarity basic idea apply competitive learning input pattern after each stage input pattern component representation stage component weight vector unit competitive procedure competitive different different input algorithm same traditional data technique known vector although neural net suggests approach
alternative models search decision processes have provided human memory using two more cues evidence against search process present alternative process search based sets two more cues two methods computing presented using information about possible other target memory matrix analysis using vectors represent cues both processes simulations using sparse distributed representations demonstrate performance process tasks cues
connectionist model human category learning human learning data its architecture based theory related networks using radial basis functions combination based representation learning constraints into back propagation networks appropriate human learning
network based described automatically number units unit parameters architecture network each application
multi layer often learn nonlinear functions complex local structure due global nature their function approximations shown standard multi layer special case more general network formulation into node allows novel network architectures developed generalization scaling properties global multi layer feedforward networks computational efficiency learning speed local computational simulation results presented well known problem show net approach
local variable selection has technique functions high dimensional spaces used several statistical methods including see these algorithms paper present tree network generalization these techniques network provides framework understanding behavior such algorithms them particular applications
ability radial basis functions generalize compare performance several types use inverse dynamics two joint test case find without choice norm inputs have generalization properties simple global scaling input variables performance suggest efficient methods approximate distance metric
have radial basis function network new computational unit pattern presented network network learns new units parameters existing units network performs presented pattern new unit response presented pattern network performs well presented pattern network parameters using standard gradient descent time series our network learns much faster than do those using back propagation uses number synapses
develop sequential adaptation algorithm radial basis function rbf neural networks gaussian nodes based method method makes use each observation efficiently network mapping function so obtained consistent information optimal least norm sense rbf network adaptation algorithm used time series compare its performance adaptation scheme based method stochastic approximation show algorithm underlying model much faster
introduce non radial basis function networks generalization radial basis function networks distance metric gaussian more general polynomial more general regions case estimation scheme requires number hidden units dimensionality associated kernel type case image hidden units features image parameters associated each unit scaling properties particular feature context scheme means image represented small number features transformation image scaling transformations individual features scheme used advantage image recognition analysis
consider forward neural networks non linear hidden layer linear output units transfer function hidden layer either case show hand theory equation other relevant understanding properties corresponding networks particular these techniques simple properties ie fact function degree precision linear combination functions addition framework problem learning equivalent problem time process results obtained case applied case transfer functions hidden layer similar results related problem generalization
paper show discrete provide analysis standard feedforward neural networks shown constructed based upon spectral property weights feedforward network training network constructed using procedure described here involves minimization convex cost functional therefore standard backpropagation algorithms extension these methods discussed
learning input output mapping set examples point view form learning related theory have previously shown between regularization class three layer networks call regularization networks note extend theory ways two learning learning presence examples learning positive negative examples
describe multi network connectionist architecture fact many tasks have structure level local global function approximation schemes main architecture associative competitive learning order learn task task decomposition networks architecture learn training patterns result different networks learn different training patterns thus learn input space performance architecture what vision task multi task presented
compare performance architecture networks suggested performance single back propagation network complex but low dimensional recognition task simulations system capable interesting complex task type decomposition nature input network use each case architecture better generalization many task
introduce framework training architectures several framework uses statistical formulation learning systems provides many classical connectionist algorithms well complex systems several algorithms allows design hybrid systems advantages connectionist algorithms well other learning algorithms
describe recurrent connectionist network called uses set given new extension traditional technique transition probability next note function previous context use representation
algorithms used features patterns machine vision speech pattern classification tasks complex speech recognition task algorithms required more computation time than traditional approaches feature selection but reduced number input features required factor features difficult artificial machine vision task algorithms able new features polynomial functions original features reduced classification error rates almost neural net nearest neighbor classifiers provide such low error rates using original features algorithms used reduce number patterns classifier training pattern recognition problem classes algorithms reduced number without significantly classification error rate applications algorithms apply found good solutions many than would required search times long but these results suggest algorithms practical pattern classification problems faster parallel developed
learning increase rate population biological effect our simulations show population artificial neural networks solving pattern recognition problem learning much learning leads amount optimal moreover given total number training different within each different rather than equal because algorithms local energy functions our hybrid learning systems applied successfully complex pattern recognition problems
given training data should particular network classifier family networks different paper discuss application stochastic complexity theory classifier design problems provide into problem particular introduce models complexity models under among other factors class entropy amount training data our prior belief particular discuss these results respect neural architectures demonstrate approach real data task
introduce method efficient design machine net arbitrary given function method based efficient simulation circuits threshold machines show various functions relevant classification problems computed machines converge their global maximum high probability after many steps
present compare learning rate stochastic gradient descent general algorithm includes line backpropagation means clustering special cases introduce search type classical constant average both speed convergence quality solution
paper prove vectors learning algorithm converge do showing learning algorithm performs stochastic approximation convergence obtained appropriate conditions learning rate underlying statistics classification problem present learning algorithm results convergence error bayesian optimal error appropriate parameters large
paper effect initial weight selection forward networks simple functions back propagation technique first demonstrate through use monte carlo techniques initial condition vector weight space significant parameter convergence time order further result additional deterministic experiments performed results these experiments demonstrate back propagation initial weight
information idea minimum description length term back propagation cost function network complexity give procedure called weight describe its dynamics parameters bayesian complexity term assumption about prior distribution weights use procedure predict time series noisy series rates
simple linear case analysis training generalization validation performance networks trained gradient descent least mean cost function provided function learning parameters statistics training data analysis generalization error dynamics dependent initial weights particular generalization error might within range during extended training cases analysis provides bounds optimal number training minimal validation error speech task predicted effects tested observed computer simulations networks trained linear non linear back propagation algorithm
study generalization ability simple linear perceptron inputs learns perceptron system trained binary example inputs generalization ability measured possible binary input patterns dynamics may solved analytically phase transition generalization point generalization ability approaches its asymptotic value critical down near transition time right critical point approach generalization power presence noise generalization ability amount above
while network problem layer threshold nets learning examples backpropagation has now hidden unit problem nets up four hidden units polynomial time empirical show method learn far more functions such randomly generated networks hidden units algorithm easily function using single layer hidden units requires time learn accuracy
series experiments measure average neural networks trained variety simple functions these experiments designed test whether average generalization performance case bounds obtained learning theory using et al find cases average generalization significantly better than bound approach performance exponential number examples rather than result bound other cases do find behavior bound these cases numerical related bound
learning time simple neural network model obtained through computation matrix describes second order properties cost function space coefficients form distribution suggests new techniques learning process provides theoretical choice state variables
computer present framework number different ways generalize during learning sources random information network training data random information complexity function computed therefore generalization analyze networks number networks trained same data their results almost results expected complexity network therefore expected generalization simulations effect presented considered consider unit backpropagation network trained without hidden units problem point learning would resulting mean weights zero output error but point discrimination error point two errors shown figure networks small random weights noise during training but has been consider classifier constructed training data has construct classifier they training data thus classification abstract its complexity cannot training data complexity fixed but case backpropagation network because
patterns dimensional feature space according probability distribution criterion show probability random input pattern nearest neighbor classifier using random patterns large values here probability error sample limit most error bayes classifier although value depends upon underlying probability distributions distribution free thus obtain between classifiers ability generalize finite sample dimensionality feature space well validation well known dimensionality
consider different types single hidden layer feedforward nets without direct input output connections using either threshold activation functions main results show direct connections threshold nets recognition but interpolation power while using rather than allows least both various results given dimension other measures recognition
develop new feedforward neural network representation functions into based level sets function show upper bound nodes represent within error st constant show number represent weights network order achieve approximation given bound entropy functional class under
introduce approach power threshold circuits variable functions vectors linear linear programming derive new results functions using threshold using approach obtain upper bounds number networks number functions depth threshold circuit lower bound number input required threshold function necessary condition arbitrary set input implement threshold lower bound error introduced functions using sparse limit known lower bound technique based computing correlations among depth threshold circuits every function input variables threshold function many input functions significantly correlated these lead key threshold circuit complexity those based so called spectral analysis approach moreover our approach yields simple based linear many these results
paper after into classification problem considered various research three chosen algorithms classification regression tree more recent tree technique known multi layer perceptron proposed compare these algorithms under two classification found general has better classification compared other two algorithms
different pattern classifiers implemented computer compared using artificial speech recognition tasks two neural network radial basis function high order polynomial network conventional classifiers gaussian mixture linear tree nearest neighbor tree nearest neighbor classifiers chosen different approaches pattern classification extend those previous study previous study both demonstrate classification error rates equivalent across different classifiers they form minimum error decision regions they sufficient training data available practical characteristics such training time classification time memory these results suggest selection classifier particular task should so much small error rate but practical memory computational implementation training classification times
performance minimization algorithms compared neural network problems these include variable step size algorithm gradient several methods numerical approximations
problem clustering defined shown problem large number vectors small number clusters finding those clusters such way they best represent full image using computational problem paper problem solved using classical techniques means clustering vector out same application competitive learning self feature maps quality result much result true image error time map provides best solution
feedback connections required so signal output neurons weights during supervised learning methods learning patterns full time feedback connections feedback network learning techniques have achieved wide because still computational efficiency back propagation show simulation networks vlsi capable learning large problems like back propagation networks deterministic mean field theory learning well stochastic learning multiple chip system these networks make high speed parallel learning them future
high speed implementation neural network designed using cmos used implement two general associative memory each up independent networks total weights each network have inputs outputs response times networks well making networks fast most robot control problems many pattern recognition signal processing problems
adaptive solutions architecture chip general chip has each local memory capable most current neural network algorithms chip learning paper implementation back propagation algorithm array these shows performance accurate hardware chip update connections per second learning process connections per second forward
describe cmos neural net chip network architecture binary connections neurons several connected form long neurons up binary connections form neurons analog connections multi layer networks implemented chip have chip into system together digital signal fast memory system use image processing applications chip features such binary level images
neural network pattern recognition feature analog parallel processing architecture developed well computational weight networks such implementation using architecture simulated training procedure network performance under limited precision would architecture presented
parallel digital stochastic architecture described performs competitive types learning vlsi design shown neuron within small yet used larger networks several neurons neuron speed allows network process training examples per second use level sensitive provides chip neural systems
during brain set changes state level neurons process has been equations cell neural network models based upon knowledge specific population their differential responses have yet been developed furthermore most have been made model across states our link eye movement using neural network approaches paper
based general non point process model computed estimates synaptic function time after stimulus between its target cell data spike pairs neurons our results suggest synaptic non further synaptic shown related average spike rate second order analysis suggests result due non linear interactions synaptic less correlated rate correlation consistent across neural pairs
recently have rules synaptic development visual system has studied such rules case two two analysis has so far each two has same structure constraint effects small correlations within between study stability solutions predict changes including rather than units
develop model independent method neural responses stimuli approach allows us measure similar stimuli based real time response single neuron data obtained neuron visual system furthermore made cells signal noise visual system form input visual system their signals visual discrimination task case movement detection limit computed compared neurons under conditions performance neuron approaches theoretical limit means under these conditions system noise process computing movement correlations signals array
single neurons multi networks recent modeling study has shown dependent present complex tree provide layer local nonlinear processing elements between synaptic inputs output cell hidden layer multi layer network paper abstract model neuron introduced called cluster these modeling studies shown using type learning rule used higher order statistics set training patterns spatial synaptic connections tree potential relevance these higher order statistics nonlinear pattern discrimination studied within full model cell using training set high dimensional sparse random patterns
single cells properties have been networks show contrast approach study here network activity control single cell parameters such input well time space parameters using computer simulations cells show firing network provides means setting these parameters mechanism control through large change both non synapses activity
trees cortical neurons perform local processing inputs explore complexity computational power neurons simulated model cell high density dependent channels channels present point relationship between synaptic input probability neuronal effect could analog stochastic
channels dynamical systems system their distribution within information between neurons but information within cell here presented rule distribution dependent channels order simulations show rule account self dynamical receptive field properties such direction conditions within cell signals cell has been various possible such learning rule proposed including activity dependent channel
consider noisy single neuron model modulation modulation correlated between states noise information through system modulation output leads strong power signal noise ratio obtained power measure information neuron response noise through maximum effect has been called stochastic problem within framework recently developed approximate theory noise low frequency comparison results theory those linear system presented
during visual development cells produce mapping normal development depends upon activity key role activity dependent synaptic plasticity recent experiments retina show during early development activity across et al provide first simulations demonstrate such synaptic early arrival account observed patterns normal experimentally
test whether known neurons sufficient account connectionist neural network simulation using cells connected according experimentally patterns demonstrated network stable manner same phase relationships among neurons observed model used explore between neurons have role between produce phase observed among during
patterns recurrent neural networks called pattern although its phase well state system using sensory inputs paper propose learning algorithm neural specific phase relationships sensory input connections correlation between input signals simulations show learning rule used setting sensory feedback connections well connections between sensory mechanisms control patterns such generated recurrent neural networks these networks produce basic without sensory inputs called pattern systems such combined have their characteristics therefore order efficient frequency phase well state system example patterns its state other pattern inputs has been shown et al et al stimuli sensory neurons over wide range frequency both negative positive feedback found those systems function sensory inputs requires computational studies neural dynamical systems algorithms learning patterns recurrent neural networks have been derived paper propose learning algorithm neural input signals specific phase relationship well known between nonlinear their relative phase between determined parameters difference their example either phase phase results symmetric between neural similar efficient involves phase relationships between variables motor our goal derive learning algorithm sensory input connections relative phase between neural specific value required task learning following continuous time model network represent states outputs neurons sensory inputs assume connection weights so network without sensory inputs goal learning find input connection weights make network state input signal specific relative phase objective function phase standard way derive learning algorithm find out objective function approximate linear relationship phase example have matrix even objective function adaptive neural specific relative phase between thus call phase matrix learning procedure using above objective function derive learning procedure first appropriate phase matrix while relative phase between changes time feedback mechanism applied so network state close target have appropriate phase relationship between phase matrix obtained gradient descent et respect between their relative phase changes time their equal systems learning performance total system example speed possible obtain matrix task phase matrix derived control close using gradient et respect network state feedback algorithm term dynamics feedback gain set small so feedback term does case small additional term have equivalent equation input weights tested above learning scheme task find weights between neural so they specific time delay used following model two goal learning time delay used performance learning equation its average using following equations figure learning neural curves represent adaptive neural first two trained using continuous time back propagation learning each two neurons time output functions instead following two step procedure described previous section network dynamics learning equations simulated parameters figure shows two without through show phase after learning time units different desired delay times zero next applied learning rule system involves critical phase between state system motor zero system shown figure system weight back fixed its weight order given direction weight specific phase motion equations shown first network trained network output two hidden units time output functions next output used weight position weight used sensory feedback inputs after scaling order effect used following learning equations speed performance after following equation learning equations time each training random after figure learning zero adaptive neural figure example motion without sensory feedback system each other left right figure shows example motion after training parameters first down sensory inputs right direction compared patterns sensory input connections made after learning different table shows connection weights output unit positive connection weight right hand negative connection fast weight up positive input larger makes weight both down table sensory input weights output unit architectures lower determined information way sensory inputs adaptive characteristics dimensions its parts back propagation through forward models systems applied learning sensory feedback learning nonlinear dynamics systems difficult task moreover multi layer back propagation appropriate biological model learning learning rule similar covariance learning rule biological model long term synapses those our work feedback motor control adaptive neural using continuous time back propagation learning neural networks neural network underlying synaptic mechanisms neuron learning control system forward modeling neural information processing systems two neural model theoretical learning state space trajectories recurrent neural networks neural computation covariance et al
dynamic behavior network model binary neurons global studied analytically prove random input signals output network consists random noisy activity our results suggest generated simple neuronal architecture signals process do role therefore considered
investigate model neurons have dynamical both property leads behavior ability model perform segmentation ie input into cell these after input off ie system model short term has limited capacity number
present multi state time delay neural network extension robust word recognition most other hybrid methods search procedure into connectionist architecture allows word level resulting system has ability sequential order units while performance paper present new approach over speaker dependent speaker independent connected
network proposed possible neural model network compared backpropagation network time series prediction problem system problem
recently much interest has been generated speech recognition systems based hidden markov models hmms neural network such systems best features both models temporal structure hmms power neural networks work define time neuron neuron back propagation network input pattern its weights show single layer network neurons equivalent gaussian recognition system propose power system using back propagation training structure multi net performance proposed network highly word multi speaker recognition task results indicate does recognition performance improve but separation between classes us set up criterion improve confidence system
estimation hidden markov model hmm local probabilities discussed particular note radial basis functions rbf networks mixture density between these methods different training present method connectionist training these discuss experiments finally discuss problems training
paper multi artificial neural networks probability density functions such gaussian mixtures found continuous density hidden markov models hmm first part paper present hybrid parameters system simultaneously respect single criterion second part paper study relationship between density inputs network density outputs networks few experiments presented explore perform density estimation
present speech speech system processing including connectionist learning traditional knowledge representation approaches dynamic programming stochastic techniques into speech speech present system along its processing components special connectionist now research et al
propose modeling speech based neural networks focus characteristics system using real data movements activity neural network learns forward dynamics motor behavior after learning simulated used properties model such natural frequency finally neural network used generate continuous motor sequence discrete
recognition system reported over between system uses neural networks used search database find best speaker independent classification rate system correct between time database
paper presents system generating connectionist networks example based systems language tasks networks exhibit three important application speech processing they learn generalize well compared they several types noise they learn use multi input presented architecture performance along several dimensions demonstrate features performance compared traditional based systems
paper problem connectionist networks based energy minimization given knowledge bound symmetric network constructed like machine network given query resolution based length than global energy function associated network represent such network generated size bound linear knowledge size type represented network
present parallel distributed network architecture problems resolution natural language understanding network their using multiple networks form net mechanism called propagation filters control between networks sequence components simulation results indicate networks propagation filters successfully represent high level knowledge trained relatively provide parallel knowledge level
have developed four language language system high quality speech system uses neural network based segmentation algorithm speech into features computed these input second network performs language classification system trained tested sets performs accuracy test set
present network architecture learning algorithm based dynamic programming allows single learning agent learn solve multiple decision tasks significant transfer learning across tasks consider class called tasks number architecture trained set temporal structure task unknown architecture learns produce temporal decomposition shown under certain conditions solution constructed computationally solutions its
paper whether temporal difference methods training connectionist networks such td algorithm successfully applied complex real world problems number important practical discussed general theoretical these practical context case study td applied learning self first application algorithm complex task found zero knowledge network able learn strong level performance better than conventional fact networks trained human data set hidden units these network have useful features goal computer research furthermore set hand features input representation resulting networks near level performance have achieved good results against world class human
system connectionist networks processing presented after being trained using error backpropagation system capable four part given part our system real world problem performance level appropriate practice power based new coding scheme relevant information backpropagation algorithms hierarchical system advantages both
network model temporal state dependent features described model data different states computer studies demonstrate states within same network under different relationships between state dependent modulation memory learning discussed
do neural net algorithm learn sequences do limit conventional gradient descent approximations instead use sequence learning algorithm do implement following method what train network predict its next input previous inputs new information inputs but inputs information about time step they inputs higher level network same self time scale such networks principle sequences without loss information thus supervised reinforcement learning tasks may use two recurrent networks multi level into single recurrent net experiments show systems based these require less computation per time step many training sequences than conventional training algorithms recurrent nets finally above method such defined but continuous
large classes time series such those nonlinear moving average components well feedforward networks linear models but recurrent networks show recurrent neural networks type nonlinear moving average model practical ability shown results sound power recurrent networks best performance
second order recurrent networks simple finite state over positive negative examples using complete gradient recurrent network sufficient training examples language solutions obtained arbitrary length method finite state corresponding network demonstrated
simple second order recurrent networks shown learn small known trained positive negative examples show similar methods appropriate learning unknown examples their training algorithm real time recurrent learning method complete gradient updates weights each after during training dynamic clustering algorithm rules neural network has learned methods rules unknown deterministic many cases neural net
present framework programming hidden unit representations simple recurrent networks based use units additional output layer present two ways network trained within framework input patterns information context units patterns activation over context units functions input sequences simulations demonstrate network learn represent three different functions simultaneously analysis used investigate functions represented space hidden unit
two well known learning algorithms recurrent neural networks back propagation al forward propagation main back propagation its off line path time error line many practical applications although forward propagation algorithm used line manner computation required update high dimensional matrix each time step therefore develop fast forward algorithm task paper proposed forward learning algorithm order faster each time step than matrix algorithm basic idea instead high dimensional dynamic equation solve forward time its function update weights error numerical example state trajectories using recurrent network presented faster speed proposed algorithm than algorithm
take networks used determine most highly units important part many neural network models convergence normal networks sensitive their weights hand generally provide right amount across relatively small range initial conditions paper presents take networks use unit provide competitive units network unit its level activation during provide right amount between single dynamic adaptation allows networks perform take function network size initial condition using connections addition unit find level necessary upon most units therefore take network
because eye do equation firing rate eye position linear manner using high rate circuits generate eye movements has signal processing including neural network these often they value behavior single neurons finding neural network models
have properties neurons temporal cortex pattern matching task simple backpropagation networks trained various stimulus conditions basis measured neuronal signal trained networks predict neuronal response spatial patterns stimuli results indicate neurons information about both current patterns well about their context neuronal signals visual pattern recognition
have previously described unsupervised learning procedure properties world information parameters different parts sensory input about common underlying given random procedure learns depth because property across space learns depth location locations paper propose two new models first model cases them second model mixture learns locations do cross
have constructed recurrent network images moving object retina simulated eye structure network visual target tracking system basic components complete target tracking system simulated including visual processing sensory motor motor control our model structure function performance than system but many complete system present recurrent eye tracking network using distributed representation image motion visual processing eye maps motor estimate motor figure structure visual tracking model target eye
networks sparse noisy function often use field function into regions approach these regions do have parts often example images regions object using type network have developed network these using support maps represent segmentation signal our approach support each region signal explicitly represented results initial implementation demonstrate method images motion sequences
network vision systems make information across levels low level through scene high level relevant object paper shows such networks markov random fields show first construct equivalent parameter network thus probabilistic basis visual networks second show these parameter networks more capable than traditional methods particular they have well defined probabilistic interpretation feedback representations decision
shown both changes position conditions prior recognition using images taken different different conditions shown computation requires least image input sufficient
neurons simple visual features area such orientation direction motion maps recent experiments have shown responses many neurons other cortical areas direction have developed neural network model visual cortex explore hypothesis visual features early visual processing new experiments suggested hypothesis using observations
visual attention ability processing subset visual field have long such mechanism necessary efficiently perform many level visual tasks paper describes novel neural network model visual attention current system models search target objects scenes containing multiple natural task studied requires attention networks behavior known data visual search visual attention much data attention provides novel view number visual areas paper biological model its relationship visual cortex superior posterior areas
exhibit way derive neural nets vision problems involves vision problem bayesian inference decision model visual domain given probabilistic
combined neural network rule based approach suggested general framework pattern recognition approach unsupervised supervised learning while probability estimates output classes probability maps higher level analysis such feedback over output label maps unknown patterns pattern suggested approach presented demonstrated analysis task correct classification rate achieved both natural advantages probabilistic approach pattern analysis demonstrated
visual object recognition involves images objects arbitrary suggest approach object recognition view represented points given their location image object set together between show novel view object linear combination linear between specific object other objects implemented using neural network architectures relatively simple structures
proposed feature method related recent statistical theory based model neuronal plasticity et al method has been recently applied feature context objects single here describe experiments designed analyze nature features their relevance theory object recognition
method risk minimization capacity classifier available amount training data capacity several factors including properties input space nature structure classifier learning algorithm actions based these three factors combined here control capacity linear classifiers improve generalization problem recognition risk minimization capacity empirical risk minimization common way training given classifier parameters classification function minimize error ie frequency errors set training examples estimates expected risk based empirical data provided available examples method thus called empirical risk minimization but classification function empirical risk does minimize generalization error ie expected value risk over full distribution possible inputs their corresponding outputs such generalization error cannot general computed but estimated test set other ways estimating include moving control method see capacity risk family classification functions its capacity dimension dimension such capacity defined maximum number training examples without error possible binary dimension cases given number free parameters classifier but most practical cases quite difficult determine analytically theory provides bounds set classification functions capacity probability number training examples simultaneously classification functions generalization error lower than risk defined small close fixed number training examples training error capacity while both risk generalization error through minimum minimum problem capacity small amount training data minimum problem key therefore capacity classifier amount training data order best generalization performance method risk minimization provides way goal risk minimization us family classifiers define structure elements family such structure capacity subset classifiers less than subset method finding subset classifier empirical risk within such subset yields best generalization performance two problems ii find good structure problem because have direct our experiments use minimum either show these two close good structure knowledge few provided theory solve problem ii find best between two terms et but increase good structure should such dimension possible increase training error now several ways such structure risk minimization recognition principal component analysis optimal brain weight consider three different methods generalization performance principal component analysis transformation input space optimal brain through weight regularization method weight learning algorithm case linear classifier these three approaches shown here control capacity learning system through same underlying mechanism reduction effective dimension weight space based properties mean error cost function used training linear classifier training consider binary linear classifier function takes two values class dimension such classifier equal dimension input space number weights empirical risk given example corresponding desired output problem minimizing function different ways but often problem minimizing mean error cost function nonlinear function has been properties cost function three structures investigate properties cost function consider parameters training leads optimal value parameter way capacity set zero linear classifier increase resulting setting order capacity should achieved possible increase weight space corresponding small good matrix second respect weights linear classifier matrix given correlation matrix training inputs matrix symmetric cross terms assume first component vector constant set so corresponding weight bias value about several weight space elements matrix after corresponding give principal takes increase due setting simple form quadratic approximation exact linear classifier corresponding small good principal component analysis common way capacity classifier reduce dimension input space reduce number necessary free parameters weights principal component analysis pca feature method based analysis input vectors dimension linear combination vectors normal basis coefficients linear combination form vector dimension optimal basis least sense given corresponding correlation matrix training inputs matrix structure obtained classifiers according dimension classifier reduced optimal brain linear classifier implemented two different but equivalent ways change input principal representation components corresponding small according pca train cost function ii change principal representation train first weights weight vector dimension procedure procedure ii involves structure classifier network architecture two weight ii based criterion procedure ii optimal brain weight procedure applied after training best those weights minimize increase defined equation weights do due factor equation either implementation dimension reduced weight capacity through additional term cost function simultaneously linear classifiers according norm weight vector structure constructed risk minimization recognition within subset those classifiers positive bounds form sequence sequence sequence positive such our training problem minimization within specific set implemented through minimization new cost function equivalent weight procedure term like energy weights zero small weights zero along principal matrix associated small principal representation minimum cost function simple function minimum limit weight factor weights effect compared weight weights such capacity introduce weight capacity expression various theoretical higher order units regularization several different structures further performance combination exponential transformation input space regularization learning algorithm shown here improve recognition generalization ability improved further
developed neural net architecture complex images ie two dimensional scene without prior knowledge objects scale into network varying algorithm has been applied video images find their over data images large conditions often quality part network containing analog neural net chip et al while implemented model digital signal
present forward network architecture multi extension previous work architecture single over input output layer network best interpretation input training errors through procedure segmentation feature maps developed space neural network rather than input space
present neural network algorithm simultaneously performs segmentation recognition input patterns self input pattern locations pattern demonstrate neural network architecture recognition using database report results resulting system simultaneously noisy images high accuracy
hand about control points each known control points have locations generated moving control points their locations images produced gaussian along real images finding model most have generated data each model use matching algorithm minimize energy function includes both energy model log probability model would generate image model total energy noise process model image noise model image models learn locations control points
method described generating like robot experiments reported here use simulated range set continuous functions perceptual input space these functions using trained adaptive algorithm its its responses sensory stimuli so negative reinforcement local therefore explicitly goal resulting trajectories form through environment
agent learns control unknown environment two have combined long term optimization short term optimization many real connectionist approaches learning control action selection might negative basic idea presented paper make agent explore unknown regions more manner achieved so called map trained predict accuracy used based system attention between two expected knowledge gain method demonstrated simple robot task
neural network solution proposed solving path planning problems proposed network two dimensional neurons distributed representation between neurons so network these used generate solutions dynamic programming equation context path planning simulation experiments these networks global optimal even presence levels circuit noise dynamic programming path planning consider robot moving about dimensional world location real vector locations set called point location robot may set points called free free robot through along path curve path free assume initial robot position desired position robot path planning problem find path such criterion path planning problem may more optimal control robot dynamic system state vector control vector levels control dynamics differential equation equation state applied control define what optimal performance functional introduced norm vector functional free functional used control does take robot into equation criterion control while do constraints optimal path planning problem states time find control performance functional method minimization problem use dynamic programming according dynamic programming optimal control obtained gradient optimal function other words optimal functional equation dynamic optimization problem given above equation easily shown first order nonlinear partial differential equation condition equation has been solved optimal path determined following gradient solutions equation generally obtained solution approach full equation time using condition point proposed numerical solution find trajectories nonlinear first order these characteristics locally ie about condition resulting numerical solutions therefore local sense fact errors introduced process result numerical solutions underlying principle equation solving path planning problems local solutions based numerical equation due local nature resulting solutions global solutions required these may obtained solving associated variational problem assume optimal function time known set variational solution equation states optimal time point set given neural fields optimal path planning norm vector equation easily generalized other vector regions ie free other words optimal neural fields proposed neural network consists neurons called neural field neurons pairs called neurons label associated neuron set neuron labels neurons whose labels called neuron neuron two states short term activity state representing neurons activity response applied stimulus long term activity state representing neurons average activity response recently applied stimuli each neuron output unit step function state ie neuron called active its output zero each neuron set these either applied inputs internal parameters they rate constant position vector position vector vector mapping neuron rate constant models states underlying dynamic time constant rate constant used whether neuron maps used networks search optimal path states state equations these equations change state equation over neurons within neuron function zero function used neurons activity level zero network parameters interactions between neurons state equation equation means state every time neurons output changes specific weights result specific network under field without loss between zero rate either zero path planning application rate used whether given neuron point free neuron called neuron neuron called free space neuron under these assumptions has been shown free space neuron active provided has least free space neuron neighbor path planning neural fields neural field introduced above used generate solutions iteration eq respect norm assume neuron states zero time assume position vectors form grid points constant size assume but zero other words specific neuron label zero assume structure neuron its nearest these assumptions has been shown state neuron time given length path respect norm fact quite states dynamics small about neuron first note state equation state every time neurons state its output neuron after has been state represent time neuron first time length path initial particular consider set neuron assume neuron has yet been neighbor has been state given value see neuron next have form iteration shown equation other words over free space neurons network solving equation respect norm use neural fields path planning first apply neuron mapping desired position allow field generate neuron mapping current position resulting state distribution neuron negative minimum distance respect norm neuron initial optimal path generated sequence gradient state distribution neural fields optimal path planning fig activity fig distribution several simulations neural path have been implemented most complex case studied these simulations array neurons several shape size randomly distributed over initial introduced desired location observed neuronal outputs shown figure figure shows neuronal activity initial neuron upper right hand figure activity without activity neuron mapping current position off distribution resulting particular simulation shown figure figure regions areas large state regions areas small state optimal path computed robot moving its goal current position neurons position vector robot generate control takes position associated neurons particular control chosen so robot neuron whose state set other words next position vector chosen such its state way because distribution property local control strategy generate optimal path respect norm robot its desired position should selection control analog neural network case states neurons set used inputs neural net competitive interactions network direction state neuronal dynamics analog nature important consider noise implementation analog systems generally exhibit noise levels effective dynamic being most noise network several ways state equation have noise term noise so distribution may optimal distribution our experiments noise noise may selection selection noise case next position position vector such array stochastic processes simulation results reported assume noise processes positive distributed processes
present two neural network controller schemes based learning architecture recognition control multiple objects first scheme network trained object specific representations recognition number objects sets objects second scheme estimation network trained function specific rather than object specific representations directly estimate parameters both recognition networks trained identify objects using visual information after learning appropriate motor each object control networks
approach uses neural networks knowledge form simple rules extend idea further algorithm equations controller determine initial weights network further trained using backpropagation apply method task significant accuracy over both standard neural network approach non learning controller furthermore using knowledge weights network less accuracy compared networks small random
method performance evaluation signals both space time into signals supervised learning algorithms presented simple observation through models trained inputs their networks original architecture suggests internal world model action space input forward model learning time example task reduced about times
large class motor control tasks requires each controller its current state action achieve state dependent goal paper optimization learning rate number experimental control performance obtained necessary computation per control memory observation robot requires two learning steps achieve performance robot while learning computational computer hardware assume within few so even processes control low have machine make their paper learning control scheme make effective use such computational power memory based learning memory based learning approach both classification function learning presented learning explicitly memory set input output pairs prediction required output novel input memory obtain inputs close these local used determine locally consistent output query three memory based techniques nearest kernel regression local weighted regression shown figure nearest kernel regression known local weighted general
backpropagation algorithm used both recognition time trajectories used has been shown performance network improved structure architecture same true trajectory particular new architecture corresponding proposed results show improvement performance hand combination suggested
introduce demonstrate method inverse function robot mapping using sample data unsupervised learning clustering techniques used image order learn space into over mapping supervised learning used each approximate inverse function inverse function global inverse solution developed
accurate require interaction between model interaction described based principle feedback error learning model part superior simple feedback controller knowledge initial eye position provides error signal correct eye gain internal feedback so size direction errors system learns make accurate eye movements position simulated eye target
based model presented simulated during goal network feedforward motor learned using training signals generated movements each target network sets output subset pattern during movement feedback off pattern task individual pattern target off distributed representation motor population vectors produced these simulations
using step target mechanisms underlying trajectory using short stimulus intervals resulting hand between first second target locations features scheme involves addition two independent point motion units moving hand location second moving between location target location similarity between locations previously reported measured points first step eye movement studies may suggest between target locations eye hand motor control
work various optimization techniques proposed models movements particular minimum change model dynamic including single joint generate hand movements hand trajectories produced algorithm discussed
current make use simple classification algorithms determine conditions due constraints power area available threshold implementation artificial neural networks potential classifiers higher performance than available paper explore several classifier architectures implementation
common yet its early have developed multi layer perceptron networks trained gradient optimization single images accuracy training data accuracy test data
attention tasks such control highly would against have taken first step goal using feedforward neural networks trained backpropagation related eeg associated high low accuracy our system data set over better than accuracy obtained using linear analysis practical require prediction over time able average over still correct prediction measure achieved good performance using eeg power short
bayesian framework give account prior knowledge such domain into networks locally units specific architecture applying specific training our method data problem large scale application neural control line application significantly higher accuracy than standard algorithms such backpropagation state solution
paper application neural networks observations because complexity application large amount data problem cannot solved using single method solution propose architectures several together such system problem propose solutions they allow accurate multi function approximations probability results compared other methods have been used problem show have developed general used large variety applications
present development complex binary error code via training examples words our connectionist architecture describe two solutions level solution networks solution mapping problem solved although both solutions our basic approach constraint our second basic constraint being solution
paper tree based neural network described inputs time series model rate time output corresponding found based model variables functional nonlinear significant results compared those obtained using kalman filter based online method other classification methods eg bayesian classification found based method other methods
experiments performed using several neural network architectures identify location time graphical results test results first experiment found correct target cases other experiments effect different architectures data results methods used most appropriate time graphical data has point such rather than continuous such
paper describes artificial neural network visual processing network capable image motion type stimulus most methods detection subset second order visual motion stimuli known processing network described paper into model capable motion detection
scheme uses neural network has been developed point point through networks neural network network type work problem through random memory distributed computing system performance neural network scheme compared two more traditional approaches search results suggest neural network may competitive certain
have new networks signals have been either time via filtering first show subset learning rules principle minimum output power apply principle network have feedback path our networks perform well real speech signals have been using time filtering
based call presented fully connected input output two layer network form networks used parallel additional input output nodes network weights accuracy chip digital neural network pattern recognition system using image feature described report output circuit process threshold chip area
based signal processing fully parallel single vector matrix has been designed process array analog matrix matrix elements input vectors digital accuracy
biological spatial temporal features reduce complexity visual tasks have tested retina several useful temporal features found cells our retina selective direction highly sensitive positive contrast changes level particular connections direction perform direction retina consists array
goal invariant properties underlying world computing contrast retina dynamic range problem relative us step goal have retina models synaptic interactions layer retina using current cmos circuits synapses between cells produce receptive field cell determine its size chip has well fully functional
described neural network chip digital signal analog neural network unit chip performs processing combination allows high speed signal processing applications including neural net steps neural networks times faster than large connections networks sparse weight matrices three applications have been implemented network detection text neural network recognition based segmentation
use constrained optimization parameters two circuits simple circuit analog vlsi artificial method uses computer test chip parameters minimize difference between circuits behavior goal behavior circuit parameters important circuit performance within certain range analog vlsi circuits complex more parameters setting these parameters hand more thus parameter setting method value parameter setting part goal based design circuits constructed parameters wide range desired automatically
novel segmentation algorithm has been developed instead more common quadratic functional constant constraint data energy problems local complex methods necessary find global minimum energy generalized power nonlinear network continuous time analog segmentation circuit constructed
present experimental data analog cmos chip adaptive neural network results time frequency domain described these include weight convergence trajectories signal noise separation complex signals such speech
many auditory consider temporal adaptation auditory key speech coding auditory experiments models auditory suggest temporal adaptation important practical auditory processing have designed successfully tested analog circuit models many auditory response including temporal adaptation
demonstrate self system based system two ways both feature set images system linear feature other signal both systems implement unsupervised competitive learning within interaction dynamics between set after training associated different image features within data
learning problem function estimation two solution considered empirical risk minimization risk minimization these two applied two different function estimation problem global local prediction power application code recognition
bayesian model comparison framework bayesian framework applied feedforward networks making possible objective between solutions using alternative network architectures objective choice type weight terms estimates error network parameters network output framework measure effective number parameters determined data relationship bayesian model comparison recent work prediction ability discussed bayesian inference task develop compare models account data typically two levels inference task data first level inference assume models true fit model data typically model includes free parameters model data involves what values those parameters should take given data each model second level inference task model comparison here current address compare models data example consider task noisy data set data set could using model feedforward neural networks first level inference find each individual model best fit process known learning second level inference alternative models state our particular data set example best interpolation model polynomial should best neural network data set has hidden units model comparison difficult task because possible model data best more complex models fit data better so maximum likelihood model choice leads us models principle states complex models should bayesian methods automatically without
paper investigate average case model concept learning give results statistical dimension learning curve behavior common framework
complexity learning dimensional neural networks has been shown linear size network network has number units cortex has even linear time might furthermore algorithm given achieve time based single work consider more natural parallel model processing demonstrate expected time complexity constant ie independent size network even node channels short local thus more biological vlsi constraints
report learning measurements system learning chip data training pattern based neuron learning chip has adaptive synapses perform mean field learning using noise gain have used system do learning experiments problem system set time learning speed about patterns per second independent system size
paper theory correct learning multiple output feedforward threshold networks weights certain shown sample size learning above similar required single output networks best previously obtained bounds improved cases
gradient descent minimum quadratic form time constant better than minimum maximum matrix respect recently shown term although case here show lower further gradient descent dynamic system explore error showing error variety effects observed simulations
many machine learning applications has training data but high level knowledge about desired behavior system example known output should invariant respect small spatial input images scale changes have implemented scheme allows network learn its outputs respect our learning time amount training data but provides language what network perform
define concept polynomial convergence relative probabilities distribution dependent context probability distribution family family has property polynomial convergence probability maximum difference over between relative frequency probability given positive most sample frequency has size polynomial given sample dimension family expectation show has property polynomial convergence such applications distribution dependent learning discussed
study particular type machine graph structure called our interest using such machine model probability distribution binary input vectors analyze class probability distributions such machines showing each class includes good distribution set vectors binary inputs present two learning algorithms these machines first learning algorithm standard gradient computing maximum likelihood estimates parameters ie weights model here give form gradient significantly compute than corresponding gradient general machine second learning algorithm method hidden units their weights time method standard method density estimation give experimental results these learning methods synthetic data natural data domain
present distribution free model learning time change while learning algorithm minimizing error between current target concept hypothesis single two show average rate depends maximum rate concept these theoretical predictions simulations several learning algorithms including back propagation
general relationship developed between dimension statistical lower capacity shows dimension lower order statistical lower capacity network trained random samples relationship generalization takes after concept generalization capacity optimal classifier over class classifiers same structure capacity bayesian classifier furthermore provides general evaluate lower bound dimension feedforward neural networks general applied two types networks important hardware two layer networks binary weights hidden units zero threshold output unit single neuron networks binary zero threshold obtain here total number weights networks represent networks
paper address important question machine learning what network architectures work better what problems learning network has similar structure hidden layer neural network general method based continuous version regression developed show regression better smooth functions than smooth functions function approximation scheme dimensionality functions
important neural computation dynamic range weights neural networks many experimental results learning indicate weights networks large size inputs here address between depth size weights polynomial size networks linear threshold elements show efficient way network large weights network small weights particular prove every depth polynomial size network large weights simulated depth polynomial size network weights prove these results use analysis functions our technique quite general provides other problems example able improve best known results depth network linear threshold elements comparison sum product two maximum
has been observed numerical simulations weight improve generalization forward neural network paper weight has two effects linear network first components weight vector vector learning problem second size chosen right weight effects noise generalization quite shown extend these results networks hidden non linear units finally theory numerical simulations using data
describe neural network called learns condition action rules domain functional over elements domain various points during learning rules these rules back into training process called iterative rules way learning generalization performance over alternative neural net approaches rule learning category learning has system show architecture applied problem case role natural language processing novel rule based solution
propose evaluate method rules trained neural networks our method context three step process learning uses rule based domain knowledge combination neural networks empirical using problems show rules our method trained neural networks accuracy network they superior rules derived learning system directly rules
paper present neural network architecture decomposition its input space based generalization architecture architecture uses among networks input space into regions learn associative within each region learning algorithm shown perform gradient log likelihood function architectures hierarchical structure
way neural networks so they generalize better term error function complexity propose new term distribution weight values mixture multiple under model set weights simple weights into so weights each cluster have similar values allow parameters mixture model same time network learns simulations demonstrate complexity term more effective than previous complexity terms
alternative technique training examples fixed distribution current example presented error reduced criterion value another randomly convergence time task sensitive value
stochastic gradient descent general algorithm includes line backpropagation adaptive means clustering special cases standard learning rate both adaptive fixed functions time often perform quite contrast our recently proposed class search converge learning rate convergence rate superior ability local user setting key parameter propose here new first adaptive learning rates achieve optimal rate convergence
although detection invariant structure given set input patterns many recognition tasks connectionist learning rules focus high variance principal components prediction often used here suggest more direct approach invariant learning based learning rule unsupervised two layer network method competitive setting learns depth information random
several parallel algorithms based upon mean field theory approximations underlying statistical formulation now finding approximate solutions difficult problems they have been applied problem well various computational vision cluster analysis show here given algorithm combined natural way areas constrained adaptive simulated single efficient parallel technique required results numerical simulations problems presented show algorithms typically order faster than algorithms show superior solutions well
method proposed generalization feedforward network trained backpropagation algorithm use artificial training vectors obtained noise original training vectors discuss connection such backpropagation training noise kernel density kernel regression estimation compare simulated examples backpropagation backpropagation noise kernel regression mapping estimation pattern classification
connections between approximation approximation functions feedforward neural networks studied potential improvement degree approximation single two hidden layer networks results degree approximation chosen basis probability distribution examples rather than function values extended
feedforward networks units compute function weighted sum their inputs have been much tested approximation estimation networks using functions more complex than three classes functions tested functions series these classes fit non functions they compared three problems prediction robot inverse dynamics complex units superior performance robot problem highly non approximation problem noisy nonlinear problems among complex units series
paper problem learning networks functions smooth examples such networks those whose neural transfer functions linear those whose error function defined terms norm up now networks whose neural transfer functions linear have but using function defined terms norm has attention work problems gradient methods used error functions have been paper upon recent results field present algorithm case our work out fact have been able show backpropagation error function based upon norm using norm
present iterative algorithm nonlinear regression based sparse lower higher order selection new terms using novel approach whether variable error algorithm based tree trees have extended approximation arbitrary input features addition provide new theoretical approach algorithm shown known polynomial samples make accurate estimates values image processing task
algorithm proposed forward neural networks uses node hidden large networks small network approximate model set training data larger more network approximate solution found network system generated data leads those hidden nodes whose weight vectors regions input space more required model these nodes two using principal component analysis new nodes two main each vector nodes using principal component analysis weight vectors matrix second network error respect weights second method applied input layer provides useful relative parameters classification task node standard multi layer equivalent decision allow more learned initial results but further evaluation long range effects decision new nodes back node position problem does networks receptive fields such radial basis functions mixtures technique work well node algorithm forward neural networks
neural network over networks important area study has previously been using variety techniques paper present information measure based new approach problem hidden units based their information measure measure decision tree techniques degree hidden unit between training data classes show results applying three classification tasks demonstrate number hidden units without significantly network performance
algorithm functional models data uses search basis functions used least regression model because population models over time rather than single model allows analysis possible other regression based approaches
probabilistic neural network algorithm likelihood function given class sum practice often pattern classifier other classifiers including backpropagation robust respect transformations feature space lead performance certain data have derived extension called weighted ie whose covariance multiple matrix covariance using algorithm interesting features its large population size experimental results our
designed trained connectionist network generate new given few during learning our network constructed distributed internal representation well fact each training instance both necessary have but hidden units representations several alternative architectures
compare two training connectionist well models statistical pattern recognition probabilistic strategy based bayesian discrimination ie optimal classification achieved classifier learns class distributions random feature vector differential strategy based class probability feature vector achieve bayesian discrimination each strategy directly family objective functions used supervised training procedure prove probabilistic strategy error measure objective functions such mean error cross entropy typically used train classifiers requires larger training sets more complex classifier architectures than those approximate bayesian function contrast prove differential strategy objective functions requires minimum classifier functional complexity training examples necessary approximate bayesian function precision measured probability error present our context show statistical pattern recognition tasks demonstrate simple extension concept leads us general information model sample complexity statistical pattern recognition
three methods performance gaussian radial basis function rbf networks tested task rbf new example computing its distance set chosen unsupervised methods application supervised learning learn non distance metric found reduce error rate rbf networks while supervised learning each variance performance best improvement accuracy achieved networks called generalized radial basis function networks locations determined supervised learning after training words rbf correct while correct test set these other experiments supervised learning locations important radial basis function learning
performance self feature maps like map involves choice output space present product measures criterion output space map global dimensionality well dimensions individual test product method synthetic mapping examples but speech data application our method suggests output space dimensionality recent recognition results same data set
present here interesting experiment modeling performed small samples several two over three decision tree neural net processing given these human better represented but different both strong convergence hypothesis between neural networks machine learning discussed now include human
two based feedforward network learning methods regression problems studied compared paper back propagation learning other learning parametric method non estimates unknown nonlinear functions neuron neuron layer layer each iteration while estimating weights terms learning efficiency both methods have training speed based optimization algorithm while more terms learning noise more sensitive
existing learning performance forward neural networks do provide basis comparison because choice training limit determine results comparison propose new have property being independent training limit efficiency measures correct networks training optimal limit provides efficiency learning performance asymptotic performance estimated implementation may found
present novel classification regression method training regression supervised training new family terms improved generalization properties demonstrated real world problems
paper describes technique learning both number states hidden markov models examples process most specific model consistent training data states both choice states criterion bayesian posterior probability compare our algorithm method estimating fixed size models find minimal hmms data cases fixed estimation does converge requires parameters converge
artificial neural networks certain nonlinear examples used include linear threshold elements elements radial basis elements results analysis theory approximation obtain almost lower bounds size ie number elements neural networks class neural networks our techniques applied quite general includes feedforward network each low degree function example prove depth network units linear threshold elements computing function variables have size fixed addition prove lower bound almost showing function computed units linear threshold elements depth network these almost bounds first known complexity results size neural networks depth more than two our lower bound techniques approach complexity analysis various models neural networks feedforward structures moreover our results indicate context computing highly symmetric networks continuous output units such elements do significant reduction size compared networks linear threshold elements binary outputs
recurrent networks recurrent networks associative memory techniques sequential structure easily trained using gradient descent techniques generate sequences discrete outputs trajectories through continuous space performance found superior recurrent networks these sequence tasks
boosting algorithm learning machine error rate less than low error rate algorithm discussed here depends large independent training samples show problem generate ensemble learning machines whose performance recognition problems improved over single network report effect boosting four codes state following upper case lower case use two performance measures error rate rate required achieve error rate patterns boosting improved performance cases factor three
memory based classification algorithms such radial basis functions nearest typically simple product pattern vectors more complex better distance measures often rather matching propose new distance measure made locally invariant set transformations input computed efficiently tested method large provided using respect scaling line method other systems tested same
artificial neural network threshold circuit network processing units called linear threshold depth network number unit time parallel computation size circuit number measures amount hardware known traditional circuits would require least depth compute common functions such product two allow size increase show paper much more than traditional circuits particular prove addition computed depth computed depth polynomial size weights moreover known lower bound results these optimal depth indicate these techniques applied construct polynomial size depth depth multiple product
although interest has been shown language inference using recurrent neural networks these models has been limited have previously demonstrated neural network model capable learning deterministic context free eg examples learning task computationally paper ways knowledge about task data could used efficient learning such knowledge often experimental learning eg
address problem learning unknown function together several information about function introduce method learning examples learning representation defined new types represented learning process examples examples function equal during learning examples different processing according given present two types fixed relative each adaptive based well each has been learned so our learning method descent technique may use
network reinforcement learning existing hidden units rather than new units after units learn via back propagation resulting algorithm tested learning network learns solve problem solutions found faster average algorithm than without
multi neural network hidden computing distributed representation input several experiments have shown representation space small fully used but computing such representation requires nodes case hidden nodes noisy find error schemes using noisy units during training random errors during backpropagation result representations average minimum increase probability predicted coding furthermore effect noise machine against node useful machine
relationships between learning development nature taken suggest model process algorithm might form neural networks learn generating polynomial time series prediction sequence define generate weights learning prediction error used determine new critical new but results presented
paper describes system probabilistic knowledge neural learning methods uses version backpropagation factors rule uses information gain new rules results two knowledge demonstrate combined approach performs better than previous methods
higher order non recurrent network two properties found useful learning sequential tasks connections
performance comparison two self networks feature map recently proposed cell structures made several performance self networks proposed models tested three example problems feature map superior results problem other more difficult more problems cell structures exhibit significantly better performance every criterion additional advantages new model parameters constant over time size well structure network determined automatically
given set training examples appropriate number free parameters problem learning algorithms solve problem automatically hidden units therefore free parameters during learning explore alternative class algorithms called algorithms number units fixed but number free parameters during learning architecture investigate rbf units constraints parameters network approach include variable subset selection robust parameter selection processing interpolation sparse training data
new radial basis function rbf classifier rbf near class described classifier complex decision regions corresponding rbf outputs similar predicted error measure used determine many determine two experiments presented demonstrate advantages classifier uses artificial data two classes two input features each class four clusters but cluster near decision region other uses large database classes input features both experiments classifier provides lower error rate than required more conventional rbf gaussian mixture classifiers
large dimension classifiers learn difficult tasks but usually because they generalize well they trained data paper show even high order polynomial classifiers high dimensional spaces trained small amount training data yet generalize better than classifiers dimension achieved maximum margin algorithm generalized technique wide variety classifiers including polynomial classifiers unit networks radial basis functions effective number parameters automatically training algorithm complexity problem shown equal number those training patterns patterns decision patterns bounds generalization error speed convergence algorithm given experimental results recognition demonstrate good generalization compared other algorithms
propose simple well way computing optimal step size gradient descent algorithms line efficient computationally large backpropagation networks trained large data sets main technique estimating principal objective functions second matrix does require even several other applications technique proposed up learning parameters
investigate use information second order error function perform network ie weights trained network order improve generalization networks reduce hardware increase speed further training cases rule our method optimal brain significantly better than based methods optimal brain often weights more weights than other methods same error training set thus yields better generalization test data inverse matrix training data information net reduction weights over backpropagation weight three problems et al optimal brain based methods correct weights trained network every case finally used weights their network used network weights better generalization
proposed model time invariant neural networks time continuous signals although simple well known recurrent neural network analysis has shown time able difficult classification problem shown has certain advantages over current available sequential processing schemes dynamic hidden markov time neural neural network finite time out structure input compared neural network finite may well fact learning short training set numerical example used trajectory classification problem problem making feature variable sampling rates internal states continuous dynamics time data phase space trajectories shown difficult other schemes problem has been learned iterations trained exact same problem expected
new network architecture has been presented paper properties such networks their generalization under particular constraint small data sets evaluation networks local linear maps using time series prediction task our results indicate potential large networks problem information small data sets without risk overfitting network architectures more than architectures same number nodes
algorithm computational procedure derive confidence intervals statistical solution applied neural networks estimate predictive distribution inputs different their convergence speed discussed small scale simulation experiment shows practical problems its potential use
previously have introduced idea neural network transfer learning target problem up using weights obtained network trained related source task here present new algorithm called based transfer uses information measure estimate defined source weights target network weight several experiments demonstrate target networks via learn significantly faster than networks randomly
algorithm presented performs gradient descent weight space artificial neural network using finite difference approximate gradient method novel computational complexity similar node but does require activity hidden neurons possible due stochastic between weights neurons algorithm similar weight optimal terms hardware used training vlsi
vector useful data competitive learning reconstruction error appropriate algorithm vector data vector data classification has different objective minimize number different algorithm appropriate show algorithm extension algorithm class case converge bayes optimal classification compare performance algorithm version step size class classification problem
many techniques model selection field neural networks well statistical methods method training other hand network trained error further validation set examples training true model selection require convergence training process paper show performance significantly model selection method training include dynamic dynamic weight complexity term methods term during training process
have designed architecture between address explore discrete processing system complex dynamics like its its learning show discrete time recurrent network architecture constructed connected associative memory described continuous nonlinear differential equations learn connection weights between system under machine sequence transitions within much digital computer transitions its binary architecture thus principle computing used systems computation presence noise have constructed system functions finite state set defined processing system but analog input representations time steps machine system implemented parameter input context their while hidden output change state hidden output states while context those states new context next input superior noise has been demonstrated systems dynamic over systems between different has been shown important transitions inference net
inverse problem nonlinear two different result need form regularization multiple solution global local certain classes learning methods applied input output data generated forward function used problem domain forward mapping into finite set regions over inverse problem well local regularization appropriate over each region result problem into finite set well problems each solved construct approximate direct inverse functions
way speed up reinforcement learning learning simultaneously multiple space time paper shows learning high level learn set tasks their learn them need their they learn their reinforcement context current illustrate system using simple task system learns multiple levels more efficiently than standard learning more map
paper describes technique called input reconstruction estimation response class multi layer technique uses networks ability input pattern its internal representation measure its more network able input pattern its internal representation more network considered provides good estimate trained results presented estimates provided used between networks trained different
artificial neural nets generalize better examples order generalize successfully neural network learning methods typically require large training data sets introduce neural network learning method many data points instead prior knowledge previously learned neural networks example robot control learning tasks reported here previously learned networks model effects robot actions used learning robot control functions each observed training example target function eg robot control policy observed example terms its prior knowledge additional information about shape target function shape knowledge used bias generalization learning target function results presented applying approach simulated robot task based reinforcement learning
recent research reinforcement learning has algorithms based dynamic programming most areas application these algorithms control dynamical systems results have been achieved significant between practice theory particular convergence problems continuous state action spaces systems non linear function such paper presents research applying based reinforcement learning theory linear quadratic important class control problems continuous state action spaces simple type non linear function describe algorithm based learning converge optimal controller large class problems describe different algorithm locally optimal function possible using non linear function based learning
brain solve two important problems movements first problem recognition objects does brain visual motor information object second problem hand shape planning does brain design hand shape object task neural network model these problems has been developed network into learning phase optimization phase learning phase internal representations objects task visual information optimization phase most hand shape object determined using computation network present address parallel distributed processing research
task used example illustrate direct associative reinforcement learning methods learning control under real world conditions uncertainty noise task complexity due use less than presence uncertainty times degree uncertainty our results indicate direct reinforcement learning used learn robust control strategy results
trajectory extension learning new technique learning control parameter desired trajectory region dynamics region desired behavior may have more difficult dynamics varying parameter practice movements near desired path while neural network learns approximate inverse dynamics example average speed motion might inverse dynamics movements dynamics fast movements provides example more general concept practice strategy sequence tasks used learning complex task show example application idea real joint direct robot
within simple test application forward short term planning robot trajectories dynamic environment studied action network system architecture world model short term predicted temporal trajectories robot state feedback action net allows between alternative planning tasks goal motor actions dynamic constraints such moving using supervised learning examples optimal mapping over structure level higher order network training database generated dynamic programming algorithm simulations local mapping highly nonlinear but represented chosen net model generalization discuss forward planning learning temporal planning dynamic programming
three step method function approximation system proposed first functions initial rule representation learned second rules much possible using information theory finally computational network constructed compute function value system applied two control examples learning upper control system learning control system model
objects over time provides perceptual learning present unsupervised learning procedure mutual information between representations forward network time steps demonstrate network learn unsupervised ensemble several patterns pattern trajectories even transitions object another between trajectories same learning procedure should variety perceptual learning tasks
neurons area visual cortex moving objects present model cells responses form such representation two different sets units local receptive fields inputs motion energy filters set units estimates local motion while second set these estimates outputs second set units outputs first set through gain control mechanism active process subset local motion responses into more global responses our model previous models estimation model yields accurate estimates synthetic images containing multiple moving varying size spatial frequency well number
multiple single neuron responses single presented cells receptive fields stimulus along several visual dimensions degree dimensional large population neurons found several cells different temporal response different stimulus dimensions ie firing same mean firing rate describe receptive field use simultaneously responses compute multi neuron receptive field information processing cells using dynamic correlation analysis propose several computational schemes cells neuronal coding stimuli discussed
classical computational model vision constraint feature ability model constraint constraint provide support required computation sparse features propose bayesian approach vision over its segmentation into multi layer depth representation simultaneously computed constraint support within each layer mutual non regions test results various random other presented
visual processing ability missing noisy information feature often lead direct information about features available available information usually sufficient highly outputs discuss bayesian techniques class probabilities given partial data optimal solution involves over missing dimensions weighted local probability show obtain form approximations bayesian solution using gaussian basis function networks framework case noisy features simulations complex task hand recognition theory both input used performance number missing noisy features performance either step
models cortex illustrate feedback may used robust low level pattern analysis information back cortex using full out so cortical while number necessary connections small
human vision systems information across long spatial example moving stimulus yet suggests visual systems information along trajectory motion stimulus our self neural network model shows moving stimuli direct trajectory specific motion representations moving stimuli these results account data model other such visual
work apply classification network image analysis goal characteristics area input image thus map region have recently proposed combined neural network rule based framework recognition framework uses unsupervised supervised learning provides probability estimates output classes describe classification network extend demonstrate its application image analysis domain
have designed neural network direction presence eye movements performance network consistent human its output neurons show similarity component cells area visual cortex now show using assumptions about eye movements perform our model generate various other cell types found well
ensemble dynamics stochastic learning algorithms studied using theoretical techniques statistical develop equations motion weight space probability stochastic learning algorithms discuss approximation provide special cases algorithm general distributions objective function being but rather upon effective potential includes effects finally present exact expression time density learning algorithm weight updates gradient
paper discuss asymptotic properties most used backpropagation algorithm network weights trained means local gradient descent examples randomly fixed training set learning rate gradient updates constant simple backpropagation using stochastic approximation results show training process approaches training provide results rate convergence further show small approximate simple back propagation sum training process gaussian solution linear stochastic differential equation using approximation indicate simple backpropagation less local than training process demonstrate number examples
presence existing self rules principal component analysis pca perform using statistical techniques including distribution binary decision fields effective propose self pca rules capable while various pca related tasks such first principal component vector first principal component vectors directly finding first vector principal component vectors without solving each vector experiments have shown proposed robust rules improve existing pca algorithms significantly present
analyze query algorithm method filtering random inputs show two algorithm information gain positive lower bound prediction error number show particular exponential query learning smooth functions
effects analog noise synaptic during perceptron training cost function include noise terms predictions made these suggest ability learning trajectory should improved such noise simulation experiments two classification problems results general training schemes weights have wide applications those analog neural vlsi
present information learning algorithm clusters data linear contrast methods information about input patterns information output robust binary implemented nodes derive local weight adaptation rule via gradient objective demonstrate its dynamics simple data sets our approach previous work suggest may extended
have use information neuronal connection structure spike two point mutual information its maximum value channel capacity between neurons found useful sensitive detection estimation synaptic three point mutual information among three neurons could give their structure therefore our information analysis shown technique neuronal connection structure examples its application simulated spike presented
use statistical study generalization large machines architecture fields yields generalization error limit large number hidden units continuous weights generalization error off number training examples per weight binary weights find transition generalization wide region found within region low fully connected architecture generalization error within approximation both binary continuous weights find transitions symmetric state hidden units generalization error
present algorithm neural network accurate probability estimates outputs network probability distribution model training database model new transformation joint probabilities database weights distributed network model theory transformation presented together experimental results advantage approach network weights without iterative gradient descent used classifier network results variety
recurrent neural networks architecture synaptic studied here randomly architecture variance synaptic weights produce parameter dependent variance transfer function but independent connectivity allows activity critical value even connectivity small size find numerical results theoretical previously fully connected networks moreover type first
recurrent networks threshold elements have been studied associative pattern recognition while most research has fully connected symmetric networks stable fixed points networks show dynamical behavior used sequence pattern recognition paper approach problem complex global behavior class random networks terms network parameters these networks show fixed point behavior parameter values our approach used set parameters necessary obtain desired complexity dynamics approach provides into system does suggests possible applications
analyze performance network inputs its memory patterns activation function memory neurons original network simple threshold function resulting threshold network input pattern probability using connections single iteration time space complexity network classifiers
present framework description performance like neural networks first two iterations using bayesian approach find performance improved based term neurons dynamics further networks performance achieved neurons those active given iteration basis their synaptic dynamics conditions low firing activity sparse connectivity two important characteristics cortex such networks performance higher than performance two independent iterations upper bound performance independent networks
method non linear data representations presented used technique extended allow non linear representations objective function individual hidden units shown result minimum dimensional respect error reconstruction
neural networks binary weights important both theoretical practical points view paper investigate single binary binary perceptron networks binary each input unit connected perceptron give polynomial time algorithm learns these networks under distribution algorithm able identify both network connectivity weight values necessary represent target function these results suggest under distributions perceptron networks may learn than fully connected networks
two presented about use estimator cross validation method model selection theorem gives asymptotic form estimator combined model selection criterion asymptotic form used obtain fit model model selection criterion used negative average predictive choice based idea cross validation method provides further model selection criterion theorem gives asymptotic form model selection criterion regression case parameters optimization criterion has term theorem asymptotic model selection criterion cross validation method distance measure between response regression function takes form difference
learning curves show neural network improved number training examples related network complexity present paper asymptotic properties their two learning curves predictive loss generalization loss other training loss result gives natural complexity neural network moreover provides new criterion model selection
compare activation functions terms approximation power their feedforward nets consider case analog well input
connection between functions theory dynamical systems feedforward neural networks allows us single hidden layer neural networks almost arbitrary activation functions terms functions solve problem such networks
have trained networks ii units short range connections simple exhibit complex three levels learning possible order learning underlying rule learning asymptotic dynamical learning training levels learning achieved without weight different provide new into their dynamics
forward networks fixed hidden units networks compared against category forward networks variable hidden units networks two classes tasks finite domain considered approximation every function subset functions representation every first task found both network require same minimal number synaptic weights second task general position shown networks threshold hidden units have times hidden units than network have
number hybrid markov model hmm speech recognition systems have been developed recent paper present new architecture training allows modeling context dependent classes hybrid different context order obtain robust estimate probabilities database have shown advantages context dependent over have shown advantages hybrid approach over approach
study modeling speech based neural networks using data speech neural network learns forward dynamics motor behavior allows trajectories generated motor constrained input global performance parameters these movement trajectories second neural network parameters used speech
paper speech analog model between time frequency resolution difference between conventional analysis signal processing signals models response like analysis scale domain good temporal resolution frequency each spectral component signal determined intervals firing rates auditory such properties model demonstrated natural speech synthetic complex signals
channel problem important problem high speed sequences channel problem considered channel problem approach direct between error probability error produced channel paper optimal design classification problem optimal classifier constructed bayes decision rule general nonlinear efficient hybrid approach has been proposed train error probability new has been shown better than linear experimental channel
would like speaker dependent such speaker independent speech recognition system paper discuss dependent neural network each while most speaker independent parameters use classification network generate dependent probabilities statistical hmm recognition system classification net high accuracy test set into our hybrid hmm neural network provided improvement recognition significant test set
filtering has been most techniques detection here show dynamic neural network conventional approach artificial neural network trained supervised learning schemes need desired signal time although paper show effects detection different construct desired signal extension bayes decision rule desired signal optimal classification performs than desired signals constructed random noise prediction during
connectionist speech recognition systems often between training problem multi state time delay neural network hierarchical word classifier uses its connectivity pattern directly trained word level consistent use word accuracy criterion during both training leads high system performance even limited training data now has been applied small recognition word tasks paper apply architecture large continuous speech recognition demonstrate our other systems have been tested database
recently state large continuous speech recognition has hidden markov modeling hmm model speech improve over hmm developed hybrid system hmm neural networks present concept neural net modeling into account simultaneously well known conditional several speaker independent experiments hybrid system consistent improvement performance over system
multi state time delay neural network nonlinear time procedure into connectionist speech recognition system word level classification error backpropagation present task small but highly our word accuracy speaker tasks previously reported results same propose training techniques level performance including free across word word modeling error backpropagation rather than word level architectures subset achieved further
paper performance two methods recognition based segmentation line hand input sequence methods designed work constraint between while both methods use neural network recognition graph their approaches segmentation quite different first method call input segmentation uses combination identify particular segmentation points second method call output segmentation trained recognition both relevant segmentation points
propose paper statistical model hidden markov model statistical properties images model single dimensional hmm used speech processing case model useful efficient segmentation algorithm similar algorithm hmm present conditions terms parameters sufficient segmentation problem solved polynomial time describe algorithm algorithm image model therefore images using algorithm joint optimal segmentation recognition image performed thus traditional systems segmentation performed recognition recognition errors approach using set hand recognition accuracy achieved analysis results even simple case recognition performance significantly advantage approach even more significant tasks such connected known high accuracy method recognition
power area large using application approaches input dimension reduction decomposition network training regression representations ability algorithms like find vectors us architecture selection problem high dimensional gradient single input single output introduce dimension reduction algorithms features relevant set many variables based minimizing level set related them implement neural network version performance achieved our approach trained data tested data achieved our study backpropagation trained networks
hidden markov models hmms applied several important problems introduce new learning algorithm hmms classical algorithm smooth applied line without most path approximation left right hmms states trained represent several including cases models derived capture important statistical properties used efficiently number important tasks such multiple detection classification
used technique estimating risk neural networks learned determined individual standard error backpropagation compared standard combined layer rbf units using out method generalization tested cases training time determined automatically cross validation performance best performance network three hidden units per view human experts
have designed tested analog vlsi chip radial basis functions parallel have developed circuit quadratic function these circuits form radial basis functions these radial basis functions together using
analog cmos vlsi neural processing chip has been designed neural state capable computing connections per second addition basic results performance chip solving real world problems demonstrated
real time computation motion real images using single chip present two analog vlsi schemes use domain circuits compute motion variable rather than represent natural temporal relationships both algorithms measure speed timing moving image our first model algorithm yields non response curve present data chip model our second algorithm yields response curve being into
describe analog vlsi implementation multi dimensional gradient estimation descent technique minimizing function implementation uses noise correlation estimate application technique setting circuit parameters chip automatically rather than gradient descent optimization may used weights backpropagation other chip learning implementation approach features continuous multi dimensional gradient descent potential optimization present data measured our analog vlsi implementation
field neural networks has been but their still being they provide levels design simulation analysis neural networks our object framework show high complex experiments obtained basic design natural way explain their computational models experiments performed networks extended easily mechanisms have been analysis complex architectures among these mechanisms experiment multiple time
networks local shown have computational performance respect classical like networks particular critical capacity network well its correlated patterns dynamic long associative memory implementation based here presented neurons circuit implemented solution change parts weights transfer function whole architecture simple into chip
demonstrate use digital signal processing construct hybrid networks computer model neurons connected biological neural network system real time synaptic connections effective therefore synapses made computer model neuron biological neuron method provides us ability additional known elements biological network study their effect network activity moreover parameters model neuron possible role individual activity neuron network present address de de present address de de
several research circuit models biological auditory processing these circuit have taken several including simple out parallel analog systems paper describe alternative output method auditory models direct digital present address unit present address present address auditory computer
methods gradient descent neural network learning based knowledge network model requires time each pattern high precision makes difficult implement vlsi present here technique measures gradient technique uses network errors modeling neuron activation synaptic weights do errors gradient descent method parallel nature implement vlsi describe theory such algorithm analysis its domain simulations using hardware implementation
basic connectionist should take form systems parallel soft constraints optimization problem solutions well structures language such have been successfully applied number problems theory natural shown rather than conventional rule systems have been computation human higher level machine designed lower level connectionist networks basic computational approach these lower level representations distributed patterns connectionist activity higher level these same representations structures particular structure set using each may corresponding lower level description activity vector these product representations defined complex structures represented vectors defined product representations lower level processes parallel numerical activation higher level these same processes form structures parallel et al lower level description activation processes certain properties process higher level structure including given input structure energy computed either lower level particular function activation pattern higher level function structure cases function lower connectionist level quadratic form networks activation vector its connection weight matrix higher level each two same structure particular may same et al connectionist well well following results et al form function computed sum terms each measures well within single structure their particular thus set soft rules each form structure simultaneously role role value may positive negative set such soft rules constraints soft rules include both those given input hidden input problem computational construct structure containing both input hidden first proposed application natural language see et al et al et al et al has more recently into non numerical called theory has been successfully applied range problems research see et al means power apply eg context free language set soft rules form given so maximum tree has these soft rules each may sense they second order describe pairs those both same these first order soft rules tree well its local trees local tree node its thus rules need pairs nodes single local tree ie pairs pairs value tree sum each such nodes given soft rules general context free pairwise evaluation consider eg following local tree here two pairwise well first rule left second right left three nodes simultaneously single rule possible approach would extend rules higher than second order more than two functions degree higher than such functions standard connectionist networks pairwise connectivity networks defined over rather than graphs natural alternative requires change but instead special basic idea taken generalized structure et al theory study natural useful introduce new normal form normal form rules three types further rule given left hand condition here use have two non general like like see every does have first take normal form each binary rule left hand using different value each rule given left hand ii rule general category may have several into each has makes possible determine well tree each tree every condition us evaluate tree up soft rules each node each link tree now first find generate set soft rules via node node node left left right soft rules first order evaluate tree nodes second order soft rules rules tree tree other tree thus tree has evaluate tree up its nodes into each either trees complete positive negative trees have total decomposition nodes each link tree up other down link corresponding rule into two each up non nodes into nodes non node has two trees such node into three nodes corresponding each link corresponding link according soft rule node distributed three each node non node has tree so into two nodes link link soft rule into two each node need up nodes trees have link evaluate tree each node now into set nodes made node its link way each original link each nodes consider first non node has have link corresponding node has left link corresponding node right thus total node has two each missing node so node general case node result non non difference now could left position node corresponding link but rather soft rule result still even case position finally node such node have but might have missing thus total tree given total missing nodes tree thus each node has its required because normal tree every every node has its required defined pairwise terms other might present thus have desired result maximum has now see soft rules generalize context free soft rules each node makes negative equal its while each link makes positive equal its node link number nodes tree negative nodes made time node present these positive link so order apply strategy set negative nodes equal their determined illustrate technique showing problem simple three rule introduced early section corresponding given above node above nodes both nodes corresponding tree according both missing missing two now necessary version but both have each node missing node corresponding but correct has technique generalized context free type equivalent machines they generate eg rule two rules new non corresponding soft rules rule node soft rules defined context free case many research presented here has been part research work stability global pattern parallel memory competitive neural networks systems product system architecture representation connection generalized structure brain state neural model gradient descent algorithm framework connectionist systems biological system between computation learning machines research parallel distributed processing
neural network models have been their make use representations paper describe series demonstrate role representations these suggest compare representations via process process have model
demonstrate paper certain rule based knowledge used neural network basis functions give probabilistic interpretation network architecture describe several ways rule based knowledge during training present method complexity reduction minimize number rules number after training rules
describe model visual word recognition several temporal processing sequences presented words model new representation words based dynamic time scaling visual input through perceptual comparison detection describe these dynamical processes account several word recognition including
propose model development explicitly involves learning model uses neural network understanding similar second through series examples model shown develop understanding similar trained using similar
representations information about words necessary many applications neural networks natural language processing paper describes efficient based method distributed representations large number words statistics means large scale linear regression representations successfully applied word sense using nearest neighbor method
processes our ability objects within complex visual input scene paper implemented neural network model described selective visual attention perceptual transformations might work together order objects out complex input scenes containing multiple objects feature maps input two main processing location information what computing shape objects location based attention mechanism early stage visual processing region visual field processing location based attention important role invariant object recognition appropriate processes within what object recognition through segmentation visual field into order represent different same time model uses mechanism connections between what lead between different functional behavior consistent variety data
system first order sensory have been shown gain its output neurons underlying neural mechanisms gain control yet fully suggest possible gain control mechanism could total output neurons paper neural model based idea used demonstrate activity levels could control both gain target neuron
model presented simulations show both single cells these compared single unit data firing cells simulated artificial environment input neuronal network whose output each next direction cells number spikes time firing respect learning off synapses synaptic activity simulated successfully more times during fields random environment allows presented goal novel limited number successfully experiments have shown spatial memory ability single unit moving have cells fields whose firing small environment corresponding fields see fig addition cells have been found whose ii ii ii time figure field rate over second eeg shown through field shows times firing cell above eeg positive negative zero eeg define phase shows phase each spike direction et al both temporal well spatial region significant model eeg best frequency making movements recently cell firing has been found have phase relationship local eeg see fig finally has been found long term synapses et al
present theory interaction learning region form new representations learning predictive stimuli stimulus stimulus cortical regions long term these new representations but capable new representations connectionist model theory wide range level classical normal several novel predictions theory region even learning tasks although may able use other learn these tasks theory they show different patterns transfer generalization task change
so far has been general method measured activity neurons associative cortex underlying network states propose model such data using hidden markov model demonstrate application approach temporal segmentation firing patterns cortical responses stimuli using such statistical model significantly two them different firing patterns well level their multi unit firing activity our study measurements out
information optimization principle has previously been used unsupervised learning statistical input ensemble principle states mapping implemented processing stage should chosen so average mutual information between input output patterns constraints presence processing noise present work show applied class nonlinear input output under certain conditions generate optimal filters have additional useful properties output activity each input pattern among relatively small number nodes filters sensitive higher order statistical structure pairwise correlations input features filters receptive fields well sets filters low spatial related coding representations solutions certain types input
eye movement images retina during its gain visual during movements possible learning mechanisms adaptation have been model system based constraints local learning rules our model adaptation behavior under certain parameter conditions these conditions predictions time adaptation learning made
present local learning rule learning conditional prediction reinforcement signal propose biological interpretation such framework its through examples reinforcement signal its target three examples presented illustrate framework applied development system
between stochastic activity has been observed responses visual cortex describe dynamics these two parallel approaches rather hand analyze neuronal responses terms hidden state model parameters model directly experimental spike they underlying dynamics well individual neurons network model thus provides new framework experimental analysis network dynamics application method multi unit visual cortex stochastic states dynamics other hand single spiking neuron derive equation time state represent phase density phase density dynamics two limit fixed point synaptic interaction nonlinear system state other finally show two approaches consistent therefore both explain time structure data
new computational model both presented experimental evidence these may same mechanisms important model input activity both distributed correlated between allows pattern degree correlation between found correlation leads experiments suggested test whether such natural system
time data obtained sensory neurons terms two simple dynamical systems noise function called signal system defined two potential system implementation analog simulation circuits dynamics given signal frequency our have two parameters signal noise show experimental data obtained these simulations finally discuss stochastic two models
studied randomly connected neural network neurons connections using computer simulations network activity single point results suggest such network via critical
paper work self feature visual processing system but assumptions made allow model used processing other sensory information here special attention auditory system much lower connectivity therefore more statistical line training obtain idea training times these compared time available feature sensitive cells
paper presents neural network able control movements input network motor map output time eye position units network exhibit neurons layer superior motor map neurons simulations out network demonstrate its ability many experimental observations
known biological data response patterns coding signal propose analytically model allows us distribution response patterns architecture network
information theory used derive simple amount information firing rate neuron about experimentally measured variable combination variables eg speed direction location cell channel whose input measured variable whose output cells spike train applying find information cells different experimental conditions
network uses set recognition weights input vector into code vector uses set generative weights code vector into approximate reconstruction input vector derive objective function training based minimum description length principle minimize information required describe both code vector reconstruction error show information code vectors according distribution weights define energy each possible code vector given input vector code vectors use distributed representations compute distribution because involves possible code vectors show recognition weights used compute approximation distribution approximation gives upper bound description length even bound used function learning both recognition weights demonstrate approach used learn codes
although recurrent neural nets have been learning finite state machines continuous internal state dynamics neural net well discrete behavior describe architecture called allows discrete states net learning consists standard recurrent neural net trained gradient descent adaptive clustering technique state space based assumption finite set discrete internal states required task network state set but has been noise due weights learns discrete state maximum probability noisy state simulations show leads significant improvement generalization performance over neural net approaches
paper presents formulation unsupervised learning clusters multiple causal structure binary data standard mixture model multiple model observed data many hidden each varying degree subset observable dimensions function different cluster order generate data whose errors both during recognition learning demonstrate weighted sum alternative form results presented algorithms ability successfully multiple causal representations noisy test data images
present new algorithm parameters network generalization after supervised training method principal based principal component analysis node network simple implement effective requires network does full cost function weight node activity correlation matrices each layer nodes required demonstrate method regression problem using polynomial basis functions time series prediction problem using two layer feedforward network
analyze simple algorithm previously shown algorithm simple function analyze algorithm significantly faster than gives lower bound speed identify features give discuss these features into real
good model set input points cross validation computationally process number possible models number training points high techniques such gradient descent through space models but problems such local more distance metric between various models reduce these search methods technique finding good model data models computational between better paper special case out cross validation applied learning algorithms but class model selection problems
show network architecture constructed connected associative memory network selective control direct computation within architecture solve inference problem previously have shown discrete time network algorithm implemented network described continuous differential equations time steps machine system implemented parameter architecture amplitude codes information activity unit phase frequency used network amplitude information activity non noise control special subset hidden other hidden they control among other direct computation attention effect transitions between two state system generate internal noise used required random transitions
learning predict sequences using long term context has many applications practical theoretical problems found training recurrent neural networks perform tasks long intervals analysis problem consider compare alternative algorithms architectures tasks results new algorithms show performance superior obtained backpropagation
paper recurrent neural networks contrast algorithms population networks uses functions unsupervised feedback search through network space used generating both gaussian weight changes applying complex search task system capable networks complex internal dynamics
point matching distance measure invariant under learn point set objects clustering noisy point set images traditional clustering methods use distance measures feature vectors representation common most problem domains object based clustering technique distance measure specific type object within problem domain clustering problem two objective functions derive optimization dynamics similar expectation maximization algorithm used mixture models
data clustering optimization problem reduce complexity data representation increase its precision pairwise data clustering studied maximum entropy framework clustering derive set equations minimization procedure yields optimal number clusters their their cluster probabilities approximation pairwise clustering used estimate probabilities solution scaling pairwise clustering derived yields optimal clustering data points dimensional space
advantages supervised learning error metric available during training classifiers algorithm directly reduce number training set modeling human learning classifiers labels often available paper show labels making use structure between pattern distributions different sensory show minimizing between outputs networks processing patterns these different approximation minimizing number each leads similar results using show algorithm performs well finding appropriate vectors classes different two
real world learning tasks may high dimensional data sets arbitrary patterns missing data paper present framework based maximum likelihood density estimation learning such data sets use mixture models density estimates make two em principle et al learning algorithm em used both estimation mixture components missing data resulting algorithm wide range supervised well unsupervised learning problems results classification data set presented
analyze data missing input features into training neural network general solution requires weighted over unknown input although computationally form solutions found certain gaussian basis function networks discuss cases solutions such mean unknown input
describe number learning rules used train supervised parallel feature systems learning rules derived using gradient quality function consider number quality functions functions higher order feature values show system learns principle components correlation matrix principal component analysis systems usually optimal feature classification therefore design quality functions produce feature vectors support unsupervised classification properties different systems compared different designed datasets database
value decomposition important linear used approximate matrices although many use decomposition principal components important these other methods apply symmetric matrices while applied arbitrary matrices property important applications signal control propose two new algorithms iterative computation given sample inputs outputs matrix although many algorithms decomposition example these first true algorithms
present fast algorithm non linear dimension reduction algorithm local linear model data pca clustering based new measure experiments speech image data indicate local linear algorithm lower than those layer associative networks local linear algorithm more than order faster train
approach presented learning high dimensional functions case learning algorithm new data local modeling algorithm locally weighted regression used represent learned function parameters approach such distance function query point instead being global statistical given local model good sampling should new area our methods explicitly case prediction accuracy during speed local prediction accuracy goal state space takes along current data support task goal achieved illustrate approach simulation results results real robot learning complex task
their nature memory based algorithms such require computationally search large database paper process distance improve speed performance found database using complexity using number vectors its maximum using each stage confidence level classification computed confidence high computation more complex resulting algorithm applied recognition close three faster than computing full distance every
propose learning algorithm variable memory length markov process human whether given text speech has multi time scales short scales dynamics generate process large scales more information used fixed memory markov models cannot capture complexity such structures other hand using long memory models practical even short memory four algorithm propose based minimizing statistical prediction error memory state length total prediction error small demonstrate algorithm learning structure natural text applying learned model text using less than states models performance far superior fixed memory models similar number states show algorithm applied prediction results hmm based methods
four nearest neighbor algorithm locally adaptive introduced compared basic nearest neighbor algorithm locally adaptive algorithms value should used query results cross validation local query local methods shown perform similar experiments used data sets results three constructed tasks show local methods significantly specific applications local methods line learning applications different regions input space patterns solving different tasks
paper shown conventional back propagation algorithm neural network regression robust data but data robust model model error mixture normal distribution function mixture model condition model robust given em algorithm used estimate parameter model selection discussed simulations performed
conventional bayesian map weight vector paper shows find map function instead term term functions small description particular feature selection weight
activity prediction recognition features describe training example location orientation example recognition best techniques problem distance method et al introduce new technique dynamic problem dynamic learns neural network examples predicted output values new models trained new computed models converge paper dynamic distance method task biological activity cross validation comparison dynamic distance activity prediction dynamic correct compared distance method neural network standard nearest neighbor method
propose method performance network designed predict next value time series networks predictions data training set out network trained time series these combined system two networks new demonstrate method applying data small network resulting complex network includes combined system find complex network more difficult train performs than two step procedure combined system
back propagation algorithm has been work without low resolution makes more hardware implementation represented point states while fixed point way large over weights trained demonstrated same performance networks computed full precision estimate circuit implementation shows large network single chip more than weight updates per second obtained machine than
data structures introduced provide efficient functions space interest describe structure has been neural network classifier compare its performance several classification tasks against radial basis function networks standard layer perceptron
performance many methods depends strategy along regression constrained mapping algorithm novel method adaptive using neural network based self maps present original algorithm provides according estimated second regression
present new radial basis function network classification regression problems through soft competitive learning radial basis functions derived distance during training observed error locally used determine next unit leads case classification problems units near class rather than near frequency most existing methods resulting networks need few training generalize well demonstrated examples
extend optimal brain second order method networks allow general error measures explore reduced computational implementation via decomposition simulations nonlinear noisy pattern classification problems does lead improved generalization performs comparison optimal brain find required steps may lead generalization result due noise back into system common technique training large network minimum validation error found test error could reduced even further means but our results approximation used indicate highly network may lead performance
present paper propose entropy method internal representation entropy function defined respect state hidden unit internal representation internal representation parameter entropy function thus transformation transformation internal representation according given problems internal representation into minimum entropy representation obtain kernel networks networks interpretation other hand parameter obtain internal representations improved generalization applied entropy method kernel networks small internal entropy addition applied method frequency problem could obtain derived networks whose generalization performance significantly superior performance standard back propagation
present algorithm training feedforward recurrent neural networks internal representation uses these manner new neurons network advantages small network neurons required internal early stage learning time reduced empirical results two real world problems faster learning speed applied training recurrent network well sequence recognition task training times significantly less than previously reported
propose learning algorithm learning hierarchical models object recognition model architecture part whole relationships parts described local context object focus report learning hierarchical models data ie structure model observed object each node probability distribution its parameters learned connections between nodes structure object formulation such their parts independent resulting model bayesian belief network many similar stochastic visual described
paper practical optimization method neural networks optimal model parameter found simultaneously conventional information criterion into function parameters minimize while back form discussed experimentally
study learning class feedforward networks networks linear outputs neuron fixed input weights they trained gradient descent algorithm finite number examples under general conditions shown general three generalization performance learning process particular network has better generalization performance learning certain time global minimum empirical error effective size machine defined used explain off between complexity machine training error learning process study leads network size selection criterion out generalization criterion learning process shown learning global minimum empirical error has effect network size selection
study complexity problem artificial feedforward neural networks designed approximate real functions several real variables ie estimate number neurons network required given degree approximation every function given function class indicate construct networks number neurons standard activation functions our general theorem shows activation function better rate approximation
training classifiers large computationally develop efficient prediction classifiers given task so most new classifier propose such practical predictive method practical because procedure training classifiers whole training set because its theoretical proposed procedure demonstrated both multi layer networks
study forward nets many using standard our complete knowledge output neural net arbitrary inputs architecture weights many critical points error training problem neural nets introduced highly models system they used studied several they forward neural net consists finite sequence positive do family real defined family real defined sequence do called architecture neural net while called weights neural nets used compute non linear maps following nonlinear function variable system suggests take asymptotic standard choice paper address given input define real following known fixed set here outputs neurons layer net output map net defined map practical applications neural net so output map given map about have information main result paper under conditions knowledge output map weights neural net up more de de assume easily neural nets do same output map set neurons layer function nets called they related note particular neural nets have same architecture our main theorem under conditions two neural nets same output map discuss conditions neural nets have such weights zero output map constant architecture neural net determined have therefore gives forward net its output so through sum output depends output map does determine weights our more than these assume equal form these conditions neural nets our main theorem two neural nets have same output nets would interesting minimal study functions other than now our main result accuracy after reduction may assume do thus outputs nodes functions variable output map neural net key idea analytically complex values note off structure net set points leads two observations form every point fact special case do obtain see assume has simple while obtain thus solutions equation many solutions point view natural make following natural domain neural net subset complex output map analytically define set setting natural domain set points these made terms output map without structure given neural net other hand sets complete information architecture weights net allow us off structure neural net its output map see sets structure net over set together their points here off depth neural net need solve show therefore off ii point
show randomly output classes various training data may used improve predictive accuracy classification algorithm present method noise learning algorithm based output classes used indicate good between complexity classifier complexity data use noise different other schemes such cross validation uses part training data various functions data adaptive noise methods use training data data adaptive non parametric they well limited training data
have recently shown known algorithm optimal estimator criterion has been introduced control theory means robust performance face model statistical information signals extend here our analysis nonlinear setting often neural networks show backpropagation algorithm locally optimal fact provides theoretical observed properties backpropagation algorithms further discuss these results
paper efficiency recurrent neural network state finite state machines shown node complexity case above shown node complexity log weights set two matching lower bounds provided each these upper bounds state subset nodes size log
two layer networks hidden units generalization error shown input dimension number training samples expectation random number hidden units probability prior distribution weights relationship makes possible explicitly regularization term networks bound obtained analytically large used applied estimate expected network complexity practice result provides large networks generalize well
show randomly points probability such multi layer perceptron first hidden layer threshold units such perceptron have units first hidden layer fully connected inputs sense input patterns per hidden unit input patterns per synaptic weight such networks both achieved networks single hidden layer same single neuron these results recent estimates dimension find contrast single neuron case large dimension capacity
backpropagation algorithm training artificial neural networks deterministic gradient method under certain natural assumptions such series learning rates while series their every point online point error function results presented parallel online term weight
problem learning examples networks studied within framework statistical using average generalization error fully connected machine limit large number hidden units number training examples number inputs network generalization error function training set size approaches finite value number training examples number weights network find first order phase transitions generalization error both binary continuous weights
neurons learning under unsupervised learning rule perform nonlinear generalization principal component analysis relationship between nonlinear pca nonlinear neurons stable fixed points neuron learning dynamics under nonlinear pca order predict what neuron learns knowledge neuron dynamics required here between nonlinear pca neural networks down shown simple model methods statistical used find objective function non linear pca what neurons learn order find solutions neurons solve dynamics
describe use analysis variance log likelihood context learning estimating probability given training set vectors form vector learned sum smooth functions sum smooth functions two parameters obtained iterative risk iterative method confidence intervals these estimates available
models nonlinear machines proposed learning artificial neural networks studied based theory differential equations learning algorithm constructed optimal parameter found without procedure models us analyze experimental results error backpropagation often statistical learning theory
random variables per performance search algorithms have variables randomly ratio fixed model has been have threshold between almost almost computer experiments out show similar threshold behavior each value finite size scaling theory critical point used statistical shown size near threshold based mean field give good account results address research work while support large scale computation without length scale possible model natural world computer has such usually length example finite down into parts may use identify natural system whole even most difficult case continuous phase transitions correlated over wide range scales provides way problem down its relevant parts behavior scales terms critical point but length scales much another large examples include large rule based systems model complex processes digital example has used network three more systems called computer internal set tasks required rules parts described rules part would factors have constrained many important problems without length scales computer classification within few size information models what have might next human described terms through data sequences known understanding computational cost these problems order see practical they study resolution search find effects may its computational complexity threshold random properties randomly generated structures often exhibit threshold phase transitions studied recently have been observed randomly generated et al consider problem instance normal form ie each variable equal probability its task determine whether variables such evaluate true here use number variables number statistical randomly generated has been shown analytically large ratio less than almost larger than almost analysis has experimental evidence suggests threshold et al main randomly generated their use empirical evaluation search algorithms good evaluation such algorithms because their complete problem larger values problem solved efficiently et al case complexity simple methods usually determine random computationally test found generating near threshold et al has made similar observation computational cost search between two model provide threshold finite size scaling method statistical direct observation threshold critical region transition used behavior across critical region analysis problems size model observed finite size scaling systems without metric see fig experimental data have generated data randomly generated fig shows random function ratio example left most curve fig shows random variables over range values each data point generated using randomly generated accuracy used highly implementation procedure procedure best data obtained samples computing cost fig shows threshold each value case curves cross single point up between curves values single point well although curves point computationally problems found al al point right scale invariant point point curves cross each other simple right probability given random input independent probability define entropy per input times log expected number entropy gives estimate threshold upper bound derived several see log called estimate because interactions between see average over many have each table results finite size scaling analysis fig threshold up larger values both threshold curves fig finite size scaling see samples against variable values derived experimental data first determined point curves large fig determined make up through critical region fig find these two parameters capture both threshold curves using see statistical models limit fig data using fig data approach limit given invariant function fig description threshold define fig find fit their data point function they obtain two few obtained good results data other values table give critical parameters obtained analysis error show range each parameter over best obtained note good approximation finite size scaling different strong evidence ie correlations even length finally found similar shape fact various curves figure shows curves point form obtained previous section define probability curve similar form but right other table critical parameters random statistical analysis space our analysis model inputs binary may represent them vector each random sum its vector has non zero input number left particular natural take value energy function inverse factors into each approximation above consists over each their interactions both energy entropy fig shows case fig predictions energy obtained theory used compare specific observed numerical experiments simple limit do gives evidence phase finally phase like phase obtained solving st finite perform over random requires see random between expectation values two new order parameter results capable statistical difference between experiment predictions finite example approximation consider two gives values table rather average found experimentally between pairs energy states shown fig theory gives solution function gives fig defined table point maximum fig entropy function fig theory experimental state up down have shown finite size scaling methods statistical used model threshold randomly generated problems given good fit our scaling analysis method give useful models phase transitions other problems control parameter several have characteristics phase transitions models systems see have proposed interactions random exponential complexity see first focus correlation length continuous phase transitions computational complexity fact both effects important but sufficient may even necessary complete problems eg phase problems cluster phase transitions yet cost cluster steps exponential search cost random inputs require space note input determined its non polynomial time because reduced problem random graph studied have form close our but studied different finding input minimum number like finding state phase even therefore both correlations size defined random effects present local search like difficult average but these characteristics do linear time algorithm certain process computing problems solution constraint problems experimental results point problems uses statistical computational complexity complexity probabilistic analysis procedure solving problem discrete applied threshold statistical systems evidence threshold random problems theory world distributions problems
prove small sets analog neural nets observable ie their computer simulations true dynamical behavior network locally finite discrete neural networks observable without
what correct theoretical description neuronal activity analysis dynamics connected network spiking neurons spike response model shows description mean firing rates possible active neurons firing temporal correlations spike structure neural code relevant neurons into local distributed description based mean ensemble activity principle possible but interaction between different highly nonlinear description spikes should therefore
most theoretical large recurrent networks focus properties order parameters such population average statistics local may important comparison between models observed cortical dynamics neuronal correlation functions stochastic network show network state cross correlations relatively ie their amplitude relative correlations order being size population states point amplitude cross correlations order behavior critical down systems near critical point near cross correlations exhibit
stochastic optimization algorithms typically use learning rate ensemble dynamics such algorithms provides path results mean weight error asymptotic apply approach stochastic gradient algorithms show times learning effective learning rate parameter describe behavior asymptotic weight error give conditions optimal convergence speed finally use results develop adaptive form optimal convergence speed independent
presented framework two iteration performance neural networks dependent bayesian dynamics now extend analysis number input patterns applied small neurons general connectivity architectures more efficient use show optimal signal activation function has shape provide account activation functions non shape function model properties cortical neurons firing
modeling analog implementation distributed simulation neural networks present dynamics general dynamical systems defined differential equations based local times times provide results convergence dynamics dynamical systems applying results neural networks obtain conditions type neural networks
several recurrent networks have been proposed representations task language learning after training recurrent network language predict next sequence next step information processing out network have finite state machines internal state trajectories their recurrent networks paper describes initial conditions discrete measurements these methods finite state
biological neurons have variety properties because large number dependent control their activity both determine properties synapses these mechanisms circuit dynamics suggest functional circuits environment they
complex spikes difficult conventional neuronal function paper such expression more important mechanism current whose task using example important synaptic inputs layer neuron derive properties synaptic input current manner depends should
based data system propose possible mechanisms modulation control between two levels information processing use neurons but architecture first feature performed input input thus images layer more images upon
using model feedback cells show sufficient effects total activity produce power may feedback
maps orientation previous observations found basic features orientation maps well correlations between them present robust changes signals well both between finding suggests depends cortical found corresponding increase orientation orientation cells change correlations between patterns orientation present visual system still more their development may process may require visual
order best visual system should natural images processes images find these scenes ensemble scale further they highly non gaussian cannot through local linear filtering find including simple gain control filtering process makes filter output quite gaussian information fixed channel variance finally use measured power upper bound information about natural scenes array
retina simulated its biological properties study local images direct visual cells units well cells simulated computer simulated analog non spiking between cells between cells well between cells cells its space retina containing units out retina effect adaptation simulation cells necessary adaptation local
gradient descent algorithm parameter estimation similar those used continuous time recurrent neural networks derived type neuron models using potential trajectories parameters activation curves time successfully estimated algorithm applied modeling non spike neuron model three trained experimental data novel role current
provide computational description function system circuit response our simulations using backpropagation constrained feedforward network have generated directly terms activity auditory principle cells system their associated neurons
eye movements their visual attention other eye movements number other out large scale design complete system using analog cmos vlsi using low power multi chip system has been real time using real world visual inputs describe paper performance early version such system including array retina circuit computing mean location activity representing superior degree models dynamic properties
signal processing classification algorithms often have limited resulting model signals underlying structure present here efficient bayesian algorithm modeling signal distributed functions applied specific problem modeling neural unknown number action previous approaches have limited due problems spike many bayesian solution each these problems obtained probabilistic model approach uncertainty form number used obtain efficient method complex algorithm many times more information than previous methods neuronal classes interactions within neuronal circuits bayesian modeling classification neural signals
do have good understanding theoretical learning neural systems address problem computational model development sound system structure model known experimental data while learning recent work field brain computation model properties sound system makes specific predictions future experiments provides theory process
results suggest motion circuits coding components movement set internal related world computational theory has yet been proposed explain finding have proposed simple model provides framework theory low level motor learning show theory observed results model concept optimal unsupervised motor learning provides set predict optimal internal representations describe two iterative neural network algorithms find optimal solution demonstrate possible mechanisms development internal representations
design analog vlsi model neural system biological network small relatively well model therefore three levels system neuron system first models real time circuit analog neurons form multiple these using known connections thus model its biological output circuit similar output pattern model same spatial scale system provide explore real time adaptive other simple systems
transition point dynamic programming reinforcement learning direct dynamic programming approach adaptive optimal control reduce learning time memory required control continuous stochastic dynamic systems does so set transition points control action changes necessary optimal control set using learning states state space applied problem learned optimal control policy much than conventional learning able do so using less memory
recently found effective method control systems fixed points using small control method based limited linear theory requires knowledge dynamics system paper use two radial basis function networks model unknown other controller controller trained recurrent learning algorithm minimize novel objective function such controller fixed point system into fixed point knowledge system dynamics our results indicate neural controller many advantages over technique
paper describes algorithm reinforcement learning into each node network local used each node accurate statistics lead minimal times simple experiments node connected network superior algorithm based able efficiently even critical simulation such network paper between stable policies
consider problem learning through eg learning dynamics actions computation should explore trajectory through input space gives us most amount information number steps discuss results field optimal experiment design may used such demonstrate its use simple problem
describe relationship between certain reinforcement learning based dynamic programming class monte carlo methods solving systems linear equations proposed these methods solution linear system expected defined over sample markov chain our observations these monte carlo methods scale better respect state space size than do standard iterative techniques solving systems linear equations analysis convergence rate estimates because methods used systems evaluation function fixed control policy approximate solutions systems linear equations connection these monte carlo methods algorithms similar td algorithms sutton more efficient sense than other methods policies further based methods have properties these monte carlo algorithms suggests although often large problems may fact more efficient than other known classes methods capable same results
reinforcement learning methods based dynamic programming attention due their control policies systems dynamic usually markov processes but environment model known adaptive methods necessary adaptive control methods often being direct direct methods directly control policy methods model process compute control policies based model our focus adaptive based methods paper present convergence result adaptive value iteration algorithms case up table used value function our result convergence several existing reinforcement learning algorithms such adaptive real time dynamic programming although reinforcement learning has been direct adaptive methods such learning methods using td algorithms sutton these direct methods practice methods such those paper
attention has recently been algorithms based dynamic programming due learning problems control stochastic system being known theoretical account these methods has been missing paper based learning algorithms techniques stochastic approximation via new convergence theorem us class algorithms both learning
describe extension mixture experts architecture dynamical systems exhibit behavior extension based markov process model suggests recurrent network set linear non linear new architecture demonstrated capable learning effective control linear non linear multiple behavior
propose trajectory planning control theory continuous movements such connected continuous natural speech its hardware based our previously proposed forward inverse neural network computationally its optimization principle minimum criterion representation level constraints trajectory represented set via points propose via point estimation algorithm estimates via points trajectory via point experiments good found between human data trajectories generated theory finally propose recognition based movement show result recognition applied recognition extended timing estimation natural speech
paper describes algorithm input algorithm based novel artificial neural network called neural network network consists two networks their outputs during training two networks features two while neuron measures distance between two feature vectors consists feature vector feature vector representation than chosen threshold other
paper describes use neural network perform address location machine address difficult object recognition problem because often large amount because address size shape used network four outputs each trained find different address simple set rules used generate network output system performs well network bound address information cases
have developed artificial neural network based tracking system individual other require user use our system non best tracking systems accurate our experiments have been able achieve accuracy while paper present empirical analysis performance large number artificial neural network architectures task
human continuous but rather short coding regions highly variable non coding regions apply hmms problem modeling human our most interesting result so far detection particular patterns minimal regions may have significant biological sequences figure structure scale typically much than
changes conditions effect performance computer vision systems report face recognition results under conditions computer vision system uses contrast sensitive retina conventional gain both input face recognition system matching algorithm based features unknown effect analog chip retina images have been filter power retina its ability recognition rate up these experiments demonstrate analog vlsi retina image data object constant features
paper new recognition based segmentation approach line database words original input sequence forward neural networks each designed different words best first search over space possible results demonstrate method effective both dependent recognition error rate independent recognition error rate
developed system finding address process four images per second address our system machine moreover measures text noisy images analysis elements present image performed order text text address speed more than four images per second obtained hardware containing two neural net digital signal system has been tested more than images its performance depends quality images between correct location noisy images over images
usually their well their many such require change initial paper show neural network comparison applied applied problem both problems best solution set possible without them called here best choice problem paper point view architecture learning strategy backpropagation neural network used best choice problem show learning phase network finally apply neural network model real problems
has high factor tree search approach used computer long range interactions make position evaluation difficult development conventional their knowledge nature demonstrate alternative training networks evaluate via temporal difference td learning our approach based network architectures spatial both input reinforcement signals training provide these techniques far better performance than networks trained network less than weights learned within position evaluation function search low level
online recognition most pattern recognition study presents novel approach problem two first dynamic trajectory into sequence discrete motor control representation while most its components second phase these control sequences used train adaptive probabilistic important trajectories eg present new efficient learning algorithm such stochastic demonstrate its segmentation our experiments show over prior higher level language model moreover both training recognition algorithms efficient compared other modeling methods models line other
paper describes parallel computer high performance low cost effective highly parallel neural network architectures has processing elements each has memory network system single computer using language class parallel terms fast vectors variable precision
implemented using radial basis functions combination analog digital vlsi hybrid system uses analog circuits input layer digital signal hidden output system advantages both analog digital low power while minimizing system error analog circuits have been tested system has been several applications have been system application provides significantly better results problem than have been previously obtained using methods
present experimental results supervised learning dynamical features analog vlsi neural network chip recurrent network containing continuous time analog neurons free parameters connection trained generate time varying outputs given signals presented network chip stochastic algorithm error gradient along random parameter space error descent learning addition learning functions random chip provides long term parameters network learns trajectory chip cmos process
recent research has shown responses cortex may code relationships between visual features objects vlsi circuit has been designed provide phase multiple allow further neural mechanism random large phase into phase multiple target binary images described phase architecture vlsi chip has been tested architecture chip amplitude modulation output system
paper describes low power vlsi neural network called three layer perceptron synapses chip neurons cmos chip neurons variable gain per neuron lower than previous application chip classification part system measurements chip indicate per connection part system has been successfully trained classification problems
use mean field theory methods statistical derive mapping give two simple ways network these has number important network properties nonlinear function form entropy these properties should use nonlinear networks such other elements constraint implement high speed analog optimization algorithms using minimum hardware
high speed digital mean field chip general problems constraint learning each chip has neural weight update arbitrary up functional neurons chip learning theoretical maximum rate connection conditions high speed due parallel computation limited but precision weights fast several design digital vlsi constraint learning
present neural network simulation implemented parallel connection machine contrast previous work based neurons single cell dynamics high connectivity structure biological data temporal dynamics spike interactions neural networks neurons about synapses per neuron estimate performance much larger systems between neurons computationally most task present novel method has been used study visual system
most used neural network models well direct digital because each node perform large number between point values ability learn examples generalize networks type networks each node simple function networks designed such way exhibit similar properties two algorithms generate networks examples presented results show these algorithms generalize well class problems network techniques described general applied tasks known have two examples applications presented image reconstruction hand recognition
present implementation circuits first time using new functional called neuron short behavior biological neurons single level search most data memory cell array instance automatically out hardware without soft hardware change its function real time control signals without hardware implementation neural network chip self learning described through studies circuit implementation interesting similarity architectures biological systems
fast has been developed large networks spiking neurons synapses network elements designed exhibit such spiking adaptation synaptic current current inputs efficient representation allows large networks simulated time would required full model simulation corresponding analog cmos vlsi circuit have been designed so large scale circuits may simulated prior
introduce new approach line recognition words performs word level model word structure using em algorithm words into low resolution images each information about trajectory direction network network output hidden markov model word system trained minimize word level errors
present method learning tracking human hand conventional without special other view based representation used model hand relevant trained found using unsupervised clustering technique use correlation networks dynamic time temporal domain distance function unsupervised clustering computed space time dimensions distributed response combination these units input data low dimensional representation supervised classification stage uses labeled outputs temporal units training data our system real time low cost image processing
propose computational model cortex shape depth model consists four local spatial frequency frequency detection frequency over space model number observations including experiments based novel random these generated noise domain order produce specific frequency simulations range stimuli including real images show human
feature problem visual object recognition correct mapping between features measured image features expected model paper show good requires information about joint probability density over image features propose likelihood based matching general principle optimal approach non models allows nonlinear transformations missing features experiments non hand recognition support theory likelihood based techniques show almost classification performance compared performance knowledge
goal work investigate role neurons solving structure motion problem three types receptive field found area neurons et et our analysis suggests st order space differential large ratio allows both smooth fields detection objects model recent data interpolation suggest area information about object shape information about spatial necessary
address problem reconstruction particular problem near they due problem ii problem both same estimates confidence these measurements correct non our approach introduce field respect estimates confidence measures note confidence measures large larger convex ie than through local interactions via markov random fields result detection motion regions images large global
present mean field theory method objects have transformations resulting algorithm form correlation matching first consider problems matching synthetic point data derive point matching objective function line matching objective function derived each line points sum algorithm tested real images line
recent work shows mechanism based mutual information spatial system learn visual such introduce more general criterion based bayesian probability theory demonstrate connection bayesian visual other early vision methods implementation using stochastic learning described special case linear filtering derive expression output
short term memory processing time varying information artificial neural networks paper model linear presented ways include connectionist discussed comparison among different memory types what each memory model
tasks require detection target patterns non target inputs performance measure interest these tasks called figure detection rate target patterns rate range new approach training presented gradient each input pattern directly using backpropagation need during training uses network model bayesian probability functions patterns have significant effect detection accuracy over rate interest training detection accuracy points hybrid radial basis function rbf hidden markov model hmm speech
have developed visual algorithms relevant features video image speaker provide speaker independent inputs system visual features such several shape its motion manner quite conditions hybrid system two time delay neural networks video their responses means independent bayesian optimal method given conditional our data hybrid system error rate lower than speaker independent task video used improve speech recognition
new classifier presented text independent speaker recognition new classifier called neural tree network hierarchical classifier properties decision trees forward neural networks standard new learning rule based learning used classification error norm approximation error uses probability measures addition class labels several speaker experiments compared decision trees vector classifiers classifier demonstrate performance perform significantly better than other classifiers task provides retrieval time over classifier classifiers compared several speaker experiments found classifier
has been made implementation speech based data inverse dynamics model speech system trajectories signals using forward dynamics model temporal activation range constraints inverse dynamics model allows use faster speech motor control scheme applied via system dynamics future use speech recognition forward model mapping trajectories parameters improved information inputs parameter source characteristics
hybrid systems model time both using markov chain through properties connectionist network paper discuss nature time our systems using recurrent networks forward multi layer particular introduce local into produce input representation form adaptive filter approach learning temporal have recognition task using database results using input representation have shown improvement over system have been obtained through filter models
previously developed concept neural net modeling continuous speech recognition neural network state large hidden markov models hmm word more recently neural net system larger more word during following research system training context dependent models regularization method ii training ii different models into hybrid system tested both development set independent test set resulting neural net system performance level hmm system hybrid system achieved consistent word error reduction over hmm system paper describes our hybrid system optimization methods
although visual auditory systems same basic tasks about its environment most connectionist work has been different problem speech recognition most task auditory system analysis signals into components corresponding individual sound sources has called auditory scene analysis computational connectionist work auditory scene analysis general model includes these approaches described
consider problem learns control dynamics system using subjects hand environment show learning control via model dynamics properties computational elements model through generalization training data
study network learns temporal relationships within between component features account such predicted generated sequences representation note predictive recurrent network network learned transitions between within timing components values development metric structures training network developed response activation individual analysis hidden unit representation sequences represented transitions between states hidden unit space
have designed neural network successfully learns complex classification task what relevant input features classifier these features combined produce classification applications into structure adaptive system thus into underlying classification problem may well important systems performance characteristics eg backpropagation based training scheme networks into equivalent set rules achieved terms network parameters network power class rules thus during training simultaneously minimize classification transformation error real world tasks demonstrate our approach
architecture units input output represent nodes graph applied task mapping locations sets locations degree internal ie hidden unit representations global properties environment depends upon several parameters learning procedure noise learning shown important factors relationships global scale
models analog retrieval require computationally method estimating similarity between large memory vector product would possible complex structures vector representations such way similarity vector representations underlying similarity paper describes such provided reduced representations method structures fixed distributed representations conditions under similarity product discussed
non linear neural networks make network solutions difficult analysis here extended analysis networks automatically generated learning algorithm because such networks have cross connections hidden standard hidden unit activation patterns defined product output weight associated activation unit whether unit input hidden unit output target current input pattern among matrix input patterns principal components analysis pca main features such analysis applied three problems continuous comparison between two three cases technique yields useful into network solutions consistent across several networks
paper propose extension extension labeled graphs representing explicitly data well direct achieved network into analog network hidden units different defined key sufficient conditions stability associated network introduced
apply active selection time series given fixed set examples method subset training these results set being fit well desired algorithm method network complexity automatically hidden units examples generated equation dimension required about hidden units method requires order point than training set examples significantly than two selection techniques suggests active selection technique performs
new neural network binary presented its use classifier demonstrated network forward type learns examples new neurons tested problem classification performed well possible applications network associative
paper consider problem eeg signals normal subjects subjects eg using class artificial neural networks multi layer shown capable test eeg signals high degree accuracy
almost models orientation direction visual cortex based feedforward connection schemes input provides both neurons neurons response non optimal stimuli studies show up synaptic input cortical cell provided other cortical cells feedback nature cortical circuits here investigate analytically through simulations model model input while has role early direction ii neurons stimulus their receptive field among visual cortical function short term memory strong use properties visual cortical neurons compared model classical model direction does include cortical connections model explain number features direction selective simple cells including small input changes have been measured experimentally during direction model allows us response curve area neurons different their contrast response curve cortical neurons
propose computational framework understanding modeling human framework many existing theoretical yet allow simulation experiments do explain but instead what within information processing system represented information information idea explore states network computational three simulations described behavior states models behavior states similar tasks our simulations show ie states performance up noise system solution
biological systems maps input sensory information into output motor behavior evidence many research suggests their representations dependent while plasticity behavior presents system system perform well under set perform environment different negative transfer dependent change previous learning explore first question paper et al here present computational results explore question context dynamic motor learning task under conditions subjects show evidence under other conditions subjects its effects these results suggest motor learning process neural networks well learning multiple connections into architecture able account results
current understanding effects neural networks even such understanding could lead important present simple framework estimating functional resulting neural network effects varying area shape number retrieval associative memory although our results based approximations they well simulation results study important features multi including strong between number after interaction has been between multi computer studies
based computational yet direct experimental validation has been proposed system uses internal model dynamic behavior motor system planning control learning sutton et al et al present experimental results simulations based novel approach temporal propagation errors process our results provide direct support internal model
model short term memory stimuli proposed implementation type memory model presence time varying context signal coding timing addition information process associated context nodes connections showing both short long term plasticity input during context feedback during output selection via take interaction approximate analysis error probabilities due gaussian noise during output presented model provides account probability error function position length word length similarity temporal proposed point model
new model presented models between activation second formulation into artificial neural network resulting forward network provides means parameter applying learning algorithms weights network corresponding parameters trained experimental data demonstrate simulation model experimental data neurons shown our model sufficient observed data models able do task
spatial distribution time signals neurons have important theoretical practical because difficult neuronal form have developed yet approach analysis approach architecture cell space using distance metric describe theory approach illustrate its use
model presented self representations input via path performs previous region performs comparison input region comparison feedback modulation set appropriate dynamics learning new representations region network novel patterns modulation new self representations but patterns based previous representations requires synaptic regions has been demonstrated experimentally
biological neuron maps temporal signal into temporal signal action have designed network temporal mapping architecture learn perform mapping arbitrary models neurons such network trained called cell used conventional model simulations transfer function important such network simulations cell advantages over models terms computational efficiency framework vlsi biological neurons
learn through auditory motor learning have developed theoretical framework learning response properties neurons have been observed many learning suggest but provides synaptic adaptive learning computer model based reinforcement learning constructed could real accuracy based measure second model accuracy
neural network model self connections input presented self process results network weights each neuron into smooth receptive fields neurons common eye form connected connections link regions same eye similar self cortical structures has been observed experimentally model shows connections cortex may develop based correlated activity connection patterns receptive field properties such
auditory system several spatial maps over their these auditory maps visual map visual input auditory maps first convergence visual auditory information plasticity auditory maps plasticity instead auditory map into model global reinforcement signal whose visual learning rule reinforcement learned auditory maps addition reinforcement learning weights brain even weights change auditory system observation learning does have but could determined learning procedure network architecture field visual system figure view auditory
pattern changes through point small due retina present three dimensional model local cell interactions development neuronal receptive fields through two patterns interactions between due find change pattern explore critical factors determine general
data have suggested two information processing cortex short term active memory present new task computational model developed parallel task developed both these functions simultaneously set data constraints model model implemented continuous time thus natural framework study temporal dynamics processing task show model used use model make novel predictions performance reduced brain area
implement study computational model theory theory associated synaptic brain regions temporal such area cortex model associative memory neural network whose input synapses represent temporal analyze face input internal synaptic connections noise levels memory generally these changes lead retrieval without their few our results explain these leads much response
cortex represent objects particular systems propose alternative approach spatial objects cortex transformations responses single neurons gaussian function position function eye position form set basis functions show here these basis functions used generate receptive fields either simple linear transformations cortex does compute objects particular but instead general representation location eye position transformation direct representation produced should but should observed multiple single prediction several experiments
many cells part superior temporal area visual cortex patterns specific previous have suggested these cells may represent self motion patterns generated relative motion particular object cell may account complex field set active cells could manner moving objects such scenes containing several independent moving objects motion describe model based hypothesis selective cells object components motion inputs model generated sequences images simulated motion motion eye movements independent object motion input representation after response properties neurons area provides input area after applying unsupervised learning algorithm units patterns motion results many known properties cells consistent recent studies these cells process object motion information
theoretical computer abstract investigate computational power model networks spiking neurons both assumption timing precision case limited timing precision prove upper lower bounds number examples train such networks
derive global optimal training algorithms neural networks these algorithms possible prediction error energy over possible fixed energy therefore robust respect model statistical information signals dimensional sense weight vector estimate requires knowledge previous weight certain finite dimensional approximation these backpropagation algorithm local backpropagation has been previously demonstrated
novel class locally networks proposed model each standard two time scales network mechanism selective up its active phase same pattern while up show analytically selective mechanism network both within connected regions between different computer simulations demonstrate networks ability multiple input patterns real time model correlation theory feature may provide effective computational framework scene segmentation
present new method response function its average most properties learning generalization linear derived first known results limit perceptron size show explicitly self limit discuss our method more general learning space input distributions weight terms finally use our method finite order discuss corresponding finite size effects generalization learning dynamics important off observation results obtained limit often directly relevant systems real world
discuss model consistent learning additional probability distribution training samples target concept hypothesis class show model provides significant improvement upper bounds sample complexity ie minimal number random training samples selection hypothesis accuracy confidence further show model has potential finite sample complexity even case dimension well sample complexity dimension achieved sample complexity average number training sample rather than size sample ie dimension
learning continuous functions using neural network give improved accuracy estimation generalization error active learning defined output ensemble over data so among networks discussed use combination cross validation give estimate ensemble generalization error type ensemble cross validation improve performance shown estimate optimal weights ensemble using data generalization query finally shown used new training data labeled active learning scheme
random errors limit performance classifier trained applied database paper propose method estimate performance classifiers database demonstrate technique task
neural network learning based information theory proposed way perform reduction among elements output layer without loss information sensory input model developed performs nonlinear up higher results independent components output layer means need gaussian distribution input output theory presented related unsupervised theory reduction goal nonlinear units used nonlinear principal component analysis obtained case nonlinear reduced minimum dimension such units used network performs generalized principal component analysis sense non gaussian distributions higher correlation taken into account basic structure architecture involves general transformation therefore entropy map without loss information minimization mutual information among output neurons between outputs results statistical features known learning
using statistical evidence error measure linear trained tested set examples generated non linear because model without error our model allows us between known case linear nonlinear comparison evidence those performance measures non linear case evidence procedure performance finally explore evidence procedure find being optimal might useful method
paper presents general nonlinear learning machine during training process trained random sample using gradient descent algorithm based reduction training error shown particular best generalization performance general global minimum training error achieved different complexity machine class complexity specific machine class during learning
present here analysis stochastic neural network three state neurons described equation product representation equation representation extension analysis two three state neurons easily performed apply approximation schemes simple three state network compare results monte carlo simulations
present statistical method learns class stochastic arbitrary activation function weights probability distribution input examples family call distributions such distributions represent important step case each input variable independent family markov distributions order stochastic perceptron mean perceptron upon input vector outputs probability because same algorithm activation function domain well studied cases radial basis functions
supervised learning learning rather than random examples improve generalization performance significantly study performance query learning problems cannot learn practice consider linear perceptron learning binary perceptron two maximum information gain ie minimum entropy minimum space entropy appropriate space unknown minimum space entropy used space known but form has been chosen find structure space query learning lead higher generalization error than random examples due feedback about way
consider effect several least expected performance regression problem computing exact bias variance curves function sample size able compare effect combination bias variance thus expected error sum two our exact demonstrate combination useful case data set small noisy function learned large data sets single estimator superior results finally show data set into several independent parts training each estimator different subset performance cases significantly improved key words bias variance least combination
performance line algorithms learning studied line learning number examples equivalent learning time each example presented learning curve generalization error function depends learning rate target rule learning curve algorithm fast target algorithm does generally converge solution generalization error case due simple output noise propose new line algorithm perceptron learning curve approach optimal generalization error fast generalize perceptron algorithm class smooth functions learning target class well input distributions algorithm optimal solution its learning curve fast
paper use artificial neural networks dynamic time series prediction more appropriate capture dynamics underlying dynamical system because model show method implemented recurrent trained trajectory learning show trajectory length train case time series experimental results proposed method
propose novel approach analysis unsupervised learning network behavior model determined underlying nonlinear dynamics set parameters rule density synapses these parameters determine presence specific receptive field connection pattern fixed point model paper perform analysis underlying nonlinear dynamics over parameter space determine effects system parameters various receptive fields predict within parameter network have potential develop connection pattern particular approach first time role synaptic density functions provides complete parameter space relationships among different receptive fields our theoretical predictions numerical simulations
estimate number training samples required performance neural network its training data obtained data applied network existing estimates higher than practice work between theory practice problem into distribution random field space weight vectors application recent technique called
study asymptotic properties sequence weight vector estimates obtained training feedforward neural network basic gradient descent method using fixed learning constant processing case exact analysis distribution gaussian general general case small learning constant approximation application results theory random matrices distribution study first few distribution compare contrast results our analysis those techniques stochastic approximation
attention has been reinforcement learning algorithms recent due theoretical analysis their behavior markov markov assumption generally algorithms propose analyze new learning algorithm solve certain class non markov decision problems our algorithm problems environment markov but has state information algorithm involves monte carlo policy evaluation combined policy improvement method similar markov decision problems converge local maximum algorithm space stochastic policies space policy performs better than deterministic policy although space stochastic policies continuous even discrete action space our algorithm computationally
use more representations than scaling reinforcement learning algorithms real world problems almost theory reinforcement learning table representations paper address function approximation present function based simple extension state used form representation soft state theory convergence arbitrary but fixed soft state novel understanding effect state online new adaptive state algorithm improved representations non discrete nature soft state empirical results presented
approach dimensionality reinforcement learning dynamic programming table function such neural net although has been domain convergence paper show combination dynamic programming function approximation robust even cases may produce policy introduce support new algorithm yet still generalization
reinforcement learning problem learning actions order performance unknown scale reinforcement learning complex real world tasks such typically studied able structure world order abstract more problem spaces paper presents algorithm defined action policies context multiple related tasks whole action sequences into single they learned minimizing action policies using description length their representation empirical results simple grid tasks illustrate structure reinforcement learning
semi decision problems continuous time discrete time markov decision problems number reinforcement have been developed recently solution markov decision problems based dynamic programming stochastic approximation among these td real time dynamic programming after semi decision problems equation context propose those above solution semi markov decision problems demonstrate these algorithms applying them problem optimal control simple system under these algorithms may applied
prove convergence algorithm equivalent learning its achieved values within policy value function algorithm novel two ways updates most action given state using relative probability action
basic learning neural networks learning examples training set input output examples used network target function learning generalization learning examples additional information about target function same learning process such information common sense rules special applications training data noisy use such have advantage demonstrate use us over explain general method learning applied other learning model method neural networks
paper weighted combination functions dependent input show functions derived either input dependent variance each estimator estimating given estimator has data region input space close input pattern solution related mixture experts approach show learning rules mixture experts derived theory about learning missing features presented approaches functions easily more furthermore derived data such systems algorithms
introduce recurrent architecture structure training procedure based em algorithm resulting model has hidden markov models but recurrent networks processing allows supervised learning while using maximum likelihood estimation
propose statistical framework modeling discrete time series maximum likelihood estimation via learning dimensional networks weights call these networks show they hidden markov models hmms special case our framework new architectures address particular hmms two such architectures parallel model feature sets time scales networks model long term between hidden states these networks show implement learning rule polynomial time without simulated mean field necessary exact statistical
data much data points sequential way bayesian decision framework develop query selection criterion explicitly takes into account use model predictions markov chain monte carlo methods necessary desired precision number data points model complexity bayesian model selection strategy properties two criterion demonstrated numerical experiments
pairwise data difficult optimization problems known scaling pairwise data clustering algorithms data set space clustering these data data support clustering process discussed maximum entropy framework active data selection provides strategy structure data set efficiently unknown data
new learning algorithm derived performs online stochastic gradient mutual information between outputs inputs network knowledge about signal noise components input propagation information depends network non higher order input density functions mutual information between outputs well their individual network input into independent components example application have achieved near separation speech signals our simulations lead us our network performs better separation than network fact derived mutual information objective
between nodes competitive learning network achieved through basis neural activity simple mechanisms limited sparse representations while schemes support distributed representations computationally neural plasticity competitive interaction instead obtain fully distributed representations use technique improve our binary information gain optimization algorithm feature same approach could used improve other learning algorithms
existing recurrent net learning algorithms introduce framework recurrent training matching vector fields dynamical systems phase space reconstruction techniques make hidden states temporal learning forward problem short propose prediction best way training recurrent networks deterministic signals using framework train multiple trajectories their stability design arbitrary dynamical systems
dynamic cell structures represent family artificial neural architectures both unsupervised supervised learning they recently introduced class representing networks feature maps learning rule competitive learning type learning rule synaptic weight vectors while learning dynamic connection structure between units feature case supervised learning ie function approximation each neural unit radial basis function additional layer linear output units according rule first rbf based approximation scheme learn map improved performance simulations selection indicate idea applied cell structure algorithm leads efficient algorithm conventional models similar tasks
although artificial neural networks have been applied variety real world they have often been low degree human techniques sets rules out artificial neural networks neural network representations paper presents approach rules artificial neural networks its key mechanism analysis knowledge rule like knowledge through backpropagation neural networks empirical studies robot domain illustrate proposed method rules networks real distributed representations
have determined capacity information efficiency associative net brain like way partial connectivity noisy input cues theory used capacity pattern achieved using strategy sum according input activity unit increase capacity associative net under these conditions sparse patterns maximum information efficiency achieved low connectivity levels level connectivity brain brain connected most information efficient way
radial basis function rbf networks known networks locally processing units see well known their use most algorithms used train these types networks require fixed architecture number units hidden layer determined training training algorithm introduced see its probabilistic extension algorithm take advantage structure hidden units introduced necessary nature these algorithms allows training stability much faster than case gradient descent based methods networks do standard their using global value parameter paper dynamic algorithm nature algorithm together independent adaptation each factor addition radial class dependent between different shown networks trained presented algorithm perform better than common rbf networks
present new algorithm finding low complexity networks high generalization algorithm large connected regions so called error function weight space environment minimum error constant using based shown low expected overfitting although our algorithm requires computation second order has order complexity experiments feedforward recurrent nets described application prediction method conventional weight optimal brain
product units provide method automatically learning higher order input required efficient learning neural networks show problems using backpropagation train networks containing these units paper these problems improve learning using these method introduced well problems significantly less neurons than previously reported product units implemented units correlation system networks trained faster than using gaussian units
present deterministic em algorithm maximum likelihood parameter estimation problems our approach em process problem minimizing free energy using principle entropy statistical simulated approaches minimization performed moreover derived algorithm conventional em algorithm obtain better estimates free initial parameter values
paper studies problem models such hidden markov models hmms makes difficult task learning long term sequences using results markov chain theory show problem reduced transition probabilities approach under condition standard hmms have limited modeling but hmms still perform interesting
introduce novel algorithm learning segmentation problems computational vision underlying factors clusters highly correlated input features algorithm new competitive clustering model cluster explain each feature data set explain each input example rather than examples features traditional clustering algorithms natural extension algorithm hierarchical models data generated multiple unknown each different multiple causal structure several simulations demonstrate power approach
paper presents minimization algorithm used training radial basis function linear networks algorithm small step point method used solving linear algorithm has convergence rate iterations measure network size measure resulting solutions accuracy two results presented two steps may convergence each step minimization
self neural network sequence classification called described experimentally feature map architecture activation order distributed response patterns different sequences yields yet representations sequential input few training iterations network has mapping arbitrary sequences binary real well representations words potential applications include word recognition models sequence processing
paper studies convergence properties well known means clustering algorithm means algorithm described either gradient descent algorithm em algorithm threshold case show means algorithm error using fast algorithm
develop strategy sample function function approximation tasks within bayesian framework using optimal experiment design introduce objective function both bias variance measure degree approximation potential data points objective show general strategy used derive algorithms data two cases learning unit step functions polynomial functions particular investigate whether such active algorithms learn target examples obtain theoretical empirical results suggest case
understanding knowledge representations neural nets has been difficult problem principal components analysis pca connection weights has into knowledge representations but much work has correlation matrix present work shows variance covariance matrix yields more account weights
neural network weights terms behavior network domains description may lead more robust generalization present approach rule based weight regions weight space corresponding specific appropriate choice representation show parameters may efficiently optimal units weights application domain our method arbitrary complexity simple complexity more general class complexity number inputs unit our method rule several over alternative approaches simulation results variety problems demonstrate its
many real world learning problems best interaction multiple independent factors such causal structure data focus paper based vector architecture unsupervised learning algorithm derived expectation maximization em framework due nature data process exact step computationally two alternative methods computing step proposed sampling mean field approximation empirical results presented
network model introduced able learn important given set input vectors means simple like learning rule contrast previous approaches like neural method model has parameters change over time able learning units connections performance criterion has been applications model include vector clustering interpolation
propose alternative model mixtures experts uses different parametric form network model trained em algorithm comparison models trained either em gradient need learning report simulation experiments show new architecture yields faster convergence apply new model two problem domains nonlinear function approximation combination multiple previously trained classifiers
most common techniques estimating conditional probability applications variables paper introduce three novel techniques such problems investigate their performance using synthetic data apply these techniques problem distribution vector data
introduce study methods synaptic noise into recurrent neural networks show applying amount noise during training may improve convergence generalization addition analyze effects each noise parameter non per time step per predict best performance achieved noise each time step simulations learning temporal these predictions
proposed generalization artificial neural nets should improve nets learn represent domains underlying work shows outputs net used inputs through information given net extend these showing net learning many related tasks same time use these tasks bias each other thus learn better identify mechanisms generalization give empirical evidence better real domains
present graph based method accurate search through transformation invariant pattern classification our method has theory same recognition accuracy other recent methods based distance et al uses same rule significantly faster during classification because far need computed our system novel graph architecture transformation constraints relationships among during learning improved graph search criterion used during classification these wide range problem domains here demonstrate recognition task basic implementation our system requires less than computation method
paper derive classifiers take approximations bayes classifier gaussian mixtures class conditional derived classifiers include clustering based algorithms like means propose constrained gaussian mixtures model derive algorithm our experiments two speech classification tasks indicate constrained model approximations improve performance over models
present efficient algorithms problem missing inputs feature vectors during training our approach based approximation input data distribution using obtain form solutions arbitrary feedforward networks training show backpropagation step pattern weighted backpropagation step complexity solutions training independent number missing features our theoretical results using classification regression problem
many different discrete time recurrent neural network architectures have been proposed has been compare these experimentally paper many these architectures compare they perform various classes simple problems including inference nonlinear system
prior constraints upon learning problem form distance measures point sets graphs learned clustering point matching graph matching distance measures point matching distance measure invariant under scale between noisy images missing points graph matching distance measure weighted graphs invariant under learning optimization problem large so variables efficiently using combination optimization techniques transformations iterative scaling deterministic
paper application temporal difference td learning sutton behavior dynamical systems outputs like performance td learning comparison standard supervised learning depends amount noise present data paper use deterministic time series low noise task direct step predictions our experiments show standard supervised learning better than td learning td algorithm predictions similar effect obtained internal representation network thus compare two architectures both first architecture hidden units consists individual networks each direct multi step prediction tasks second hidden units has single larger hidden layer representation predictions next steps generated data set do find significant difference between two architectures paper time
vlsi neural network has been designed tested perform classification tasks techniques chosen power area system neural network architecture noise approaches network multi layer perceptron chip digital weight input network has take circuit output network trained signal processing path system has successfully different better than true positive true negative cannot present chip implemented cmos less than maximum average power area
present model shows based neural correlations across both space time circuit number features its biological including threshold after amplitude provide simple circuit present data chip standard cmos process through implementation time stable propagation
describe analog vlsi implementation algorithm chip has been standard low cost single cmos process has area chip version original architecture such has been shown computational properties original algorithm while being more appropriate vlsi chip network nodes nodes therefore cluster binary input patterns into up different system possible array without resulting layer nodes layer nodes pattern classification performed less than means equivalent computing power connections connection updates per second although chip analog nature world through digital signals thus true digital behavior experimental chip test results available have been obtained through test digital
novel two layer between non memory action synaptic weights chip previously used dynamic weight two different discussed results presented
present analog vlsi chip parallel analog vector cmos chip array based distance estimation cells mean difference metric input analog vector field analog vectors distance cell including dynamic measures chip features take output circuit linear complexity global positive feedback fast single output experimental results complete system demonstrate correct analog input dynamic range time power
orientation various novel interesting environment critical ability superior role behavior responses visual auditory stimuli sensory information different should represented same auditory cues particular computed based paper analog vlsi implementation auditory described architecture proposed eye movement system further transformation required transformation model auditory cortical areas superior system analog vlsi based eye movement system being constructed our
consider problem data using dynamical system out algorithm codes show implement recurrent neural network using simple but highly nonlinear analog circuit models neurons synapses nonlinear system has many fixed points but have our procedure parameters such way solution desired solution stable partial concept present experimental data small system neuron analog cmos chip analog well process chip each choice parameters stable state each state shape
have our study parallel learning method et al its implementation analog vlsi our new results indicate most cases single parallel per pattern function parameters weights neural network best true certain problems may generally true implementation such limited precision these cases multiple parallel may best our previous results
paper describes way neural hardware implementation analog digital neural chip full neural vlsi artificial neural used implement speech recognition system multi layer perceptron linear neurons trained successfully under limited accuracy network large input layer tested words forward retrieval hardware suggested more extended performance capacity ii
describe single synapses compute learn provide non memory single synapses simultaneously perform long term weight compute product input weight value update weight value according backpropagation learning rule memory via long term synapses efficiently use perform weight updates weight value using weight value using small size low power single synapses allows development synaptic describe design modeling array single synapses state source current used representation weight value both functions power source current synaptic array standard analog process available
appropriate representation use modeling human auditory processing critical auditory while have successfully performed many single speaker tasks methods more difficult problems need representation paper describes auditory representation known shows non linear representation back into sound loss important information interesting because representation sound paper shows improved methods conventional pattern model representation
paper consider speech coding problem speech particular prediction speech over short time performed using hierarchical mixture experts gives two advantages over traditional non linear function such multi layer statistical understanding information about performance form likelihood information local error these two both real world problems regression time series prediction speech coding context extend principle local predictions via vector scheme fixed local combined line each observation
system hand speech through adaptive hand control parameters parallel speech mapping allows hand artificial speech real time gives addition direct control frequency best version uses several input including space parallel speech neural networks speech task into using network weight outputs neural network network network trained examples user network fixed user defined relationship between hand position sound does require training examples user frequency produced fixed mapping input has trained speech quality similar text speech but far more natural
paper presents work speaker independent visual speech recognition system work presented here previous research area potential use simple hidden markov models limited speaker independent visual speech recognition task hand recognition first four task possible applications images mixtures independent gaussian distributions temporal standard left right hidden markov models results indicate simple hidden markov models may used successfully relatively image sequences system achieved performance levels equivalent first four
paper hierarchical mixtures experts method probability estimation developed into continuous speech recognition system resulting system continuous density hmm system but instead using gaussian mixtures system large set but relatively small neural networks perform probability density estimation hierarchical structure decision tree two important each neural net performs soft decision rather than decision decision trees parameters neural nets automatically using em algorithm report results word word using models
paper presents speaker technique based neural network spectral mapping neural network used continuous speech recognition system hmm based input data new speaker spectral difference between reduced using limited amount new data recognition error units continuous speech ratio used local basis networks gaussian kernels units line optimization parameters model application model linear term results compare linear mapping based constrained transformations
speech provide good performance most but error rate often small different those used training solution problem more training data sample these second solution paper number training speech existing training approach similar training set recognition training images but more difficult because continuous speech has much larger number dimensions eg temporal spectral across use simple linear spectral training data used word average detection rate points points increase small but similar obtained amount training data
present view discrete time models used context finite word length linear signal processing made between recently presented model models nonlinear system prediction using neural networks new model based adaptive transformation above models presented
describe framework learning eye movements using representation target points natural scenes representation takes form high dimensional vector responses spatial filters different scales first demonstrate use response vector task previously points scene use property strategy derive adaptive motor map accurate
describe system hand sequence video hand user independent manner system hand each video hand tracking system able hand within its correct location test set containing video sequences different different recognition network hand being test set system has been designed real time existing hardware
describe framework real time tracking uses correlation interpolation methods distributed view based representation used state computed using correlation network ensemble response set view correlation input network based interpolation method maps perceptual state motor control states simulated face model activation levels motor state derived model fast robust processing models obtain system able complex real time
perceptual learning defined fast improvement performance learned ability over time set experiments demonstrated perceptual learning discrimination direction stochastic motion stimuli here model learning using two approaches clustering model learns motion noise model learns noise simulations models show performance similar results
paper dynamic theory development adaptation neural networks feedback connections given input ensemble connections change according associative learning rule approach stable state neuronal outputs apply theory visual cortex dynamical orientation selective cells connections theory gives experiments orientation contrast orientation adaptation using parameter achieve good between theoretical predictions experimental data
paper presents new method image neural networks first show use neural networks framework so called pca present image method based pca similar experimental results real images reported finally present method step learning pca
paper presents unsupervised learning scheme objects their images scheme associative networks ability each view single object into representation its view direction propose two models different classification mechanisms first model associative network whose view best input view second model based architecture whose additional network input space demonstrate proposed classification models through simulations using objects
problem computer vision between two sets points space solved novel robust easily algorithm technique noisy point sets may may non transformations between point sets related transformation scale objective problem derived mean field theory objective em like dynamics experiments both synthetic data provide empirical evidence method
problem between images image sequence simple but important task model based vision describe approach based abstract task learning present results both synthetic real image sequences problem development combined speech recognition system
efficiency image search improved using search strategy multi resolution image representation resolution so low objects have few features search difficult show performance search such low improved using context information ie objects low resolution objects interest but associated them networks given context information inputs they learn context objects case user does have their use feature represent high frequency information low use search techniques allows us information about objects many scales efficient way natural selection these techniques illustrate these training hierarchical systems neural networks find clusters
performance nearest neighbor classification schemes recognition improved specific transformations underlying distance metric so called distance resulting classifier memory due large amount need used distance paper develop models representing large these models either used per class basic means clustering algorithm work performed while statistics data analysis research
paper presents results first use neural networks real time feedback control high experiment principal experimental research into approach up strong fields accurate control position shape requires real time feedback control field structure time scale few simulations have demonstrated neural network approach give significantly better performance than linear technique used most experiments practical application neural network approach requires high speed hardware fully parallel implementation perceptron using hybrid digital has been developed
construct mixture locally linear generative models based images use them recognition different models given used capture different new images their log under each model use em based algorithm step computationally principal components analysis pca information about expected local requires vectors into sample covariance matrices pca performance
theory optimal unsupervised motor learning shows network reduced order controller unknown nonlinear system representing most significant here extend theory apply sequences so most significant components network motion these used produce wide variety different movements demonstrate applications human decomposition well analysis experiments movements resulting
study neural network control architecture nonlinear dynamic systems presented most recent neural network control field has error feedback control input adaptation problem architecture paper forward control error feedback adaptive control using neural networks paper different internal these two neural network certain input eg state feedback error feedback error feedback neural network learn respect error feedback error adaptive systems results demonstrate two control scheme combined their individual advantages shows good tracking adaptation neural control architecture
each amount time text type typically amount due word patterns structure paper describes neural network system call what next most word single instead its multi layer perceptron its predictions text word pattern characteristics text being speed code have been demonstrated using system potential time more than per user per addition speed number user type similar amount computer has potential significantly reduce frequency most common environment
text neural network used approximate conditional probability distribution possible next given previous outputs into standard coding algorithms generate short codes high predicted probability long codes highly tested short our method used algorithms used functions such
experiments demonstrated perceptron networks provide better risk prediction than conventional regression used predict risk networks hidden layer networks hidden layer trained using stochastic gradient descent early networks regression used same input features using sampling areas using input features regression networks regularization provided early important component improved performance approach generating confidence intervals risk predictions using confidence developed confidence trained confidence intervals generated during training using outputs networks trained different samples
system has been used early predict increase accuracy many factors have been because stage model these new factors factors has lead what required new system test factors predictive factors variables order increase accuracy using area under curve compare accuracy following predictive models terms specific system principal component analysis classification regression trees regression correlation neural network gradient descent neural probabilistic neural network backpropagation neural network several statistical models significantly more than system regression backpropagation neural network most accurate prediction models specific
paper presents learns learns evaluation functions represented artificial neural networks neural network learning temporal based learning performance results illustrate approach
human machine missing data problem many variables unknown additional information obtained joint probability distribution data used solve problem model mixture models whose parameters estimated em algorithm gives missing data database new information performed using maximum principle system based learning domain independent less than systems probabilistic networks example using database presented
applications data often used basis training pattern recognition algorithms generate maps objects interest practical experts may images provide noisy estimate bias non problem paper discuss our recent work context small images empirical results using expectation maximization procedure suggest noise quite significant terms both human algorithm detection performance
paper present connectionist system independent large line recognition system robust input representation dynamic information neural network architecture so called multi state time delay neural network recognition segmentation single framework our original sequence into still temporal sequence feature vectors local features like direction like representation architecture well temporal sequences provided input representation our system tested both dependent independent tasks up words example word achieve word recognition rates up dependent independent without using language models
machines perform classification tasks such speech recognition patterns key high performance presents new type classification system adaptive input field neural network includes simple trained neural network input field input layer using iterative method determine optimal input field original convergence algorithm shown applied recognition patterns total performance improved without neural network
multi class classification problems efficiently solved original problem into problems two classes each classes small neural network trained using data these two classes show outputs two class neural networks order obtain posterior probabilities class resulting probabilistic pairwise classifier part recognition system applied present results real world data show practical point view these results compare other neural network approaches
experiments performed computational properties human motor memory system show practice movements while novel environment they learn internal model inverse dynamics environment subjects show model after initial practice representation internal model memory such learn new inverse dynamics map after mapping learned suggest same computational elements used first inverse dynamics map being used learn second mapping predict leads learned
properties both neural networks system ability learn generalize examples while property has been studied neural network has been human perceptual motor learning have chosen transformation system map visual into motor study generalization effects learning new input output pairs using computer visual feedback have studied generalization map both local context dependent local two input output pairs significant global yet change map representation map units large functional receptive fields our study context dependent single point visual space two different locations context variable point movement furthermore context between two consistent two being learned context
clustering similarity two stimuli weighted measure their common features recent work unsupervised learning multiple models propose new well algorithm structure natural stimulus classes using model practical efficiency solution quality over present results artificial data two similarity data sets
have recently developed theory spatial representations position object particular but instead involves neurons computing basis functions their sensory inputs type representation able perform nonlinear transformations consistent response properties neurons now whether same theory could account behavior human these known stimuli simulated basis function representation found three most important models cross line experiments ii multiple could object these results support basis function hypothesis spatial representations provide computational theory single cell level
significant neural networks representations they learn usually present novel algorithm representations trained neural networks our algorithm uses decision tree concept represented given network our experiments demonstrate able produce decision trees high level their networks while being accurate previous work area our algorithm general its scales well large networks problems high dimensional input spaces
attention means goal behavior non dynamics attention should two long term transition these two characteristics within linear domain propose near behavior unit self connection dynamical mechanism both these further show simulations tasks near node behavior recurrent networks functional property
choice input representation neural network have its accuracy novel neural networks typically computationally train making difficult test large alternative representations paper fast quality measures neural network representations estimate possible representations problem best show our measures representations more accurate than previously measure based experiments three difficult real world pattern recognition problems
feature sensory processing ability focus part signal interest against signals able direct focus paper problem auditory scene segmentation considered model early process proposed model shown number well known results principal model might result interactions between patterns activity input signals previous activity feedback way signals
have relationship between correlated spike cross correlation spike pairs simultaneously neurons previous study area et al common input order wide spike train cross correlation spike observed two second time scale both common may significant correlation
while generally neurons information about their synaptic inputs through spike code information well upper bound information obtained timing each spike information here develop general approach information spike under hypothesis apply model neuronal dynamics problem terms probability distribution intervals spikes arbitrary but finite temporal resolution noise could information information rate entropy distribution times spike rate thus provides exact expression information rate methods developed here used determine experimentally information spike even lower bound information rate provided stimulus reconstruction method series experiments have used these methods estimate information rates neurons response current these experiments suggest information rates high information rate spike cortical neurons use spike other neurons output each neuron stochastic function its input other neurons interest much each neuron other neurons about its inputs much information does spike train provide about signal consider noise signal st produce total input st through stochastic functional produce output spike train assume information spike train represented spike times information properties such spike note many characteristics spike train such mean rate derived representation such property out relevant formulation mutual information between input signal ensemble st output spike train ensemble defined terms entropy signal entropy spike train their joint entropy note mutual information symmetric joint entropy note signal st spike train independent mutual information joint entropy sum individual line our case spike train provide information about signal information estimation through stimulus reconstruction et al have used reconstruction method obtain lower bound mutual information experimental setting method based expression equivalent eq conditional entropy signal given spike train upper bound conditional entropy obtained reconstruction signal entropy estimated second order statistics reconstruction error et st maximum entropy property gaussian upper bound first equation information about spike train stimulus initial uncertainty signal knowledge spike train uncertainty about signal spike train known second equation second uncertainty particular estimate than optimal estimate information estimation through spike train have different approach based equivalent expression mutual information first term entropy spike train while second conditional entropy spike train given signal like inverse spike train given applications same signal eq has advantage spike train deterministic function input exact mutual information important difference between conditional entropy term here eq has both deterministic stochastic component has stochastic component thus noise discrete entropy eq independent terms entropy discrete distribution log information through spiking neuron number spikes here probability spike assumption finite timing precision potential information finite advantage distribution rather than full spike train distribution while estimating requires much less data under what conditions independent correlations between either through stimulus spike mechanism correlations do spike model information about previous spike next spike further limit stimuli ie stimuli noise ensemble independent eq applied presence noise give conditional entropy given signal probability response particular stimulus presence noise conditional entropy spike generating mechanism average spike train generated response applications same stimulus maximum spike train entropy what useful compare information rate neuron case exponential distribution has maximum entropy point process given rate provides upper bound information rate possible spike train given spike rate temporal precision exponential distribution mean spike rate temporal precision log rate example gives spike train into possible more than reduce size two rate log while note different firing rate eg size still but because spike rate high increase information rate model now consider functional model spike noise signal st st threshold sum produce spike train st neuron time constant both have gaussian distributions has mean variance threshold time neuron spike time initial condition language model case neuron spike generating mechanism many synaptic inputs note input correlations spike train signal neuron after each spike correlations mechanism thus independent eq applied estimate mutual information between ensemble input signals ensemble outputs model independent need evaluate determine distribution conditional distribution ensemble signals note first time distribution process neuron model has two determined asymptotic potential threshold threshold threshold even signal variance zero threshold limit et ie mean firing rate low compared time constant distribution exponential its low rate firing mean more neuron stochastic firing rate parameter probability firing over depends stimulus ie st present case exponential distribution deterministic mechanism between these threshold equal asymptotic potential have exact solution distribution et al special case potential its interpretation inputs inputs so neuron firing information rates noisy signals here compare information rate neuron point maximum entropy spike train consider zero noise case ie fig shows information per spike function firing rate eq signal variance assume spikes temporal resolution ie distribution has wide line shows theoretical upper bound given exponential distribution limit neuron far threshold limit both model upper bound information per spike function spike rate model almost upper bound mean equal time constant model information low firing rates but exponential distribution information without bound high firing rates information zero firing rate fast individual temporal resolution fig shows information rate information per second neuron point through information through spiking neuron maximum firing rate maximum lower firing rate than exponential distribution line information rates stimulus reconstruction eq gives exact expression information rate model therefore compare lower bound provided stimulus reconstruction method eq et al lower bound provides fig shows lower bound provided reconstruction line line methods function firing rate firing rate mean input stimulus noise set low firing rates two estimates but high firing rates reconstruction method information rate amount depends model parameters noise stimulus bound therefore empirical question while show under conditions their experiments less than factor two potential under different conditions different systems while generally spike information about neurons inputs information idea mean firing rate signal about mean noise alternative view signal ie information times spikes view information terms distribution spike train scheme yields much higher information rates than mean rate over than considered here have information spike under hypothesis simple neuronal model consider model independent so information rate computed directly information per spike spike rate information per spike depends temporal precision spikes precision information would well could example arrival time single spike spike mechanism entropy distribution low firing rates neuron limit distribution close exponential distribution much recent interest information neural code work et al et al measured information rate sensory neurons number systems present results those considered information rate linear threshold model developed functional first term describes limit spike times independent second term correlations model present model does after each spike natural model gaussian signal noise filter times resulting threshold called spikes representation spike train model sequence firing times while model natural representation sequence choice two representations equivalent two models model results obtained signals noise while such conditions model model contrast class highly correlated spike considered model condition required model less than independent spike condition model spikes independent distribution exponential particular high firing rates distribution far exponential therefore spikes far independent even independent because have input st its entropy mutual information without bound temporal precision spikes spike train total available information signal capacity spike train while whether real neurons cortical neuron many synaptic inputs information rate each input same target information rate upon target synaptic could than its capacity series experiments have used method estimate information rate neuronal spike response current under these conditions independent so method developed here applied these experiments information rates high observed de neural code optimization neural code neural information processing systems probability random variables stochastic processes de neural coding highly firing cortical cells temporal random solutions stochastic model neuronal spike
maps areas cortex result training nature consistent competitive neural networks has been demonstrated computer simulation model training hand representation cortex using neural field theory changes both receptive field size factor derived consistent experiments make prediction them
images retina during gain ratio eye typically target images gain context eye position eye first describe model sensory information available neural eye position propose dynamical model compare eye responses measured dynamical model observed amplitude time modulation suggests way required neural signals within brain makes predictions responses neurons multiple inputs eye position system
extended version constraint model motor presented includes activity dependent independent wide range recent evidence strong relationship between synaptic computational model level its predictions real synapses
neuron model output rate process time varying rate parameter function stimulus neuron gives firing rate probability firing output stochastic function input part because its model used usually addition single unit studies st usually taken value sensory stimulus neuron model contrast output function input input through low filter determined time constant potential threshold point its initial value contrast model model deterministic function input although model real neural dynamics many features often used point behavior single neurons here show model derived model noisy inputs st model transfer function whose shape determined noise variance understanding between simple neuron models may between two levels
computational model learning learns different uses train model computational learning shows competitive learning may lead specific brain results previous model perceptual learning through reinforcement learning
eye particular using basic theory differential various related through transformations between systems computed using next describe means so us demonstrate direct connection showing eye space equivalent space our analysis provides framework system could extended investigate multi joint movements
detection requires auditory signal processing high temporal precision present model spike processing auditory shown temporal precision range achieved neuronal time least important feature our model unsupervised learning rule leads temporal neuronal connections temporal coding range model auditory
selective feedback synapses during learning proposed mechanism associative feedback self feedforward synapses experimental data synaptic layer feedback synapses layer feedforward synapses network feature uses local rules learn during learning sensory stimuli desired response simultaneously presented input feedforward connections form self representations input while feedback connections feedforward connectivity during sensory input self representation activity learned response
present hypothesis about could movement presence significant feedback without forward model motor show model learn control nonlinear system both models involves prediction but instead sensory input directly movement input patterns include sensory feedback
because distance between brain their different eeg data point human includes activity generated within large brain area spatial eeg data does significant time independent component analysis ica algorithm source separation eeg data ica algorithm problem source source first results applying ica algorithm eeg related potential data during auditory detection task show ica training different random ica may used eeg components line noise eye movements other sources ica capable eeg including components ica channels eeg state using ica via changes amount correlation between ica output channels
visual systems different whether certain functional properties receptive field mechanism such example here shown artificial neural network learns difference furthermore input pattern noise hidden units signal noise ratio same dependent plasticity present real visual neurons cells retina shown here experimentally well large cells eye described plasticity shown present responses these artificial biological visual systems thus spatial temporal filtering properties wide variety see world changes space time
paper problem learning appropriate domain specific bias shown achieved learning many related tasks same domain theorem given number tasks theorem tasks known common internal representation number examples required per task good learning tasks simultaneously scales like bound minimum number examples learn single task bound number examples required learn each task experiment strong support theoretical results reported
statistical theory proposed analysis stochastic neural networks trained loss asymptotic case shown asymptotic gain generalization error small perform early even have optimal time cross validation question what ratio examples should into training sets order obtain performance non asymptotic region cross early generalization error our large scale simulations our
study characteristics learning solving simple model ensemble linear find learning large use under over fit training data optimal performance obtained training set optimization ensemble weights significant ensemble generalization performance individual noise training process wide range regularization parameters makes improvement robust against changes unknown level noise training data
paper shows neural networks use continuous activation functions have dimension least large number weights result long question whether well known log bound known threshold nets more general nets number samples generalization discussed
recurrent perceptron classifiers generalize classical perceptron model they take into account those correlations among input linear digital filtering paper provides bounds sample complexity associated such models experimental data
has unknown whether principle out digital networks models neurons presents real time arbitrary given circuits finite high networks noisy spiking neurons addition show even networks spiking neurons real time neuron threshold therefore perceptron threshold circuit manner these provide possible fact biological neural systems out quite complex out assumption these require about shape noise
paper perceptron learning task task provided another perceptron architecture both have nonlinear output functions gain output function level learning task observed high level leads overfitting give rather observation develop method overfitting method has two possible learning noise other cross early learning rules examples property makes feedforward neural nets interesting many practical applications their ability approximate functions given examples forward networks least hidden layer nonlinear units able approximate each continuous function dimensional well while neural function still knowledge about their practical problems good like overfitting need better understanding work study overfitting layer perceptron model model allows good theoretical description while similar behavior perceptron layer perceptron has input units output unit between input output has layer weights output nonlinear function weighted sum inputs ie learning task overfitting quality function approximation measured difference between correct output nets output over possible inputs supervised learning scheme network using set examples correct output known learning task minimize certain cost function measures difference between correct output nets output over examples using mean error measure difference between outputs define training error et generalization error eg development both errors function number trained examples given learning curves training gradient theoretical useful study learning tasks provided second network so called network concept allows more learning task training process possible compare network network directly such comparison perceptron case following order parameters both have interpretation between weight vectors norm weight vector these order parameters used learning but their number number possible between hidden units learning task here case has learn mapping provided another networks both have same output function ie network architectures tasks principle able learn task provided tasks finite error use distributed random inputs weights weighted sum gaussian distributed generalization error order parameters gaussian measure equation see learns gain output function norm its weights gain important role allows function between linear function highly nonlinear function now determine learning curves task overfitting expression weights capacity ie minimum training error et zero zero training error every example has been thus weights minimal norm condition given see et al note weights independent output function they same case linear perceptron learns linear perceptron statistical order parameters method statistical used method about approach see et al solution continuous perceptron problem found et al results statistical exact limit ie variable more natural measure defined number patterns over system size ie limit but still finite system such well described theory usually zero limit because training error et its minimum every number presented examples corresponding order parameters case linear perceptron learns linear zero limit called training net trained minimum et small high ie levels training leads overfitting means generalization error should overfitting training examples critical gain whether generalization error function small values determined linear approximation small both order parameters small function linear function equation following expression function has upper bound ie critical gain numerical solution gives higher positive small following use gain example level learning task overfitting figure learning curves problem perceptron learns different values gain even case training lead overfitting gain high overfitting here evaluation generalization error order parameters fig shows function between between training cases line independent output function means training training error generalization error gain higher than line eg lower than results overfitting overfitting fig fast compared ratio between better during training process so have develop description training process first training process found order parameters finite statistical approach good description training process learning task so use finite order parameters task these taken task linear learns linear dependent variable local local figure defined generalization error function two order parameters minimum eg eg given line eg parametric curves order parameters certain training line training lower optimal training fig here gain zero limit show now dependent parameter describes order parameters during training process training process natural parameter number parallel training steps each parallel training step patterns presented weights fig shows order parameters parametric curves learning curve defined parameter line each training curve illustrate training process simulations training process have shown theoretical curve good description least after training steps now use description training process training strategy optimal training strategy corresponding but value ie generalization error lower curve parametric curve value chosen every function has two between line minimum parametric curves corresponding local given note value related through equation but parameter related number training steps learning task overfitting local local simulation figure training process order parameters parametric curves parameters line learning ie describe training process fixed iterative training parameter examples given lower line learning curve achieve curve value chosen eg between error has two indicate second local minimum compare fig see local minimum early procedure minimum first minimum during training process see simulation early fig fig together indicate training process overfitting but order determine point has generalization error during training cross validation provide approximation real generalization error cross validation error defined like et see set examples used during training here using real generalization error given determine optimal point early lower bound training finite cross validation sets have shown small cross validation sets approximate real quite well training eg resulting curve given fig indicate standard simulation over fig same results shown learning curves see early strategy overfitting paper have shown overfitting learning tasks critical gain fig eg local local simulation figure learning curves corresponding parametric curves fig upper line shows training finite curve lower line optimal training lead results see simulation early first minimum overfitting problem network task have developed method overfitting two ways training finite overfitting noisy examples other interpretation learns without noise but training early cross validation observed early simple lead local minimum generalization error should early nonlinear same effects important learning study large scale simulations et al has shown overfitting learning tasks would like overfitting finite learning artificial neural networks generalization ability continuous outputs
stability criterion dynamic parameter adaptation given case learning rate backpropagation class stable algorithms presented studied including convergence
new nearest neighbor method described estimating bayes risk pattern classification problem sample data eg training set although classification problem described smooth class conditional distributions these distributions corresponding prior probabilities classes required thus method applied practical problems underlying probabilities known method using two different pattern recognition problems
paper estimation algorithms dynamic networks developed models based gaussian rbf networks network considered two first time varying second based state mixture local experts scheme resulting algorithm uses kalman filter estimation model estimation probability estimation both soft based estimation schemes developed most network networks appropriate data
linear threshold elements basic artificial neural networks linear threshold function weighted sum input variables weights arbitrary they exponential number input variables practice difficult implement weights present made between two cases linear threshold functions polynomial size weights those exponential size weights main paper up further separation prove class linear threshold functions polynomial size weights into according degree polynomial fact prove more general result minimal weight linear threshold function arbitrary number inputs weight size prove those results have developed novel technique linear threshold functions minimal weights
describe use techniques solving dynamics symmetric recurrent neural networks near these explicitly take into account correlations between synaptic allow prediction
functions has important role many important results demonstrate techniques useful practical algorithm addition being theoretical describe more changes have introduced algorithm without performance algorithm would present confidence level each prediction measures likelihood prediction correct
propose way using circuits perform real computation way their multiple threshold model shown hardware implementation continuous neural networks dimension sample size analysis systems performed best known sample real neural network experimental results sample required networks significantly than networks
process machine learning considered two model selection parameter estimation paper technique presented dynamical systems desired properties approach based fact dimensional nonlinear dynamical system into gradient systems thus model selection stage consists gradient so certain behavior estimate parameters learning rule presented algorithm has been converge desired system trajectory initial conditions system inputs technique used design neural network models solve trajectory learning problem
recent experiments show neural codes work wide range common features first these observations show these features linear threshold model set threshold information maximization process requires neural adaptation signal level conventional adaptation but statistical structure signal noise distributions present new approach mutual information between neurons output spike train its input signal does require reconstruction input signal formulation provided correlations spike train small provide procedure assumption paper based joint work results model previous time have been further analysis model
present statistical method learns class constant depth perceptron networks weights taken arbitrary distribution input examples family product distributions these networks known perceptron networks over weighted threshold basis free neural nets each node has arbitrary high probability able identify connectivity target perceptron network using new statistical test strong property independent random variables
propose active learning method hidden unit reduction first our active learning method point out many information based methods applied have critical problem information matrix may solve problem derive condition information propose active learning technique its through experiments
analyze compare well known gradient descent algorithm new algorithm called gradient algorithm training single neuron arbitrary transfer function both algorithms easily generalized larger neural networks generalization gradient descent standard back propagation algorithm paper prove loss bounds both algorithms single neuron case local make difficult prove case bounds gradient based algorithms use loss function local define such matching loss function transfer function prove case loss bound such transfer function its corresponding matching loss example matching loss function loss matching loss loss different structure bounds two algorithms new algorithm out performs gradient descent inputs large number components
show single neuron function transfer function number local error function based loss dimension
adaptive back propagation algorithm studied compared gradient descent standard back propagation line learning two layer neural networks arbitrary number hidden units within statistical framework both numerical studies analysis show adaptive back propagation method results faster training between hidden units more efficiently faster convergence optimal generalization than gradient descent
brain approach understanding structure such map points representing input features space few dimensions points dimensional space using algorithm more general approach may useful between features constrained objective function matching chosen rather than being self algorithm investigate analytically example more general approach applied structure such pattern visual cortex
dynamics complex neural networks process cortical maps include long short term memory network such equation neural activity fast equation synaptic part neural system present quadratic type function competitive neural system fast dynamic variables show stability analysis neural net parameters
evaluation model specific parameters two examples dimensional perceptron dimensional higher order neuron both models solved their curves compared against true learning curves shown has potential generate variety curves including phase transitions
present bayesian framework parameters mixture experts model based ensemble learning variational free energy bayesian approach over noise level under estimation problems traditional maximum likelihood inference demonstrate these methods artificial problems time series prediction
paper consider probabilities different algorithm type neural network case random patterns show results total memory
theory early applied linear models presented backpropagation learning algorithm gradient descent continuous time given training set validation set weight vectors found early certain usually given training set early weight vector validation sets have least weights certain fact estimate probability given point along trajectory initial weight vector weights derived training set estimate probability training theory nonlinear models discussed
given recurrent neural network discrete time model may have asymptotic dynamics different related continuous time model paper consider discrete time model continuous time model study its parallel sequential dynamics symmetric networks provide sufficient necessary many cases conditions model have same free dynamics corresponding continuous time model symmetric networks
introduce analyze mixture model supervised learning probabilistic online learning algorithm efficiently structure estimates parameters each model mixture theoretical analysis simulations indicate learning algorithm best model large models present application model
paper introduce approach training estimation posterior probabilities using algorithm em based forward algorithm estimation sequence although general method developed context statistical model transition based speech recognition using artificial neural networks generate probabilities hidden markov models hmms new approach use local conditional posterior probabilities transitions estimate global posterior probabilities word sequences although still use estimate posterior probabilities network trained estimates local posterior probabilities initial experimental result shows significant error rate comparison system
paper propose recurrent networks feedback into input units two types data analysis problems hand scheme used data input variables missing other hand used sequential data input variables missing available different case probabilistic models eg gaussian missing variables network does model distribution missing variables given observed variables instead more approach missing variables minimizing learning criterion eg minimize output error
family task learning dimension structure family stochastic models appropriate training examples into samples single parameter value present three family algorithms based learning show they significantly improve performance over two classification task
nearest neighbor classification class conditional probabilities locally constant bias high dimensions propose locally adaptive form nearest neighbor classification dimensionality use local linear analysis estimate effective metric computing determine local decision information these local decision them parallel based classifier using propose method global dimension reduction local dimension information indicate these techniques extended regression problem
propose new learning method generalized learning vector vectors based descent method order minimize cost function cost function so obtained learning rule convergence condition prove rule used does convergence condition thus recognition ability experimental results recognition superior recognition ability
investigate stochastic performance algorithms function particular address two problems have been applied problem problem demonstrate simple stochastic methods able achieve results superior those obtained designed address these two problems further illustrate case problem obtained formulation stochastic algorithm lead used
independent features finding representation signal distribution principal component analysis pca linear correlated gaussian distributed signals independent component analysis ica features case linear statistical dependent but gaussian distributed signals nonlinear component analysis finally should find representation nonlinear statistical dependent distributed signals paper task novel forward information nonlinear map transformations problem non gaussian output distributions single higher order statistics
bayesian learning scheme called machine proposed based two but equivalent bayesian representations joint density their scheme existing supervised unsupervised including classical maximum likelihood least learning maximum information em em algorithm information recent machine well other learning methods new new results but scheme provides number new learning models
natural artificial neural circuits capable specific state space trajectories natural approach problem learn relevant trajectories examples gradient descent learning complex trajectories networks suggest possible approach trajectories simple various ways contrast two fast cases show have approximation properties discussed
derive recurrent network models prediction performance training data generalization first order dynamic models form expression both time recurrent nets feedforward nets linear nets special cases have successfully tested number case studies found performs better than standard quadratic weight
interest general nonlinear density models based latent hidden variables such models have ability presence relatively small number underlying combination give complexity observed data set train such models generally requires large computational paper introduce novel latent variable algorithm general non linear previous models but uses training procedure based em algorithm demonstrate performance model problem data multi phase
present framework learning hidden markov models distributed state representations within framework derive learning algorithm based expectation maximization em procedure maximum likelihood estimation standard update rules step our algorithm exact solved analytically due nature hidden state representation exact step simple mean field approximation derived empirical results set problems suggest both mean field approximation sampling computationally exact algorithm
new boosting algorithm used improve performance decision trees constructed using information ratio criterion algorithm boosting algorithm series decision trees each decision tree being trained examples have been previously trained trees examples have been previous trees ensemble higher probability give new probability distribution next tree ensemble train results recognition knowledge data problems show comparison single trees trees trained trees trained feature space boosting ensemble much better
develop mean field approximation inference learning probabilistic neural networks our mean field theory most does assume units independent instead way large computationally illustrate advantages framework show higher order interactions into first order hidden markov model but first order structure within mean field theory
have shown long term sequential data difficult both deterministic dynamical systems such recurrent networks probabilistic models such hidden markov models hmms hidden markov models practice problem have used domain specific knowledge give hidden state variables representing context paper propose use more general type knowledge temporal long term represented variables long time scale principle applied recurrent network includes multiple time scales experiments advantages such structures similar approach proposed hmms
study bayesian networks continuous variables using nonlinear conditional density demonstrate useful structures data set self way present sampling techniques belief update based markov conditional density models
conventional binary classification trees such either data using they perform computationally search continuous space show without every training data points line data points line such comparison datasets found method generating standard methods training sets small
bayesian analysis neural networks difficult because simple prior over weights complex prior distribution over functions paper investigate use gaussian process over functions predictive bayesian analysis fixed values out using matrix two methods using optimization via hybrid monte carlo over have been tested number problems have produced results
type belief networks class probabilistic neural networks provide natural framework representing probabilistic information variety unsupervised supervised learning problems often parameters used these networks need learned examples estimating parameters via exact probabilistic ie em algorithm even networks small hidden units propose step instead computing them introduce extended representations these networks show estimation network parameters made fast reduced quadratic optimization estimation either alternative domains networks used continuous density estimation well
neural network have been shown accurate classification techniques previous work has shown effective ensemble should networks highly correct but make their errors different parts input space well most existing techniques address problem such set networks paper present technique called uses algorithms directly search accurate set trained networks first initial population uses new networks set networks accurate possible while each other much possible experiments three problems show able generate set trained networks more accurate than several existing approaches experiments show able prior knowledge available improve quality its ensemble
compare two regularization methods used improve generalization gaussian mixture density estimates first method uses bayesian prior parameter space derive em expectation maximization update rules posterior parameter probability second approach apply ensemble density estimation includes recently has been found produce results classification networks
following study function complexity network two other reinforcement connections results indicate significant spatial gradient both non functions two inputs network cells much their sensitive parameters highly non linear way
recently several have reported experimental results using gaussian like activation functions networks type usually require hidden units often learn much faster than networks explain these results consider network simple perceptron hidden units activation function points dimensions into two classes limit approaches capacity show case practice ratio perceptron approaches
backpropagation learning algorithms typically networks structure into single vector weight parameters suggest their performance may improved information instead introduce framework each weight model activation error signals independent random variables scale weight changes properties such nodes out local learning rate error model upper bound global learning rate updates leads different update rules bias non bias weights approach yields performance family multi layer network both learning algorithm convergence optimal learning rate up more than order
propose hierarchical scheme learning context dependent based recently introduced map underlying idea first learning system into more range out prior learning stage during system set basis set adaptation new context achieved space basis thus demonstrate potential approach task map robot two includes forward robot retina joint after phase transformation learned new set up single observation
has recently been shown gradient descent learning algorithms recurrent neural networks perform tasks long term paper explore problem class architectures called networks have previous work reported gradient descent learning more effective networks than recurrent networks hidden states show although networks do problem long term they improve performance such problems present experimental results show networks often information two three times long conventional recurrent networks
present two hierarchical mixture experts architecture applying likelihood each tree during training most path through tree may either they demonstrate results path algorithms show significant speed more efficient use parameters over standard fixed structure between two patterns
new learning algorithm developed design statistical classifiers minimizing rate method based information theory statistical data classes probability distributions chosen minimize expected classification error while simultaneously classifiers structure level measured entropy classifier structure associated cost constrained optimization problem equivalent minimization free energy resulting optimization method basic extension deterministic algorithm explicitly constraints while entropy expected cost limit low error rate directly classifier structure obtained learning algorithm used design variety classifier structures approach compared standard methods radial basis function design demonstrated other design methods several examples while often design complexity than descent based methods
practical method bayesian training forward neural networks using monte carlo methods presented small computer time approach other state methods tasks real world domains
introduce learning system regression problems models data means locally linear experts contrast other approaches experts trained do data during learning prediction query required do experts their individual predictions each trained minimizing local cross validation error using second order methods way able find local distance metric size shape receptive field its predictions relevant input features its bias individual input dimensions derive asymptotic results our method variety simulations properties algorithm demonstrated respect learning speed prediction accuracy feature detection task learning
paper computational power recurrent correlation architecture finite state while recurrent networks equivalent paper presents theoretical analysis architecture form large class cannot
report our development high performance system neural network other signal processing applications have designed implemented vector conventional present performance neural network backpropagation training ii system significant over code
new technique applied first time two optimization problems problem graph has recurrent neural framework two way constraints without use terms energy functions generalized two way take constraints multiple constraints required graph technique compared within statistical framework term has been used method two way constraints common within many optimization problems present evidence has advantages accuracy speed over term optimization problems two way constraints
investigate optimization neural networks general objective functions practical such difficult solve common problem local result applied methods paper novel framework introduced solution optimization problems about objective function applied general nonlinear non convex functions variables thus efficiently combination techniques deterministic optimization attention mechanisms region optimization methods
paper learning context learning whole learning tasks such provide transfer knowledge across multiple learning tasks order generalize more less training data paper several different approaches learning described applied object recognition domain shown across learning approaches generalize more less training data their ability transfer knowledge across learning tasks
many classification problems have property part examples class label paper suggests simple method using distribution information examples labeled examples supervised training framework empirical show technique described paper significantly improve accuracy supervised well its asymptotic accuracy level
introduce new algorithm designed learn sparse over input representations include high order features our algorithm based hypothesis boosting method able learn relatively natural class target moreover algorithm work well practice set three problem domains algorithm classifiers small features yet exhibit good generalization performance most our algorithm concept
algorithm relatively efficient method stochastic generative model high dimensional data addition top down connections model makes use up connections probability distribution over hidden units given data these up connections using simple rule use variety synthetic real data sets compare performance algorithm monte carlo mean field methods same generative model compare other models less but fit
analog models need filters cmos using line difference between both line these independent cmos threshold current sources implemented much better than current sources measurements test shown improved matching
both highly contrast independent over more has been possible adaptation point while high gain responses properties retina allows system information image retina models adaptation properties properties cells retina layer retina illustrate temporal responses retina moving chip has well
architecture search hardware has been developed using novel neuron like high called neuron short key circuit circuits developed work find location maximum minimum signal among number input data continuous time basis thus real time tracking well fully parallel multiple input data have developed two circuit schemes ensemble finding node other ensemble variable threshold common competitive data through search actions test circuits cmos process their has been experimentally
present analog real time decomposition reconstruction continuous temporal signals frequency range performs complex modulation gaussian filtering parallel channels each different rate mapping frequency scale our implementation uses analog digital circuits techniques filters achieve wide linear dynamic range while circuit size low power include experimental results its components measurements single channel test chip
special low power analog digital speech applications feature analog circuit models biological process signal paper describes our most recent design system uses several chip compute multiple representations sound analog input multi representation system auditory scene analysis approach sound processing
dimensional model smooth mechanism has been implemented cmos vlsi model negative feedback model positive feedback scheme produce smooth system target retina furthermore system uses current eye motion future target motion analysis stability biological system discussed implementation local correlation based visual motion detection technique used measurements over provides input smooth system system performed tracking high contrast scenes circuit design performance complete smooth system presented
systems process sensory data model matching stage class combined complex introduce new model single function multiple data model appropriate stage small hardware certain existing architectures addition programming model machine allow faster model matching but increase its general machine its initial sensory processing
describe two parallel analog vlsi architectures data obtained estimate direction time direction computation performed simulations evaluate most important properties field determine best functional implementation architecture time theorem data present architecture average out possible errors
technique using processing based early auditory processing presented technique based features sound neuron spike suggests sound signal each signal signals both time across frequency channels using network neurons spikes timing these spikes used sound traditional speech interpretation techniques based hidden markov model neural network interpretation stage have both continuous speech speech presence noise has interest biological auditory systems speech interpretation systems et al auditory systems use similar early auditory processing used biological systems auditory processing uses two signal first through pattern active process using both cells movement cells into neural neurons these down auditory various parts other areas superior example see sound speech interpretation systems use form filtering following far most use perform energy each over time usually between what does auditory length they early auditory processing but term generally least filters used high temporal resolution initial means use filtering techniques rather than stage such filtering systems have been implemented directly et al et al auditory models have filtering cell has been either simple has been based work example has version processing such al et al have considered early their possible based different cell types et al auditory model based systems have yet find their way into speech recognition systems work presented here uses auditory up cells temporal neural network up segmentation produced part has been system has biological effective data segmentation technique implement able techniques used sound applied auditory sound into channels each frequency these effect cells signals produced auditory real system has far more channels each channel spike information coding here models signal population auditory filter signal present auditory near than effect much more certain cell types these after sound they sensitive signal each filter two more recent less recent less recent more recent possible consider neuron same input other input has time constant than input both weighted using filter have been but much most recent part signal making more effective based sound segmentation filter output input signal determine times system sensitive used so filter has positive negative these values system sensitive energy positive signal signal negative signal used sound analog difference used images performed segmentation directly signal signal signal into two positive signals signal positive part signal negative part both taken dynamical system models biological effects signal models output population cells technique signal related et al neural network sound using signals they need across frequency across time temporal clustering achieved using network units unit its weighted input over time activity according input neuron describes threshold unit ie after firing input called such neurons discussed eg neuron used per neuron input either single set channels equal positive output each neuron back set neurons fixed positive weight time step here because nature activity input neuron its activation threshold has effect next firing time than input activation lower thus similar input applied set neurons channels effect neuron connections first its almost allows network such neurons cluster signals spikes across number channels internal weights network so input neurons while internal input firing used set system system system effect produce firing responses across channels response increase energy channels thus both appropriate these generally output stage call map more due effects example sound but see even does sound more due thus cannot sound instead reduce neurons produce train call output stage map results technique data applied sound source has been applied both speech figure shows effect applying techniques discussed short speech fig shows neural network across channels these used segmentation technique up continuous speech each single channel does system near each other do result short segmentation have least minimum length set neural information processing systems has representation into following same text more over rather than has representation using technique gives following st although between system provides effective segmentation relatively speech rate system effective finding speech certain types noise such motor noise fig system has been used sound single these have between correct segmentation achieved directly signal but achieved change figure here using network segmentation produced based sound segmentation figure maps neural information processing systems original sound map channels filter parameters text neuron per channel neuron but network has input applied channels internal feedback channels map produced noise maps best results obtained here input network across channels further work effective data segmentation technique based feature detection using neurons has been demonstrated relatively noise segmentation technique application figure sound showing between found using single neuron per channel but internal feedback each channel channels found segmentation information propose extend work segmentation described here work same frequency amplitude modulation sound subset segmentation many due computational speech analysis means based model visual representations speech signals auditory system applied classification unit types analysis based sound segmentation model processing auditory computational auditory scene analysis computing et al language systems research speech processing use auditory models speech perceptual models linear predictive coding speech signal using analog model internal report systems what world do approach auditory do so responses neurons auditory analysis research auditory computer neural networks may theory analog model speech analysis neural information processing systems theory detection simulation auditory neural further studies suggested auditory filter patterns biological
application self maps recognition presented connections learn correlations activity between units map resulting connections focus activity into local connections activity map map thus internal representations eg perceptron network recognition rate subset database higher than self map higher than recognition input directly these results form point pattern recognition systems map
paper describes training recurrent neural network posterior probability estimator hidden markov model off line recognition system network estimates posterior distributions each series representing word supervised training algorithm backpropagation through time requires target outputs provided each three methods these presented novel method based upon algorithm found result error rate
method context dependent classes connectionist hmm hybrid speech recognition system introduced approach single layer networks between different context classes given class data context networks combined context independent network generate context dependent probability estimates experiments show average reduction word error rate system word word tasks due improved speed system more than fast system
new line learning algorithm statistical among outputs derived separation signals measured average mutual information outputs source signals matrix unknown number sources instead used natural gradient approach used minimize novel activation function proposed line learning algorithm has property easily implemented neural network like model new learning algorithm computer simulations
hybrid radial basis function markov model off line word recognition system presented task radial basis function networks estimation probabilities associated markov states model because estimation probabilities takes into account left context current image represented its sequence new system does previous system without context but
parallel object recognition complete complexity requires between parallel sequential processing system parts given image after another generated sample image these samples generate temporal context results over time computational model based recurrent feedforward network proposed made world problem recognition results
paper describes two neural network algorithms its first network trained find individual field while performs classification both networks original images high rates compared its version system system has implemented parallel hardware allows has been its rate level without into field rate fields system field rate
define multi layer synaptic weights filters proposed de de associated gain terms derive gradient descent update equations apply model recognition speech find both filters synaptic performance compare back back architectures local approximation scheme find results reduction error rates
matching feature point sets many approaches object recognition present framework non matching point matching multiple features improve object representation based spatial regions model local transformations algorithm feature matching updates transformation parameters solution each mapping solved form its use data dimension set via method two way constraint called has recently neural complexity non matching algorithm multiple features same point matching algorithm results synthetic real world data provided point sets data multiple types features parts
higher vision processes require selection subset available sensory information further processing usually selection implemented form region visual field so called focus attention visual scene dependent input state here present model control focus attention based map mechanism expected model biological vision but understanding complex scenes machine vision
sensory system model environment its input might need models accuracy method time series prediction good model could predict near future activity its inputs much good theory future data such model would require top down connections compare predictions input feedback could improve models performance two ways internal activity expected patterns generating specific error signals predictions concept model computationally efficient network cortical features like synapses local constructed make near future predictions simple moving stimulus after unsupervised learning network units features stimulus like orientation motion but
visual source depth information paper presents self neural network learns represent predict relationships during after motion sequences containing network two parallel channels connections every motion trajectory channel chain chain moving stimulus other channel off chain chain representation motion stimulus due learning rule uses chain learning off chain off chain neurons learn object depth results related recent neurons posterior cortex motion stimuli
action coding system provides objective means expression paper approach expression analysis actions generated database over image sequences subjects over actions action compare three different approaches actions these images spatial analysis based principal components images local image features such matching motion fields containing individual actions subjects these methods generalization novel subjects combined performance improved
visual depends ability make eye movements known over interest visual scene known pattern activation target location computed prior movement visual feedback these properties has been general model strategy human visual system during visual search natural scenes paper model uses scene representations derived spatial filters multiple scales visual search scale filter responses being compared first model tested its performance eye movement data human subjects natural visual search task results indicate between eye movements predicted model those human subjects
model human motion presented model two direction selective units first stage units while second stage units model motion through units first stage interactions second stage model two moving different single population moving direction vector sum two moving different motion model motion both cases non motion
neural network model presented upon theory system early ratio neurons well results across different used provide functional constraints theory suggest contrast hypothesis states ratio measures between regions given more weight regions simulations model address data including ratio hypothesis cross
finite sample sufficient determine density therefore entropy signal directly assumption about either functional form density about its necessary both amount prior over space possible density functions far most common approach assume density has parametric form contrast derive differential learning rule called entropy way kernel density estimation entropy its sampling density estimate resulting parameter update rule simple efficient show used correct images application existing parametric entropy models
have developed recognition system environment active using vision previously implemented environment determine spatial location parts user active obtain images hidden state reinforcement learning used implement visual attention attention based goal recognition uses new multiple model learning formulation given set target our system learn particular
visual object recognition system described called whose goal identify common objects large known set independent distance non database consists objects non statistical complex scenes recognition results obtained using set shape feature channels within simple feedforward network architecture response test set novel test each object presented video images object time using nearest neighbor classifier similar levels performance obtained subset non objects generalization behavior natural category structure input feature dimensions
present neural network based face detection system connected neural network small image whether each face system between multiple networks improve performance over single network use algorithm training into training set training difficult task non face training examples chosen space non face images another state face detection system presented our system has better performance terms detection positive rates
performance improvement relative individual networks error correlation between networks methods error between networks training networks different sets original training set methods tested artificial task real world problems
behavior within environment during time practice patterns more complex actions paper development such learning systems using weight hand used being developed artificial learned sensory inputs using connectionist reinforcement algorithm while two sensory data objects using competitive learning back propagation algorithm system consistent during initial learning stage but new after training
learning position critical specific tasks paper describes our work memory based technique action based continuous state position investigate question agent performs training our experiments indicate random within bound initial training agent performs better initial training rather than
report development neural system visual robot actions several neural networks single system human hand pairs video images output hand recognition stage set sensitive neural networks determine location target object finally information used robot target object another location second accuracy current system allows identify location target object accuracy area our current environment sufficient target objects within system consists neural networks perform tasks image segmentation estimation hand location estimation direction object recognition necessary use learning algorithms functions network data examples
state speech perform channel selection using spectral strategy strategy lead high frequency features between present paper novel channel selection strategy based upon pattern recognition allows channel made proposed strategy implemented using multi layer trained speech database input network energy coefficients energy channels output system channels compare performance our proposed system spectral strategy show our strategy produce significantly better results
most current methods prediction structure use small sequence predict structure describe new method prediction non local structure called consists two more connected often chain network two introduced after training set network well but many using global energy function prediction combined local prediction three structures energy function using simulated give prediction
present results use neural network based motor trained obtained motor have demonstrated trained has small reconstruction error measurements but larger error those motor have designed motor system using detection process system three
report here changes eeg cross used feedforward neural networks changes near real time previously have shown eeg spectral changes changes error rate auditory detection task here report first time frequency detection errors task patterns spectral several frequency eeg channel pairs relationships between eeg performance between subjects but within subjects their spectral stable changes changes correlations among eeg different neural networks estimate correlation changes eeg signals
paper propose memory based learning algorithm called predictive adaptive control address two problems policies under low network learn new optimal policies under conditions other memory based reinforcement learning algorithms memory used increase learning speed best learned them has been under various network conditions simulation results show superior terms both learning speed
recent interest has dynamics paper decision problem applying programming reinforcement learning based algorithms using artificial rate strategy reinforcement learning learning shown equivalent policy computed dynamic programming approach tested task here neural networks used value function resulting strategy superior policy further example neural network based reinforcement learning problem setting high dimensional state space
paper use feedforward neural networks based its various factors demonstrate approach consists long short constructed its against
paper describes neural network based controller capacity network system proposed order real time response constraint two basic architectures feedforward network feedforward network recurrent network these architectures compared against linear programming used label data samples feedforward neural network training algorithm found systems able provide obtained linear solution trained neural network based solutions found time required
current systems assume do them based system developed through two dimensional matching two types neural network semi linear units compared image classification neural network approach shown capable recognition performance while number advantages over matching
paper robot learn goal tasks using local sensory inputs such learning tasks could problem dynamical systems desired trajectories task space should into sensory based internal state space so mapping internal state space motor could paper shows recurrent neural network self such internal state space temporal sensory input our experiments using real robot range robot dynamical environment shown such stable global self internal dynamics
paper describes policy iteration algorithm performance function based controller respect user defined value functions represented potential distributions over problem domain being control policies represented gradient fields over same domain policies ie during adaptation process algorithm has efficient implementation parallel architectures potential application distance minimization its
control standard method tasks like but requires estimation state between robot objects here present method learn model movement measured data method requires prior knowledge resulting model explicitly estimates current hidden state variable discrete hmm control dependent transition probabilities between states functions show their parameters estimated measurements same time parameters movement each learning algorithm em procedure step computed solving step possible general here gradient used produce increase likelihood
neural network based approach presented two types nonlinear systems first nonlinear systems parametric parameters second systems control structures cannot determined proposed neural shown result system stability under certain conditions
paper describes application reinforcement learning difficult real world problem domain combination most research systems continuous state spaces continuous time discrete dynamic systems their states fully observable they due arrival rates addition use each global reinforcement signal noisy each agent due effects actions other random nature observation state these show results simulation best control algorithms these results demonstrate power large scale stochastic dynamic optimization problem practical
important task particular task processing space paper our previous work task solution reinforcement learning algorithm previous work its hand input features paper shows extend time delay neural network architecture apply length experimental show network performance our previous hand system show both neural network approaches significantly best previous non learning solution problem terms quality resulting number search steps required construct them
paper practical use hardware neural networks robot have developed hardware neural system based vlsi chip ii designed hardware neural applications present here application robot system robot basic few training using rule training
consider solution large stochastic control problems means methods representations value iteration algorithm compute approximate functions while such methods known general identify new class problems convergence well error bounds class involves linear cost function together assumption dynamic programming respect norm applied functions class provide special case assumption transitions state space other cases discussed full length version paper
describe reinforcement learning problem algorithms approximation function present new convergence results two such algorithms
policy iteration dynamic programming should require knowledge relative rather than measures actions what advantages actions states most existing methods dynamic programming including compute form function smooth problems advantages two differential conditions including they free show these lead appropriate policy improvement terms advantages
paper introduce new algorithms noisy each experiment algorithms global non linear model expected output same time using bayesian linear regression analysis locally weighted polynomial models local model about confidence noise gradient use them make similar those made response global local models combined locally weighted regression question whether global model optimization extend case time varying functions compare new algorithms highly higher order stochastic optimization algorithm randomly generated functions simulated task note significant total time converge solution quality
continuous time continuous state version temporal difference td algorithm derived order application reinforcement learning real world control tasks modeling optimal nonlinear feedback control derived using value function performance algorithms tested task up limited both position nonlinear feedback controller successfully implemented radial basis function rbf networks
present new algorithm associative reinforcement learning algorithm based upon idea matching networks output probability probability distribution derived environment reward signal probability matching algorithm shown perform faster less local than previously existing algorithms use probability matching train mixture experts networks architecture other reinforcement learning rules converge even simple problems architecture well our algorithm compute complex functions yet output probability simple
following use single neuron learning algorithms improve performance text retrieval systems natural language retrieval process natural language query into query real retrieval system initial query using statistical techniques used binary classification results experiments suggest gradient descent learning algorithm significantly better than previous approaches
although td machine learning has similar temporal difference learning other applications even other able td competitive evaluation function parameter forward neural network without using back propagation reinforcement temporal difference learning methods instead apply simple relative environment these results further analysis suggest more do structure learning task dynamics
present connectionist method representing images explicitly their hierarchical nature data about whole object sensitive cells cortex basis field modulation about hierarchical based resulting model makes critical use up top down analysis illustrate model simple example representing information about hierarchical models images objects important case such parts such representation part whole hierarchical information fixed hardware connectionist has been many interesting such visual system cortex construct representations presented objects both objects so require fully representations level using different sets cells natural way represent part whole relationship between have neuronal connections up units face units so information about used analyze image face connections top down face units units synthetic knowledge face scene usually empirical support against such neuronal but correct set levels classes objects recent evidence cells areas visual processing such visual attention suggests alternative strategy representing part whole information interaction control between top down generative up recognition processing version our example units represent particular face leads through top down model pattern activity lower areas related pattern activity would face activation lower areas provides up input recognition system up direction signal activation example activity lower part face should case units pattern activity being particular therefore have provided way visual system represent part whole relationship between describes many instance control could active during top down phase instead would areas activity corresponding lower face first focus attention need so spatial scheme based hierarchical top down up analysis model visual processing machine note here processing rather than part whole discussed above synthetic model effective map object eye position image shown form figure image probabilities over units various levels system would object focus scale attention use model during way described above hierarchical description particular image use statistical inverse synthetic model way images determine what objects they process sensitive eye position nature object scene but way ie its parameters eye position particular up analysis model connections selective image cells reported et al form population codes represented images top down model connections direction our scheme may necessary generate image way down map top down computational task like up using synaptic matrix model neural models part whole layer figure model top down generative direction model images based eye position selection single top layer unit up recognition direction inverse map response neurons layer graphs shown representing neurons layer eye position see section more et al our solution control eye position various levels processing most activity equivalent modulation cortex based rather than eye position has been terms basis fields they these basis fields used solve same tasks model but neuronal rather than synaptic modulation fact eye position modulation almost many levels system including our scheme requires eye position able spatial eye position et al evidence part hypothesis although systems modulation their data up top down learned eye position modulation into account experiments used version algorithm its computational requires learning up model generated during learning model during observation real input during current version eye position set during recognition but ways results have developed simple model scheme presented above context generating face its parts recognition involves image face part arbitrary position retina face eye figure recognition left each shows stimuli right shows resulting top layer face eye stimuli random retina recognition performed setting eye position image setting scale attention position shown corresponding size position each shows output generative randomly chosen eye position each top layer units focus attention whose size scale object whose neuronal representation top layer shown above each setting appropriate top level unit units zero involves either whole face its parts active unit top layer arbitrary position retina model figure consists three layer retina recognition direction retina into layer hidden units these top layer has four neurons generative direction connectivity network fully connected both activity each neuron based input recognition following layer linear function weight matrices recognition generative direction eye position activity through modulation neuronal responses hidden layer linear response each neuron layer based up top down connections curves each dimension eye position coding scale focus attention thus activity hidden neuron have recognition generative curves chosen random random other have used gaussian functions fact shape functions through them construct functions show eye position recognition direction eye position has activity input layer attention implemented using gaussian eye position its size given scale allow system learn models parts based images whole train model unsupervised algorithm algorithm generative trained during phase neural models part whole stimuli input layer retina our case activation neurons network through recognition error signal train using rule phase random activation top layer unit randomly chosen eye position leads via connections activation layer image input layer used recognition weights using rule although rule recognition direction leads model our simple case much more difficult than recognition solution therefore train weights using back propagation uses activity top layer recognition input activation pattern target signal learning still unsupervised appropriate eye set during recognition have system weights weights between trained model training could standard algorithm ie using local rule both sets weights figure shows several examples performance recognition different stimuli after iterations network able stimuli different visual field figure shows several examples output model its capacity produce images their parts arbitrary locations whole face attention eg area its unit through recognition relationship eg part face way representing hierarchical structure key problem visual images example possible underlying neural mechanisms theory based view object selective cells eye position modulation firing cells these work context analysis recognition generative models such part whole object such face generative direction view object through different effective eye position recognition direction real eye view selective cells scheme related associative memory system provides way representing tree information instance learn object whose structure standard associative net would pattern hidden unit would learn finally would representation whole object its inverse required methods tree structure our scheme representing hierarchical information similar using eye position perform its its codes levels trees here images real available those instance their associated changes learning task but direct recognition without parts various our scheme require way eye position recognition coding different objects use top down information during up recognition scheme objects fit into single image hierarchical objects other than images more correct version advantage statistical machine eye position information visual processing areas including well cortex further effect et study form two but eye much study even image retina eye so fixed least component eye information about eye position effects visual processing manner consistent model presented here based modulation required et theory perceptual stability across up scene form mapping general many object eg many different general case top level would implement distributed code parameters objects methods form representation into model key feature model interaction analysis part whole interaction between two system image analysis information across feature required short term memory memory information about various trees have been our system memory required during generative whole activity lower even after activity upper has free these upper units part memory during recognition necessary cases information across parts well whole solution hierarchical representation gives up computational neuronal hierarchical scheme described
order process efficiently auditory system statistical structure natural auditory scenes first step between system its inputs study low order statistical properties several sound using filter analysis amplitude phase different frequency find simple parametric their distribution power different types particular amplitude distribution has exponential its power power behavior self similarity long range temporal correlations furthermore statistics different within given ensemble along these results show natural highly have possible neural code used auditory system
noise signal study dynamics response single neurons cortical area visual motion responses using correlation optimal linear reconstruction filters reconstruction signal noise ratio lower bound estimates information rate lower than expected information lower bound rate simulated motion energy spike statistics able out perform neurons temporal measured correlation stimulus faster but change temporal frequency constant
proposed view based model object recognition several properties certain recognition tasks model predicted view view invariant units found et al et al cortex trained specific objects model does inputs view units their internal paper propose model these view units consistent data single cell responses
result two see different scenes recent evidence account component similar other test hypothesis generated between cortical inputs rather than direct between inputs recent evidence shows neurons even they selective between stimuli presented extend our model address these effects
train recurrent networks control computer model model presented based each constraints relevant information processing simulated moving simulated variety similar those biological
random time varying stimuli single spike neurons using methods statistical signal processing first stage system spike found time random stimuli while second stage neurons features temporal stimulus therefore stimulus information second stage system temporal features image environment first stage
introduce model visual inputs individual model neurons visual inputs via receptive fields like those distributed space each location finite number cells model cortical interactions neural produced visual inputs elements smooth input elements within produce neural show analytically neural increase length observed experimentally model gives predictions addition feedback mechanism higher visual
paper family temporal log linear models represent temporal correlations among spiking neurons models represent pairwise correlations but correlations higher order methods discussed correlations estimating their bayesian approach correlation detection compared method based estimates obtained via principle bayesian approach markov chain monte carlo model algorithm applied search over connectivity structures method used approximate their posterior probability performance methods tested synthetic data methods applied experimental data obtained means measurements out neural connectivity structures need hierarchical learning patterns among spiking neurons
modeling studies have previously shown cortical cells strong type synaptic containing dependent channels more synapses several optimal size comparison same number synapses about nonlinear interactions cluster property layer nonlinear hidden units basis learning memory certain classes nonlinear sensory processing present study show single neuron inputs off cells principal nonlinear response properties complex cell visual cortex orientation contrast type processing could explain complex cell responses simple cell input
recently nature demonstrated classical receptive field but change neurons response stimuli they cells their stimuli their orientation here analyze such complex response patterns simple model visual cortex show observed orientation contrast between local interactions long range connectivity between orientation domains particular demonstrate observed properties might without specific connections between cross
codes used brain sensory motor variables methods designed these codes such population vector analysis either ie variance estimate much larger than possible variance like maximum likelihood moreover these methods compute vector estimate variable neurons similar estimation problem they out responses neurons but contrast they typically variable further population code rather than show non linear recurrent network used perform these estimation optimal way while estimate code work suggests connections cortex may up noise among neurons representing similar variables
linear model cortical simple cells presented model mutual through synaptic functions distributed space possible basis wide variety temporal simple cell response properties including direction while spatial explicitly structure temporal specific mutual scheme considered simulations model reported
change mean firing rate neuron but its pattern firing therefore neural coding scheme whether rate coding spike time based coding robust dynamic environment common observation modulation leads reduction spike frequency adaptation spike timing would make neural code based spike timing difficult paper effects modulation studied test hypothesis spike timing neural code using whole cell technique modeling techniques show modulation spike timing response inputs conditions result suggests spike timing may much more changes than previous studies have
parameter space neural networks has metric structure natural gradient should used instead conventional gradient true descent direction loss function space behavior stochastic gradient learning algorithm much more effective natural gradient used present paper studies information structure other networks prove line learning method based natural gradient efficient optimal algorithm adaptive learning constant proposed terms measure shown efficient natural gradient finally applied separation independent signal sources
paper shows large neural network used pattern classification problem learning algorithm network small weights has small error training patterns generalization performance depends size weights rather than number weights more consider layer forward network units sum weights associated each unit probability error estimate related error training set rate log factors number training patterns input dimension constant may explain generalization performance neural networks number training examples than number weights such weight early weights small during training
new method full training process neural network introduced methods like used results directly related number training steps results presented here like learning rate exact description early necessary number training steps further problems approach
study number hidden required neural network threshold units compute function td dimension functions hidden layer under assumption multiple point defined set consider multiple point give necessary sufficient conditions locally hidden layer show these conditions assumptions sufficient global hidden layer new non local critical hidden layer
new regression technique based concept support vectors introduced compare support vector regression regression technique based regression trees regression feature space basis these experiments expected have advantages high dimensionality space because optimization does dimensionality input space
convergence properties gradient descent algorithm case linear may obtained response function derive general expression response function apply case data simple input correlations found correlations may down learning pca method training time finding furthermore propose input data mean across input variables well examples correlations numerical classification problem theoretical results
propose new method compute prediction intervals small data sets prediction does variance target distribution but accuracy our estimator mean target ie confidence confidence ensemble neural networks each them trained original data set second improvement use validation patterns instead training patterns estimation variance target distribution synthetic example our method better than existing methods interpolation data limited amount data yields prediction intervals confidence levels desired confidence levels statistical intervals paper consider feedforward neural networks regression tasks estimating underlying function between input output variables based finite number data points noise given set pairs generated according noise zero mean trained such regression task output network given new input vector real world computing neural networks practical confidence prediction intervals estimate regression ie mean target distribution given input estimate regression many applications important accuracy our regression problems two different accuracy our estimate true regression accuracy our estimate respect observed output confidence intervals first ie consider distribution prediction intervals ie see prediction corresponding confidence method similar introduced estimate both mean variance target probability distribution based assumption large data set ie their risk overfitting neural network correct regression practical applications limited data sets such assumptions paper propose new method estimates estimator through validation patterns rather than those training patterns early based idea available data set but particular unknown probability distribution instead sampling over true probability distribution empirical distribution so called empirical distribution sum available data points each probability sample patterns empirical probability distribution sample but our training set patterns do training set part validation set large probability pattern part validation set training neural network particular sample weights order minimize error training data training error validation data increase so called early procedure strategy overfitting neural networks alternative regularization techniques such weight context procedure generate training validation set similar cross validation each train single neural network output network input vector estimate our ensemble networks regression take average output so called estimator shown network outputs even better results confidence intervals confidence intervals provide way our confidence estimate regression ie have consider probability distribution true regression given our estimate our line see assume our ensemble neural networks yields more less estimate ie distribution neural networks example neural networks trained finite number examples have almost other model data bias correct confidence intervals should taken into account would possible compute such bias should do first better estimator our hypothesis here bias component confidence intervals comparison variance component do methods give confidence intervals second see eg order correct ie up including terms order after do bias component such confidence intervals require amount samples our first order correct intervals up including terms order symmetric derived gaussian distribution variance distribution estimated variance outputs networks method see eg distribution gaussian so inverse distribution find regression randomly data sets data points according true distribution inputs corresponding best do define empirical distribution estimate distribution yields estimate so following procedure confidence intervals depends desired confidence level factors taken table points distribution number equal number more direct alternative such more than network predictions paper assume both inputs outputs stochastic case deterministic input variables other techniques see eg more appropriate statistical intervals resulting may practical confidence prediction intervals prediction intervals confidence intervals accuracy our prediction regression ie mean target probability distribution prediction intervals consider accuracy predict ie they based estimates distribution propose following method two noise components independent variance first component has been estimated our procedure confidence intervals task estimate noise regression problem assume noise more less gaussian such compute its variance may input prediction intervals new points do left set test patterns used training our neural networks could estimate model fit using error measure out these test patterns data our procedure alternative each pattern about part training set us pattern validation set each pattern use average instead average close possible estimate independent test patterns without training data so suggest find function error yet out test patterns would data using training data would error but information about validation patterns have found function compute both mean combined prediction factor found table chosen such more than patterns st function may neural network similar method proposed exponential instead linear transfer function output unit variance positive input input input input figure prediction intervals synthetic problem training set true regression line network prediction line validation training true variance line estimated variance based validation line based training line standard error more method line procedure line what should line prediction intervals line network prediction line test points consider synthetic problem similar used example demonstrate regression estimator prediction intervals inputs probability density ie more examples than generated according regression line figure variance target distribution line figure following obtain training set data points figure train ensemble networks each hidden units transfer function linear output unit average network output line practical confidence prediction intervals figure following compare two methods prediction intervals more method described section ie into account uncertainty estimator training data procedure similar both effects compute validation based pattern part validation set training based pattern part training set validation most time larger than training our more method uncertainty our model validation other procedure training estimate variance target distribution distribution figure does allow complex model here take feedforward network hidden unit parameters found through minimization error both method line procedure line variance target distribution estimated step function being based validation uncertainty estimator more than being based training both estimates far line yet such limited amount noisy better figure standard error ie prediction intervals error level procedure prediction line figure directly estimate variance target distribution our more method uncertainty estimator line correct prediction ie would include particular input given line prediction intervals obtained through more procedure figure together set test points probability distribution inputs corresponding method proposed section has several advantages prediction intervals method include test points figure close desired confidence level procedure confidence level difference due use validation instead training uncertainty estimator important regions input space few training data example density training data both interpolation prediction intervals obtained method those obtained through procedure more less constant prediction line near result relatively large variance network predictions region shows our method effect density training data has accuracy interpolation have presented novel method compute prediction intervals applications limited amount data uncertainty estimator has been taken into account computation confidence intervals improvement over existing methods low density training data validation instead training patterns yields prediction intervals better have computation time have train ensemble networks about different other good over networks generalization performance early natural strategy overfitting would interesting see our method bayesian see eg prediction intervals used detection training set point out prediction error level wide prediction new test pattern test pattern region input space low density training data making prediction point our method assumption computation confidence intervals assumption makes confidence intervals general discussed such methods perform better than other based computation matrix because they due random furthermore model prediction function input but still even confidence our accuracy regions input space have been regression input dependent noise bayesian these machine learning
study generalization mixture experts learning examples generated another network same architecture number examples than critical value network shows symmetric phase role experts upon critical point system continuous phase transition phase network input space each appropriate find mixture experts multiple level shows multiple phase transitions
results study case learning curves particular class probability distribution input space threshold hidden units presented shown particular limit scaling number connections first hidden layer although true learning curve its dimension based bound its entropy bound shown bounds following true learning curve derived based density error patterns
paper apply method complexity regularization derive estimation bounds nonlinear function estimation using single hidden layer radial basis function network our approach previous complexity regularization neural network function learning schemes random metric entropy making possible consider much activation functions functions constraints previously network parameters way network trained means complexity regularization empirical risk minimization bounds expected risk terms sample size obtained large class loss functions rates convergence optimal loss derived
study line bayesian learning algorithm similar studied updates its state learns makes algorithm makes binary using linear threshold classifier time linear number have been able show simulations algorithm performs well under assumptions quite different those prior original bayesian algorithm do linear time bayesian algorithms our techniques useful other algorithms
exhibit novel nets networks noisy spiking neurons coding furthermore shown networks noisy spiking neurons coding power nets number units
introduce model noise robust analog time most important cases such noisy analog neural nets networks noisy spiking neurons show presence small analog noise power analog computational models finite prove new type upper bound dimension computational models analog noise
present algorithm expected bayes optimal predictions large forward networks based mean field methods developed within statistical systems give single layer show algorithm provides out cross validation test predictions simulations show theoretical results statistical
stochastic line learning faster than learning times learning rate noise present stochastic weight updates phase convergence rate mean best number input alternative increase size noise paper explore convergence using small but fixed adaptive size show best adaptive exponential has rate convergence same ie best
shown conventional faster than networks although networks take exponential time converge stable state arbitrary network found conventional computer polynomial time theory gives strong evidence such separation networks demonstrated case several classes networks including those graphs class graphs graphs degree graph neighbor connected graph
paper points learning rule show input has low information measured inputs variance learning rule learning weight vector converge zero vector information certain value rule automatically learn feature input our analysis suggests under certain conditions first principal component learned weight vector length provided variance input finite simulations theoretical results derived
given computational best use criterion minimal expected error model determine its parameters may performance higher learning speed method set out here so choice made furthermore method class models including fast memory based methods such first time means properties such models bayesian framework
study effect noise regularization line gradient descent learning general two layer network arbitrary number hidden units training examples randomly input vectors labeled two layer network arbitrary number hidden units examples gaussian noise either output model effect both types noise weight regularization dynamical order parameters generalization error various learning process
given data set model its density consider define optimal interpolation between two points cost each path through space based two through regions high density other minimize length path functional derive equations motion given two points desired interpolation found solving value problem show interpolation efficiently high dimensions gaussian mixture models
online learning finite training sets learning rates extension statistical methods obtain exact results time dependent generalization error linear network large number weights find example small training sets size larger learning rates used without asymptotic generalization performance convergence speed optimal less weight given learning time generalization performance online learning good learning
support vector method recently proposed estimating solving linear equations report results applying method these problems
learning properties machine studied line back propagation learning within statistical framework numerical studies show model has features do previously studied two layer network models without eg symmetric even cases data
neural networks wide class weight shown limit number hidden units prior over functions gaussian process paper derived covariance function gaussian processes corresponding networks gaussian hidden units allows predictions made efficiently using networks number hidden units shows may compute networks than finite
consider equations learning problems neural networks fields example obtained fields fields example learning process energy assume density local exponential distribution properties first step solution equations provide learning algorithm results higher stability than conventional algorithms
consider problem prediction time series using architecture known mixtures experts here suggest mixture several models study theoretical prediction problem context more demonstrated model respect learning unknown prediction function upper bounds mean error based these results possible compare other models eg neural networks state dependent models shown version fact equivalent neural network number experts architecture similar role number hidden units model
classifier called consistent respect given set points set consider defined local propose algorithms consistent classifier reduction expected proposed algorithms derived along expected classifier particular proposed approach yields consistent reduction nearest neighbor classifier performs classification each new object class data structure proposed reduction method suggests soft classification respect objects data proposed classifiers behavior compared achieved nearest neighbor method
full bayesian method applying neural networks prediction problem set up structure net perform necessary these analytically markov chain monte carlo methods parameter space high dimensional using gaussian processes approximate weight space analytically so small number need over methods have applied idea classification problems results real world problems so far
most regression problem distribution target data described deterministic function inputs together gaussian noise constant variance use maximum likelihood train such models minimization sum error function many applications more model would allow noise variance input variables use maximum likelihood train such models would give highly results paper show bayesian allow input dependent variance while bias maximum likelihood
self map algorithm has been studied has been applied wide variety problems algorithm derived leads number significant paper consider problem probability density data space several dimensions terms number latent hidden variables introduce novel form latent variable model call algorithm mapping allows general non linear transformations latent space data space trained using em expectation maximization algorithm our approach while significant demonstrate performance algorithm simulated data multi phase
power sampling methods bayesian reconstruction noisy signals well known extension sampling temporal problems discussed sampling over time demonstrated visual tracking
problem points dimensional real space clusters such sum each point nearest distance used problem minimizing linear function set shown equivalent minimizing function set fast finite algorithm solving few linear form leads point computational number out database training set mean algorithm its set better database important curves algorithm mean algorithm obtain such curves same database
support vector learning machines svm finding application pattern recognition regression estimation problems against general methods generalization performance speed test phase interest paper two such techniques pattern recognition problem method generalization performance support vector method does so known problem method error rate test images method speed reduced set method does so support vector decision apply method achieve factor test phase over support vector machine combined approach yields machine both times faster than original machine has better generalization performance error support vector method svm problem known reduced set method support vector machine
describe equivalent kernels suggest provides framework different classes regression models including neural networks both parametric non parametric statistical techniques standard techniques down models such neural networks more than layer parameters propose algorithm estimating equivalent kernels neural network models using data approach experimental results indicate networks do use maximum possible number these using techniques equivalent kernels network both size shape different regions input space
supervised learning usually between inputs outputs inputs what measure outputs what predict those measurements paper shows between inputs outputs simple features more useful outputs than inputs using feature output more than case values but learn mapping other inputs feature many features mapping may more useful than feature value present two regression problems classification problem performance features could have been used inputs used outputs instead result feature used output used during
paper developed two parts discuss new approach self single layer linear forward network first two novel algorithms self derived two layer linear associative network classification trained constrained least mean classification error criterion second two adaptive algorithms derived these compute principal generalized two correlation matrices two sequences random vectors these novel adaptive algorithms implemented single layer linear forward network give convergence analysis adaptive algorithms using stochastic approximation theory example consider problem online signal detection digital
work time delay neural networks general two those inputs those include hidden units both architectures capable representing same class memory machine but hidden units problems features over short time
method defined capable large points multi layer perceptron mean error using algorithm large points two test problems found shown neural network have ratio points compared local even small neural network problems have large solutions
describe criterion minimize error minimizing its estimated bias describe experiments locally weighted regression two simple problems bias approach more common variance approach even presence noise
many optimization problems structure solutions complex relationships between different input parameters example may us certain parameters related should may subset parameters take particular values search cost should take advantage these relationships present framework analyze global structure optimization novel efficient algorithm estimation structure derived use knowledge structure search through solution space our estimate structure our technique significant speed over other optimization
described use mean field approximations step em algorithms data latent structure models described among involves second order approximations computed step potential method using simple latent models
paper describes new framework graph matching point recently reported bayesian measure using distance main work demonstrate discrete components cost function second show cost function used using continuous nonlinear finally show resulting graph matching algorithm standard quadratic problem
using self maps either scaling being discussed recent empirical relevant theory ability both same time new combined technique online means clustering mapping cluster shown perform significantly terms error structure clusters empirical study using series normal clustering problems
real random hidden variables useful latent structure correlations among observed variables propose simple unit zero mean gaussian noise its input through function such units produce variety useful deterministic binary stochastic continuous stochastic show sampling used inference learning top down networks these units demonstrate learning two simple problems
propose novel approach automatically hierarchical mixtures experts algorithm proposed here large several experts trained show trained our procedure better generalization performance than traditional evaluation algorithm performed classification within hybrid version speech recognition system using subset large speaker independent continuous speech recognition database
compare different methods predictions neural networks trained different samples regression problem these methods introduced here call based analysis ensemble generalization error into term term generalization individual networks show estimate these individual errors validation patterns factors different networks quadratic programming problem real world problem prediction well known data set other recently proposed early training strategy overfitting neural networks complete data set up into training validation set through learning weights order minimize error training data training error validation data network depends training validation set often usually random initial weight chosen minimization procedure other words early neural networks highly small changes data different initial conditions produce large changes estimate ie apply same procedure several times using different training validation set different initial real world computing neural networks between neural network often training neural networks paper discuss methods outputs networks obtained through such procedure first have generate training validation sets among cross validation paper consider based idea available data set but particular probability distribution principle would like do inference true yet unknown probability distribution natural do define empirical distribution so called empirical distribution sum available data points each probability number patterns sample patterns empirical probability distribution data points even more than sample sample taken training set patterns do particular sample validation set large probability pattern part validation set advantage over other techniques most statistical theory based using generate training validation sets out our complete data set input output paper regression problems output variable matrix components whether part validation set training set each train neural network layer hidden units output network weight vector input use validation error number validation patterns error network pattern after training left networks practice quite different complete data set should these outputs best possible performance new data several methods have been proposed see eg paper consider same architecture but trained different data training validation sets recently two such methods have been suggested model parameters prediction input vector average over network predictions performance individual networks data used training other hand networks error complete data set following describe form due here call theoretical analysis idea found after training new set test patterns do true but network output each network give each network factor define prediction networks pattern weighted average goal find factors constraints possible generalization error problem our about takes networks generalization error form term depends network outputs thus term networks outputs first part idea more general than discussed here paper consider its version between containing generalization errors individual networks depends thus unknown networks have low generalization error next section find estimates these generalization errors based network validation data have obtained these estimates finding optimal factors under constraints quadratic programming problem estimating generalization error first good estimate generalization error network could performance validation data during training validation error depends training validation set example few part validation set validation error relatively large training error relatively small correct bias result random introduce expected validation error first define number pattern part validation set error over these validation expected validation error validation ratio between observed expected validation error whether validation error network relatively high low our estimate generalization error network ratio scaling factor being estimated average generalization error validation note make assumption bias introduced minimal error validation patterns ie validation patterns used network considered new network independent test patterns simulations compare following methods neural network outputs individual average individual generalization error ie generalization error average perform other methods compared generalization network error data available training mean table generalization error relative average individual generalization error result several methods neural networks trained predict several generalization error take average network outputs our prediction generalization error factors chosen ie estimates individual generalization errors networks expression generalization error factors chosen minimize our estimate generalization error generalization error individual error ie result chosen network generalization error possible generalization error could obtain estimates individual generalization errors two methods used practice applied these methods real world problem prediction several each networks hidden units trained samples about patterns test set various methods combination measured consists about patterns inputs include conditions previous results table give generalization error relative average individual generalization error table performance error data used training generalization error amount overfitting generalization performance obtained through ie first over outputs better than average individual generalization error between number number figure generalization error relative average individual generalization error function number different combination methods shown mean left standard right networks trained tested database these data better than but than cases maximization better among methods table shows much better could find more accurate estimates generalization errors individual networks method most networks ie solution quadratic programming problem under constraints yields few factors different zero average about set simulations thus between networks into network compared these methods well known data set several based variables see eg more information left out available cases generalization performance other cases used training neural networks hidden units average individual mean error over mean error reported study performance depends number randomly sets out our ensemble applied combination methods these sets each times figure shows mean generalization error relative average individual generalization error its standard out best larger number both more both maximization still increase their performance fully into account network yields them far maximization several predictions thus between between better regression problems obtain estimates quality different networks these estimates factors see similar related work context generalization several computationally feedforward neural networks us choice furthermore ensemble neural networks used approximate confidence prediction intervals see eg estimate relevance input fields so has been combination several structure may present single estimator structure neural networks do have they show ensemble neural networks does give more accurate predictions but more information than single network machine learning
neural unit learning rules problem independent component analysis ica source separation introduced these new algorithms every ica neuron into independent components learning rules use simple constrained learning feedback may speed up convergence these stochastic gradient descent rules novel computationally efficient fixed point algorithm introduced
develop node efficiently large probabilistic networks constraints set network yet exact methods they approximations use they upper lower bounds desired times show machines belief networks combination ie chain graphs within same framework accuracy methods experimentally
obtain classification systems both good generalization performance efficiency space time propose learning method based classifiers linear classifiers do better than making random algorithm proposed find classifiers they combined through demonstrated through experiments method developed able obtain classifiers good generalization performance fast training time variety test problems real applications
study time series model decision tree markov temporal structure model exact thus variational approximations consider three different distributions approximation markov performed decision tree decision tree performed time steps markov chain like assumption made out single most state sequence present simulation results artificial data
present paper propose method information maximization minimization hidden units information maximization minimization performed two different levels individual level thus two information individual information defined information minimizing individual information simple networks generated terms number connections number hidden units obtained networks expected give better generalization improved interpretation internal representations method applied inference maximum principle artificial language problem shown individual information minimization information maximization addition experimental results improved generalization performance because over training significantly
unsupervised algorithms based convex proposed find convex combination basis vectors input learning algorithms produce basis vectors minimize reconstruction error convex algorithm locally linear models input while algorithm features both algorithms used model compared vector principal component analysis neural network feedback connections reconstruction back input layer
introduce new algorithm improvement performance measures patterns network output errors several artificial problems algorithm other techniques
architectures such those used bayesian belief networks machines provide framework representing learning higher order statistical among inputs because exact probability these models often much interest finding approximate algorithms present algorithm efficiently higher order structure using em sampling model stochastic recurrent network lower level states through feedback higher levels demonstrate performance algorithm problems
tasks source separation density estimation local structure distributions obtained mixtures independent sources our self map algorithm results digital learning rules perform non parametric density estimation non parametric nature separation allows source separation non linear mixtures introduced into our role network locally independent component approach provides exact condition source separation prior source distributions
dimension feature neural network techniques relationships data have been domain self maps recently introduced novel dimension feature process based upon radial basis function architecture has been observed performance system model order complexity other factors such kernel derived supervised neural network models paper provide effective property give theoretical self architecture forward neural network transformation recently important class neural network based feature approaches related traditional statistical methods scaling have been introduced these novel like approaches feature several interesting properties instance architecture has observed property does model order complexity based upon knowledge its supervised paper presents evidence their self provides terms trained models now provide
belief network obtain tree minimum state space according optimal search over graphs our approach discrete set convex continuous domain cost function over solving nonlinear optimization task obtain good respect cost paper presents two ways problem into continuous domain shows they perform well compared best known
set learned models form improved estimator set models existing approaches their respect discussed new approach based principal components regression proposed address these evaluation new approach domains most robust combination method learned models could without learned models principal components learned models provided weights could
address statistical classifier design given training set small feature set generally larger set eg images although training features may required their class labels propose classifier structure learning algorithm make effective use data improve performance learning based maximization total data likelihood ie over both data two em learning algorithms proposed em applied data classifier based joint probability model features labels mixture experts structure equivalent radial basis function rbf classifier but likelihood based training application new method extended observation test data new data fact additional combined much what image segmentation new data experiments data sets database demonstrate new learning algorithms structure achieve performance over alternative approaches
paper propose method learning bayesian belief networks data method uses artificial neural networks probability thus need making prior assumptions nature probability distributions relationships among variables new method has potential being applied domains containing both discrete continuous variables distributed compare learning performance new method performance method proposed experimental results show although learning scheme based use learning accuracy two methods category algorithms architectures
radial basis functions have been studied but general basis functions such used have been proposed derive new classes simple order networks form general basis functions these global form al form these bound corresponding order network weights function dimensional input space global local cases different simple direct without need monte carlo new shown better generalization errors than weight assumptions weight new between input output weights capture interactions between them address computer architecture
separation generalization error into two types bias variance leads error reduction over classifiers performance both average error classifiers degree correlated across here method correlations introduced uses take procedure similar competitive learning individual networks different weight space respect training set such correlations generalization performance reduced error
adaptive line algorithm learning learning idea proposed gradient information applied learning continuous functions distributions even loss function given available its efficiency demonstrated non separation task signals
present algorithm fast stochastic gradient descent uses nonlinear adaptive scheme time convergence rate algorithm makes effective use information requires computation convergence rates close theoretical demonstrate technique linear large nonlinear networks stochastic search learning algorithms perform gradient descent cost function either stochastic line form stochastic version takes form current weight estimate learning rate gradient estimate input time corresponding learning rule constant over stochastic learning provides several advantages over learning large datasets average compute stochastic learning stochastic update noisy estimate update noise reduce likelihood local assume inputs achieved random sampling training data using information fast stochastic search noise reduced training allow weights converge after within local learning rate allows convergence weight error well known expected weight error its rate furthermore achieve rate have finally optimal gives possible value multiple dimensions optimal learning rate matrix local information into stochastic learning difficult two first available point stochastic learning perform over training data second even available optimal learning requires its inverse compute result paper achieve algorithm ie inverse full without computational algorithm requires computation number weights network uses adaptive parameter our work fully non linear problems demonstrate performance several large back networks trained large datasets stochastic learning typically use constant learning rate during early part training what call search phase obtain exponential convergence local learning called converge phase use adaptive search converge algorithm determine point means during phase compare its performance adaptive well provide comparison gradient optimization stochastic gradient descent adaptive algorithm propose suggested work convergence rates learning constant section relevant results work include learning rule parameter constrained so analysis dynamics expected weight error learning rate shows times learning algorithm without but effective learning rate result consistent work learning small constant same result proposed algorithm convergence rate estimates time finite gradient learning rate inverse its extension multiple dimensions would require time both large models allow effective learning rate matrix following our
quadratic algorithm has recently effective strategy variety optimization problems pattern recognition optimization while algorithm demonstrated simulations known convergence here provide convergence most general form algorithm
paper three terms respect efficiency supervised learning using second order learning algorithms our experiments factor combination term second order learning algorithm convergence performance more than times over other same time about better generalization performance
information about target function learned consider states function learned input variables application demonstrated two real world application task problem measure error function defined objective function derived bayesian report experimental results show using leads significant improvement performance both problems
present new algorithms parameter estimation hmms framework used supervised learning construct iterative algorithms likelihood observations while close current estimated parameters use bound relative entropy between two hmms distance measure between them result new iterative training algorithms similar em algorithm training hmms proposed algorithms step similar expectation step new update parameters maximization estimation step algorithm takes more time per iteration version uses same expectation step evaluate experimentally new algorithms synthetic natural speech data sparse models ie models relatively small number non zero parameters proposed algorithms require significantly iterations use states hmm state special initial state state special state state sequence initial state but state observations observation sequences discrete output hidden markov model hmm two matrices first matrix dimension probability moving state state second matrix dimension probability state set parameters hmm initial state distribution vector represented first hmm probabilistic sequences initial state does following state current state next state chosen according transition probabilities out current state matrix after state output according output probabilities state matrix probability likelihood hmm observation sequence path state state conditions paper assume hmms every state path state non zero probability similar parameter estimation algorithms derived hmms hmms probability over state observation sequences ie likelihood observation sequence obtained over possible hidden state sequences obtain likelihood set observations likelihood values individual sequences hmm likelihood given set observations log likelihood our parameter total number parameters might less zero total number parameters fixed between into classes corresponding matrices class parameters vector st both parameters same two matrices context use both class parameters number ie state associated class now so number times parameter used along path observation sequence note value does parameters next compute partial likelihood log likelihood using here expected number over produce these values expectation step expectation maximization em training algorithm hmms known algorithm next use additional following note here over arbitrary length expected number times state distance functions hmms our training algorithms based following framework iterative updates assume have number iterations our current parameters assume further set observations current iteration case set changes line case typically single observation new parameters should close knowledge obtained iterations but should log likelihood current set thus instead see further training algorithms hidden markov models here measures distance between new parameters off factor usually difficult both distance function approximate log likelihood first order constraints parameters each class sum used distance function relative entropy relative entropy between two hmms need sum over possible hidden state sequence leads following above difficult convex function computational non upper bound relative entropy using log sum note distance function hmm joint distribution between observation sequences hidden state sequences further bound relative entropy using following hmm gives following new ii eq equation still difficult solve new set known therefore approximate distance function ii new parameter updates now would like use functions discuss previous section first derive our update using function setting resulting gives following set equations now solve factor sum parameters above estimation rule update hmms now derive update mixture weights approximate original mixture weights lead state dependent learning rate parameters class computation time limited see values available possible choice use sample based approximation these weights gradient expectation step approximation leads following distance function results update call update hmms given current set parameters learning rate obtain new set parameters right hand update update expectation step weights obtained us evaluate right hand update update more requires additional expected number times state data compute these need sum over possible sequences state observation pairs probability possible given state sum probability state each possible time sequence length hmms efficiently using dynamic programming compute probabilities state sequences up length typically sufficient obtain accurate approximations therefore time complexity depends number states dimension output vector training data improvement possible over update transition probabilities output probabilities first transition probabilities based state probabilities based new parameters possible state probabilities transition probabilities output probabilities finally output probabilities used training algorithms hidden markov models em convergence properties first show em algorithm hmms derived using our framework do so approximate relative entropy distance see use distance approximate de minimizing version distance function following same steps update what call update hmms setting results update maximization estimation step em algorithm although paper due space shown updates update improve likelihood each iteration therefore these updates family generalized em algorithms converge local maximum given additional conditions furthermore using analysis second order approximation likelihood function local maximum similar shown update mapping close local maximum learning rate results faster rate convergence than using experiments artificial natural data order test convergence rate algorithms compare them synthetic data using hmms our experiments used sparse models models many parameters zero previous work eg might suggest updates perform better sparse models used models generate data algorithms almost same performance training algorithms randomly chosen model algorithms used same initial model due different trajectories parameter space each algorithm may converge different local maximum show here results cases updates same maximum often hmm generating data sparse examples typically observations per non zero parameter tested both updates updates learning rates than speed up convergence two updates converge almost fast synthetic data generated hmm natural data update faster than version update learning rates larger than update need used does non new parameters problems data generated hmm therefore used updates our experiments natural data order have comparison learning rate set figure give comparison update update left figure using hmm generate random observation sequences but parameters average each vector parameters hmm non zero performance update update same both updates performance two updates same observations generated hmm case sample based these results suggest alternative using sparse hmm large number parameters zero instead suggest full model updates find relevant parameters approach demonstrated right part figure example data generated sparse hmm states possible output hmms parameters three log likelihood curves given figure log likelihood achieved those parameters non zero hmm generating data random non zero values other two log likelihood update parameters randomly curves show update its less than iterations see line figure point requires more iterations converge compared given prior knowledge non zero parameters contrast full model its convergence much than update update update em iteration iteration figure comparison updates next tested updates speech data natural speech word might different common practice construct set stochastic models order capture possible alternative given word problem studied previously using state algorithm hmms using probabilistic finite experiments discussed here compare above algorithms updates but rather compare updates resulting hmm models usually sparse typically two three have non zero output probability given state average number states practice states about therefore updates may provide good alternative algorithms presented used database database continuous speech labels words models data labels according words data data so words between times used training evaluation according following each word used training data learning algorithm used evaluation each word three models training fully connected hmm whose number states set times sample models training algorithms hidden markov models log likelihood over different random parameter each hmm each word test set table give negative log likelihood achieved test data together average number iterations training log likelihood small means results should update obtained likelihood test data while least number iterations update achieve similar results test data but requires more iterations resulting models update higher likelihood values does better setting parameters zero does faster negative log likelihood iterations states update table comparison updates speech data future research paper have framework used derive parameter updates algorithms hmms view hmm joint distribution between observation sequences hidden state sequences use bound relative entropy distance between new parameter approximate relative entropy distance exact state sample based approximation learning rate framework yields alternative em algorithm hmms em update uses sample based estimates state use line setting contrast line our updates easily derived using observation sequence time alternative gradient descent based methods estimating parameters hmms such methods usually exponential such soft parameters see case learning set mixture coefficients exponential algorithm convergence rate compared algorithms derived using whether still case hmms our future perform study different updates line showing us simple used paper interesting smooth line learning algorithms hidden markov models neural computation statistical inference probabilistic finite state elements maximum likelihood data via em algorithm statistical comparison new algorithms mixture estimation problem learning theory gradient gradient descent linear computation
paper probabilistic model based approach clustering sequences using hidden markov models hmms problem generalization standard mixture model approach clustering feature space two first novel parameter procedure proposed second more difficult problem number clusters data experimental results indicate proposed techniques useful hidden cluster structure data sets sequences
algorithm described based algorithm main its high complexity inverse weight thus much time net better algorithm should use matrix more than weight because inverse takes most time algorithm algorithm called unit described method algorithm inverse whole unit thus time nets further advantage unit used do feature input data understanding unknown problems
analyze two factors call underlying set observations fit training data models explicitly represent two factor structure these models easily during new us solve three general tasks new classification observed new new observed new classification models probabilistic framework mixture models work mixture models significant performance improvement speech shows our approach
optimal brain method number weights neural network estimates increase cost function weights approximation learning algorithm has into local minimum other hand often learning process local minimum early paper show estimates increase cost function network local minimum show extended such used connection early call new approach early brain allows weights demonstrate achieved using three available data sets
present theoretical framework population codes important case population provides information about whole probability distribution over underlying rather than single value use framework analyze two existing models suggest evaluate model such probability distributions
two dimensional image motion detection neural networks have been implemented using general analog neural computer neural circuits perform feature based cortical motion detection model neural computer provides neurons synapses synaptic time required model vlsi hardware results show visual motion estimation implemented simple sum neural hardware temporal computational neural circuits compute general visual motion real time
many learning rules terms continuous analog inputs outputs biological systems use action digital amplitude analog information action potential representations now being used advantage vlsi systems well report simple learning rule based equation described action potential neuronal outputs demonstrate learning rule analog vlsi chip uses synaptic weights show our time dependent learning rule sufficient achieve approximate weight temporal correlations spike spike based learning neuron analog vlsi
use constant statistics constraint array gain algorithm has been analog hardware designed cmos measured results chip show system gain input signal
dimensional visual tracking chip has been implemented using analog vlsi techniques model selective visual attention control smooth eye movements chip processing compute image take circuit feature tracking target position direction motion reported target across array demonstrate its system performs smooth tracking movements using dimensional eye
problem has practical application analog has been accuracy due analog characteristics each result paper dynamic control architecture allows analog neural networks characteristics change input level have applied architecture input analog cmos take chip have experimental data show architecture
describe implementation hidden markov model state system component speech recognition system key state design power analog circuit implementation word state state test chip
propose architecture real time processing analog vlsi show time frequency signal allows robust implementation correlation algorithm algorithm uses binary instead analog analog need analog analog simulations show resulting algorithm has same out sample classification performance correct matching algorithm
detection amplitude modulation step sound present model uses spiking neurons frequency sound based observation so called well certain rates amplitude modulation cells frequency our model uses three different circuits ie artificial cell circuit spiking neuron circuit
use visual well auditory speech signals words variety systems have been task main research compare performance range dynamic visual features task have found images due scale generalization performance visual representation used addition dynamic information difference between better performance than based approaches local low filtering better than global principal components analysis pca these results possible
paper general adaptation algorithm standard neural network increase its recognition accuracy specific user basis algorithm output neural network input even output output using output adaptation maps output into correct user dependent confidence vector network radial basis functions line applied construct adaptive recognition system line word error rate test set average while basis functions each test set
paper presents new approach speech recognition hybrid while standard approach hybrid systems based use neural networks posterior probability new approach based use mutual information neural networks trained special learning algorithm order mutual information between input classes network its resulting sequence firing output neurons during training shown paper such neural network optimal neural vector discrete hidden markov model system trained maximum likelihood main advantages approach fact such neural networks easily combined hmms complexity context dependent shown resulting hybrid system high recognition rates now same level best conventional hmm systems continuous parameters mutual information neural networks yet
time series prediction applications neural networks after short
reduce computational complexity classification systems using distance et al developed algorithm models representing large data automatically best associated proposed classification system based several use distance error reconstruction measure propose gradient based learning algorithm model several advantages both models space improved respect our algorithm thus models dimension determined automatically algorithm our algorithm able learn new transformations
prediction estimation signal processing perform these tasks given noisy data form time series model process data noise system explicitly into account kalman discussed process estimating both model parameters underlying state system several methods linear case propose several kalman filters forward filters neural networks methods compared several simulations noisy time series include example nonlinear noise reduction speech
paper number ensemble methods performance classification use speech recognition system two ensemble methods described boosting mixtures experts both combination results presented two speech recognition word database large continuous speech database these results show ensemble methods such boosting mixtures provide superior performance more ensemble methods such
future have combined artificial neural network classifier context search over segmentation word segmentation word recognition provide robust recognition hand text new models present training use classifiers word recognition including output error frequency error negative training discussed
field has suggested neurons line found visual cortex form sparse distributed representation natural scenes has such responses should unsupervised learning algorithm find code independent visual features show here non linear applied ensemble natural scenes sets visual filters these filters like those produced network field addition outputs these filters independent possible network able perform independent components analysis ica compare resulting ica filters their associated basis functions other filters produced principal components analysis pca zero phase filters ica filters have more distributed outputs natural scenes they receptive fields simple cells visual cortex suggests these neurons form information system images
paper describes new technique object recognition based learning models image into local regions described new representation called generalized second derived output filter class local features their global learned hierarchical mixture experts architecture technique applied database general back without back difficult problem class new technique has rate compared images give rate nearest give rate
paper propose model connectivity orientation selective cells visual cortex based study properties input signal visual cortex find new statistical structures have been applying idea system representation signals derive connectivity achieve set local orientation selective well complete spatial structure layer such compare results various measurements
study correlation natural time varying images explore hypothesis visual system optimal coding visual representation through input signal based measured power input signal derived analytically compared processing observed experiments
local information often sparse noisy two estimating image region need average accurate estimate problem over have developed network model estimation based neurons such those found early processing visual cortex model estimate multiple region may real images random use selection mechanism local estimates results superior performance compared standard back propagation cross correlation approaches addition representations learned selection mechanism consistent recent results cells cortical visual area multi scale image processing power mixture experts learning algorithm approach yields both high performance new into visual system function selective model estimation
self architecture developed image region classification system consists filtering compute vector image properties properties vector inputs system learns noisy their probabilities architecture applied difficult real world image classification problems including classification synthetic natural images recent state system natural
paper describes early visual process using em algorithm underlying computational representation based according our em approach parameters iterative weighted least process expectation step our em procedure likelihood data using mixture model defined over set these limited their spatial using gaussian functions likelihood leads set linear equations parameters solve weighted least problem evaluate technique structures images
simple model large scale visual cortex introduced shown basic cortical architecture recurrent local account such properties orientation model account such local effects cross orientation shown state dependent between similar orientation model such effects non local orientation non local following account given perceptual object segmentation such direct
compare generalization performance three representation schemes using single classification strategy neural network face images presented represented full face their similar constrained eye areas finally eye areas obtained random image system generalization novel face images networks trained database human subjects identify single face
have processing visual system could achieved using order firing different code rather than more conventional firing rate schemes using neural net based input layer function delay have initial visual processing initial results even activity output cells limited spike per neuron per image out form rate coding processing based activation possible
computational vision research has been estimation local scene properties requires measurements across image many have therefore suggested solving vision problems using architectures locally connected units their activity parallel convergence traditional methods such architectures has general they do stable point global minimum paper show architecture bayesian about image properties between units yields convergence times several faster than traditional methods local particular our architecture non iterative sense every time step local estimates given location optimal given information has been location illustrate algorithms performance real images compare several existing methods theory our approach shown figure figure shows problem interpolation function sparse data figure shows traditional approach problem array units value function points activity unit based local data those points data available activity points discussed local update rule images bayesian figure problem traditional approach array units represent value function units update their activity based local information activity units bayesian belief propagation approach units probabilities them according probability two non defined such network state activity each unit value optimal function figure shows bayesian belief propagation approach problem traditional approach function represented activity array units units probabilities rather than single estimates their probabilities according probability above represent activity unit location noisy samples true function interpolation problem would minimize have defined grid points data points data quadratic local update direction gradient converge optimal estimate yields updates algorithms their choice over method choice such problems derive update rule problem note minimizing equivalent posterior probability given following generative model ratio role similar original cost functional advantage cost functional posterior us use methods hidden markov models bayesian belief nets optimal estimation derive local update rules posterior property allows us factor into three terms local data another data left data right thus constant now conditional terms another constant symmetric equation suggests propagation scheme units represent probabilities given left hand equations updates right hand ie units gaussian generating process probabilities represented their mean variance thus gives kalman filter like update parameters update rules parameters so far have considered continuous estimation problems problems estimate label discrete values label value zero typically form algorithms minimize cost form choice linear sum gives discrete network updates linear sum threshold gives continuous mean field field updates yet another form gives algorithm see methods derive algorithm posterior markov generating process process gives same equations linear sum probabilities here gaussian represented mean but rather vector length thus update rule sequence labels those should do rather than propagation images bayesian figure first sequence hand left using standard methods convergence equations possible show after iterations activity units converge correct distance between two units architecture iteration update units furthermore have been able show after iterations activity unit represent probability hidden state location given data within distance significant made local propagation rules scheme units their limit fast information given unit ie after iterations unit about information within distance thus minimal number iterations required data units between two types iterations those allow information units those used estimate based information has shows uses first type iteration iterations used allow more information units information has correct posterior given information further iterations estimate moreover have been able show schemes do probabilities such those equations general represent optimal estimate given information has both traditional updates equation updates equations give simple rules units activity based local data units fact updates based probability units activity optimal given information has gives difference between convergence these two types schemes next section demonstrate difference image interpretation problems results figure shows first sequence hand left figure shows hand using standard techniques motion propagation along local measurements along determine motion suggested local minimizing following figure local estimate along performance gradient descent function time faster than motion estimate after iterations motion estimate after iterations cost functional spatial temporal image point along functional interpolation functional eq updates figure shows estimate motion based local information estimates due problem figure shows performance three propagation schemes gradient descent gradient descent so improvement its estimate much faster than gradient descent but still has significant error after iterations correct estimate after iterations here iteration update units network due fact after iterations estimate location optimal given data case data every such along estimate motion figure shows estimate produced after iterations even simple visual estimate quite figure shows correct estimate produced after iterations direction figure propagation figure bounds region direction figure eg these two regions figure local given three points along makes defined those points images bayesian figure local estimate along performance descent function time method global minimum estimate net after convergence estimate after convergence rather than figure shows results using local hand local sufficient local minimizing cost functional takes into account points addition local point along define determined location figure shows performance four propagation algorithms task three traditional algorithms field et al constrained gradient descent three traditional algorithms converge local minimum while global minimum figure shows local minimum field network figure shows correct solution algorithm section converge correct posterior given data previous two examples reduced information other points same cases information should points image such propagation problems markov random field generative models posterior cannot efficiently have recently shown hierarchical multi resolution models current work have been using multi resolution generative model derive local rules case bayesian between units representation image although work still find results comparison traditional schemes update rules equations those derived conditional probabilities sum using original algorithm sequences long lead small our update rules forward algorithm hmms based assumption states updates symmetric finally equation equation addition these context use update rules different while hmms kalman filters updates posterior use these updates parallel network local units estimates units network improve function iteration have shown architecture bayesian according probability yields convergence over traditional schemes do probabilities thus image interpretation provides important example task bayesian bayesian nets training applied optimal estimation visual motion markov random field modeling computer vision efficient regularization application computation image processing vision probabilistic systems networks inference speech recognition scene systems level visual representations
has been suggested long range connections cortex may role et al number studies have possible role long range connections modulation contrast detection et al various detection tasks field et al have developed network based connectivity cortex well temporal dynamics neuronal processing able observed experimental results network has been tested real images has applications terms image processing systems
present algorithm linear patterns based concept orientation selective cell concept vision multi neural network fixed architecture orientation define output elements corresponding different allow us make selection decision algorithm takes into account well presence noise method applied sample data order identify linear pattern signals two dimensional representation relevant part used algorithm performs well given its architecture system good fast pattern recognition parallel processing
paper presents method data link so quality constraints method uses samples results different conditions neural network decision function previous similar approaches problem have significant bias bias real system results data either bias provide confidence level method applied sources based difficult analyze data data method accurate control function results more than data
artificial neural networks used predict future order take should network each same network paper explore other prediction future different different tasks parameters across form multi task learning series experiments obtain more than above various
paper shows option means extended kalman filter algorithm consider call option pairs time two output nonlinear system approach radial basis functions neural network used nonlinear system generating these observations show both these systems may using algorithm present results simulations data discuss problem sequential manner
data simple techniques models such neural networks have potential features data useful models have effective control overfitting paper study predictive quality neural networks other models applied real artificial data results suggest complex features real data demonstrate bayesian neural network provides effective control overfitting while ability complex features artificial data
related reduced through early detection current detection techniques such achieve high technique changes rbf ensemble algorithms based such provide near implementation detection results more direct accurate than those achieved either human experts statistical algorithms
present mixture experts approach sparse correlated data interpolation method uses global model estimated data take account spatial data based close relationship between radial basis function rbf network use mixture generalized rbf networks input space into correlated regions learn local model data each region applying approach simulated real world data show able achieve good input space learn local models improve generalization
high frequency data into three components effect component information component information component presence effect make analysis due information information component difficult propose neural net based independent component analysis high frequency data into these three components our empirical results show our proposed multi effect decomposition behavior
dynamic programming learning other discrete markov decision process applied continuous dimensional state spaces state space into array often above two dimensions lead policies possible solutions variable resolution function approximation neural nets option has been studied learning interpolation grid paper study interpolation techniques result online behavior resulting control systems interpolation interpolation algorithm based interesting dimensional space these under three reinforcement learning value iteration known model ii learning online value iteration previously unknown model learned data describe empirical results resulting practical learning continuous non linear dynamic control grid based interpolation techniques reinforcement learning algorithms generate functions map states cost values continuous state spaces these functions following used may used two dimensions above two dimensions value functions see lead even two dimensions neural nets have been used td sutton learning high dimensional spaces while they produce accurate value functions might control dynamic systems most used methods applying value iteration policy iteration neural net value function often interpolation over points grid another useful value functions has been studied reinforcement learning paper interpolation schemes may because they local convergence has been such cases value iteration interpolation methods discussed here state space into grid dimensional data points associated resulting value given point continuous state space computed weighted average data points interpolation using interpolation data points value within weighted average scheme global value grid given value dimensional space interpolation involves linear between data points higher dimensional space efficient implementation described arbitrary query point along each two containing query point use two dimensional over each these two values both these points between two values generated previous step interpolation processes data points every query based interpolation possible over data points given query time still achieve continuous each into according assume unit each possible set points equation each into manner two elements dimensional common have common across use interpolation scale system containing query point unit new query point us use algorithm through query point interpolation reinforcement learning convex combination relevant use coefficients determined previous step weights weighted sum data values corresponding point do explicitly represent different above steps performed time second log time using conventional problem domains domain goal near top dimensional back up order speed goal state space two dimensional see further but note our formulation than formulation goal region range random states task reward action taken goal region goal used two actions available maximum maximum two link robot under its joint joint goal hand least above sutton state space four dimensional two two position down task same way actions two applying interpolation three cases case value iteration known model first effect each possible action each state corresponding grid suggested use these derive discrete action state results possible states number used per interpolation without interpolation interpolation based interpolation optimal policy derived using value iteration because value iteration performed discrete much less computationally than they would have been many other function value iteration gives us values our grid may use values other states during online control results value iteration known model tested two interpolation methods variety levels first value iteration random states number steps taken goal those states number required convergence well time required value iteration see figure results steps goal values means expected error steps grid size interpolation method steps goal time steps goal time steps goal time figure value iteration known model grid size interpolation method steps goal time steps goal time steps goal time figure value iteration known model functions require more convergence but improvement policy both interpolation methods provide even high grid grid along each better than along each results value iteration known model used same value iteration algorithm domain case our test same state but larger set grid figure different grid cell different locations these locations important problem performance grid resolution changes cases interpolation necessary solution without interpolation value iteration often converge relatively may trajectory goal through grid more than would algorithm constant value over grid using interpolation better than those based interpolation value function provided interpolation value iteration interpolation about fast interpolation higher dimensions speed ratio increase interpolation reinforcement learning case ii learning under second reinforcement learning do use model rather learn function directly maps state action pairs long term does interpolation here implementation function zero after sufficient distance our decision point perform single grid point values according perceptron like update rule action function current state results learning used learning grid size figure shows learning curves three using three different interpolation techniques both interpolation methods provided significant improvement both initial online performance without interpolation achieved average performance about steps goal interpolation based interpolation note these significant over corresponding results value iteration known model functions often because learning being performed online learning controller these control values such results learning used same algorithms domain grid size results shown figure figure left performance learning grid interpolation out top interpolation right learning grid two out top performance each shows sum better average performance gradient negative because each state transition goal results reward both using interpolation improved goal relatively small number steps per using interpolation achieved average steps goal per using based interpolation achieved steps per other hand using interpolation much average more than steps per controller actions randomly typically takes about same number steps goal based interpolation provided line performance close provided interpolation but computational cost case value iteration model learning here use system but do assume have instead model system assume model value function via same algorithms would use true approach may tasks data computation here models learned using simple grid based function without interpolation both reward transition functions model same grid resolution used value function grid model model so every state state zero reward while making transitions through state space update model use relevant parts state space effects actions under model value iteration convergence time rather updates performed system figure left performance model learning grid right grid both cases interpolation out top while interpolation up results value iteration learned model used algorithm described above grid average about two performed per transition complete performed every steps first two every steps figure shows results first over first using based interpolation much better than using interpolation its performance shown close using interpolation average steps goal per while using interpolation using interpolation significantly than these steps per interpolation reinforcement learning model performance improved more than over first few other hand their performance significantly results value iteration learned model used same algorithm grid domain time complete every steps through first two every figure shows results case using interpolation so much time per experiment early after still average more than steps goal using interpolation much better using interpolation solution steps per using based interpolation about steps graphs show these three improve significantly faster than using similar grid have shown two interpolation schemes based weighted average points cell other may used three reinforcement learning optimal policy computation known model learning online value iteration while learning model each case our empirical studies demonstrate interpolation level necessary solution future research explore use variable resolution multiple low dimensional high dimension interpolation manner memory based more research part research generalization reinforcement learning value function neural information processing systems performance using reinforcement learning neural information processing systems stable function approximation dynamic programming machine learning reinforcement learning less data less real time learning algorithm variable resolution reinforcement learning state spaces machine learning applications report
new reinforcement learning architecture nonlinear control proposed direct feedback controller trained value gradient based controller architecture both efficient use value function simple computation real time implementation good performance multi dimensional nonlinear control tasks using gaussian networks
general bayes optimal adaptive markov decision processes require amount computation optimal learning problem paper approximate approach processes used model certain local sense given processes important have optimal learning defined terms computed relatively efficiently thus scheme optimal learning general actions suggested optimal respect local models
control sensory feedback usually free but cost may take sequences actions describe reinforcement learning algorithm learns control cost although assume use control means actions taken current state system special case hidden state problem reinforcement learning our algorithm short term memory main result paper rule significantly possible memory states memory states estimated value information than its cost prove rule allows convergence optimal policy
reinforcement learning methods discrete semi markov decision problems such real time dynamic programming generalized processes optimal control problem value problem fully nonlinear second order differential equation type numerical analysis provides methods equation case learning control systems equations various grid levels obtained using observed information transitions local cost special attention type time space during observation algorithm multi grid observation proposed multi grid algorithm demonstrated simple problem
now learning task ie without prior knowledge learn they initial well approach learning problem other learning control paper learning applied context reinforcement learning consider function value function policy model task dynamics possible areas speed up learning general nonlinear learning problems model based reinforcement learning shows significant speed up after while special case linear quadratic problems methods implementation complex robot demonstrate real signal processing model based reinforcement learning most problems using suggested methods robot learns single after second long human
model learning combined dynamic programming has been shown effective learning control continuous state dynamic systems method learned model correct dynamic programming but many provide uncertainty estimates fit they paper case system during learning propose new algorithm control use bayesian locally weighted regression models dynamic programming common reinforcement learning assumption should paper case system has algorithm dimensional simulated control problem
have bias variance provided various temporal difference value estimation algorithms change updates over markov using table representations illustrate classes learning curve behavior various show manner td sensitive choice its parameters
probability models used predict missing data but even model cannot used make between them provided many real world problems such cost test well expected improvement considered relatively work has been learning optimal decision making paper show temporal difference reinforcement learning td used determine decision within context mixture model apply new approach problem learning number have achieve same level performance compared probability model results significant cost efficiency
present monte carlo simulation algorithm real time policy improvement adaptive controller monte carlo simulation long term expected reward each possible action measured using initial policy make each step simulation action measured expected reward taken resulting improved policy our algorithm easily has been implemented parallel have obtained initial results applying algorithm domain results reported wide variety initial policies random policy td strong multi layer neural network each case monte carlo algorithm gives reduction much factor more error rate algorithm useful many other adaptive control applications possible environment
present new results about temporal difference learning algorithm applied cost function markov chain using linear function algorithm analyze performs line parameter vector during single trajectory finite state markov chain results include convergence probability limit convergence bound resulting approximation error addition new results than those previously available our analysis based new line provides new about dynamics temporal difference learning furthermore discuss two examples line function
propose analyze algorithm solutions problem optimal markov chain scheme involves use linear fixed basis functions approximate function weights linear combination through iterative process similar learning simulation underlying markov chain due space provide convergence probability bounds approximation error first theoretical result algorithm combined arbitrary linear function solve sequential decision problem paper case finite state spaces results extend continuous state spaces full length paper
have developed neural network architecture theory attention learning cortical based adaptive between cortical areas here present specific higher order cortical model networks interaction cortical levels processing auditory results experiments showing auditory depends structure inputs timing mechanisms model allow us explain relative timing information such relative order between model suggests auditory attention may
novel neural network model attention processing tasks presented using line taken experiments study hypothesis between parallel processes global information internal representations visual scene model two first visual via principal component analysis second data target order identify target our main finding found experimentally parallel system while experimentally cannot difference via variance analysis representations numerical criterion parallel our model yields mapping response time similar search formulation their feature similarity presents neural processing may classical visual search parallel processing computational study visual search
human subjects known their motor behavior visual field about over their have studied analog effect speech using back speech signals real time subjects their speech feedback found learn their feedback change moreover effect across different
value decomposition method unsupervised training network two classes linear connections through single hidden layer used learn represent among large words large natural text they result dimensional spaces trained word could represented vector measured between vectors good accuracy human has been demonstrated performance multiple choice domain knowledge several other ways examples given knowledge method applied
structure cortex study multi model associative memory successfully memory patterns different levels activity show synaptic into linear nonlinear networks memory retrieval performance compared conventional single associative memory network multi network has two main advantages less input its response consistent data category specific
connectionist single models have been over correct process recent models predict subjects should show words word eg than prediction has been human experiments would effect left right process single parallel connectionist models cannot account presented here network models do show interaction along statistics explain effect
often specific functional brain has proposed alternative class partial multiple explore performance observed presented objects but performance relatively normal objects auditory cues appropriate use presented objects model highly specific through partial two maps visual input other maps responses effect tasks require other show performance but task requires both ie presented objects our model other associated makes experimental predictions study resulting functional systems brain generally particular functional system between systems suggested alternative class partial multiple systems through interactions among explore left posterior including cortex presented objects visual demonstrate recognition presented objects example appropriate use object visual into their visual objects cues such made objects auditory highly specific nature rules out terms single standard model visual figure more complex model required theory figure standard model visual levels representation mapping level representation another although cannot vision proposed terms partial both multiple systems multiple visual more account suggested might partial two standard model those visual input effect these tasks require these eg visual auditory relatively tasks both eg visual show significant model present computational model theory architecture figure architecture has four visual input auditory input each associative memory critical property required explain speed accuracy off initial output but may over time output best interpretation input implement using architecture suggested architecture inputs their best means two stage process figure first mapping performed feedforward connectionist network input directly its corresponding output iterative up process out recurrent network architecture shows speed accuracy off assumption feedforward mapping network does have capacity produce right output every input inputs noise up stage required produce interpretation noisy output mapping network fully distributed networks have been used similar eg network layer state units layer radial basis function rbf units rbf unit per each rbf unit measures distance current state activity unit figure connectionist implementation processing consists feedforward mapping network recurrent network connectionist processing units connections between units between units way output up network mapping network input state unit activity vector time vector location region state space over its rate state converge state units input mapping network units activity state unit time output mapping net given linear threshold function bounds activity between weighted time average output mapping net simulations activity state units two input feedforward net first term equation unit second term parameter mechanism relative these two basic idea input mapping net system should input should yet input case input through state units should have value close input focus input following dynamics network being zero weighted time average update rule what allows smooth transition function its new value certain function have convergence algorithm speed accuracy off these dynamics have another important present model respect into such into state unit input because these change over time state approaches well state dynamics quite complex input property important several associated pattern patterns constructed each spaces visual auditory input responses each space made dimensional generated binary patterns each space known domain visual auditory spaces patterns into similarity clusters per cluster patterns chosen randomly two constraints patterns different clusters least between because similarity patterns spaces our modeling similarity structure these spaces theory instead generated patterns these spaces random constraint every pattern least every other after generating patterns each spaces arbitrary among patterns such visual pattern auditory pattern pattern pattern pattern represented same concept appropriate response visual task visual pattern would pattern pattern training procedure feedforward networks four trained using back propagation each these networks single hidden layer units units network used symmetric activation function give range amount training chosen such performance training examples usually several elements output would ie have would correct ie assumption feedforward net does have capacity map every input right output up process required training required up network due representation up network hand each up net its domain along state same value state state required lower so even input would sufficient network out state simulation after each been trained model connections mapping networks connections chosen random equal two up nets architecture total different times simulated tested each four tasks input patterns task results report across simulated input patterns responses determined after system been given sufficient time into taken response each response following response types correct response same produced three visual error visual pattern corresponding response visual pattern corresponding correct response error error other error mechanism recently stimuli has been found across wide variety tasks normal subjects our model parameter recently see related approach model mechanism often results have models behavior amount parameter report performance simulated amount effects produced error rates visual task range performance table error rate model various tasks task error rate auditory auditory visual visual table presents error rates model four tasks pattern errors shows fit human data model produced errors auditory task because two component relatively few errors made auditory visual tasks each because up nets able error rate visual task quite large due both its component error rate visual cannot effects two component because sum error rates auditory visual each involves two four times rather effects these their interaction leads visual pattern presented model into representation up while up up process during time up network correct representation into combined effect noisy representation input leads representation point up interactions architecture arbitrary assumption into our model point consider two architecture might interaction model first into well state its output into would interaction effects would cortical do stage its computation next stage moreover brain such processing strategy partial results next speed processing without
data showing specific information makes important recognition memory existing memory models furthermore evidence present model based known features following key characteristics ie studied leads less but does quality ie information study
given set objects visual field does visual system learn particular object interest while so object paper these context kalman filter based model visual recognition has previously useful certain such related classical receptive field effects visual cortex using results field robust statistics describe extension kalman filter model multiple objects visual field resulting robust kalman filter model certain attention property interaction between top down up signals model suggests functional certain effects have been observed visual cortical neurons experimental results provided demonstrate ability model perform robust segmentation recognition objects image sequences presence varying
recently have derived complexity analysis analog computation setting discrete time dynamical systems empirical training recurrent neural networks systems analog mechanisms previous work learn process simple context free language extend work show learn simple its into sensitive solution provide dynamical systems analysis network but information
present study word recognition rates compare human machine series experiments interaction word recognition word frequency non words level study segmentation compare human performance our artificial neural network model found proposed computer model uses word context efficiently but performs recognition task
known make between eg than between eg different noise here show corresponding present early auditory processing based previous work demonstrated natural robust statistical properties could auditory system those properties construct efficient neural codes test hypothesis measure information rate auditory spike stimuli whose amplitude modulation has characteristics compare information rate stimuli non modulation find inputs significantly rate information neural responses characteristics natural auditory scenes natural scene statistics neural code goal research complex natural scenes auditory system natural difficult describe complexity auditory responses they makes gain into their processing most studies auditory noise stimuli resulting limited understanding auditory paper novel approach study natural sound auditory spike our corresponding figure left amplitude modulation stimulus stimulus set spike train neuron right amplitude modulation non set spike train same neuron method consists statistical characteristics natural auditory scenes them into simple stimuli manner thus stimuli us study natural first stage has been described second reported fig shows two long stimuli corresponding spike same neuron amplitude these stimuli while both stimuli random have same mean both spike have same firing rate may high low more stimulus left these stimuli two stimulus sets different statistical properties our present study auditory coding efficiency neural code given stimulus set well input sound between similar sound based spike train those stimulus statistics discrimination auditory neurons using information theory et al et al leads optimal coding given auditory scene particular statistical properties possible design scheme would those properties resulting neural code optimal scene but less efficient other scenes here investigate hypothesis auditory system uses code natural auditory scenes question discrimination auditory neurons between sound stimulus set non set statistics natural first step between neural responses auditory inputs studied temporal statistics natural auditory scenes well known different locations different frequency components sound eg frequency spatial location vision therefore large database including speech using various filter each frequency amplitude phase limited signal cost amplitude probability distribution correlation coding stimuli auditory neurons speech sound curves give low curve function computed well those frequency those statistics found across particular distribution log amplitude log have zero mean unit variance could well form should large amplitude several examples fig log amplitude distribution amplitude distribution found known distribution speech signal processing well shown amplitude distribution gaussian signal power found have form together results those show natural arbitrary robust characteristics present paper explore what auditory system them efficient neural codes another important point made well visual signals natural inputs often gaussian eg signals used conventional system methods often applied system paper use non gaussian stimuli study auditory coding rate information transfer experiment based our results temporal statistics natural auditory scenes construct stimuli simple signal more characteristics natural into use stimuli amplitude sound phase modulation point amplitude statistics constructed amplitude exponential distribution each time point using modulation frequency ie used non stimulus set chosen distribution so both stimulus sets same mean short each set shown fig two distributions right stimuli minimize adaptation effects between two sets using long single unit made auditory processing stage eg each unit best range sound called its best frequency units have similar frequency auditory system each unit stimuli frequency most units used firing rates response those stimuli between stimulus signal sampling rate after spikes stimulus amplitude both amplitude spike train down analysis order ability between different inputs based observed spike train computed mutual information between spike train response spike times stimulus amplitude st consists two terms stimulus entropy log number different stimuli entropy stimulus response log number different stimuli could given response thus could based response over responses our approach generally et al et al first stimuli st st function chosen so gaussian exponential stimuli stimuli inverse error function has two advantages first expression mutual information now being given frequency dependent signal noise ratio see depends power st second more noise distribution observed gaussian following transformation compute bound above requires conditional distribution note these variables complex joint real parts gaussian mean variance variance fact power noise define st computing mutual information those gaussian distributions provides lower bound coding stimuli auditory neurons figure left signal noise ratio modulation frequency stimuli right noise distribution line amplitude distribution stimuli line stimuli line true its log signal noise ratio given stimulus performed over responses main object here estimate stimulus spike train would given conditional mean each gaussian estimator generally non linear linear given filter our distributions used conditional mean obtained kernel estimate gaussian kernel spike train data points obtained computing using scaling assumption distributions their variance us use data points estimate given our estimate produced higher than estimate used et al et al information stimuli exponential stimuli shown fig left our units neurons have modulation frequency eg about unit generally stimulus response independent thus stimulus components higher than cannot estimated spike train stimulus amplitude distribution shown fig right line together noise distribution have unit variance line gaussian figure left signal noise ratio modulation frequency stimuli line compared stimuli line right noise distribution line amplitude distribution stimuli line compared stimuli line stimuli line using obtain information rate spike rate measured unit into across units have stimuli although information rate computed using conditional mean estimator interesting filter provides optimal linear estimator stimulus discussed previous section filter fig line has temporal several information non stimuli stimuli shown fig left line same unit fig significantly lower than corresponding exponential stimuli comparison line mutual information rate obtain across units have non stimuli stimulus amplitude distribution shown fig right line together exponential distribution line comparison well noise distribution have unit variance noise case less gaussian than exponential stimuli our bound may lower stimuli fig shows stimulus reconstruction filter line has similar time filter exponential stimuli but significantly its temporal more than measured rate auditory neurons information simple stimuli amplitude modulation found higher than stimuli non modulation result along same obtained et al using gaussian signals whose according call work vision field suggests visual receptive field properties consistent optimal coding predictions based characteristics natural images future work explore coding stimuli more complex natural statistical characteristics coding stimuli auditory neurons figure response reconstruction filter stimuli line non stimuli line extend higher processing useful experimental support research theory early visual processing neural could information theory provide theory sensory processing network temporal low order statistics natural neural information processing systems de neural code temporal theory non responses network field between statistics natural images response properties cortical cells statistical signal processing estimation theory new simple coding procedure neurons information capacity
relationship between neurons precision its response stimuli constructed model spiking neuron probabilistic firing model both average firing rate response precision cell model based free firing rate function may better description spiking neurons response than stimulus time
experiments ways make predictions about use those predictions control their behavior standard model many stimuli suggests individual predictions should together various key results show model alternative model selection between different available stimuli new model form mixture experts has close relationship other existing well
while understanding functional role different classes neurons visual cortex has been studied time our understanding feature functional role neurons auditory cortex much complete moving have long been optimal stimulus many visual cortical neurons finding has recently been extended using correlation methods et al et al study neurons auditory cortex used novel correlation technique compute receptive fields stimuli both multiple frequency components time these receptive fields make neurons auditory cortex visual cortex typically show structure their feature processing properties often including multiple regions their receptive fields these neurons sensitive stimulus frequency time sensitive stimulus transitions such changes frequency these neurons show strong responses continuous frequency stimuli visual
current understanding neural information processing biological systems code large neurons parallel present algorithm stochastic firing patterns large neurons algorithm machine family predict observed spike patterns data model consists observable layer directly input spike patterns hidden units through connections input layer hidden unit activity down observable layer prediction data pattern produced hidden units their weights improve fit between predictions data increase bound probability data given model strategy optimal but computationally large neurons show data constructed spike early results data our multi cortical
pattern eye movement smooth eye direction direction eye position form has been described but amplitude limited has been observed previously subjects describe results produced normal subjects propose new model neural circuits control eye movement but under normal such plasticity due lead
provide model standard task more task novel locations exhibit learning after few training model uses cells support reinforcement learning manner use
initial activity independent map system has long been matching cues retina direct experimental evidence such has new data has new set models experimental here these models gradient they predict derived
system target derived factors important role appropriate paper shape such gradient might have function distance target time factor using estimates relevant parameter values experimental domain could such gradient derived large times value maximum range about obtained value well experimental data times analysis over may possible prediction tested
propose model early visual processing model consists population linear spatial filters through non linear statistical estimation theory used derive human responses population units model able human contrast orientation discrimination tasks predict contrast presence varying orientation spatial frequency
paper present new method auditory systems based sequences method allows us study linear response system presence various other stimuli such speech allows construct linear kernels receptive fields same time other stimuli being presented using method modulation transfer function single units different points discuss response
normal vision inputs two into single images presented two perceptual gives way between inputs called although recent evidence involves modulation neuronal responses cortex basic mechanisms differential processing stimuli using neural network models early visual system demonstrate here firing cortical like neurons first inputs two results activity patterns visual contrast firing among these cells such temporal cortical activity its effects neural network connectivity its dynamics these results suggest input related relative spike timing early stage visual processing may give both perceptual vision
here analyze synaptic information derive form lower bounds capacity simple model cortical under two coding under signal estimation assume signal mean firing rate neuron performance optimal linear estimator signal provides lower bound capacity signal estimation under signal detection presence signal has performance optimal spike allows us compute lower bound capacity signal detection find single synapses measured parameter values information but significant improvement achieved small amount
proposed complex cells visual cortex simple cells same orientation but different spatial wide variety experimental results over two have hierarchical model many complex cells input cells do simple cell input recently using model nonlinear interactions among synaptic inputs tree could provide nonlinear complex cell responses work result case complex cell model cell resolution much than dimensions cells receptive field optimal values pairs both good our results potential computation visual processing particular cortical general account
cortex neurons have been found complex while showing respect stimulus transformations such scale changes limited depth training novel like objects et al could investigate whether these properties due many object mechanisms allow cells show response previously object they found object selective cells limited various transformations after training single object while previous models cells depth their specific object relative population objects model described here explain way additional properties size using same stimuli experiment find model neurons exhibit properties parallel those real neurons simulations show model capable unsupervised learning view neurons useful
discuss solution problem produced multiple cells neural take explicitly probabilistic approach using latent variable models varying describe distribution produced single cell models range single gaussian distribution each cell mixture hidden markov models statistical structure approach generative model chosen specific neural
have studied application independent component analysis ica approach possible statistical technique components according their amplitude distributions over time thus between signals signals many category order method produced eye movements due presence digital results demonstrate method identify produced
model responses cells visual area during natural vision our model consists classical energy mechanism whose output gain control contrast mechanisms apply model stimulus sequence cell during free natural images data three cells using different model fit data each energy mechanism find but significant correlations between model data these correlations improved allow effects case fit data time models response
prove measure optimal distance measure use nearest classification show distance feature space function classes linear fixed set features like bounds given required learn experiment presented neural network environment used do classification
introduce new computing related linear threshold version neuron instead function arbitrary many transitions function weighted sum its inputs call new computing linear threshold multiple transitions paper consists following main related our study circuits efficient circuits addition multiple number product two particular show compute addition single layer elements ii area vlsi reduced circuits circuits inputs symmetric functions computing power relative circuits
recent theoretical results pattern classification real functions such support vector machines networks boosting give bounds probability do size classifier than bounds theory paper show these techniques more applied representing other functions two layer neural networks convex functions example show high probability decision tree depth more than consistent training examples has probability more than log class node decision functions effective number small distribution training data far bound different bound use same technique give similar results should
simple linear outputs several networks eg decomposition sum error sum error average model quadratic function factors networks ensemble quadratic programming algorithm finding optimal factors output network probability sum error linear outputs probability paper whole about model quadratic programming find optimal factors specific error but combination probability long role error measure examples model classification models under cross entropy error measure models estimating
derive first order approximation density maximum entropy continuous random variable given number simple constraints results density similar classical polynomial density using approximation density approximation differential entropy derived approximation entropy both more exact more robust against than classical approximation based polynomial density without being computationally more approximation has applications example independent component analysis
present new approximate learning algorithm machines using free energy second order weights linear response correlations given free energy computational complexity algorithm number neurons compare performance exact learning algorithm first order mean field theory second order mean field theory learning task consists fully connected model neurons method well problems gives significant improvement over mean field theory both problems weights approximation problems but problems
study line generalized linear regression outputs ie neural networks multiple output nodes but hidden nodes allow layer transfer functions such function need consider linear output neurons use distance functions certain two independent line learning algorithms such tasks use distance function define matching loss function transfer function allows us generalize results dimensional outputs use another distance function made line updates shows previously studied algorithms such gradient descent gradient fit into common framework evaluate performance algorithms using relative loss bounds compare loss line best off line relevant model class thus probabilistic assumptions about data
generalization ability neural network improved regularization analyze improvement more results than asymptotic distribution weight vector here study simple case dimensional linear regression under quadratic regularization ie regression study random design case derive optimal regularization parameter improvement possible construct examples best use regularization
both equation order parameter approaches analyze asymptotic dynamics line learning different learning rate between results obtained two approaches obtain new results optimal coefficients their number hidden nodes two layer architecture
present method optimal line learning rule soft machine under statistical framework work previous results locally optimal rules rate change generalization error considered total reduction generalization error over whole learning process show resulting rule significantly locally optimal rule
perceptron decision trees known linear machine order data dependent risk applied data dependent analysis performed margin decision nodes improve generalization analysis uses novel technique bound generalization error terms individual nodes experiments performed real data sets approach
derive between regularization used regularization networks kernels support vector machines more prove functions associated regularization support vector kernels equivalent regularization properties product show large number radial basis functions positive functions may used support vector kernels
simple but standard gaussian distribution studied variables gaussian constrained use energy functions two examples competitive distributions illustrate power gaussian distribution represent pattern potential gaussian modeling pattern
online learning most common neural network training present analysis online learning finite training sets non linear networks soft machines theory more learning dynamical equations derived appropriate set order parameters these exact case either linear networks training sets simulations suggest theory effects finite training sets but may yet account presence local
apply general algorithm prediction algorithm problem linear regression loss our main assumption response variable out particular problem algorithm but different estimation procedure general results about algorithm bound difference between our algorithms performance best sense linear regression functions performance show optimal constant our bound constant regression procedure general times
demonstrate problem training neural networks small average error computationally consider data set points input vectors real outputs work class neural networks relative error fit data set prove several classes neural networks relative error than fixed positive threshold independent size data set
study capacity fully connected machine large number hidden nodes capacity obtained structure weight space related internal representation asymptotic behavior order parameters limit large capacity found up order result bound given symmetric solution conventional approach bound
inverse information matrix used natural gradient descent algorithm train single layer multi layer have new scheme represent information matrix stochastic multi layer perceptron based scheme have designed algorithm compute natural gradient input dimension much larger than number hidden neurons complexity algorithm order simulations natural gradient descent learning rule efficient but robust
bayesian learning neural networks typically based either local gaussian approximations posterior weight distribution markov chain monte carlo simulations approach called ensemble learning introduced approximate posterior distribution minimizing between true posterior parametric distribution deterministic algorithm use gaussian distribution covariance matrix so capture posterior correlations between parameters paper show ensemble learning approach extended gaussian distributions while computationally extend framework simple estimation procedure initial results standard problem
bayesian methods have been successfully applied regression classification problems multi layer present novel application bayesian techniques radial basis function networks gaussian approximation posterior distribution fixed basis function parameters setting regularization single optimal parameter estimate prior distributions these data under simple estimation
recently model supervised learning probabilistic represented trees introduced algorithm large trees large computer memory paper propose new more model parameters distributions associated similar conditional output distributions illustrate advantages proposed algorithm experiments
exact inference connected bayesian networks computationally so interest effective approximation schemes approach has been bound log likelihood using mean field distribution while leads algorithm mean field distribution paper demonstrate using class distributions based mixtures mean field distributions derive efficient algorithm mixture parameters apply problem learning belief networks our results demonstrate improvement over simple mean field theory number mixture components
study several learning rules using same visual environment made up natural scenes same single cell neuronal architecture allows us feature neuronal coding properties these rules these rules maximization quadratic form learning rule single cell ica using structure method demonstrate receptive fields developed using these rules small distribution find quadratic form rule manner similar maximization rule distribution although equations computationally
derive robust optimization schemes noisy vector basis deterministic cost function clustering channel noise develop soft vector algorithm based maximum entropy principle performs maximum likelihood estimate em parameter leads phase transitions existing code vector representation during process critical function covariance matrix data transition matrix channel noise whole family vector algorithms derived among them deterministic scheme self map algorithm call applied vector image data via noisy binary symmetric channel algorithms performance compared those while superior does take into account channel noise its results compare well those computationally much more
many applications such prediction image recognition test inputs available addition labeled training examples propose method test inputs into learning our method results solutions test errors than simple training solution noisy problems small training sets
paper problem learning set based upon information eg limited number observations describe two algorithms hypothesis their application correct expected loss learning empirical results provided demonstrate these both synthetic datasets real world data design optimization problem
many applications order rather than here consider problem learning order given feedback form ie effect instance should another two stage approach first learns conventional means function form whether new so learned function show problem finding best function complete even under assumptions describe simple algorithm find good approximation discuss line learning algorithm based algorithm finding good linear combination experts use algorithm combined line learning algorithm find combination search experts each domain specific query strategy search present experimental results demonstrate our approach
paper discuss learning algorithms data techniques such cross validation achieve model selection possible further determine confidence level practical these problems minimum variance estimation approach makes use extended kalman algorithm training multi layer novel paper show theoretical between extended kalman filtering variable learning rate algorithms bayesian estimation framework so propose algorithms need initial conditions noise covariance matrices kalman approach
classification finite sequences without knowledge their statistical nature problem many important applications propose new information approach problem based following sequences similar they generated same source ii cross estimated via sequences these design method classification discrete sequences they introduce method illustrate its application hierarchical clustering estimating sequences
first describe hierarchical model non linear factor analysis implemented neural network model performs perceptual inference consistent manner using top down up connections these connections learned using simple rules require locally available information show connections into model model sparse distributed hierarchical representation depth random first hidden layer form map presented image natural scenes model local feature
learning techniques classification tasks work first fit full probabilistic model observed data whether good idea depends respect model study question experimentally yet non interesting case consider independent model single binary hidden variable other ie target model finding most value variable given known values linear function observed values learn two techniques standard em algorithm new algorithm develop based compare these against algorithm version find good linear classifier directly our using model classification data model performance directly learned linear classifier
discuss strategy classification involves estimating class probabilities each classes estimates together model similar method study nature class probability estimates performance procedure simulated datasets classifiers used include linear nearest application support vector machines described
adaptive line algorithm proposed estimate hierarchical data structures non data sources approach based principle minimum cross entropy derive decision tree data clustering idea learning learn changes data characteristics its efficiency demonstrated non data hierarchical segmentation images
address problem learning structure nonlinear markov networks continuous variables non gaussian density estimation certain conditional variables markov networks graphical way conditional well model relationships do exhibit natural causal use neural network structures model relationships between variables main focus paper learning structure into underlying process using two data sets show interesting structures found using our approach inference
active data clustering novel technique clustering data sequential experiment design order data data analysis proposed active data sampling strategy based expected value information concept statistical decision theory considered important step analysis data sets because way data data present applications unsupervised segmentation computer vision information retrieval
present computationally efficient algorithm function approximation linear nodes hidden layer network constructed node time using method task individual nodes using new algorithm best fit solving sequence quadratic programming problems approach significant advantages over based search algorithms eg backpropagation its characteristics algorithm include finite step convergence simple criterion deterministic good local good scaling properties robust numerical implementation
new class classification techniques have recently been developed statistics machine learning technique method takes standard classifier such trees into algorithm produce new classifier standard classifier known classifier these methods often produce large over using single classifier paper investigate these methods give its
map network simple learning algorithm self self map probabilistic generative mapping simulations suggest algorithm has self random initial than map algorithm further learning without network
multiple instance learning supervised learning task learn concept given positive negative each may many but labeled positive even within concept labeled negative negative describe new general framework called density solving multiple instance learning problems apply framework learn simple description series images containing selection problem activity prediction problem
applications gaussian mixture models fields statistics artificial neural networks key mixture model estimate number mixture components paper markov chain monte carlo algorithm case gaussian mixtures using hierarchical prior model using method number mixture components fixed but model estimate algorithm capable moving between parameter models different mixture components result sample full joint distribution unknown model parameters generated technique demonstrated simulated example well known
paper probability model mixture trees account sparse relationships present family efficient algorithms use em minimum tree algorithm find map mixture trees variety including
several effective methods performance single learning algorithm have been developed recently general approach set learned models applying algorithm different training data learned models predictions according scheme work has been predictions models generated many learning algorithms different representation search paper describes method uses analysis model relationship between learning examples way they learned models nearest neighbor method applied within resulting representation previously examples new algorithm performs well better than other techniques data sets
propose networks type recurrent neural network probabilistic dynamics models learning natural signals continuous time space give gradient log likelihood path respect parameters network gradient used networks wide variety problems techniques have fields such system state estimation signal filtering work particular interest computational hardware design choice activation function eg linear gradient local space time
consider general problem learning multi category classification labeled examples present experimental results nearest neighbor algorithm samples different pattern classes according rule instead class probabilities amount improvement query based approach over approach depends complexity bayes rule principle algorithm based general used learning algorithm model selection criterion error rate classifier terms complexity model
existing computational recurrent correlation similar networks explicitly limit their results units threshold transfer functions et al given here shows finite discrete transfer function used units network finite state network cannot model many units used continuous transfer functions finite number fixed points such radial basis functions
high dimensional data has locally low dimensional distributions perform local dimensionality reduction further processing data paper several techniques local dimensionality reduction context locally weighted linear regression possible derive local factor analysis regression principle component regression principle component regression joint distributions partial least regression after statistical these methods perform monte carlo simulations evaluate their respect their statistical assumptions locally weighted partial least regression best average results thus even factor analysis most our techniques regression tasks mapping dimensional continuous input vector dimensional output vector they form class problems found fields including process control control transformations various information processing biological systems paper focus learning techniques example kernel regression gaussian functions local learning advantages real time learning problems due fast convergence problems negative large model selection local learning usually based data local query point high dimensional learning problems fact high dimensions local they almost local global learning methods such feedforward networks do face problem they do although they require strong prior knowledge about problem hand order local learning high dimensions being high dimensional does data high dimensional locally example control robot biological have shown estimating inverse dynamics dimensional space average dimensions locally local learning system such locally low dimensional distributions should able dimensionality question what context local regression method perform local dimensionality reduction paper derive compare several techniques under statistical eg gaussian noise gaussian input distributions linear data ii less conditions eg non gaussian distributions quadratic data dimensionality true data distribution focus nonlinear function approximation locally weighted linear regression allows us variety global linear dimensionality reduction techniques has found application several local learning systems particular derive investigate locally weighted principal component regression locally weighted joint data principal component analysis locally weighted factor analysis locally weighted partial least section these methods their theoretical while section evaluate these methods using synthetic data sets statistical assumptions techniques methods reduction assume our regression data generating process two sets inputs outputs characteristics process functional both obtained through independent mean zero noise different each observable such focus dimensional output data functions either linear quadratic these cases most common nonlinear function approximation locally linear models regression error each data point weight gaussian kernel query point positive semi distance metric size shape regression et al parameters determined framework statistics parametric maximum likelihood et al present study they determined their results paper without loss our data sets set zero vector compute weights input data such weighted mean zero output data mean zero mean zero data necessary most techniques considered input data matrix corresponding outputs elements vector corresponding weights matrix cases need joint input output data local reduction factor analysis factor analysis technique dimensionality reduction most appropriate given generating process our regression data observed data produced mean zero distributed dimensional vector factors matrix mean zero independent noise covariance matrix both distributed parameters obtained expectation maximization algorithm em linear regression problem generated vector regression coefficients linear model matrix after em joint data space estimate derived conditional probability distributions normal expected value mean conditional distribution locally weighted version obtained together estimate factors joint weighted covariance matrix expectation matrix coefficients estimating factors note noise zero estimated different true average out noise data joint space principal component analysis alternative way parameters reduced space locally weighted principal component analysis joint data space principal components weighted covariance matrix unit length matrix theorem provides means derive efficient estimate our dimensional output case dimensional vector evaluation does require matrix but rather normal distributions variables special case noise covariance ie same noise under these both methods same regression coefficients different those noise level zero coefficients according noise data equation thus normal distributions correct expected perform than partial least partial least input data performs single variable along these previous iteration step locally weighted version partial least shown equation single variable training least makes same statistical assumption linear ie output variables do have noise but input variables less choice still strong way chosen correlation inputs previous step against inputs order way optimal function single ie certain input distributions address our empirical step step principal component regression although optimal computationally efficient techniques dimensionality reduction linear regression principal component regression inputs principal components weighted covariance matrix input data matrix regression coefficients thus equation evaluate after matrix inputs have noise includes zero noise case during dimensionality reduction does take into account output data input dimensions low variance have important regression output statistical point view less low variance inputs have significant linear regression confidence regression coefficients increase variance associated input input data has non noise focus regression monte carlo order evaluate methods data sets inputs output randomly generated each data set training points test points distributed either unit outputs local dimensionality reduction generated either linear quadratic function dimensional input space into dimensional space randomly chosen distance linear transformation finally gaussian noise various both dimensional inputs dimensional output test sets noise outputs each regression technique gaussian kernel equation dimensional distance metric chosen gaussian kernel many data points data areas kernel experimental conditions those suggested linear functions ii quadratic functions ii noise conditions each conditions output noise low noise local ratio high noise ii equal noise inputs outputs low noise high noise noise inputs outputs low noise high noise input distributions unit ii unit data points gaussian function more than distribution every algorithm times each conditions complete test three further conditions varying called factors algorithms true dimensionality dimensional data ie few correct many factors average results figure figure show results three factor conditions over per condition each mean these over two input distribution conditions linear quadratic function condition these four cases observed statistical assumptions nonlinear function approximation locally linear models figure number factors underlying dimensionality problem algorithms well gaussian distributions random variables shown assumptions best results almost noise condition two pca based techniques perform expected they statistical assumptions parts its advantages such results figure quality function changes significantly correct number factors figure few factors figure performs because randomly principle components input data without respect important regression second according its assumptions signal cannot model noise estimate regression results has lead test methods evaluate data set non iterative em iterations log likelihood less than iteration many factors than necessary figure now effect due its noise regression parameters equation other algorithms perform almost well small lead output equal noise noise noise inputs outputs inputs outputs regression results factors results factors regression results factors results figure average results monte carlo experiments each into three noise conditions each noise condition four further coefficients linear quadratic model equal low noise ii like high noise coefficients linear quadratic model different low noise like high noise text monte carlo studies further local reduction figure monte carlo experiments average every other technique least our number factors made these high dimensional regression problems local dimensionality ie number factors defined number but rather varying way generating process usually process does need generate locally low dimensional distributions often do so instance human movements patterns they could generate arbitrary thus local dimensionality reduction find appropriate number local factor locally weighted partial least out robust technique even probabilistic factor analysis principal component analysis number factors easily based variance threshold input space while factor analysis usually requires cross validation techniques simple variance based control over number factors improve results practice shown figure more robust number factors while more robust number factors while good regression results few factors appropriate should well factor performed figure locally weighted partial least robust local weighted factor analysis noise both input output data moreover superior number factors most technique local dimensionality reduction high dimensional them least work human information processing research support includes research research locally weighted learning artificial locally weighted learning control artificial regression data sources new
explore methods prior knowledge about problem hand support vector learning machines show both under transformations prior knowledge about images appropriate kernel functions
boosting general method performance learning algorithm classifiers need perform better than random recently proposed boosting algorithm has been applied several machine learning problems using rather simple learning algorithms decision trees paper use improve neural networks compare training methods based sampling training set cost function our system about error data online more than adaptive boosting multi layer network achieved error error data set
constraint many application domains present machine learning model network ie functional form method training network described networks continuous functions apply networks real world task prediction compare them other approaches
paper technique previously used supervised learning applied unsupervised learning used non parametric density estimation finite mixture model kernel density experimental results both simulated data real world data sets demonstrate density estimation other such single best model based cross validation weights even single best model chosen data used independent
similarity based retrieval neural associative has lead applications efficient model sparse patterns high asymptotic information capacity practical use because high cross noise retrieval finite here new iterative retrieval method model presented called retrieval performance discuss its asymptotic capacity limit analyze first step compare experiments model applying efficient memory model either information retrieval systems functional model cortical requires more than against random noise input our experiments show segmentation ability retrieval containing provided even high memory
nonlinear dimensionality reduction here problem find feature space set observations possible their metric between points observation measured along our feature mapping procedure able low dimensional nonlinear structure perceptual data sets such face images conventional global mapping methods find local map provides set features allows perceptual transformations such interpolation highly nonlinear transformations original observation space computed simple linear feature space
our paper develop bayesian matching hierarchical models goal make discrete label so global cost function information different levels our bayesian development between level level constraints allows its level representation but upon its
source separation information matrix used metric parameter space descent algorithm likelihood function parameter space rule property algorithm further using asymptotic form information matrix
density digital neural network system has been developed our consists neurons via synapses solve nonlinear first order differential equations fully parallel continuous performance system measured take network neurons although input network parameters each neuron them processing speed connections per second range neural networks including filtering feedforward feedback networks appropriate network parameters system
have developed analog vlsi system models have implemented tested system consists chain pattern generating circuits their nearest each pattern generating circuit implemented two neurons connected network discuss mechanisms two cell network explore system behavior based frequency along chain
describe design test results analog cmos vlsi neural network chip phase based machine vision algorithms chip image filtering similar filtering because filters output complex used define phase every image phase used robust algorithms estimation control vision image motion analysis chip reported here takes input image two outputs every corresponding real parts output
present method analysis time series multiple particular possible model both dynamics less time another achieved two steps first unsupervised training method provides prediction experts dynamical trained experts used hidden markov model allows model application data analysis modeling real world time series improved taken into account
discuss problem recognition systems problem systems need different channels non practice shows recognition within each tested their assumptions their product increase results explore solution problem based upon bayesian competitive models inference each sensory channel provided simple noise context models perceptual hypothesis context estimated context changes noise automatically approach tested fixed speech recognition problem good results
hidden markov models hmms speech recognition high dimensional feature vectors properties speech correlations between features speech signal non noise investigate model these correlations using factor analysis statistical method dimensionality reduction factor analysis uses small number parameters model covariance structure high dimensional data these parameters estimated expectation maximization em algorithm training hmms evaluate combined use mixture factor analysis hmms total number parameters fixed find these methods combined better models than either method its
apply information maximization maximum likelihood source separation complex signals complex matrices case signals known source signal distributions adaptation thus making algorithms less results reduction amount data convergence adaptation signal conditions such now demonstrated simulations
paper present novel hybrid architecture continuous speech recognition systems consists continuous hmm system extended arbitrary neural network used takes several feature vector input produce more feature vectors respect underlying hmm system hybrid system extension state continuous hmm system fact first hybrid system capable these standard systems respect recognition accuracy experimental results show relative error reduction about achieved good recognition system based continuous hmms word continuous speech recognition task
observed distribution natural images far real images have complex important structure image processing recognition analysis have been many proposed approaches statistical modeling images but each has been limited either complexity models complexity images present non parametric multi scale statistical model images used recognition image de high quality
paper describes new approach structure point sets novel feature tasks estimating transformation mixture model over graph representing using em algorithm according our em framework probabilities expected likelihood function used estimate maximum likelihood parameters provides means
image result several different object effects including dimensional object problem vision solve eg observed image problem approach bayesian computational methods human performance set test images found made consistent properties our computational model simple prior probabilities different image solved most interpretation bayesian framework test images our algorithm compared well mean our subjects
image often represented set features representing images way furthermore representation small noise image features typically chosen manner show good set features obtained using sufficient statistics idea sparse data representation dimensional dimensional signal reconstruction problem make our
model motion detection presented model three first stage selective contrast next two work parallel phase stage across different contrast through filter thus first second order motion phase sensitive stage contrast each through filter thus first order motion differential phase therefore account detection first second order motion phase cortical complex cells phase sensitive simple cells
neural network approach presented based effects simple fast scheme within single network structure map associated validation map view scene available network based simple biological algorithm fully parallel non iterative
implement model small robot result system capable through field key system use behavior during movement shown behavior focus found systems without behavior system models several response similar response field computation mapping motor system resulting system simple should easily hardware
evidence has shown human object recognition depends images object further similarity between objects object more important image information these do rule out use information recognition degree information used visual memory important model image independent could account human performance novel object now present results models generalized radial basis functions nearest neighbor matching allows transformations bayesian statistical estimator over possible transformations performance human relative each models better novel than generalize better novel bayesian estimator yields optimal performance transformations independent therefore models matching independent account human recognition performance
scale property natural images their non gaussian properties less well but they indicate statistical structure work present study statistics variable related images numerical analysis shows extended self similarity scaling property than self similarity its power given more interesting predicted terms log process same model used recently predict correct structure functions these results allow us study underlying particular find most structures dimensional most consists category visual processing
ability similarity invariant image transformations important image classification tasks such face recognition analyze invariant metric has performed well distance study its applied images showing most significant among these convergence local reduced computing distance setting leads distance significantly higher image transformations easily combined robust estimation
many real world tasks small available inputs important particular time paper presents method relevance inputs temporal method proposed paper relevance inputs using their future values model task learned model simultaneously extended task specific predictions future values inputs inputs either relevant therefore model those noise predicted these inputs de new improved model task techniques presented paper have significant vision based control vision based hand tracking scenes detection
new algorithm presented visual similarity between images images into feature space visual structure using tree filters similarity inverse distance perceptual feature space using algorithm have constructed image database system perform example based retrieval large image using constructed target sets limit single visual retrieval rates compared those standard methods
general vision chip spatial processing presented size processing receptive field architecture allows cells small computation out array addition image chip outputs four images parallel presented application chip line orientation detection found receptive fields
capable visual motion information relevant ways first stage visual motion processing array functional units known motion several developed correlation based model motion detection described behavior these neural circuits have implemented model analog cmos vlsi process result low power continuous time analog circuit motion real time responses circuit temporal frequency response spatial frequency response direction motion sensitive neurons observed addition its possible applications circuit could used hardware models higher level motion
multi scale neural network system given system four part after being trained like approaches learning structure system able learn high order structure like structure sequences achieved using feedforward networks different time scales combination networks structure results their quality has been experts human
eeg activity eye movements line noise problem eeg interpretation analysis eeg results loss information may data many methods have been proposed eye movement eeg often regression time frequency domain performed eeg derive parameters eeg channels brain signals so out activity involves relevant eeg signal each well regression cannot used noise line noise these have channels here propose new generally method wide variety eeg method based extended version previous independent component analysis ica algorithm source separation linear mixtures independent source signals either gaussian gaussian distributions our results show ica activity eeg wide variety sources results those obtained using regression based methods extended ica eeg
present novel approach problem related potential classification based competitive neural net architecture network weights converge signal patterns resulting filter network performance via simulation study under low conditions compared expected performance information classifier applied real related potential data during type first time variable signal patterns automatically strong stimulus related selective data
have constructed video based tracking system learns uses real time graphical user inputs signals train neural network inputs neural network images motion information images used provide scale during online training phase neural network input weights upon different channels environment adaptation allows system even other objects moving within
work problem time series modeling video different existing methods model time domain model coefficients domain model includes approach model both long range short range video simultaneously computationally efficient method model generating high quality video performance analysis using model
networks important problem call control so use network problem dynamic programming problem complex solved use methods reinforcement learning together decomposition approach find call control policies performance our policy network different feature compared used policy
speed sensitive factor two more order presented potential efficiency algorithm such algorithms hand time show problem learning task algorithm automatically our focus problem line code called basic our empirical results show few features quite good performance task real several supervised learning methods perform respect features used
paper learning algorithm optimal proposed new formulation approach using value function many allows model free policy iteration after new algorithm real data risk within framework markov decision problems proposed methods allows multi system takes into account risk several constraints
computer networks during few has computer systems good way use through user activity methods detection based hand rule sets line paper new way applying neural networks user using system neural network used learn identify each user much like use scenes behavior does system possible backpropagation neural network called neural network trained task tested experimentally system system accurate activity rate these results suggest learning user effective way
paper propose technique information into object classification real word cases object due noise measurements based classification should made reduce information context our case objects technique applied cell classification made against context approach superior classification performance achieved using context our particular application significantly rate thus cost due information cell
describe system learning rules these rules learned examples rule based neural networks rules applied generate new real time constraints learning processes including types information system use input amount processing system perform demonstrate algorithms generating rules examples these constraints describe method including knowledge into rules yields significant performance describe techniques applying these rules generate new real time paper analysis experimental results
paper about application bayes neural network classifiers field using bayesian learning task two first bayesian inference known regularization automatically second effect bayesian learning leads larger variance network outputs regions without training data results well known effects used cross validation experiment full bayesian solution found hybrid monte carlo algorithm better than single maximum map solution found evidence approximation second experiment studied properties both solutions classification movement bayesian learning real world application
discuss development multi layer perceptron neural network classifier use between mean error sufficient make correct objective about performance neural classifier introduced combined curves based objective observations such results neural network able make predictions
paper presents new approach problem using neural networks first model conditional distributions such way model order process time dependent shape scale conditional distributions after over particular patterns able long term
explain training data into information noise data neural network into time invariant structure used noisy part propose theory optimization algorithms learning together algorithms control data noise parameter noise combined algorithm allows data local control network parameters therefore improvement generalization approach useful task
model based reinforcement learning method focus limited computational achieve good estimate value environment states planning step uses simple focus computation states have errors paper introduce generalized method generating such estimates representation specific manner allows us extend state based representation representations necessary large state spaces apply method generalized model such bayesian networks describe experiments compare our approach classical
paper describes interactions model learning algorithms planning algorithms have found model based reinforcement learning paper local trajectory used learned models find trajectory fully consistent learned model often have finding early learning trajectory learned model minimizing cost reward often do better even fully consistent learned model
new policy iteration algorithm observable markov decision processes presented more efficient than policy iteration algorithm key representation policy finite state controller representation makes policy evaluation show dynamic programming update used policy improvement step transformation finite state controller into improved finite state controller new algorithm value iteration approach solving problems
initial experiments described here using reinforcement learning develop system high control system designed range out control states level minimum time while constraints here report results simple version problem single simulated through simulated control using simulation system optimal policy inputs produce minimum time transitions level cases while system able constraint while simulated via reinforcement learning
paper problem reinforcement learning continuous state space time stochastic control problems state equation value function use finite difference method approximation scheme propose algorithm based scheme prove its convergence optimal solution
propose local error estimates together algorithms adaptive grid time reinforcement learning consider deterministic system continuous state time cost functional grid procedure numerical methods equation time propose new criterion based estimates discrete solutions demonstrate optimal ratio time space optimal learning rates accuracy approximate optimal value function
present new approach reinforcement learning policies considered learning process constrained machines allows use prior knowledge reduce search space provides framework knowledge across problems component solutions solve larger more problems our approach link between reinforcement learning behavior based approaches control present algorithms problem solving learning hierarchical machines demonstrate their problem several states
planning sutton abstract planning learning multiple levels temporal key problem artificial paper approach problem based framework markov decision processes reinforcement learning current model based reinforcement learning based step models cannot represent common sense higher level actions such object paper prior work abstract models sutton prediction setting include actions control planning introduce more general form abstract model multi time model its planning learning its relationship equations paper theoretical framework multi time models their potential advantages planning task need hierarchical abstract planning problem see eg et al model based reinforcement learning possible solution problem planning real time learning decision making sutton current model based reinforcement learning based step models cannot represent common sense higher level actions modeling such actions requires ability different levels temporal new approach modeling multiple time scales introduced sutton based prior work sutton approach models environment different temporal scales abstract models work environment paper extension approach including actions control environment sutton particular generalize multi time models abstract planning step action abstract action arbitrary policy prior work behavior agent environment system under single given policy here learn different models set different policies each possible way agent learns model what planning between these policies well between actions illustrate make consider example shown figure standard grid world actions grid cell cell learning agent given new tasks form new goal locations possible agent level actions its many actions long take relatively long time compute planning could much faster abstract actions could used moving rather than cell cell each agent learns two models two abstract actions efficiently each do address paper question such abstract actions could without instead focus theory abstract actions particular define general property required order them used general planning typically used markov decision processes paper illustrate theory example problem showing abstract actions speed planning actions up left right time down abstract actions each figure example task natural abstract actions reinforcement learning framework reinforcement learning learning agent environment discrete level time scale each time step agent state environment st basis action response each action environment step numerical reward next state st objective learn policy mapping states probabilities each action expected future reward each state rate parameter expectation conditional policy being called value state under policy called value function policy value under optimal policy planning reinforcement learning use models effects actions compute value functions sutton assume states discrete form finite set st theoretical present assumption allows us value functions vectors each components values states general vector use its component model action whether abstract has two components matrix state result action each state other vector reward along way case action matrix step transition probabilities environment times these predictions corresponding state st unit basis vector corresponding st reward prediction action expected stochastic policy define its step model st planning conventional planning step models used compute value functions via equations prediction control vector prediction control equations function applied component control equation planning these into updates eg converge value functions thus equations usually used define compute value functions given models actions following sutton here take value functions given use equations define compute models new abstract actions particular model used planning stable consistent equations useful define special terms each equation arbitrary model vector matrix model policy sutton model used compute via iteration algorithm direct sense model planning introduce here parallel control equation model non has positive elements component model control equation condition true value state thus model does more than multi time models abstract planning option planning step models actions due show step model policy more model single matrix model has been vectors corresponding value functions into initial using new models combined using two basic two models matrix new model set models weighted set matrices such new model sutton set models policy under models different time scales together resulting model still used compute have set models under sutton these variety models than they do models because models combined need particular policy multi time models model do each other sutton good model should both would like describe class models sense includes interesting models non include common sense abstract action these have us multi time model example multi step model called step model policy step state steps into future times different models same policy result called mixture model mixtures non due properties previous section mixture suggested sutton allows exponential weights over time parameter figure two markov mixture models properties environment order about power model should have us consider example figure state two presented should significantly different models step models linear mixture step models cannot achieve goal order problem models should average over different trajectories possible through state space full model sutton sutton between these two model more general form mixture model different parameter associated each state state probability trajectory through state space state although models have more power they cannot describe step models would like have more general form model both classes goal achieved accurate multi time models multi time models defined respect policy step model policy defined define accurate multi time model sequence random weights such weights random variables chosen according distribution depends states time weight measure given state trajectory particular state has weight associated weight along trajectory given state effect state state trajectory random weights along each trajectory make general form model necessary constraint weights previously states particular sequences generate types multi step models described sutton variables such obtain step models sequence form parameter associated state time step describes full model main result multi time models they two defined previous section accurate multi time model these results long include here example order illustrate way multi time models used practice us example figure cells grid states environment state agent perform four actions up down probability actions agent cell corresponding direction would take agent into case same state probability agent instead other three takes into into each defined two abstract actions each each abstract action has set input states states two states target state other agent has out each abstract action given its complete model optimal policy into target variables along trajectory have value states multi time models abstract planning iteration ii ii iteration iteration iteration iteration iteration figure value iteration using abstract actions goal state have arbitrary position but us goal two steps down right value goal state along way factor performed planning according standard value iteration method states goal state experiment over actions other over set including both abstract actions using actions values step each iteration after iterations instance states most steps goal non zero values models abstract actions produce significant speed up propagation values each step figure shows value function after each iteration using both abstract actions planning area each state value state first three iterations case actions used values first states values well states containing goal these values abstract action into right following optimal actions goal point path goal known each state right environment even path optimal states after iterations optimal policy known states environment models abstract actions do need given they learned fact abstract models used experiment have been learned during step random environment point sutton learning represented states each abstract action along associated these states used learning learn optimal state action value function associated each abstract action policy respect policy associated abstract action same time used model learning algorithm presented sutton compute model corresponding policy learning algorithm online its complexity step models abstract actions while agent environment without additional such models used planning process they would represent actions more efficient learning planning goal over time paper research part sutton sutton support generalization temporal difference learning representation neural computation learning neural information processing systems hierarchical learning stochastic domains results machine learning learning solve problems general learning mechanism machine learning reinforcement learning less data less real time machine learning efficient learning planning within framework adaptive behavior sutton multi time models reinforcement learning role models reinforcement learning structure behavior scaling reinforcement learning learning variable temporal resolution models machine learning sutton td models modeling world mixture time scales machine learning sutton reinforcement learning
paper show factor asymptotic rate convergence learning provided state action pairs fixed probability distribution here ratio minimum maximum state action results extend line learning provided now minimum maximum state action corresponding distribution
learning system linear control reinforcement learning selection hybrid reinforcement learning system proposed fast learning real world control problems selection appropriate control dependent state hybrid learning system applied control type robot learned control more than reinforcement learning because need learn control linear control control robot trained step learning during first learning step selection trained training procedure linear controller learned control more average number about so small learning system real robot control
based computational concept internal model adaptive control has been into forward inverse model yet evidence learning control through adaptation other here two adaptive control architectures based inverse model other based combination forward inverse models show movements hand novel fields learning forward model results key characteristics performance human subjects contrast adaptive control system inverse model produce patterns observed subjects fact more stable our results provide evidence learning control novel dynamics via forward model
task problem well known neural networks previous work learning approach problem does learning point out problem connected problem solution both problems proposed based correlation using time delay network our simulation results consistent human performance human terms time both special case our network without time these shape position size orientation
fact based few basic simple algorithms have difficult time even make associative process memory without use rules algorithms exhibit certain associative both type error error frequency propose model process associative compare its performance both these data normal model proposed et al
demonstrate ability generate accurate appropriate motor behavior under many different often conditions paper describes new approach human motor learning control based multiple pairs inverse controller forward models architecture simultaneously learns multiple inverse models necessary control well inverse models appropriate given environment simulations object ability learn multiple objects appropriate generalization novel objects activation motor based visual cues line size weight
connectionist systems have representing complex structures system simple neuron like computing elements complex recently have representations extend both time space many have proposed firing units complex representations identify approach present model complex structures model approach our architecture similar mechanism
learning many visual perceptual tasks has been shown specific stimuli while new stimuli require learning here demonstrate generalization using novel motion discrimination learning has been previously shown specific trained subjects moving previous results learning does transfer trained direction new tracking subjects performance across time new direction found their rate learning therefore learning generalized task previously considered difficult generalization second experiment transfer following training stimuli perceptual learning between learning difficult tasks different learning processes different visual cortical areas here show these results terms signal detection theory assumption limited computational obtain observed direct transfer change learning rate levels human generalization expected behavior discrimination system
structure visual scene described many levels level scene objects level each object made up parts parts work propose simple principle such hierarchical structure visual scenes among different parts object than internal structure part principle applied define part whole relationships among elements scene principle does make use object models other higher level knowledge rather part whole relationships based statistics set sample visual scenes illustrate model performs unsupervised decomposition simple scenes model account results human learning experiment relationships
consider problem learning small positive examples perform but capable machine learning present both theoretical analysis empirical study human subjects simple task learning corresponding feature space existing learning models applied task cannot explain subjects generalize few examples concept propose bayesian model based assumption examples random sample concept learned model gives human behavior simple task provides into more complex cases concept learning
recent experimental data indicate synaptic connections between neurons depends relative timing action synaptic rule based these data leads stable state inputs neuron pattern firing has been proposed neurons such
contrast response function many neurons visual cortex higher contrast values following high contrast visual stimuli using recurrent neural network spiking neurons synapses show both effects could fast component synaptic adaptation fast synaptic leads phase cortical response high contrast stimuli ii adaptation synaptic probability derived such mutual information between input output cortical neuron component given learning rule contrast adaptation potential component well experimental result stimulus component component cortical cells potential based our results propose new experiment estimate effective feedback cortical neuron suggest relatively simple experimental test our synaptic mechanism contrast adaptation
movements produced distributed neural networks within regions cortex experimental data indicate single neurons these regions parameters movement appropriate neurons action neurons using neuronal population vector provides estimate movement parameters direction may even parameters movement designed model cortical motor investigate between desired direction movement direction movement direction motor cortex model two layer self neural network visual information motor initial part movement two link network trained motor simulations network produced appropriate movement direction over large part small trajectory desired trajectory these large both trajectories these results suggest does give image cortical processing during movements should
cortical has been proposed mechanism neurons visual cortex less fact same form used de using network model recurrent cortical propose spatial phase complex cell responses through recurrent feedforward input neurons network like simple cells low gain complex high gain similar recurrent mechanisms may role generating invariant representations feedforward input visual processing
human studies show brain synaptic during about synapses have previously shown network memory performance while synapses requires synapses synapses now show neuronal mechanism recently observed average neuronal input field results weight dependent synaptic under correct range dimension synaptic upper bound neuronal synapses synapses near optimal synaptic memory performance network synaptic thus paper shows addition known effects changes neuronal may important role self brain networks during development
relationship between activity single cell population question basic neural computation paper apply information approach level activity among cells context possible between activity cells activity difference between information they provide measured information they provide define value positive first case negative second show value measured simultaneously activity cells among cortical cells positive found while cells active during same task do exhibit similar activity address computer neural computation
related eeg both phase experimental usually increase their ratio relative non phase eeg activity fact response activity single may time distribution study linear decomposition independent component analysis ica single eeg derive spatial filters single eeg into sum independent fixed components brain brain networks our results normal subjects show ica stimulus response non related eeg into components types single eeg both eeg components second study new image responses eeg show single order time underlying patterns response performance these analysis research both normal single related
correlation based learning rule spike level compared learning firing rate description differential equation learning dynamics derived under assumption time scales learning spiking linear neuron model time dependent stochastic input show spike correlations time scale role correlations between input output spikes structure provided form learning principle conditions average synaptic weight discussed
here derive measures information loss synaptic signal due presence noise sources along active model linear noise sources distributed along its length noise sources consider noise channel noise stochastic nature dependent channels synaptic noise due activity information transfer using signal detection objective spike synaptic allows us analytically role each these noise sources information transfer our choice parameters find synaptic noise noise source maximum length over information
within layer neurons response input stimulus here investigate model activity dependent development maps allows degree correlation based learning model strong self map thus receptive fields second order statistics input patterns strong higher features individual patterns important correlated stimuli two cortical development find map receptive fields degree critical value ii receptive fields exhibit eye second critical value correlated activity between second order statistics system develop even but critical degree
new proposed spikes multi data using transfer functions between cells every cell stable linear these properties their relative main advantage method shape amplitude spike spike out two steps first statistics each spike type generated clustering transfer function spikes data using spike statistics these techniques applied data generated response system
study effect correlated noise accuracy population coding using model population neurons two dimension activity gaussian noise pairwise correlations difference between information system show relevant parameters positive correlations estimation network relative population moreover strong positive correlations result information capacity finite value number cells population contrast negative correlations increase information capacity neuronal population
graphical models provide probabilistic applications speech recognition hidden markov models belief networks artificial machines computing time typically exponential number nodes graph within variational these models present two classes distributions machines belief networks standard approach give mean field equations both these approximations simulation results small problem suggest using these approximations against previously reported
study dynamics supervised learning neural networks size training set number inputs here local fields described gaussian distributions use dynamical theory predict including relevant error measures limit
kernel parameter few parameters support vector machines complexity resulting hypothesis its choice model selection its value usually found means validation set present algorithm automatically perform model selection additional computational cost need validation set procedure model selection learning but kernels during learning process find kernel parameter provides best possible upper bound error theoretical results approach experimental results its presented
solve dynamics type neural networks sequences patterns close interaction matrix such models leads out statistical analysis using generating functional methods derive exact equations dynamical order parameters sequence correlation response functions limit system size time invariant solutions these equations limit leads phase effective self interaction usually symmetric models here found significantly capacity compared networks patterns our results tested against computer simulations found
gaussian process prediction scaling data set size using finite dimensional basis approximate computational complexity reduced derive optimal finite dimensional under number assumptions show these over bayes regression method optimal show minimal model size given up numerical experiments
describe method relative loss bounds online linear threshold classification algorithms such perceptron algorithms classification problems discrete loss used ie total number prediction introduce continuous loss function called linear loss derive updates algorithms first prove bounds linear loss them discrete loss introduce average margin set examples show relative loss bounds based linear loss relative loss bounds discrete loss using average margin
recent parameter estimation neural coding have demonstrated optimal performance related mutual information between parameters data consider mutual information case parameter vector conditional each observation vector through product derive bounds asymptotic mutual information compare results obtained same model technique
algorithm simple learning rule models hidden variables shown algorithm applied factor analysis model linear version machine but even factor analysis model general convergence describe understanding algorithm contrast em algorithm algorithm result prove convergence algorithm factor analysis model show condition convergence general models
show similarity between belief propagation method special case error code code word randomly original solutions obtained two methods various values show solutions may sensitive choice initial conditions case patterns good approximations obtained generally patterns case being used
following recent results showing dimension effect large margin generalization performance current paper these results case datasets two approaches setting threshold approaches into boosting algorithm loss functions performance two approaches tested experimentally computational learning theory generalization large margin estimates loss datasets
study probabilistic inference large bayesian networks represented graphs show exact inference such networks does their effective use give algorithms approximate probabilistic inference nodes large show these algorithms compute lower upper bounds probabilities interest prove these bounds exact limit large networks provide rates convergence
analyze asymptotic behavior neural network processes using techniques markov non linear time series analysis shown standard without connections linear connections weights determine whether system standard conditions linear processes used
connected recurrent networks have recently been used models neural because separation between biological neural networks study between networks their showing they have different dynamical behavior computational illustrate our results case network selective
consider recurrent analog neural nets each gaussian noise other common noise distribution whose probability density function large set show many cannot networks type example language give those result constraints recurrent analog neural nets robust against types analog noise other hand present method analog neural nets robust analog noise type
margin training margin distributions our direct optimization algorithm curve curve significant training error improved test error margin line
study approximation functions two layer feedforward neural networks algorithms units estimating single unit parameters each stage standard algorithms fixed architectures optimization each stage performed over small number parameters many difficult numerical problems high dimensional non linear optimization upper bounds error algorithm functions class previous results provided rates convergence functions certain convex functional spaces our results recently derived lower bounds show algorithms optimal combined estimation error results algorithms strong case made type approach
based simple develop bounds different types bayesian prediction errors regression gaussian processes basic bounds fixed training set obtained sampling input distribution weight function covariance kernel results results compared numerical experiments
solve dynamics line learning size training set scales number inputs consider both noisy our cannot extended rules but solution provides test more general solving dynamics learning training sets
log log upper bounds dimension set neural networks units polynomial activation functions depth network number hidden units number parameters maximum number polynomial activation function maximum degree lower bound dimension such network set cases constant special case dimension log
new algorithm support vector regression described chosen automatically minimal data such most data points moreover shown use parametric non constant algorithm experimentally
present exact solutions class recurrent neural network models both sequential parallel neuronal dynamics between long range synaptic interactions found novel well transitions between pattern states non states
consider problem learning curves ie average generalization performance gaussian processes used regression simple expression generalization error terms decomposition covariance function derived used point several approximation schemes identify these exact compare existing bounds learning curves new approximations used input space dimension generally
present theory mean field approximation based information theory includes consistent way mean field approximation well approach linear response theorem statistical information them
many belief networks have been proposed binary units tasks such object speech recognition produce real data binary network models usually independent component analysis ica learns model real data but power model limited independent factor analysis technique ica network models each level network latent variables non linear functions input data highly adaptive functional form resulting hierarchical distributed representation these data exact maximum likelihood learning network derive algorithm lower bound likelihood based variational approach
introduce semi supervised support vector machine svm method given training set labeled data set data support vector machine using both training sets use solve problem using risk minimization problem estimate value classification function given points set standard learning problem estimating classification function possible values using fixed function classes set data propose general model both error function capacity based available data show svm model norm linear support vector machines solved using programming standard norm support vector machine approach compared data sets our computational results support statistical learning theory results showing data generalization training information available every case either improved significant difference generalization compared traditional approach semi supervised support vector machines
learning memory based technique query prediction locally examples query considered relevant according distance measure paper propose data method query query basis optimal number considered each prediction efficient way identify local models least algorithm introduced context local approximation learning furthermore takes strategy model selection local combination most models method proposed tested different datasets compared state approach
technique principal component analysis pca has recently been maximum likelihood solution generative latent variable model paper use probabilistic basis bayesian pca our key result effective dimensionality latent space equivalent number principal components determined automatically part bayesian inference procedure important application framework mixtures probabilistic pca models each component determine its effective complexity
standard techniques eg available learning process models simple directly observable dynamical processes noise means dynamics observed learning still been achieved via expectation em together kalman filtering does more complex dynamics multiple classes motion problem show here em combined algorithm based propagation random sample sets experiments have been performed observed dynamical models found learning process
inference key component learning probabilistic models observable data learning temporal models each many inference requires over long data sequence furthermore data structures large making process computationally describe approximate inference algorithm stochastic processes prove bounds its approximation error paper apply algorithm approximate forward propagation step em algorithm learning temporal bayesian networks provide related approximation step prove error bounds combined algorithm show real domain em using our inference algorithm much faster than em using exact inference almost quality learned model extend our analysis online learning task showing bound error resulting attention small observations present online em learning algorithm dynamic systems show learns much faster than standard em
present monte carlo generalized em equations learning nonlinear state space models monte carlo step consists sampling posterior distribution hidden variables given observations new idea presented paper generate samples gaussian approximation true posterior obtain independent samples parameters gaussian approximation either derived extended kalman filter algorithm case posterior density propose approximate posterior sum mixture approach show sampling approximate posterior obtained above algorithms leads better models than using point estimates hidden states our experiment algorithm obtained better approximation posterior than distribution mixture approach superior results
propose novel strategy training neural networks using sequential sampling algorithms global strategy allows us learn probability distribution network weights sequential framework well applications line nonlinear non gaussian non signal processing
problem estimating parameters distribution over large number discrete most do training data analyze problem bayesian develop hierarchical prior assumption observed small subset possible show efficiently perform exact inference form hierarchical prior compare standard approaches
present stochastic clustering algorithm based pairwise similarity our method existing deterministic methods including algorithms graph algorithms connected components thus provides common framework these methods our graph based method existing stochastic methods based systems stochastic nature our method makes more robust against noise including small clusters demonstrate our algorithm using example noise
expectation maximization em algorithm iterative procedure maximum likelihood parameter estimation data sets missing hidden variables has been applied system linear stochastic state space models state variables hidden both state parameters model have estimated simultaneously present generalization em algorithm parameter estimation nonlinear dynamical systems expectation step makes use extended kalman estimate state while maximization step estimates parameters using these state estimates general nonlinear maximization step because requires out uncertainty states gaussian radial basis function rbf used model maximization step solved via systems linear equations stochastic nonlinear dynamical systems inference learning discrete time dynamical systems hidden state inputs outputs state according nonlinear dynamics inputs noise vectors matrices represented zero mean gaussian noise covariance outputs related states inputs zero mean gaussian noise covariance vector but arbitrary models have been various most nonlinear state space models form systems control paper these models within framework probabilistic graphical models derive novel learning algorithm them based em best our knowledge first paper learning stochastic nonlinear dynamical systems have described within framework em algorithm classical approach system parameters hidden variables extended kalman filtering algorithm described section nonlinear system state vector parameters approach line may important certain applications furthermore provides estimate covariance parameters each time step contrast em algorithm present algorithm does estimate covariance parameters three important advantages em algorithm has over classical approach first em algorithm provides method missing inputs outputs second em more complex models discrete real hidden variables example em mixture nonlinear dynamical systems often difficult prove analyze stability within classical line approach em algorithm likelihood function stable learning next describe basic components learning algorithm expectation step algorithm conditional distribution hidden states using extended kalman section maximization step first discuss general case section describe particular case represented using gaussian radial basis function rbf networks section extended kalman given system described equations need hidden states observed inputs outputs inference problem conditional density fact system stochastic therefore our about gaussian noise assumption less nonlinear systems than linear systems used generate non gaussian state noise have have applied em same model method uses approximate requires sampling hidden states fit use gaussian radial basis functions model fit analytically without sampling see section important use extended kalman algorithm simultaneously estimate parameters hidden states our use estimate hidden state part step em learning nonlinear dynamics using em linear dynamical systems gaussian state observation conditional density gaussian algorithm computing its mean covariance known kalman kalman directly forward algorithm computing conditional hidden state distribution hidden markov model special case belief propagation algorithm nonlinear systems conditional density general non gaussian fact quite complex multiple approaches hidden state distribution such nonlinear systems including sampling methods variational approximations focus instead paper approach extended kalman extended kalman kalman local nonlinear system every point space vector functions define matrices dynamics about st mean kalman filter state estimate time output equation prior distribution hidden state gaussian system conditional distribution hidden state time given inputs outputs gaussian thus kalman used system conditional distribution see figure left learning step em algorithm estimates parameters given observed inputs outputs conditional distributions over hidden states model have described parameters define noise two step first may computationally fully estimate example they represented neural network single full step would training procedure using backpropagation other optimization method could use partial steps example each few gradient steps second have trained using state estimates output algorithm consider takes inputs outputs each conditional density estimated full covariance gaussian space so has fit set data points but instead mixture full covariance input output space gaussian data over type noise non almost form simple but approach problem large sample these gaussian data fit these samples way similar next section show gaussian radial basis functions model both these forward part kalman kalman filter radial basis functions gaussian present general formulation rbf network should fit special consider following nonlinear mapping input vectors output vector zero mean gaussian noise variable covariance example form represented using another parameters coefficients matrices inputs output bias vector each rbf gaussian space given covariance matrix goal fit model data data set form mixture gaussian distributions here show analytically over mixture distribution fit rbf model assume data set different using expectation over objective samples variables each gaussian data over gaussian has mean covariance matrix set parameters log likelihood single data point under model maximum likelihood rbf fit mixture gaussian data obtained minimizing following quadratic form learning nonlinear dynamics using em respect setting zero gives linear equations solve other words given optimal parameters solved via set linear equations show these computed analytically but simple gaussian gaussian form new space under these new compute algorithm right figure gaussian evidence gaussian evidence gaussian evidence inputs outputs input dimension figure steps algorithm left shows information used extended kalman hidden state distribution during step right regression technique during step fit mixture gaussian required gaussian rbf networks used fit solved analytically line shows rbf fit four gaussian while line shows rbf fit using covariance information show support rbf kernels results tested well our algorithm could learn dynamics nonlinear system its inputs outputs system single input state output variable each time state time step next given sample outputs system response noise shown figure left nonlinear model linear dynamical model trained em factor analysis model given space within range automatically determined density points space after over algorithm dynamics within less than iterations em figure right further experiments need determine practical method real domains figure left data set used training first consists time series inputs outputs log likelihood iterations em linear dynamical systems line nonlinear dynamical systems trained described paper line note likelihood nonlinear dynamical systems cannot generally computed analytically what shown here approximate likelihood computed curve linear dynamics learned right means gaussian computed along line rbf learned algorithm point does algorithm pairs these inputs outputs current model parameters paper together two algorithms statistics another systems address learning stochastic nonlinear dynamical systems have shown extended kalman algorithm state estimation step radial basis function learning model solution step em algorithm capable learning nonlinear dynamical model data effect have derived algorithm training radial basis function network fit data form mixture our initial approach has three potential first step presented does rbf kernels possible compute required change but requires partial step low dimensional state spaces space fixed kernels but strategy many high dimensions second em training understanding different hidden variable models related example model used first learned simple linear dynamical system factor analysis method presented here learns data dynamics have recently extended online learning dynamics belief network has recently been two methods approximate inference markov chain monte carlo variational approximations our knowledge paper first instance extended kalman has been used perform approximate inference step em while does have theoretical variational methods its has wide estimation control method inference nonlinear dynamical systems now method learning nonlinear belief networks learning nonlinear dynamics using em would like support part systems required fit need compute equation do rbf kernel gaussian rbf kernel equation gaussian density over mean covariance constant due al using evaluate other finally mixture approach approximate inference learning nonlinear state space models maximum likelihood data via em algorithm statistical series
investigate problem learning classification task data represented terms their pairwise representation does feature representation data thus more general than standard approach using feature vectors pairwise our first approach based combined linear classification procedure resulting extension optimal algorithm data alternative present another approach based linear threshold model values using risk minimization show prior knowledge about problem choice distance measures different their generalization finally algorithms successfully applied structure data data cortex they show better performance than nearest neighbor classification
adaptive special form regression quadratic each parameter model shown equivalent least selection sense both produce same estimate thus particular quadratic observation derive fixed point algorithm compute solution provides new parameter model complexity finally present series possible sparse regression kernel modeling neural net training
cluster analysis principle data analysis user description structure given data key problem context interpretation clustering solutions high dimensional abstract data spaces particular probabilistic structure capture cluster relationships simple probabilistic variables present novel approach structure based statistical model object have been observed estimated probabilistic clustering procedure objects data points low dimensional space observed data statistics gaussian mixture model algorithm provides new approach structure variety data types eg data data data demonstrate power approach images example large scale data application
paper previously connection between two important fields regularization independent component analysis ica show least class algorithms reduce network complexity independent features product algorithm minimum search recent general method finding low complexity networks high generalization minimizing both training error required weight precision according our theoretical analysis hidden layer trained coding each input sparse code few simple features possible experiments method optimal codes difficult noisy problem underlying sources ica pca real world images per than ica pca
data domain two finite sets objects observations made ie pairs either set type data many application computational information retrieval analysis computer vision paper present domain independent framework learning data statistical mixture models our approach different models hierarchical latent class structures propose version standard em algorithm model variety data sets different domains
sparse coding method finding representation data each components representation significantly active such representation related reduction independent component analysis has paper show sparse coding used using maximum likelihood estimation variables gaussian noise show apply components sparse coding so reduce noise furthermore show optimal sparse coding basis our method related method but has important over methods both features parameters estimated directly data
task text retrieval find subset relevant information usually set words represented vectors word its form relevance defined product between query vector measure number common terms text retrieval presence word sufficient determine relevance query linear dimensionality reduction has been proposed technique underlying structure domains such vision dimensionality reduction computational complexity text retrieval more often used improve retrieval performance propose alternative novel technique sparse representations constructed sets highly related words represented their distance these sets relevance measured number common clusters technique significantly retrieval performance efficient compute properties optimal linear independent components
generative probability models such hidden markov models provide way missing information variable length sequences other hand methods such support vector machines us construct decision often result classification performance superior model based approaches classifier should these two approaches paper develop natural combination kernel functions use methods such support vector machines generative probability models provide theoretical combination well demonstrate improvement classification performance context sequence analysis
present conditional maximization algorithm extension em maximization algorithm conditional density estimation under missing data maximization process given conditional likelihood instead joint likelihood apply method mixture models use techniques derive models update rules convergence computational efficiency regression results superior em demonstrated
principal curves have been defined self consistent smooth curves through dimensional probability distribution data recently have new approach principal curves continuous curves given length minimize expected distance between curve points space randomly chosen according given distribution new made possible out theoretical analysis learning principal curves training data paper propose practical based new simulation results demonstrate new algorithm previous methods both terms performance computational complexity
present unsupervised classification algorithm based ica mixture model ica mixture model observed data into several data classes components each class generated linear mixture independent sources algorithm independent sources matrix each class class probability each data point approach gaussian mixture model so classes have non gaussian structure demonstrate method learn efficient codes represent images natural scenes text learned classes basis functions better approximation underlying distributions data thus provide coding efficiency method well modeling structure high dimensional data has many potential applications
generative model binary data using small number hidden continuous units model conventional principal components analysis relationships between correlations underlying continuous gaussian variables binary output variables learn appropriate weights network advantages approach invariant binary distribution images
introduce two new techniques density estimation our approach problem supervised learning task performed using neural networks introduce stochastic method learning distribution deterministic technique demonstrate convergence our methods both experimentally provide estimate our theoretical results demonstrate better convergence properties than estimate
two nonlinear latent variable models based radial basis functions discussed first use constraints models considered means data structure low dimensional representations approach introduced makes more effective use latent samples likelihood
present new energy minimization framework graph problem based equivalent maximum formulation approach result recently various ways allows us maximum problem terms standard quadratic solve use equations class simple discrete time dynamical systems developed various theoretical show their local solutions they provide experimental results competitive those obtained using more mean field
training support vector machine svm requires solution large quadratic programming problem paper algorithm training sequential minimal optimization large problem into series possible problems analytically thus does require numerical computation time evaluation kernel kernel database times fast while database linear times faster than algorithm
boosting methods classification margin known techniques do exhibit overfitting low noise cases noisy data boosting margin give much weight leads non smooth overfitting therefore propose three algorithms allow soft margin classification regularization variables into boosting concept linear quadratic programming experiments show proposed algorithms comparison another soft margin classifier support vector machine
signal processing pattern recognition algorithms make use many cases computational accuracy important computational speed feature instance features interest signal usually quite form noise level order achieve faster feature our approach consists regions signal low degree resulting signals order obtain functions functions representation simple implemented quite true result method yields speed up feature neural networks
describe new iterative method parameter estimation gaussian mixtures new method based framework developed supervised line learning contrast gradient descent em estimate mixtures covariance matrices proposed method estimates covariance matrices furthermore new parameter estimation procedure applied both line show experimentally typically faster than em usually requires about many iterations em
models useful case domain knowledge about function estimated model extend two learning algorithms support vector machines linear programming machines case give experimental results machines
present probabilistic latent variable framework data key feature its binary data types few methods variational approximation likelihood derive fast algorithm model parameters application real synthetic binary data sets given
present em algorithm local maximum problem parameter estimation finite mixture models case mixture models non global often many components mixture model part space few another part space such perform using new criterion efficiently apply proposed algorithm training gaussian mixtures mixtures factor using synthetic real data show using improve likelihood both training data out test data
hierarchical representation data has various applications domains such data machine vision information retrieval paper extension expectation maximization em algorithm learns mixture computationally efficient manner efficiency achieved up ie clustering mixture components given level obtain those level above clustering requires knowledge mixture parameters being need samples addition practical applications algorithm allows new interpretation em makes relationship non parametric kernel based estimation methods provides over off between bias variance em estimates new about behavior deterministic methods used em local likelihood
gaussian process regression covariance between outputs input locations usually distance positive matrix often taken but allow general positive matrix basis training data analysis shows hidden features dimensionality hidden feature space determined data demonstrate predictions using general matrix over those based matrix two test problems
propose new sample cross validation based method parameters bias variance fit complexity soft classification soft classification learning procedure estimates probability example given vector class class target distance between estimated probability distribution true probability distribution representing knowledge population method uses estimate cross validation cost single data
basis selection procedure presented regression both basis threshold using method includes prior knowledge shape basis functions into basis selection procedure results method demonstrated using functions results method other basis function based methods
paper introduce new class image models call dynamic trees dynamic tree model prior over large number trees each tree belief net experiments show capable generating images less models have better properties than fixed show simulated effective finding trees have high posterior probability
paper problem visual search bayesian inference bayesian ensemble problem particular address problem detection visual global criterion local information analyze convergence rates search algorithms using results information theory bound probability within bayesian ensemble analysis characteristics domain call order parameters determine convergence rates particular present specific algorithm high probability expected time size problem addition work address target ie algorithm independent results use non
paper present novel approach both models described stable linear state space systems separation problem into two process separation state estimation based minimization develop novel learning algorithm train matrices output equation estimate state model introduce new concept called hidden implement kalman filter computer simulations given show high state space approach
present analog vlsi architecture version system real time image processing models across several visual cortex design each functions simple cells complex cells complex cells cells three grid analog current cmos circuits used perform detection local selective long range kernels global gain control experimental results cmos demonstrate architecture image noisy
chip set chip learning developed active noise chip set error backpropagation learning rule practical applications allows multi chip developed demonstrated active noise without digital signal multi path channels random noise nonlinear speaker adaptive learning circuits experimental results reported noise real time
paper describe architecture implementation experimental results classification chip chip processes vector dimensional vectors while maximum power rate per vector per second significant previous work achieved low power supervised classification matching scheme used chip unsupervised classification computational support low rate data adaptive matching scheme used amplitude sample time
performance vlsi neural processing hardware depends design implemented algorithms have previously proposed algorithm classification implemented demonstrated algorithm architecture now investigate algorithm using time frequency channel input output schemes train values goal optimal classification performance chosen hardware
circuit fast low power motion presented chip uses signal cmos components implement detection set detection models retina superior circuit uses time address two linear provide analog motion vlsi chip used fast line following algorithm discussed
describe first single sound system its human sound allow estimate sound source using our single model structure role designed analog vlsi uses time processing sound cmos circuit has been designed successfully demonstrated
robust algorithm presented computing position focus point fields such those generated self motion measurements shown fully parallel cmos analog vlsi motion array direction local motion each directly implement algorithm field point computed real time power less than computation point more general fields requires measures field shown computed real time hardware using field these measures along location point provide robust real time self motion information visual moving such robot
paper presents novel fast classifier based binary correlation matrix memory neural network robust method developed input hardware implementation described gives over times speed current range large problems tested several compared simple method classifier less than lower over times speed up hardware
common way represent time series into each represented set basis functions approach temporal basis functions underlying structure time series arbitrary present algorithm time series does require data algorithm efficient representation best temporal functions kernel basis these have arbitrary temporal constrained allows model capture structure signal may arbitrary temporal relative temporal structure underlying model shown equivalent sparse highly basis under model mapping data representation nonlinear but computed efficiently form allows use existing methods basis data approach applied speech data results invariant spike like representation coding
paper method regularization hmm systems parameter overfitting training data regularization em training method term simple smooth hmm systems term constructed mixture model negative exponential distributions generate state dependent probabilities hmms new method transfer well known regularization approach neural networks hmm domain generalization traditional state hmm systems effect regularization demonstrated continuous speech recognition tasks models speaker adaptation limited training data
describe maximum likelihood mapping alternative hidden markov models hmms processing sequence data such speech while hmms have discrete hidden space constrained fixed finite architecture has continuous hidden space map constrained through space into same probabilistic framework speech recognition hmms but more model speech process evaluate speech information generated continuous speech maps three used through them predict measured speech data correlation between obtained speech measurements independent test set used train unsupervised model achieved correlations over lower than those obtained using supervised method used measurements well
investigate probabilistic framework speech recognition based properties curves particular analyze setting two variables continuous discrete time vector out smooth curve variable function length along curve length does rate curve gives family markov processes whose predictions invariant nonlinear time describe use such models known markov processes curves speech recognition feature trajectories two tasks new connected find lower word error rates than trained hidden markov models
has been much recent work image statistics learning probability distributions images mapping images statistics many show phase space factor phase space approach entropy technique learning distributions images derived image statistics addition shows phase factor distribution approximation yields algorithm computation time entropy learning concept using gaussian approximate phase factor gives good approximation results time phase space approach gives into multi scale found suggests phase space finally prove probability distributions learned feature space equivalent entropy learning approximation phase factor
present method learning complex such images objects traditional interpolation networks case smooth function linear objects define mapping examples set smooth interpolation networks these networks regions parameter space set procedure used find example clusters well within their convex interpolation within these sets examples method images produced even regions parameter space examples have different show results generating both simulated real images
scene interpretation best image data example may scene best explain two image image synthetic data model relationship between image scene between scene scene given new image markov network effect underlying scene yields efficient method form low level scene demonstrate technique motion analysis estimating high resolution images low resolution
finding objects like presents difficult object recognition show find finding those consistent constraints result properties model requires least possible present every classifier instead search using classifier corresponding describe efficient algorithm classifier demonstrate our approach used whether images real scenes
previously proposed model early visual processing based non visual filters efficient decision now use model observed modulation range human without visual attention our model procedure simultaneously four classical pattern discrimination tasks performed while attention another task our model complex certain observed attention fully available discrimination tasks best among early visual filters
visual search task finding target image against features them out against while defined features features more difficult known target detection change figure mechanisms underlying out visual search have been paper shows model segmentation based interactions explain many visual search
face recognition class problem number known support vector machines binary classification method face recognition problem output svm classifier developed svm based face recognition algorithm face recognition problem problem difference space models between two images difference space face recognition two class problem classes between same between different interpretation decision generated svm generated similarity metric between learned examples between svm based algorithm compared principal component analysis pca based algorithm difficult set images database performance measured both performance svm pca equal error rate svm pca
most important problems visual visual objects same transformations such scaling paper describe bayesian method learning based theory show previous approaches based first order series inputs special cases approach being capable principle large transformations using based generative model images derive unsupervised algorithm learning input data containing transformations line unsupervised learning algorithm posterior probability generating training data provide experimental results proposed method learn large
present probabilistic method images produced multiple approach based image model images noisy locally linear functions underlying true scene bayesian framework provides maximum likelihood maximum estimates true scene images maximum likelihood estimates parameters image model local second order image statistics thus related local principal component analysis demonstrate method images
recent neural model based distribution natural moving constant speed given input model consists pairs position direction constraints output consists distribution such pairs general these their distribution scale invariant paper show compute scale invariant distribution given position constraints use result explain well known effect
paper describes simple efficient method make based object classification invariant task into two parts orientation discrimination classification key idea orientation discrimination classification input image each class interest image its similarity training images each class these object orientation process yields set images least have object position resulting images models have been trained examples approach has been successfully applied two real world vision based tasks recognition face detection scenes
paper presents probabilistic modeling methods solve problem between labeled data three models first model second model capable modeling set arbitrary model allows between show three these models accuracy learned models improved small number labeled training images large set images using expectation maximization important because often difficult obtain image labels while many images available through large set empirical data each models using two randomly labeled examples per class between accuracy labeled examples achieve accuracy
gaussian processes provide good prior models spatial data but smooth many along example near fields describe method such constrained demonstrate model parameters fields sampling
high energy experiments has through high rate few interest key factors making decision location interaction here present novel solution problem finding location based two feedforward neural networks fixed architectures whose parameters chosen so obtain high accuracy system tested simulated data sets shown perform better than conventional algorithms
neural network performs both test patterns classes during training discrimination whether test pattern classes during training performance tested data obtained field compared nearest neighbor based algorithm extension
computer through numerical simulation based models but computationally paper numerical simulation dynamic models more efficient neural networks automatically trained off line dynamics through observation based models action model its neural network two faster than conventional numerical simulation demonstrate variety based models
detection systems automatically use network used problem previous approaches features derived call patterns individual paper present call based detection system based hierarchical model detection problem inference problem probabilities inference implemented applying tree algorithm underlying graphical model dynamics learned data using em algorithm training methods using data real network
paper describes bayesian graph matching algorithm data large data matching algorithm uses node similarity determine probability query graph each data node feature vectors constructed computing pairwise similarity computing distance between recognition data has probability illustrate recognition technique data containing line patterns real world here recognition technique shown significantly number algorithm
order computer make difference its time factor two more order achieve best possible speed use appropriate each specific architecture implementation these time paper present results using both reinforcement learning construct basic reinforcement learning performed almost well
previous work new technique direct visual matching images face recognition image retrieval using probabilistic measure similarity based bayesian map analysis image basis similar performance advantage probabilistic matching technique over standard nearest neighbor matching recently demonstrated using results face recognition probabilistic matching algorithm found top have further developed simple method nonlinear online bayesian similarity measures relatively computation linear simple online thus resulting significant computational speed up implementation large image typically real world applications
propose train systems objective functions via reinforcement learning performance functions consider ratio our recently proposed differential ratio online learning presented empirical results demonstrate advantages reinforcement learning relative supervised learning here extend our previous work compare learning our recurrent reinforcement learning algorithm provide new simulation results demonstrate presence through well analysis provides into structure
describe real time computer vision machine learning system modeling human actions interactions two different domains recognition two multiple interactions visual task our system top down up information using feedback bayesian framework two different graphical models hmms hmms used modeling both individual actions multiple agent interactions shown work more efficiently given amount training finally limited training data demonstrate synthetic used develop prior models interactions
processes such cell number different cell types stimuli free these signals often complex temporal spatial patterns even under conditions here study temporal cells cells under et al use novel fast fixed point algorithm independent component analysis ica source separation temporal dynamics cell using approach find two significant independent components out input signals signal mean high frequency signal power spectral density results good study high frequency et al further theoretical experimental studies have performed question functional these independent signals et al
have previously presented hierarchical network architecture image processing techniques neural networks paper present applications general architecture two problems computer first application detection designed learn large scale context small objects like analysis suggests hierarchical architecture detection performance well system second application directly large extended objects architecture problem instead construct architecture designed learn small scale structure associated extended objects our initial results applying detection detection about ability architecture information across scales both makes well objects may have structure scales other than natural scale object
paper mixture probabilistic model combined expectation maximization optimization task three dimensional range data robot provides way information allows
set reinforcement learning algorithms designed so their behavior global function theory present experiments using theory design control these experiments indicate previously based path algorithms
reinforcement learning algorithm has dimensionality algorithms applied high dimensional problems paper introduce algorithm further improve its performance addition while solutions improved locally standard local path improvement techniques introduce algorithm same instead improve solutions non local manner
simple learning rule derived algorithm generate wide range new algorithms these algorithms solve number problems define several new approaches reinforcement learning different approaches reinforcement learning under single theory these algorithms have convergence include several existing algorithms known converge simple these include advantage learning addition these value based algorithms policy search reinforcement learning algorithms learn optimal policies without learning value function addition allows value based algorithms combined thus two different approaches reinforcement learning into single value policy search algorithm these algorithms converge without belief state simulations results given several areas future research discussed convergence many reinforcement learning algorithms known use function represent value function weights during learning examples include learning advantage learning simple original form these algorithms converge table cases algorithms converge under assumptions such gradient descent general reinforcement learning table current convergence results value based algorithms algorithms every first two new algorithms proposed change fixed policy distribution table markov chain linear nonlinear table linear nonlinear table nonlinear convergence known either between best possible policies learning rates cases known either between best possible policies have different values even training time learning rates each first two made converge using form algorithm form but possible learning fixed training distribution practical most large problems useful explore policy usually respect current value function changes value function changes case current convergence good way convergence three algorithm so stochastic gradient descent average error function average weighted state current usually policy changes policy changes might gradient difficult compute consider distribution usually respect learned function difficult single weight change many values single value change many action choice probabilities state single action choice probability may frequency every state although might difficult estimates distributions respect weights resulting algorithms every case table equation consider sequence transitions observed while following particular stochastic policy st sequence states actions up time action state yields reinforcement transition state stochastic policy may function vector weights assume has single state has states state st set possible sequences time given error function error each time step such time other error time function weights smooth function weights consider time time probability after sequence st probabilities such expected length finite expected total error during expectation weighted according state generated given policy time after trajectory note first line particular st error every sequence st each these terms weighted probability complete trajectory st sum probabilities trajectories st probability st being observed probability so second line first line probability sequence factor might function so probability smooth function weights partial respect particular weight vector space here limited may short but over does give estimate expected total error during algorithm perform stochastic gradient descent weight update given left table over previous time steps each weight algorithm more general than previously algorithms form function previous states actions rather than current reinforcement what allows do both value policy search every algorithm proposed paper special case equation left table note model algorithm probability algorithm policy transition probability stochastic gradient descent update rule correct observed transitions trajectories found following gradient descent general reinforcement learning table general algorithm left several right single algorithm includes both value based policy search approaches their combination convergence case current stochastic policy both should smooth functions given vector should algorithm simple but large class different algorithms choice zero single sequence following current policy sum along sequence give estimate true gradient finite variance therefore during learning weight updates made each weights within region learning rate approaches zero converge probability weight term constant times norm weight vector weight small initial learning rates global minimum found using general function but least converge true well algorithm many reinforcement learning algorithms value based they learn value function equation examples learning learns value function algorithms learn value function policy respect td learns value function based future other algorithms policy search algorithms they directly learn policy high these include through time learning algorithms algorithms proposed here two approaches they perform value policy search general equation expression value based reinforcement policy search linear combination two value policy search single update rule left table variety different types algorithms described following mean per has states time state possible minimize expected total error per zero each form learning value iteration advantage learning generated shown right table each case expected value taken over possible given policy smooth function weights so could policy action probability would gradient two values state equal but policy could approaches positive approaches zero number possible actions each state each instance table other than value iteration gradient estimated using two independent estimates expected value example estimate true gradient algorithm described convergence but may learn more than gradient descent values note gradient time uses variables means new state action time generated state action time deterministic variables same but model known model additional time other state model known three first model could learned data give independent sample second could variables variables may quality learned function random but convergence approximation practice transitions could variables could found times has been randomly those transitions using its state action variables equivalent learning model sampling so special case first choice large state action spaces many states give same result practice variables variables note weights do effect policy these algorithms reduce standard algorithms possible reduce mean per step rather than per making independent policy so minimizing error per minimize error per step example might defined first steps after state state note every state action has positive being first steps solving finite problem solving problem every state but determined what during first steps many different problems solved algorithm different ways policy search value based learning possible term reinforcement directly example could defined rather than table gradient descent general reinforcement learning figure number learn combination policy search value based either zero after each state constant does expected gradient but does noise distribution discussed algorithm learn function equation directly learns policy minimize expected total reinforcement resulting function may even close containing true values equation give good policy between algorithm both equation give good policies similar made algorithms table special case algorithm algorithm has been special case gaussian action distributions case policy search interesting because need model generating two independent other algorithms have been proposed finding policies directly such those given various algorithms learning theory algorithms proposed here first these two approaches reinforcement learning finding value function both equation solution directly policy figure shows simulation results combined algorithm have learned policy optimal graph shows average different initial random weights between learning rate each value state state algorithm used learning table equation states same parameters so learning could converge shown value based new algorithm but cannot learn optimal policy state those two values learn equal policy search learning but value function results long sequence states near two approaches new algorithm learns much more than either interesting algorithms described three applied directly observable markov decision process true state hidden available each time step observation function true state algorithm such has applied algorithms converge such cases new algorithm has been presented special cases give new algorithms similar learning advantage learning but convergence range problems than previously possible including first time these converge even policy changes during learning other special cases allow new approaches reinforcement learning between equation policy simulation combined algorithm learned more than either approach theory first time both value based reinforcement learning theoretical interest practical value simulations performed future research framework may able analytically address question better learn value functions better learn policy directly may new question best do both research part us algorithms reinforcement learning function approximation machine learning stable reinforcement learning neural information processing systems reinforcement learning its application control report planning observable stochastic domains artificial available now simulation based optimization markov decision processes reinforcement learning selective hidden state computer learning
paper application reinforcement learning problem problem requires while simultaneously quality constraint into certain states present general solution multi problem able significantly higher than
classifier systems now because their problems such rule rule set performance problem problem order solve problems have developed hybrid classifier system generalization learning system view model free learning take hybrid approach finding best generalization given total number rules uses policy improvement procedure et al locally optimal stochastic policy set rule conditions given uses search best set rule conditions
paper address two long interest reinforcement learning first what performance made learning after finite number actions second what made between learning model based approaches use estimate next state distributions off line value iteration first show both learning approach rather convergence optimal policy function number state transitions observed particular order transitions sufficient both algorithms within optimal policy model observed transitions well state thus two approaches have same sample complexity sample complexity far less than what required model based approach construct good approximation next state distribution result shows amount memory required model based approach than either approach assumption observed transitions well consider model transitions determined fixed arbitrary policy bounds number transitions required order achieve desired level performance related distribution time policy
learning real time control method planning has been shown solve search problems known efficiently paper apply problem given goal location unknown environment path state potential goal state good but show does minimize case time compared other methods result interest reinforcement learning many reinforcement learning methods use dynamic programming planning exhibit face uncertainty like
real world problem making good limited knowledge environment observable markov decision processes model decision problems agent its reward face limited feedback recent work has shown reinforcement learning algorithm called efficiently find optimal policies map current observations actions problems algorithm uses form short term memory called observation action pairs lead up reward paper effect ability algorithm find optimal policies called step applied four test problems taken recent work empirical results show significantly without ability find optimal policies
reinforcement learning methods used improve performance local search algorithms optimization learning evaluation function search evaluation function therefore able search low cost solutions better than original cost function describe reinforcement learning method local search previous work off line learning phase value function learned useful search multiple problem illustrate our technique several such functions problem our learning local search algorithm improvement more over standard local search algorithm
order find optimal control continuous state space time reinforcement learning problems approximate value function particular class functions called sufficient conditions under algorithm optimal even use approximate models state dynamics reinforcement functions
order object need solve inverse problem ie transformation visual joint vector although several models transformation learning have been proposed they number human motion control learning hand position error feedback controller inverse important paper novel model transformation learning human visual feedback controller uses change joint vector corresponding change hand position error norm proposed model using numerical simulations
present method automatically actions actions during reinforcement learning process idea perform action after action such pattern actions has been test method task task task grid world tasks tasks use actions learning time while grid world tasks learning time reduced factor method work task discuss
propose new reinforcement learning method based architecture gaussian networks networks local linear regression units trained line em algorithm proposed our previous paper apply our method task up single task near position experimental results show our method applied optimal control problems continuous spaces method good control small number errors
describe reinforcement learning algorithm observable using short term memory call learns stochastic model based bayesian learning overfitting problem solved moreover has efficient implementation paper shows model learned provides most accurate predictions given short term memory
observable markov decision processes important class reinforcement learning problems present theoretical computational markov property reinforcement learning algorithms such learning may effective memory based methods partial via state estimation alternative approach stochastic policy each observation environment probability distribution over available actions average reward per reinforcement learning algorithm learns locally optimal stochastic policy has been proposed but present algorithm discuss its implementation demonstrate its using four test problems
provides experimental bounds possible potential experiments complex dynamic order study without control dynamic brain computer research has been about signals complex environment paper shows environment experimental results show negative down order test line recognition signal down recognition results show may successfully used control
evidence selective attention visual search experiments work hierarchical system neurons modeling underlying mechanisms selective visual attention demonstrate our neural system visual search across visual field parallel but due different dynamics show two experimentally observed visual attention parallel search other words model focus attention maps used focus attention property dynamic behavior system neural population dynamics framework mean field approximation whole process system differential equations
spatial information two direct spatial information example position temporal information objects general close spatial information neural network here given spatial several objects networks trained prediction task networks using temporal sequences direct spatial information found develop internal representations show correlated spatial information direct spatial information system during training either consistent approach allows relative spatial temporal
data speed responses during classical experiments should provide strong constraints models learning most models have these data few have address them have least order discuss key data speed show account them using sound model learning differential stimuli role
many classification tasks recognition accuracy low because input noise propose approach these based model human selective attention model early selection filter top down control each output class sequence gain coefficients order produce strong response class chosen class response least modulation attention present simulation results classification showing significant improvement recognition rates algorithm has been applied domain speech recognition results
figure network proposed based novel representation nodes network obtained through local each node nodes same region corresponding node rules connections node its probability being according differential equation system figure problem through temporal different perceptual such shape decomposition through local system optimization many results fixed set parameters
describes stimulus context according choice probability into components stimulus context has been pattern results feedback models paper using neural network models defined via stochastic differential equations show related condition channel has do feedback connections channels they converge into response units without direct connections other channels their directly inputs other channels analysis computational discussed
introduce novel method language models problems associated recurrent neural networks method prediction machine described experiments presented demonstrate language modeling between minimal pairs their behavior consistent hypothesis their potential into language processing
paper two rules computing similarity should both special cases more general bayesian learning framework bayes specific these two rules similarity measured well generalization should similarity based different analysis suggests even computationally may still useful level part approximation fully bayesian learning
recent suggest language easily paper learned recurrent neural network relatively few examples generalization different generalization specific examples find different generalization general results provide empirical support theory language well language environment role learning far more language than language
paper question levels learning classification tasks focus two tasks require levels defined human single hidden layer network learn both tasks without moreover analyze networks solution task show its solution makes use computation
investigate short term dynamics recurrent neural activity visual cortex terms information processing context orientation propose after stimulus recurrent due fast synaptic network highly nonlinear more linear orientation first highly competitive phase second less competitive phase multiple long range modulation eg connections possible effects thus network first features stimulus process show signal processing strategy optimal neurons have limited their objective maximum amount information time stimulus
paper classical learning find necessary effective associative memory learning synapses should difficult achieve robust manner synaptic learning depends network level information effective learning yet obtained neuronal process zero sum synaptic memory capacity associative networks capacity scales networks size effective patterns coding levels single network such neuronal successfully out activity dependent neurons synaptic recently observed cortical thus our suggest effective associative learning synapses synapses processes brain
consider between two neuronal different neurons given number output neurons connected each input neuron out number input neurons each output neuron convergence determine minimize total results following rule neurons layer should have than those layer data neurons whose connectivity known rule may used connectivity neurons their
accuracy population spiking neurons studied different distributions their symmetric receptive fields neurons usually considered out information point view both neural population into improve accuracy
investigate behavior cell spiking neurons via temporal synaptic learning curve learning function based recent experimental includes short time between synaptic neuronal spiking spiking order between dynamics synaptic learning neuronal activation leads interesting results find cell but may function complete distributed cell into cells manner behavior distributed both simulations resulting synaptic distributions
visual image consists figure against cells observed give higher responses image regions corresponding figure relative their responses figure relatively higher responses compared responses other locations figure between figure receptive fields cells small compared global scale figure effects has been suggested these effects may feedback higher visual areas show these effects mechanisms size figure small certain scale they processes segmentation between image regions
stochastic channels generate current noise neuronal noise may critical information processing within neural systems using monte carlo simulations out relationship between channel resulting noise using stochastic markov version model cortical neurons our simulations show parameters lead increase channel lead increase threshold noise noise threshold suggests channel may neurons ability function its synaptic inputs may limit precision neural information processing
long term has long been biological associative learning recently evidence has long term results cell after cell computational here synaptic kernels both have been proposed other based studies unit here interaction between time dependent studied small networks
previous modeling work nonlinear interactions among synapses active trees provide large memory capacity cell our present work estimating capacity neuron model inputs combined across cell single global threshold active model threshold applied output each combined focus here case binary synaptic weights derive measure model capacity estimating number input output functions available both neuron types show application fixed each models neuron size capacity nonlinear cell same linear cell more than order capacity cells relatively large number relatively small size analysis memory capacity two class classification problems stochastic rule used train both linear nonlinear models found large capacity predicted nonlinear model achieved practice
circuits feedback more than synapses made cortical neurons other cortical neurons such recurrent what its role cortical computation recent experiments have shown plasticity recurrent synapses learning rule describe such rule may allow cortex recurrent synapses prediction input sequences goal predict next cortical input recent based previous similar input sequences show temporal difference learning rule prediction used back action plasticity observed simulations demonstrate network cortical neurons learn predict moving stimuli develop direction selective responses learning space time response properties model neurons shown similar those direction selective cells
simple model two connected neural networks studied analytically similar those delay sample tasks stimuli tasks memory attention model many experimental data these types tasks provides framework understanding experimental observations context neural network
accuracy spike have been shown nature stimulus neuron channel neuronal models results behavior input dependent precision real neurons amount information channel based stochastic neuron model about wide set stimuli show both information rate information per spike stochastic model similar values reported experimentally moreover amount information neuron correlated amplitude input less so average firing rate neuron show channel density information capacity robust changes density channels ratio between channels has effect information neuron finally suggest neurons may their information capacity density different channels neuronal
human times during sensory motor tasks neuronal response time early visual processing conventional view temporal information information through network mean rate units tested whether neuronal different processing like mean rate units source separation algorithm applied signals sensory motor tasks response time multiple visual sources estimated single stimulus each source two subjects tested four visual time tasks sources early visual processing standard response early rather than processing hypothesis human response time early visual processing
study population maximum likelihood inference based model usually case neural population because process brain known because model computational cost consider model correlation between neuronal prove efficient neuronal correlation limited range performance compared maximum likelihood inference based model method out has advantages computational complexity high level accuracy same time effect correlation accuracy discussed
analyze conditions under synaptic learning rules based action potential timing learning rules based firing rates particular consider form plasticity synapses spike spike temporal such differential under certain conditions learning rule depends time firing rate such learning rule neural activity patterns recurrent neural networks
paper presents novel practical framework bayesian model model selection probabilistic graphical models our approach full posterior distributions over model parameters structures well latent variables manner these out free form optimization procedure large sample approximations generally computed predictive obtained analytically resulting algorithm standard expectation maximization algorithm its convergence demonstrate approach applied large class models several domains including mixture models source separation
unsupervised learning algorithms designed structure data samples robust inference requires structures data source ie similar structures have second sample set same data source overfitting maximum entropy based algorithms studied class clustering models large used determine approximation quality minimal monte carlo simulations support proposed model selection criterion finite
give necessary sufficient conditions support vector solution problems pattern recognition regression estimation general class cost functions show solution support vectors bound give simple examples non solutions note solution does solution show compute threshold solution but support vectors bound case method does work
new parameter model selection support vector machines introduced based support vectors feature space shown using these both predict best choice parameters model relative quality performance value parameter
generalize recent describe dynamics supervised learning neural networks data case noisy our theory predictions time generalization errors class learning processes large neural networks those overfitting
show recently proposed support vector machine svm algorithm known svm separation between convex data call soft convex soft convex choice parameter convex between them such distance between convex measured along normal normal determined soft convex but its position distance minimize error sum proposed interpretation svm leads necessary sufficient conditions choice svm solution
present three simple approximations posterior mean gaussian process classification first two methods related mean field known statistical approach based bayesian online approach recent results statistical neural networks present simulation results showing mean field bayesian evidence may used online approach may achieve low training error fast
recent algorithm view gradient descent potential function potential function allows new algorithms related these new algorithms generally known have boosting property paper question potential functions lead new algorithms two main results general sets conditions potential set resulting algorithm while other algorithm these conditions applied previously studied potential functions such those used ii
bayesian predictions stochastic like predictions other inference scheme generalize finite sample while simple variational shows bayes generalization optimal given prior parameter distribution less distribution unknown define class including both bayes prior maximum likelihood estimation special cases show bayes generalization optimal family distribution two learning problems analytically learning mean gaussian smooth
performance type code via methods statistical original two randomly constructed sparse matrices number non zero elements these matrices family codes show channel capacity may many codes while lower performance obtained may higher practical relevance considered approach used belief propagation based show codes may capacity but improved dynamical properties
gaussian mixtures so called radial basis function networks density estimation provide natural neural networks function approximation both cases possible give simple iterative improvement performance components network introduced time particular mixture density estimation show component mixture estimated maximum likelihood iterative likelihood improvement introduce log likelihood within order log likelihood convex combination approximation estimation using risk given minimum description length principle optimal number components risk bound
important neural computing description learning dynamics dynamical variables recent line learning often case training set introduce new framework model learning sets examples learning cost function fully into account temporal correlations introduced examples analyze effects weight early during learning generated examples
neural networks need more than single layer nonlinear units compute interesting functions show take nonlinear unit function computed single unit applied weighted input variables continuous function well single soft take unit applied weighted input variables positive weights these linear weighted may interest point view synapses cortex addition special cortex compute take our results support view take useful basic computational unit neural vlsi take input variables computed efficiently total length area linear analog vlsi et al show take useful special but may nonlinear unit neural circuits computational power show multi layer perceptron many compute take input variables take provides more computational unit than perceptron about same cost implementation analog vlsi complete further these results found
known decision tree learning form boosting existing boosting decision tree learning allow binary trees generalization multi trees practical decision tree algorithms such implement off between number improvement tree quality measured function here give boosting particular off curve our main theorem states require improvement log number top down decision trees effective boosting algorithm
order compare learning algorithms experimental results reported machine learning often use statistical most these do take into account due choice training set perform theoretical variance cross validation estimate generalization error takes into account due choice training sets allows us propose two new ways estimate variance show via simulations these new statistics perform well relative statistics considered
study here simple stochastic single neuron model self feedback capable generating spike simulations show its spike exhibit behavior between noise delay order gain into model study stochastic binary whose transition probability depends its state fixed model analytically compute show between noise delay observed such elements through interaction
study effects structure input distribution data simple perceptron determine learning curves within framework statistical generalization function number examples distribution patterns highly although simple model capture relevant features class support vector machines recently shown present behavior
lower bounds size neural networks approximate continuous functions particular show approximation network size has log degree bound input dimension ie number variables result obtained new method upper bounds dimension lower bounds size networks approximate continuous functions
paper define probabilistic computational model many noisy neural network models including recent work identify mechanism computational power probabilistic models independent characteristics noise whether discrete analog depends input independent whether variables discrete continuous give examples models including noisy computational systems noise current state inputs models computational systems update continuous time
effective methods capacity control via convergence bounds function have been limited support vector machines good bounds entropy number approach extend these methods systems terms arbitrary basis functions wide range regularization methods whole range general linear models achieved data dependent analysis corresponding design matrix
hierarchical learning machines non non statistical models whose true parameter sets sets using analysis prove stochastic complexity non learning machine equal number training samples moreover show number using resolution obtain number parameters
paper discuss statistical model first introduce filters problem framework model family estimating functions derived natural gradient learning algorithm developed training filters stability natural gradient algorithm framework
recently sample complexity bounds have been derived problems linear functions such neural networks support vector machines paper extend theoretical results area dimensional independent number bounds linear functions under certain regularization conditions show such bounds lead class new methods training linear classifiers similar theoretical advantages support vector machine furthermore present theoretical analysis these new methods asymptotic statistical point view technique provides better description large sample these algorithms
paper propose full bayesian model neural networks model model dimension number neurons model parameters parameters noise parameters random variables need estimated propose markov chain monte carlo method perform necessary find results better than previously reported but robust respect prior moreover present convergence theorem algorithm
present new technique time series analysis based dynamic probabilistic networks approach observed data terms independent factors recently introduced technique independent factor analysis factors each factor has its temporal statistical characteristics derive family em algorithms learn structure underlying factors their data these algorithms perform source separation noise reduction manner demonstrate superior performance compared
belief networks graphical models local conditional probabilities weighted states learning inference such networks generally approximations need considered learning these networks has been made using variational demonstrate variational important inference network introduce alternative procedure based weighted input node gaussian distributed our approach previous gaussian field assumptions take into account correlations between nodes procedure significantly faster than variational procedure
dimensionality modeling high dimensional discrete data number possible variables paper propose new architecture modeling high dimensional data requires parameters most number variables using multi layer neural network represent joint distribution variables product conditional distributions neural network graphical model without hidden random variables but conditional distributions through hidden units connectivity neural network using between variables experiments modeling distribution several discrete data sets show significant over other methods such bayes bayesian networks show significant obtained network
used gaussian noise model nonlinear regression more noise model based distribution chosen such special cases either gaussian distribution distribution used robust regression distribution being mixture parameters such distribution learned data based em algorithm show modeling using distribution leads improved real world data sets particular present distribution superior gaussian noise model effect system learn between non online learning tasks weight changes due stable online learning show experimentally using distribution noise model leads stable online learning algorithms state online learning methods like extended kalman filter algorithm
introduce algorithm estimating values function set test points given set training points without estimating step regression function demonstrate direct way estimating values regression classification pattern recognition more accurate than traditional based two steps first estimating function values function points interest
machine recurrent neural network model describe data application maximum likelihood estimation model gives learning rule binary machine mean field approximation describe monte carlo sampling techniques used learn its parameters sampling well distribution efficiently implemented sample distribution illustrate learning invariant distribution well generative model images human
many problems correct behavior model depends its input output mapping but properties its matrix matrix partial models outputs respect its inputs introduce algorithm efficient general method computing exact partial variety simple functions model respect its free parameters algorithm feedforward model including nonlinear regression radial basis function networks
present algorithm model structure mixture factor using efficient deterministic variational approximation full bayesian over model parameters procedure automatically determine optimal number components local dimensionality each component ie number factors each factor used posterior distributions over number components parameters out method overfitting using stochastic procedure components possible perform variational local results show method well practice number dimensionality synthetic examples sampling variational approximation show obtain estimates true evidence exact predictive density between variational posterior true posterior model but variational approximations general
inference principle takes training sample estimating values function given points so called sample whole input space provides confidence measure single predictions rather than classifiers feature important risk sensitive applications number functions reduced finite number classes sample bayesian analysis standard classification loss cannot more than test point time probability label given test point determined posterior measure corresponding subset hypothesis space consider setting binary classification linear functions kernel space such probability labels determined ratio version space suggest sample region experimental results real world data indicate bayesian well known support vector machine particular posterior probability used confidence measure test points low confidence
describe class probabilistic models call networks using trees internal representations images networks able perform segmentation recognition simultaneously need segmentation results problem obtained
present general framework estimation based maximum entropy principle its distributions over structures parameters rather than specific reduce relative entropy even data within chosen parametric class context detection rather than classification labels training set support vector machines under class provide several able estimate efficiently distributions over tree structures class conditional models within experimental results potential these techniques
transformations such image has been successfully into feedforward mechanisms eg neural networks propagation describe way transformation density model nonlinear transformation discrete set transformations em algorithm original model extended new model computing over set transformations show discrete transformation variable gaussian mixture modeling factor analysis mixtures factor analysis give results filtering images face clustering modeling recognition
new decomposition algorithm training regression support vector machines svm presented algorithm basic decomposition proposed et al optimal set selection new set derived based these principle proposed form optimal sets experimental results show superior performance new algorithm comparison traditional training regression svm without decomposition similar results have been previously reported decomposition algorithms pattern recognition svm new algorithm svm based regression such density estimation equation svm
latent variable generative model finite noise used describe several different algorithms independent components analysis ica particular fixed point ica algorithm shown equivalent expectation maximization algorithm maximum likelihood under certain constraints conditions global convergence algorithms their behavior near point size optimal likelihood about point role higher order correlations features ica application convergence these algorithms demonstrated simple example
describe new algorithm training linear threshold functions online maximum margin algorithm approximation algorithm previously examples maximum margin known such maximum margin hypothesis computed minimizing length weight vector number linear constraints relatively simple these constraints efficiently prove bound same perceptron algorithm our analysis more computationally maximum margin algorithm bound first case performance algorithm describe experiments using updates its hypothesis more algorithms computational complexity these algorithms similar perceptron algorithm but their generalization much better describe sense performance svm limit bias considered
recent bayesian networks have highly analysis decision making real world domains present efficient algorithm learning bayes networks data our approach bayesian networks first each nodes markov nodes consistent way contrast work typically uses approaches may produce nets our approach yields much more causal networks data causal networks fast inference prove under assumptions our approach requires time polynomial size data number nodes presented here yields results much higher
provide abstract boosting algorithms gradient cost product function space prove convergence these functional gradient descent algorithms under quite conditions following previous theoretical results generalization performance convex classifiers terms general cost functions margin present new algorithm ii gradient descent optimization such cost functions experiments several data sets demonstrate ii generally high noise overfitting predicted our cost functions
paper present new multi class learning algorithm related family algorithms algorithm predictions set experts online model learning special type distribution over finite number classes learns linear function experts uses function make class predictions provide bounds show performs well target represented few relevant experts show used solve more traditional problems leads natural extension learns multi class problems both traditional experts
prior knowledge construct nonlinear algorithms invariant feature discrimination framework terms nonlinear propose non linear pca using support vector kernel functions simulations show our approach
present class approximate inference algorithms graphical models type give convergence rates these algorithms algorithm these theoretical predictions present empirical results difficult network problem performance new algorithms algorithm
local linear regression performs well many low dimensional problems high dimensional spaces its performance typically due well known dimensionality possible way approach problem varying shape kernel work suggest new data method estimating optimal kernel shape experiments using generated data set data show kernel
present new learning architecture decision graph used many two class classifiers into classifier class problem classifiers each classes present analysis case node classifiers resulting bound test error depends margin achieved nodes but dimension space algorithm kernel feature space uses two class margin each decision node faster train evaluate than either standard algorithm while accuracy both these algorithms
bayesian mixture model necessary limit number components finite paper gaussian mixture model presented difficult problem finding right number mixture components inference model using efficient parameter free markov chain sampling
other ensemble methods have successfully been applied number classification tasks problems overfitting performs gradient descent error function respect margin patterns learn noisy problems theoretical analysis has shown margin distribution minimal margin role understanding should has margin points propose new boosting algorithm allows points margin area even decision
linear analysis classical technique both dimension reduction classification data vectors into low dimensional such class out much possible simple classifier linear decision many applications linear do classes present nonlinear generalization analysis uses kernel representing kernel functions presented algorithm allows simple formulation em algorithm terms kernel functions leads concept unsupervised mixture analysis supervised analysis semi supervised analysis observations feature spaces
provide analysis algorithm setting gaussian context able show algorithm density generated may significantly desired posterior density means these two
given underlying probability distribution estimate simple subset input space such probability test point between propose method approach problem estimate function positive negative functional form given kernel terms small subset training data length weight vector associated feature space provide theoretical analysis statistical performance our algorithm algorithm natural extension support vector algorithm case data
paper describes recurrent mixture density networks model multi distributions type without assumptions about use context these pattern recognition problems sequential data example speech recognition experiments show proposed generative models give higher likelihood test data compared traditional modeling approach they statistical properties data better
present simple sampling explicitly important regions target distribution prove technique yields estimates show reduce variance standard monte carlo achieved samples more significant regions sample space
present variational bayesian method model selection over kernels classifiers like support vector machines gaussian processes algorithm user interaction able large number kernel parameters given data without training cases validation use kernels small standard kernel classes method other work gaussian processes between support vector machines certain gaussian process models
describe iterative algorithm vector machines used classification tasks algorithm support vector machines boosting generalized models algorithm used various differential functions bound discrete classification loss simple implement test proposed algorithm two different loss functions synthetic natural data describe norm version algorithm exponential loss function used performance algorithm natural data support vector machines while typically its time than svm
introduce novel clustering algorithm mutual information per cluster between data given algorithm considered up version recently introduced information method algorithm compared top down soft version information method relationship between soft results demonstrate algorithm data set subset two achieve original mutual information
paper consider problem active learning polynomial networks give necessary sufficient condition sample points provide optimal generalization condition functional point view mechanism optimal generalization show set training examples condition does provide optimal generalization but computational complexity memory required learning results finally examples sample points condition given computer simulations performed demonstrate proposed active learning method
gaussian processes regression models mean covariance functions standard approaches estimate these parameters known maximum likelihood maximum map approaches paper propose investigate predictive approaches maximization predictive probability minimization mean error respect predictive mean error estimate derive results standard cross validation error make comparison these approaches tested number problems experimental results show these approaches competitive existing approaches
paper input selection radial basis function rbf like classifier within bayesian framework approximate distribution over both model coefficients input samples updates using datasets compare classification accuracy method conventional scheme these datasets used probabilities different input
propose novel approach finite memory predictive models similar variable memory length markov models models constructed first structure training sequence into spatial structure points unit such common two their point representations such transformation markov assumption long common produce similar finding set prediction problem solved vector spatial representation compare our model both classical variable memory length markov models three data sets different memory stochastic components our models have superior performance yet their fully shown case
support vector machine svm state technique regression classification properties sparse kernel representation does number probabilistic outputs estimate off parameter need kernel functions paper introduce relevance vector machine bayesian linear model functional form svm above examples demonstrate performance requires kernel functions
new method density estimation developed based support vector method svm solution inverse problems solution has form mixture method gaussian kernels compared both method gaussian mixture model method synthetic data achieve more accurate estimates dimensions
estimation problem simultaneously estimating state dynamic system model gives dynamics algorithms include expectation maximization em kalman filtering joint kalman methods these methods have recently been context nonlinear modeling neural network used functional form unknown model typically extended kalman filter used part algorithm estimates state given current estimated model may used estimate weights network paper points out using improvement based new approach called transformation performance gain achieved same order computational complexity standard approach several estimation methods
local belief propagation rules proposed converge correct posterior probabilities connected graphical models recently number have demonstrated good performance belief these same rules graphs most instance near limit performance codes whose algorithm equivalent belief propagation case graphs single has been theoretical understanding performance propagation here analyze belief propagation networks arbitrary nodes graph describe gaussian random variables give true posterior probabilities those using propagation give sufficient conditions convergence show belief propagation gives correct posterior means graph networks single related product belief propagation algorithm maximum posterior probability estimate connected networks show even non gaussian probability distributions convergence points product algorithm networks over particular large local posterior probability these results empirical performance results using belief propagation algorithm class networks problems probabilistic belief propagation wide variety applications including error codes speech recognition graph connected local schemes posterior probability variable given observed variables derived such scheme connected bayesian networks belief propagation algorithm converge correct posterior probabilities several have recently reported experimental results algorithms equivalent algorithm networks most instance performance code error codes these codes have been described most important development coding theory many have recently been shown algorithm equivalent belief propagation network analysis belief propagation has been made case networks single these networks shown deterministic belief propagation converge difference between true related convergence rate faster convergence more exact approximation hidden nodes binary true both same although confidence paper analyze belief propagation graphs arbitrary nodes gaussian random variables give exact correct posterior probabilities using belief propagation show belief propagation give correct posterior means graph networks single show covariance estimates generally but present relationship between error covariance estimates convergence speed gaussian non gaussian variables show product algorithm map estimate connected networks points over particular large posterior probability networks analysis assume graphical model has been into graphical model pairwise graphical model into form belief propagation pairwise graph equivalent belief propagation original graph assume each node has local observation each iteration belief propagation each node each based other its local observation pairwise ii assume parallel idea analysis tree tree graphical model belief propagation solving belief propagation rules network constructed same local structure network but nodes so observations graph figure shows tree graph belief node node graph after four iterations belief propagation each node has observed node here because original network gaussian variables so tree tree belief propagation give correct graph thus use gaussian true mean both original networks way accuracy belief propagation gaussian networks arbitrary assume joint mean zero means joint belief propagation figure left markov network multiple right network corresponding structure given construct inverse covariance matrix joint gaussian describes given gaussian graphical model out joint shows mean given observations given covariance matrix given so posterior variance given data use tree first order vector values hidden nodes tree so observed nodes same order inverse covariance matrices first order nodes nodes number nodes nature mean belief node after iterations belief propagation number variance belief node after iterations because data over non have same connectivity corresponding zero but these relationships between inverse covariance matrices into equation following expression true iteration vector zero but components corresponding nodes our choice node tree arbitrary so nodes network node network means each iteration belief propagation true posterior means relationship between inverse covariance matrices into node figure conditional correlation between node other nodes tree fig after iterations chosen randomly nodes presented first order so elements correlations between node nodes show correlation zero belief propagation means exact correlations nodes node graph sum these correlations gives correct variance node while propagation uses first correlation belief propagation true vector zero but components while equal nodes tree other components zero figure shows network fig generated random potential functions observations conditional correlations tree note conditional correlation distance tree first order so components nodes number iterations propagation size tree conditional correlation between nodes node equations conditional correlation between nodes nodes zero large belief propagation means exact may practice conditional correlations equal zero finite give more conditional correlation node nodes belief propagation means exact may show sufficient conditions correlation rate correlation determined ratio off components quadratic form term equation sum many components shows these components correct variance sum components while belief propagation variance sum first term positive correlation between node other variance less than true variance estimate belief propagation iterations figure graphical model simulation nodes connected their four nearest observation node error estimates propagation over function iteration note belief propagation much faster than note conditional correlation zero two first convergence faster because approaches zero faster second approximation error because thus have shown single case convergence correlated good approximation simulations belief propagation grid fig joint probability nodes randomly probability set observations chosen randomly problem approximation problem sparse data points found exact posterior solving equation belief propagation found means true means up machine precision predicted theory small belief propagation estimate many applications solution equation matrix iterative methods used figure error means function iterations propagation over considered best methods note after iterations propagation gives right while requires many more expected fast convergence approximation error quite small error comparison true mean nodes approximation error nodes two other have recently special cases gaussian graphical models graphical model corresponding factor analysis conditions stable fixed point graphical model but gaussian joint density specific graph they sufficient conditions convergence means exact our main interest gaussian case performance belief propagation general networks multiple similarity our results arbitrary networks results single arbitrary distributions first single networks binary nodes belief node true belief node same while confidence gaussian networks multiple mean each node correct but confidence mean may second both gaussian networks fast belief propagation convergence accurate both discrete single networks statistical between nodes convergence rate accuracy two models quite different mean field approximations exact gaussian while they work connected discrete networks single results gaussian single cases lead us similar results may larger class networks our analysis extended non gaussian distributions basic idea arbitrary graphs arbitrary belief propagation exact inference tree has same local neighbor structure graph linear used exact error belief propagation iteration gaussian variables have used similar approach analyze related product belief propagation algorithm arbitrary graphs arbitrary distributions both discrete continuous nodes show product algorithm product has posterior probability particular large region while condition than global maximum much than simple local maximum posterior probability sum product product belief propagation algorithms fast due well known probabilistic inference graphical models belief propagation work arbitrary networks distributions empirical evidence shows its many networks our results applying belief propagation certain networks multiple may fast approximate probabilistic inference range new applications convergence iterative graphs single near limit error coding codes inference bayesian networks learning graphical models iterative presented information theory belief propagation fixed points product algorithm report learning estimate scenes images neural information processing systems factor analysis neural information processing systems bayesian networks pattern classification data channel coding low density codes iterative codes probability propagation graphical models areas instance belief propagation algorithm areas decision algorithm control computing belief propagation approximate inference empirical study uncertainty analysis gaussian neural information processing systems probabilistic systems networks inference
many hierarchical clustering algorithms available but these statistical basis here set up hierarchical probabilistic mixture model data generated hierarchical tree manner markov chain monte carlo methods demonstrated used sample posterior distribution over trees containing variable hidden units
data feature selection methods proposed based joint mutual information ica methods find many good high dimensional data interpretation cannot easily found other existing methods new variable selection method found better inputs than other methods based simple mutual information methods signal analysis problem find data inputs neural network classifier feature selection joint mutual information ica classification
propose new markov chain monte carlo algorithm generalization stochastic dynamics method algorithm performs state space using its structure efficient sampling complex distributions applied bayesian learning neural networks our algorithm found perform least well best state method while less time
data examples dimensional space apply standard machine learning algorithms describe parallel problems they allow work large data sets within work many computing algorithms computational power machine learning demonstrate system number tasks example perform independent components analysis large text making minimal changes original source applying techniques data previously their leads interesting both data algorithms
system moving eye motor system has been successfully tested made field view image up direction four analog vlsi circuits motor control off circuits each other non address system based smooth human eye performance smooth sources moving up visual field
describe network neurons global neuron output neuron respect input output models property wide field cells visual system property useful system output signal code inputs dependent number inputs each neuron equivalent take circuit additional circuit outputs neurons code neuron input difference here multiple chosen varying neuron network transition between soft behavior behavior show results chip neurons cmos
have developed tested vlsi system models biological underlying such its current form system consists chain pattern generating circuits capable arbitrary synaptic each pattern generating circuit implemented two independent neurons total based synapses address provides synaptic connectivity delay describe analyze data set experiments system behavior terms synaptic
have developed vlsi neuron corresponding model two state variable system describe circuit implementation compare observed neuron model perform analysis model varying applied current show neuron under corresponding conditions good those predicted analysis
paper presents system sound uses three vlsi two cell circuits two spiking neuron consists filters because delay between two outputs spike these outputs range contrast traditional filters increase has off against response time proposed system independent
neural model described uses correlation speech sound sources model two layer neural network sound represented population different represented model has been using speech improvement signal noise ratio every mixture
present hidden markov model hmm hidden state neural activity during single activation experiments task inference based bayesian using combination variety markov chain monte carlo sampling techniques advantage method detection short time learning effects between possible inference based single experiments
paper role biological constraints human auditory process neural system modeling approach performance between models human explore relevant constraints cues upon sound based derived human subjects related transfer functions sound stimuli generated noise presented both model input stimuli model using auditory image model processing data time delay neural network temporal spectral information determine spatial location sound source combined model neural network provided system model sound process human like performance achieved stimuli model architecture frequency trained using variable frequency
differential spectral cues human sound using combined approach cues location correlated individual basis human responses variety spectral cues derive filtering auditory measured related transfer functions auditory performance determined auditory space experiments amplitude sound stimulus each while normal timing cues free field environment auditory noise stimuli generated over target direction such left using subjects sound right so either true right spectral true spectral subjects both true right true spectral conditions their control performance analysis different cues along subjects responses suggests significant use spectral cues auditory systems spectral cues sound condition
sources using based second order statistics using model process case show parameter estimation problem reduced arrival each signal paper presents two methods time frequency domain experimentally shows possible signals different moreover use spatial cues solve channel selection problem processing filter
stochastic descent new technique online adaptation local learning rates arbitrary systems like matrix uses full second order information while computational complexity efficient computation vector here apply independent component analysis resulting algorithm separation time varying mixtures matching individual learning rates rate change each source signals mixture coefficients our technique capable simultaneously tracking sources different unknown
speech linear stochastic state space system its parameters estimated using expectation em algorithm problem em algorithm standard schemes lead trajectories but these trajectories important paper investigate methods em paper state space system method em algorithm em methods similar they both estimate state sequence but using kalman filters kalman estimate parameters but using least maximum likelihood similarity em use em non iterative requires em iterative requires optimal compared em probabilistic sense during experiments real speech methods compare conventional techniques they produce trajectories have frequency resolution produce higher work while speech using em techniques
paper use mutual information distributions information space mutual information between label feature joint mutual information between label two three features estimated bias entropy mutual information estimates extended include higher order terms recognition estimated results those classification our results show information locally information time frequency
evidence shows sound signals their visual signals effect known work sound set effect suggests important information about sound location between video signals evidence used source information computer vision tasks paper explore use visual sound sources developed system regions visual highly signals them source discuss our system present results speaker task discuss potential applications approach
three dimensional motion observation limited single due video present system motion human subjects single video prior knowledge about human motion learned training data those after tracking reconstruction show results several video sequences results show power tracking inference problem
independent component analysis natural images leads simple cell properties ie linear filters functions paper extend ica explain further properties cells first natural images into independent instead components model leads phase invariant features similar those complex cells second define between linear components obtained ica distance between two components defined their higher order correlations so two components close each other they dependent each other leads both similar complex cell properties
paper propose information maximization provide framework understanding eye movements framework mutual information among cortical representations image constructed our long term visual dynamic short term internal representation constructed recent provides map eye locations maximum complexity neuronal ensemble responses each step eye movement system information about world while neural representations process framework several such out long term visual short term memory provides interesting computation neural representation visual system
describe method learning set basis functions modeling sparse structure images basis function coefficients mixture distribution gaussian coefficients small variance distribution zero while more other capture active coefficients large variance distribution show prior such form efficient methods learning basis functions well parameters prior performance algorithm demonstrated number test cases natural images basis functions learned natural images similar those obtained other methods but sparse form distribution much better described parameters prior data assumption about sparse structure images need made rather learned data
model probability distributions image spaces show distribution images into conditional distributions feature vectors resolution level image information lower would like factor over levels make but such may long range introduce hidden class labels each result hierarchical mixture conditional probabilities similar hidden markov model tree model parameters found maximum likelihood estimation using em algorithm have obtained results problems various objects images target recognition images
statistics images represented using exhibit two types behavior first coefficients have extended second joint exhibit variance second order models properties class gaussian scale mixtures show these both joint distributions natural image coefficients class model suggests markov structure coefficients hidden scaling variables corresponding local image structure derive estimator these hidden variables show nonlinear procedure used coefficients recent have interest modeling statistics natural images such models important applications image processing computer vision many techniques either explicitly prior density number empirical studies have demonstrated power natural images radial frequency typically close two eg such second order because images usually exhibit highly non gaussian behavior instance coefficients typically have much than gaussian furthermore being suggested theoretical analysis processes coefficients exhibit statistical particular standard typically scales values its number have distributions coefficients generalized eg special cases include gaussian but appropriate density positive stable form density function stable generalized form form table example class gaussian scale mixtures positive variable density function random variable defined natural images typically less than has variance pairs coefficients et al have using two component mixtures have cross joint multi dimensional generalized following explore semi parametric class gaussian scale mixtures show class being scaling between coefficients show particular class variables distributed according density range joint statistical coefficients natural images derive estimator show nonlinear procedure used coefficients form random tree scale mixtures random vector gaussian scale mixture distribution random variable gaussian random vector independent variable has density given probability density variable special case finite mixture discrete random variable more generally provide conditions either density function but these conditions do provide form number well known distributions may gaussian scale mixtures case few these along their associated functions table each variable scale parameter parameter models table produce variance scaling joint scale mixtures statistics natural images figure empirical each parameter values relative entropy between model entropy modeling natural images
novel learning approach human face detection using network linear units presented learning architecture sparse network linear functions over defined learned feature space learning presence large number features wide range face images different different under different conditions used training set capture human experimental results used data sets wide range face images show based approach methods use neural networks bayesian methods support vector machines furthermore learning evaluation using based method significantly more efficient than other methods
problem modeling time series data minimizing short term prediction errors does between model experiments introduce modeling simultaneously learns short term predict new way nonlinear principal component analysis predictions constrained within these learning fast parameter estimation sample data time series less than
action coding system objective method movement terms component actions system used processes interaction coding performed highly trained human experts paper techniques automatically actions sequences images these methods include unsupervised learning techniques finding basis images such principal component analysis independent component analysis local feature analysis supervised learning techniques such linear these data compared basis images best obtained using representation independent component representation both achieved accuracy actions ica representation basis images than representation takes less time compute new images results provide support using local basis images high spatial statistical actions
paper application reinforcement learning problem problem requires channel while simultaneously minimizing present solution multi problem able significantly reduce power solution uses variable factor capture effects
discuss information approach modeling dynamic processes approach learn states predict future observations furthermore uncertainty prediction joint density over learned present observation discuss application technique both noise dynamical systems random processes density first case show results both dynamics random statistics noise second case present results learned noisy random states both cases algorithm yields approach processes dynamics method information theory statistics
three algorithm analog circuits provided paper first method representing highly nonlinear non continuous analog circuits using current potential functions within context markov field described second relatively efficient algorithm markov field objective function described convergence empirical results approach provided within context design problem proposed algorithm generated set circuit components circuit model generated desired curves analog circuit design using markov random fields markov random field models markov random field generalization concept markov chain markov field set random variables represented graph each random variable paper discrete random variable takes finite number possible values each node graph specific random variable link node node conditional probability distribution random variable field dependent upon random variable random variable neighbor random variable upon markov field ie condition probability every field positive idea markov field design potential energy function every graph such subset random variables associated obtain their optimal values potential function its minimal value see markov random field models provide mechanism representing local constraints analog circuit design using signal application specific circuit design problems most circuit design well known but
paper develop first information general method learning similarity between text each individual information source based latent class decomposition term matrix learned model similarity function known kernel derived our approach applied unsupervised supervised learning problems particular interesting cases both labeled data available experiments text advantages proposed method
approach has been proposed model uncertainty generalization performance advantage depends performance individual structure errors between paper presents input technique technique input variables first based their mutual information similar variables same each input set input variables different our designed have less error correlation between its each different input variable individual feature sets less information because highly correlated variables combined together feature sets almost complete information each set feature each information empirical study noisy problem shows constructed our proposed technique using several existing techniques
provide evidence existing algorithms small scale networks expression data large scale expression data steps clustering many their expression time data into minimal set clusters modeling various conditions under time measured using time analog recurrent neural network cluster mean time such model cluster mean time simulated weight several such circuit parameter sets including connection matrices procedure used existing future expression time data sets relationships such
typically consists mixture several mixture coefficients assume linear normal noise derive probabilistic map framework data characteristics face problem unsupervised linear different prior information eg leads family interesting algorithms example noise free case algorithm constrained independent component analysis ica simulations our theory
analysis data signals changes cortical noise such patterns problem often filtering used but underlying assumption spatial frequency mapping component other components global signal here propose alternative ways processing data using source separation techniques based spatial data first perform artificial data order way processing most robust respect noise apply experiments visual cortex show our technique able orientation maps single condition data standard processing patterns often maps our method source separation using extended spatial superior technique analysis data
recently number have proposed systems markov decision processes practical application algorithms systems number have general reinforcement learning systems based framework have applied two systems our experiments demonstrate understanding correlations complex dependent
propose new efficient technique information into object classification most current techniques face problem exponential computation cost paper propose new general framework partial context linear cost technique applied image recognition resulting significant improvement recognition rate over context free approach gain would have been using conventional context techniques recognition context number pattern recognition problem domains classification object should based more than object image classification each part more area than areas text analysis find certain particular other information information human experts apply information their decision making makes sense design techniques algorithms make more complete set information their decision making way human experts do pattern recognition systems often source information used identify object set measurements features associated object information context into classification process significant consider set objects each object class label label set set measurements many techniques context each object call feature posterior probability objects joint features objects respect shown given certain assumptions context free posterior probabilities known eg through use standard machine learning model such neural network computing possible would finding maximum has complexity large another problem formulation estimation high dimensional joint distribution data way these problems limit context local regions approach close considered such techniques may useful information apply context have such case image recognition another way problem using specific domain knowledge but possible certain domains these efficient partial context general framework section section discuss image recognition address using context application section techniques proposed identify relevant context empirical results shown section section formulation partial context exponential computational cost using objects directly context use partial context called partial because derived class labels objects depends problem hand our application presence certain classes posterior probability object class label its feature vector relevant context assume feature distribution object depends its class ie assumption true most real world problems image recognition context application called context ratio through context its role context sensitive posterior probability obtained through context free posterior probability context ratio partial context maximum likelihood decision rule class label such approach identify relevant context section partial context approach each set but additional information context factor known context obtained possible values take total number complexity finding maximum both linear density estimation part estimate pca
describe bayesian approach model selection unsupervised learning both feature set number clusters evaluate scheme based likelihood based cross likelihood bayesian scheme derive form solution likelihood appropriate likelihood function prior experiments compare these approaches results comparison against these experiments bayesian scheme using our objective function better results than cross validation
problem images visual problem bayesian inference leads natural effective solutions two most design retrieval system support region based without prior image segmentation user feedback during retrieval present new learning algorithm belief propagation account both positive negative examples
reinforcement learning generally important yet difficult problem paper problem environment model called hidden markov decision process changes small number hidden markov decision process time according markov chain while special case observable markov decision processes modeling environment via more general model problem complexity algorithm developed model learning less data time
many have methods hierarchical reinforcement learning temporal abstract actions defined perform many actions known about learning state state space previous work developed method hierarchical paper define conditions under state combined value function decomposition prove learning algorithm under these conditions show experimentally state important application learning
consider problem near best strategy class ii observable markov decision process assume given ability study what might called sample complexity amount data generate order good strategy prove upper bounds sample complexity showing even large complex amount data finite depends complexity strategy class ii time variety ways including application gradient local search algorithms our measure complexity classical supervised learning dimension reinforcement learning planning
propose analyze class algorithms simulation based optimization markov decision process over family policies these two time scale algorithms uses td learning linear approximation architecture approximate gradient direction based information provided show features should choice convergence properties problems
consider problem learning grid based map using robot noisy compare two approaches online em map fixed parameter bayesian inference map matrix random variable show even simple example online em local robot resulting map contrast bayesian approach multiple much more robust introduce method bayesian solution called filtering show approximation active learning strategy fast but accurate
propose new approach problem space stochastic markov decision process observable markov decision process following several other our approach based policies example via gradient descent solution quality rather than estimate values policy directly do so using estimates probability policy states different points time our algorithms many techniques efficient robust approximate density propagation stochastic systems show our techniques applied both deterministic propagation schemes dynamics given explicitly form stochastic propagation schemes have generative model present empirical results both these complex problems
model predictive control control algorithm uses solve optimal control over future time based upon model process has standard control technique process over two most applications linear dynamic model developed using empirical data used even process often nonlinear linear models have been used because nonlinear model empirical data computational often using nonlinear models paper present neural network based technique nonlinear dynamic models empirical data show these models efficiently used model predictive control framework nonlinear based approach has been successfully implemented number applications paper performance controller nonlinear process presented
problem good policies observable markov decision problems most areas research stochastic planning line research area involves use reinforcement learning belief states probability distributions over underlying model states method small problems but its application limited computing representing full belief state large problems recent work shows many approximate belief state close true belief state particular has been shown approximate belief states out correlations between state variables paper investigate two methods full belief state reinforcement learning novel method reinforcement learning using approximate belief states compare performance these algorithms several well known problem our results demonstrate approximate belief state representations large problems
problem address paper robot order its goal minimum uncertainty traditional motion planning algorithms often assume robot its position real world may observable markov decision processes provide way goal state but cost computational large state spaces method propose explicitly models uncertainty position state variable trajectories through uncertainty space minimizing uncertainty goal robot likelihood demonstrate experimentally uncertainty goal
problem reinforcement learning non markov environment using dynamic bayesian network conditional assumptions between random variables represented network parameters parameters learned line approximations used perform inference compute optimal value function relative effects inference value function approximations quality policy learning solve difficult task two value function approximations linear quadratic found perform but quadratic model more sensitive both performed level human performance task dynamic bayesian network performed model using hidden state representation while parameters
function approximation reinforcement learning but standard approach value function policy has so far paper explore alternative approach policy explicitly represented its function independent value function according gradient expected reward respect policy parameters method methods examples approach our main new result show gradient form estimation approximate action value advantage function using result prove first time version policy iteration arbitrary function approximation locally optimal policy large applications reinforcement learning require use function such neural networks decision trees instance based methods approach has been value function approach function approximation into estimating value function action selection policy represented policy respect estimated values eg policy each state action estimated value value function approach has well many applications but has several first finding deterministic policies optimal policy often stochastic different actions specific probabilities eg see second small change estimated value action such changes have been key convergence algorithms following value function approach example learning dynamic programming methods have been shown converge policy simple simple function even best approximation found each step policy whether best mean error sense different gradient temporal difference dynamic programming methods paper explore alternative approach function approximation sutton rather than value function using compute deterministic policy approximate stochastic policy directly using independent function its parameters example policy might represented neural network whose input representation state whose output action selection probabilities whose weights policy parameters vector policy parameters performance corresponding policy eg average reward per step policy gradient approach policy parameters gradient positive step size above achieved usually converge locally optimal policy performance measure value function approach here small changes small changes policy state distribution paper prove estimate gradient obtained using approximate value function certain properties algorithm estimate gradient but without learned value function learns much more than methods using value functions has relatively attention learning value function using variance gradient estimate learning result similar special case function approximation corresponding our result arbitrary function developed result see our result suggests way convergence wide variety algorithms based policy iteration architectures eg sutton sutton paper take first step direction first time version policy iteration general function approximation locally optimal policy obtained but similar result their family methods like policy gradient methods includes policy value functions gradient methods methods do gradient performance expected long term reward but measure performance accuracy result does converge locally optimal policy case weight upon value function accuracy case value iteration value based but does find locally optimal policy policy gradient theorem consider standard reinforcement learning framework see eg sutton learning agent markov decision process state action reward each time st dynamics state transition probabilities st expected st decision making procedure each time policy parameter vector assume respect its parameter ie usually policy gradient methods function approximation function approximation two ways objective useful average reward formulation policies according their long term expected reward per step st distribution states under assume independent so policies average reward formulation value state action given policy defined second formulation state so about long term reward obtained give our results but they apply formulation well under st rate tasks formulation define states so following our first result gradient performance metric respect policy parameter theorem policy gradient either average reward state see way gradient first discussed average reward formulation based related expression terms state value function due extend their results state formulation provide more direct theory algorithms key both gradient their terms form effect policy changes distribution states does gradient sampling example distribution would estimate obtained following known estimated use state formulation approximation each leads algorithm actions known expected value policy gradient approximation now consider case learned function approximation good might use sutton still point direction gradient example special case function approximation could positive product gradient sufficient improvement moving direction here extend their result general function approximation prove gradient our approximation parameter natural learn following rule such estimator such process has local theorem policy gradient function approximation policy sense gives us error gradient policy because expression above zero policy gradient theorem application algorithms advantages given policy theorem used derive appropriate form value function example consider policy distribution linear combination features points out being linear features given may way condition policy gradient methods function approximation each dimensional feature vector state action condition requires so natural other words linear same features policy mean zero each state other algorithms easily derived variety nonlinear policy such multi layer backpropagation networks have form given above requires have zero mean each state sense better approximation advantage function much rather than our convergence relative value actions correct each state value state state our results special advantages target value function approximation fact our generalized include arbitrary function state value function its approximation example generalized arbitrary function because choice does our but variance gradient here those use reinforcement work eg sutton practice should set best available approximation our results approximation process without expected convergence policy iteration function approximation given theorem prove first time form policy iteration function approximation locally optimal policy theorem policy iteration function approximation function policy value function condition step size sequence such sequence defined such such our theorem update direction gradient together us bounds sutton these together step size necessary conditions apply convergence local into optimal policy under function approximation advantage report algorithms reinforcement learning function approximation machine learning gradient descent general reinforcement learning sutton elements solve difficult learning control problems systems direct gradient based reinforcement learning gradient estimation algorithms dynamic programming analysis markov processes control reinforcement comparison connectionist models stable function approximation dynamic programming machine learning learning report reinforcement learning algorithms observable markov decision problems analysis algorithms using reinforcement learning value functions algorithms simulation based optimization markov reward processes report learning without state estimation observable decision problems sutton temporal reinforcement learning sutton reinforcement learning
present monte carlo algorithm learning observable markov decision processes real state action spaces our approach uses sampling representing monte carlo approximation belief propagation reinforcement learning algorithm value iteration learn value functions over belief states finally version nearest neighbor used generalize across states initial empirical results suggest our approach well practical applications
introduce novel algorithm performance prediction algorithm measures elements neural system tasks performs algorithm neurons areas task given data about performance small set allows accurate prediction due new algorithm demonstrated two models recurrent neural networks complex interactions among algorithm analysis large neural networks given recent techniques has potential significantly under biological systems about local distributed brain
present agent design language reinforcement learn allows user policies considered learn language includes standard features such parameter memory variables but allows agent learning present learning demonstrate example agent language well state learned
framework adaptive coding often constructed choice design instead probabilistic latent variable model form mixture constrained gaussian mixtures model derive coding algorithm constrained version generalized algorithm vector design our
model cells cells visual stimuli visual provided video robot set filters nodes graph learning fields cells basis reinforcement learning experimental results robot presented
paper presents probabilistic framework speech signals framework problems into signal estimation key idea use strong speech model large data set speech computational efficiency achieved using variational em frequency domain framework both single multiple apply approach noisy speech signals results better than standard methods
present algorithm between characteristics real world problems assumptions independent component analysis algorithm provide additional information ica network top down selective attention signal channel error ica network backpropagation process results estimation expected ica output signal top down attention matrix according new cost function representing error well density signals density appropriate noisy speech signal real algorithm improved recognition performance against parametric changes
present computational model neural mechanisms temporal support spatial scenes long term representations associated local spatial features region representations generated long term memory part model model locations objects complex after model experiment our model makes novel predictions neural representations regions behavior
develop approach object recognition based matching using resulting measure similarity nearest neighbor key problem here between image shape shape introduce new shape shape context makes possible using simple robust algorithm shape context point distribution over relative other shape points thus global shape local demonstrate shape between points two given shape used de robust shape similarity have used nearest neighbor recognition hand well objects using same distance function yields error rate other techniques
consider efficient algorithms learning class learning model ie prior assumptions distribution resulting problem finding best over input sample approximate within constant factor suggest way theoretical bound new measure such algorithms algorithm margin ratio outputs good training points its prove computational results respect measure hand every positive efficient margin learning algorithms other hand prove algorithm time polynomial sample size margin
present novel method clustering using support vector approach data points high dimensional feature space support vectors used define them data space set containing data data points each defined cluster parameter gaussian kernel these fit data more algorithm clusters according probability distribution thus clusters take arbitrary other algorithms soft margin constant cluster bound structure data varying two investigate our method these parameters apply several data sets
goal statistical language modeling learn joint probability function sequences words difficult because dimensionality propose its proposed approach learns simultaneously distributed each word ie similarity between words along probability function word sequences these generalization obtained because sequence words has been high probability made words similar words report experiments using neural networks probability function showing two text proposed approach significantly model
variational mean theory presented theory applied belief networks further approximations empirical evaluation small scale networks show proposed approximations quite competitive
many processes expression memory brain constructed networks present small about noise stability analysis noise simple schemes stable than direct prediction well discussed
field demonstrated learning algorithm generate sparse code natural scenes complete family receptive fields similar those simple cells paper describes algorithm sparse code sequences images information about input algorithm trained natural video sequences representing movement particular particular similar receptive fields cells observed cortical visual areas furthermore contrast previous approaches learning direction timing neuronal activity phase movement so timing spikes important information suggested goal early sensory processing reduce sensory information activity sensory neurons independent features neural give into these neural nets may learn training neural network natural images pairwise correlation between neuronal responses results neurons receptive fields those neurons field demonstrated learning algorithm generate sparse code natural scenes while information about visual input complete family receptive fields similar those neurons coding signal presence basic components natural images field their algorithm sparse representation because higher degree statistical among its outputs similar receptive fields obtained training neural net so make responses neurons independent possible other have shown direction may unsupervised learning way receptive fields neurons movements paper describes algorithm sparse code sequences images critical information about input algorithm trained natural video images representing movements particular particular similar receptive fields cells observed early visual areas neurons signal presence moving certain certain each neuron its speed direction furthermore contrast previous approaches timing neural activity movements phase so timing spikes important information coding proposed algorithm extension proposed field high level algorithm cannot directly implemented neural network neural network similar task developed proposed algorithm described section show methods results simulations finally section algorithm previous approaches presented results proposed algorithm extension described field section
present novel way bounds generalization error learning algorithms explicitly using their stability properties stable learned solution does change much small changes training set bounds obtain do measure complexity hypothesis space eg dimension but rather learning algorithm space thus applied even dimension demonstrate regularization networks required stability property apply our method obtain new bounds their generalization performance
describe extension markov decision process model continuous time dimension state space allows representation exact solution wide range problems transitions over time problems based planning observation
detection involves modeling normal detection has potential applications many areas such detection features data approach hypothesis estimating support normal data ie function positive region data negative recently kernel methods have been proposed estimating support distribution they have performed well practice training involves solution quadratic programming problem per propose kernel method estimating support based linear programming method implement learn large datasets demonstrate method detection datasets
paper presents predictive gain technique reinforcement learning problems decomposition link control call used demonstrate technique control problem into online prediction call arrival rates policies call processes decision time predictions used among policies simulations show technique results faster learning without performance loss compared reinforcement learning controller does problem networks such transfer networks control network well objective quality while call level quality measured terms call probabilities key network call control two such control problems markov decision processes framework optimal model dynamics network computing control policies using dynamic programming control standard assumption such models according processes makes models dynamics relatively simple although assumption most networks number studies indicate many types al processes networks well local area networks self similar makes difficult find models dynamics models large complex number system states large application programming structure should possible design efficient control methods have previously presented method based td learning call yields higher than controller call arrival processes method convergence control policy paper presents alternative solution above problem called predictive gain control problem into two parts prediction call arrival rates set control policies call arrival processes decision time policy based these predictions thus arrival process process rate predictions made artificial neural networks trained online policies computed using dynamic programming other reinforcement learning techniques paper link control problem describe used optimal shown other recent work reinforcement learning includes et al show extend use td learning network et al apply reinforcement learning quality constraints traditional model network arrival processes have been demonstrated number studies eg indicate time distributions correlations arrival processes models have been shown better arrival process has natural length its arrival over many time scales makes variance its sample mean sample size its function time compared complexity control prediction reduced property process its expected future depends arrival but process other hand makes possible improve predictions process future statistical measure degree stochastic process parameter parameter takes values processes have parameter link control problem link capacity different classes such class have same call times distributed mean link policy maps states actions set link states action set call set link states given set call number product representations call arrival processes because memory arrival processes given number link assume call means reward rate time equal time discrete call arrival reward obtained state time next state time expectation reward expected time state under policy optimal actions policy probabilities state transitions so increase probability states high objective link control find policy average reward per stage note average reward does initial state state average reward zero example probability other state every state positive certain states special interest optimal policy these states set such states given set call number available multiple call states reward may future expected gain control theory technique parameters controller function conditions approach taken here up policies table predictions call arrival rates call arrival processes optimal policy link control does arrival processes due property constant arrival rates our gain control call arrival processes predicted self similar call arrival processes processes arrival processes based predicted function rbf per class trained predict its arrival rate solving link control problem call arrival processes dynamic programming solving problem paper policy iteration used involves two steps value policy improvement value step makes use objective function concept relative values difference between two relative values under policy expected difference reward over time state instead state paper relative values computed solving system linear equations method chosen its fast convergence dynamics system state transition probabilities given policy per class call arrival mean times policy improvement step consists finding action relative each state after policy value policy improve steps policy does change prediction over what future time should predict rates used policies work prediction set average estimated mean first times states back following mean time arrival process process within time choice prediction effects decision action state future probabilities other states state next time new made previous decision does future expected reward assumption mean time estimated call instead full state case call arrival processes mean first times other states state solution linear system equations probability state determined states solving linear system equations matrix containing state transition given mean time link defined average individual mean times states weighted their probabilities implementation time number call length class computed mean time arrival rate off although size prediction future call arrival rates prediction future arrival call rates based measures recent arrival rates work following representation arrival process used classes weighted times computed different time scales these vectors computed using factors values arrival time call class studies prediction nonlinear feedforward linear time series long memory rbf symmetric gaussian basis functions rbf units sum produce smooth output function locations rbf units determined data sets region vectors trained average time target after every new call arrival prediction error computed learning performed online using least mean rule means up call predicted arrival rates used control policy arrival call given prediction arrival rate linear search minimize prediction error sample performance gain controller simulated link capacity call arrival comparison simulations three other link two based controller us complete ie call free capacity link sufficient based td controller uses rbf per input each has hidden units units per call class activation unit its weights states td controller call arrival processes call number states value function table value per controller used evaluation performance loss call call synthetic generated gaussian moving average model results arrival process parameter easily generated containing pairs two call classes call times mean parameter used call arrival rates make expected arrival rates two classes ratio gain constant prediction used simulations computed according section resulting prediction size obtained table policies used gain computed predicted step size total policies two both hidden units weights numerical results both td learning gain controller first simulated call obtained four methods measured call call call arrival rate ratio initial weight neural weight neural weight based td controller call figure weight based performance figure shows weights call arrival rate class figure weights rbf corresponding call number these weights different class vectors activation weights gain rbf converge few call td learning controller about call converge rbf td learning up set training data so single much less than rate gain controller td learning trained moving due learning rule stochastic action selection policy few weights gain change even after long train these weights rbf units large inputs figure performance terms arrival rate ratio each data point gain same td learning rbf up compared td learning up better than complete difference between td learning complete low arrival rate increase high rate higher than loss low rate have presented predictive gain technique reinforcement learning problems link control network used demonstrate technique call arrival rates part full state policies call arrival processes computed state online convergence rate times compared controller full state input decomposition result performance loss computational complexity controller using predictive gain may computational size state space optimal policies policy iteration state relative value function combined temporal difference learning possible significantly reduce number relative value functions linear interpolation relative value functions algorithm use less than relative value functions without performance loss further have successfully gain link control network performance improve compared conventional methods larger than link control use gain reduce complexity reinforcement learning problems limited link control general technique should problems parts state used directly after among policies version original problem network dynamic programming optimal control modeling actions nature extended version nature network scaling computer sutton reinforcement learning
conventional nets hidden units generalize show nets capacity generalize well trained early experiments two overfitting significantly different regions model capacity allows better fit regions high often overfitting regions low size nets learn task similar sequence nets through similar those learned nets early training large net net show gradient generalization because regions low learning fit regions high
online algorithm training support vector machines vector time presented conditions previously training data number steps each computed analytically procedure efficient method evaluate generalization performance interpretation feature space relationship between generalization data
risk minimization principle between generative models methods derived risk principle such support vector machines statistical explain provides framework number existing algorithms such support vector machines regression constrained classifiers show approach new algorithm solving problems usually associated generative models new algorithms described pattern recognition problems different pattern distributions data empirical results presented
learning has recently novel interpretation synaptic plasticity depends relative timing synaptic spikes paper dependent learning rule basic principle mutual information maximization studies its experimentally observed plasticity supervised spike dependent learning rule similar structure experimentally observed plasticity mutual information stable near optimal level moreover analysis temporal structure time dependent learning rules determined temporal applied neurons over their inputs these results suggest experimental prediction learning rule neuronal parameters
high dimensional data modeling difficult because dimensionality propose technique called high dimensional density estimation dimensionality structures data recent statistics independent component analysis mixture models propose procedure each data first least dependent each density estimation than traditional kernel methods radial basis function methods efficient solution nonlinear independent component high dimensional
work made use so called world assumption about scene statistics scenes assumption such scenes grid image gradient statistics paper explore general assumption show large variety less including scenes us single image determine orientation relative scene structure target objects grid these performed using bayesian model probability distributions eg image gradient statistics real data
output coding general method solving problems them multiple binary classification problems previous search output coding has almost discrete codes describe algorithm performance output codes them continuous codes procedure optimization problem quadratic support vector machines describe experiments proposed algorithm standard discrete output codes experimental results indicate continuous output codes often improve generalization performance short codes
develop approach sparse representation gaussian process models order large data sets method based combination bayesian online al together sequential relevant data fully prediction model results examples large datasets indicate efficiency approach
competitive algorithms almost modeling pattern cortical development particular model development patterns competitive cortical free common
has been considered terms inference states belief networks show bayesian context inference about weights relationships such those between stimuli experiments such show weight space using extension kalman filter model new approximate way kalman gain matrix correlation matrix observation process suggest network implementation using architecture due show resulting model
structure set images most difficult problem between measurements most existing approaches assume features across methods constraints matching do so under motion paper propose bayesian approach associated out best instead consider distribution over possible both fully bayesian approach yields posterior distribution map approach makes use em posterior show markov chain monte carlo methods used implement these techniques practice present experimental results real data
nearest neighbor classification locally constant class probabilities assumption high dimensions finite samples due dimensionality bias introduced under these conditions using nearest neighbor rule propose locally adaptive nearest neighbor classification method minimize bias use distance analysis compute metric along less relevant feature dimensions along most result class conditional probabilities better classification performance achieved our method compared against other techniques using variety real world data
recent work has data unsupervised learning new types generative model data recently shown generative model non negative distribution gaussian distribution model constrained first second order statistics data learning practical problems made difficult need compute under model distribution cost markov chain monte carlo methods low mean field techniques has interest mean field variational methods here present second order approximation machine model obtained using theory tested learning dimensional model invariant distribution generative model hand
prior knowledge particular task into architecture learning algorithm improve generalization performance study here case function learned two its convex them propose class functions similar neural networks but has those properties continuous functions these other properties apply new class functions task modeling call experiments show call using new types function classes
problem learning probabilistic models presence variables these variables observed yet several observed variables such they complex de among recent much attention has been development algorithms learning parameters cases structure presence hidden variables per address related problem hidden variables observed variables problem interest both our understanding domain step learning procedure models natural approach search hidden variables learned network suggest presence hidden variable make basic idea show algorithms evaluate method several synthetic datasets show performs well
many neural systems extend their dynamic range adaptation adaptation context stimuli demonstrate visual system adaptation statistical ensemble stimulus information about stimulus further while rate response has long adaptation takes consistent optimal variance estimation
complex auditory visual information often using other analysis even low level including accurate statistical models signals their rates previous approaches simple parametric models joint distribution while cannot capture signal relationships learn joint distribution visual auditory signals using approach first data into density estimation model stochastic between signals using density estimator these learned allow processing across signal demonstrate synthetic real signals video face particular speaker video
way approximate inference connected graphical models apply sum product algorithm probability propagation algorithm while fact graph has sum product algorithm directly applied gaussian networks graphs coding but many conditional probability functions including function direct application sum product algorithm possible introduce networks have low local complexity but exponential global complexity so sum product algorithm directly applied network probability given its computed inputs markov chain more generally tree after inference learning networks give results problem problem image
important class problems inference bayesian networks binary state each variable noisy states variables example presence noisy may may inference connected noisy networks but approximate methods eg variational techniques showing practical solutions problem most approximations they relatively small number true posterior other hidden variables introduce new sequential variational method networks including true posterior models posterior distribution tree compare method other approximations using ensemble networks network statistics network variational approximations approximate algorithms probabilistic inference now even being into vlsi hardware approximate methods include variational techniques et al et al local probability propagation markov chain monte carlo many algorithms have been proposed each these classes problem most above algorithms relatively small number target distribution distribution being case markov chain monte carlo methods usually sample but may take long time even transitions figure approximate mean variance gaussian result minimizing most variational methods result minimizing used results local probability propagation connected networks show able between et al but other results show between et al most variational techniques minimize cost function single most less target distribution eg et al more variational techniques capture multiple using part original network although these methods increase number they still variational techniques approximate target distribution using distribution bound example may distribution current set observed parameters distributions make close possible common approach variational inference minimize relative entropy log often respect parameters using iterative optimization even exact optimization see minimizing may target distribution gaussian region density between two shown fig minimize respect mean variance two fig assume because region has density contrast minimize respect mean variance region see fig many problems including more important our approximation include than cost other leads low number may lead large number present figure bayesian network observed hidden noisy networks fig shows noisy bayesian network binary hidden variables binary observed variables present results active active joint distribution case form independent although do other form considered representation problem et al likelihood takes noisy form probability product probabilities each active probability active probability probability active active exact inference distribution over given subset observed values observed corresponding likelihood node may give new network describes distribution over variables so assume variables observed variables so variables active variables posterior distribution taken together two terms right take simple product form over variables so step inference dependent given present variables constant have been have term left does have product form expression out give sum product exact inference performed results exact inference each product exponential time complexity makes large problems such sequential inference using variational trees described above many variational methods minimize approximations posterior distribution present method observation time so posterior approximate posterior distribution tree trees equivalent use representation each variable has most algorithm active time new tree tree sense product previous tree likelihood next search performed time using probability propagation two previous tree compute weights new tree applying minimum weight tree algorithm tree approximation obtained after take tree variables has equal obtained described above tree previous step current prior over use likelihood next obtain new estimate posterior tree new tree new tree function conditional probability found minimizing log have log log log log given structure function optimal conditional probability constant table easily computed using probability propagation two trees compute two optimal conditional probability table variable independent relationships network so current compute optimal conditional probability possible relationships time using probability propagation use minimum weight tree algorithm search best tree have been use tree distribution make about given order generally quality resulting tree but used random experiments reported results type networks using parameter statistics network given et al simulated type networks each networks each active number active small compare our approximate method exact method two other approximate inference methods local probability propagation et al variational upper bound important question many most under approximate posterior most under exact posterior found exact inference algorithm give approximate algorithm most give each networks each inference method values each value left fig shows average active sequential tree method optimal cases right shows work number approximate methods positive exact tree positive tree positive exact tree positive tree positive exact tree positive tree figure number most under approximate posterior most under exact posterior found approximate methods include sequential tree method presented paper tree local probability propagation variational upper bound noisy networks used model variety problems including exact inference large connected noisy networks most approximate inference algorithms small number most hidden variables under posterior presented variational method noisy networks including cost including method tree posterior distribution ie observation time results ensemble type networks show method performs better than local probability propagation variational upper bound most about work independent factor analysis neural computation algorithm construct minimum tree network research new points product algorithm information theory special codes graphs iterative algorithms graphical models machine learning digital scenes probabilities through into models computer vision pattern recognition computer variational learning non linear gaussian belief networks neural computation low density codes hidden markov models machine learning inference algorithm multiple uncertainty variational probabilistic inference network research
new form covariance gaussian mixture models hidden markov models presented extension efficient form covariance used speech recognition variance matrices standard form covariance matrices covariance matrix into highly covariance matrix use presented paper number possible without number free parameters maximum likelihood estimation schemes model parameters presented including component parameters new model form large speech recognition task shown using form covariance word error rate
new learning algorithm described margin norm set data our algorithm called approximate large algorithm norm takes rate data margin larger than margin data bound quadratic programming implement fast online algorithms such perceptron report experiments two algorithms perceptron our algorithm perform quite better than both accuracy levels achieved those obtained support vector machines other hand quite faster implement than standard training algorithms
variational approximations bayesian learning graphical models provide theoretical results variational updates general family exponential graphical models show belief propagation tree algorithms used inference step variational bayesian learning applying these results bayesian analysis linear gaussian state space models obtain learning procedure kalman propagation while over model parameters demonstrate used hidden state dimensionality state space model variety synthetic problems real high dimensional data set
many algorithms approximate reinforcement learning known converge fact showing weights algorithms may within region rather than point paper shows two algorithms such weights cannot but instead converge region algorithms algorithm used well known td
present algorithm samples hypothesis space kernel given prior over weight vectors likelihood based model label noise leads constant posterior kernel markov chain monte carlo method random direction parameter space samples resulting constant density along line chosen used bayesian bayes point machines active learning evidence based model selection small data sets label noise simple example demonstrate experimentally bayes point machine based svm into account label noise
present improvement perceptron convergence theorem bound margin dependent allows us give error bound learned perceptron learning algorithm bound value depends margin support vector machine would achieve same data set using same kernel bound yields better than available support vector solution
present efficient algorithms problems problems statistical learning focus examples including classification kernel density estimation detection correlation these include problem requires comparison each points each other point would solved using distance practice often large make present new techniques principle computation including mixtures rbf neural networks hmms our algorithms exhibit asymptotic scaling several faster than computation even small datasets exact algorithms these problems more either addition our framework yields simple algorithms two important standard problems more difficult these represented our examples multiple correlation correlation
techniques visual representations machine vision tasks particular compare principal component independent component analysis combination regression methods variable selection found local methods based statistics image global methods based statistics images result consistent previous work expression recognition addition use regression technique variables regions interest performance
computational neural feedback circuits important problem theoretical study symmetric threshold linear networks derive stability results theory energy functions applying linear analysis neurons determine stability potential states stability depends two types type global stability other type whether possible prove our stability taken quadratic programming show sets neurons state sets cannot sets sense sets sets sets synaptic connections provide formulation memory more general than traditional point networks function used prove given set equations example neural network function almost initial condition outputs neurons converge stable state stability property used construct networks patterns theory symmetric networks neurons have activation functions here show activation functions threshold linear but new into computational behavior recurrent networks see present three main about neural responses constant inputs theorem provides necessary conditions synaptic weight matrix stable set points these conditions terms concept quadratic programming linear theory they terms certain synaptic weight matrix making connection linear systems theory theorem network produce state response constant input response computational output network its second second theorem introduce idea sets under certain conditions synaptic weight matrix show sets neurons recurrent synaptic connections being stable state what input applied other sets sense they input same conditions synaptic weight matrix lead conditional input more than stable state other words sets conditional sets suggests new way about memory neural networks input applied network set active neurons selection constrained sets therefore sets synaptic connections our theorem states constraints sets network learning algorithm used active neurons cannot into sets because sets have sets have basic de our theory network dynamics synaptic weight matrix symmetric dynamics more matrix vector form state network input network arbitrary vector output network state response outputs their relationship input determined synaptic weight matrix vector its components set vectors shown trajectory therefore consider initial conditions global asymptotic stability de state stable initial conditions close state trajectory close times state stable initial conditions close state trajectory set states stable almost initial conditions state trajectories converge states measure zero de principal matrix matrix constructed certain set corresponding following theorem necessary conditions global asymptotic stability theorem symmetric following conditions equivalent principal have positive matrix network has set states stable minimum over unit minimum value less than equal zero methods elements corresponding principal than equal function lower under network dynamics constant states stability theorem stable states stable language optimization theory network dynamics local minimum constraint principal than equal used construct trajectory dynamics these stability conditions best conditions linear network obtained linear network would have than asymptotic stability here able without bound due so their less than principal considered because sets feedback connections active set neurons above threshold linear network would have positive de asymptotic stability but because here condition condition conditions theorem global asymptotic stability but other hand states do next mapping input output vector input such state equation input de states vector point point stable such networks theorem single neuron active principal corresponding single active neuron elements according positive possible single neuron stable point following theorem vectors stable point sets following stable states based theorem theorem principal symmetric matrix between particular than de set neurons neurons stable state input other hand set neurons they cannot stable state what input might have de set set corresponding matrix has positive set could de set least non positive theorem matrix corresponding non positive sets have have both positive non positive components theorem matrix following equivalent matrix positive de set network input such more than stable state positive de so stable state neurons active eg set neurons set active neurons without loss assume principal corresponding has positive non positive theorem fact elements positive subset true neurons neurons quadratic function de theorem de point point de positive its minimum but because neurons lower values either because non along trajectories way trajectories cross have constructed input network function convex so has single local minimum convex domain local minimum global minimum dynamics converge minimum positive de symmetric threshold linear network has state has been shown previously next theorem result equivalent condition using concept sets theorem symmetric following conditions equivalent matrix positive de sets state stable positive de theorem so theorem eg set so set neurons active sets see following theorem sets theorem subset set set according theorem symmetric matrix positive so its principal principal negative so original matrix example network symmetric threshold linear network local larger range has been studied model simple cells visual cortex obtain their orientation visual these results have recently circuit containing network using analog vlsi have neurons network because active sets more than number neurons here give more account fact provide result about sets synaptic matrix neuron network invariant connection between neurons given global self neighbor second neighbor figure have computed sets network parameters taken eg sets determined matrices corresponding figure shows resulting sets those have consistent such networks explain contrast invariant cells response modulation cells found sets more than active neurons many non sets could principle neurons neurons because activation sets requires highly input high spatial frequency presence sets relevant normal network inputs typically such inputs visual cortex set number neuron number neuron number figure left output network neurons input random initial condition right sets neuron number set number means neurons set means does left right symmetric sets shown have been set output left have shown pattern threshold linear networks terms sets neurons eg sets neurons state according de synaptic weights inputs concept memory does input would case de memory based points dynamics pattern retrieval constrained input input allow retrieval arbitrary sets fact dependent sets but input theorem example network positive input sets neurons but sets figure generally network possible more than single neuron threshold linear networks traditional networks inputs represented initial conditions dynamics example network input sets determine stable points thus case sets point hierarchical sets theorem point per hierarchical de set fact set have subset constraint possible symmetric networks constraint does have being constraint may lead understanding learning algorithms representations constraint problems they solve problems backpropagation similar way problems do natural symmetric networks might
system has been developed information data support vector machines applied detection provide measure shape learning representation describe novel method support vector machines including information second class detection give results analysis
concept over bayesian analysis learning based has recently been demonstrated linear version space set consistent training set known bayes point algorithm presented small sample size because requires memory computational steps number training patterns number random posterior distribution paper present method based simple perceptron learning algorithm allows method simple easily extended multi class case present experimental results data set show bayes point machines competitive current world support vector machine addition computational complexity varying number samples posterior finally test points basis their posterior probability leads error eg error given rate
present bound error linear terms margin training set result obtained framework based space linear new bound exponential improvement so far margin bound et al scales inverse margin even case less training examples than input dimensions large lead non bound values maximum complexity term furthermore classical margin measure error ratio between whole hypothesis space subset consistent practical relevance result fact well known support vector machine optimal new bound feature vectors same length use feature vectors well our numerical experiments two data sets
key reinforcement learning scaling up large observable domains paper show used among variable length short term appropriate task higher levels agent over lower level back over variable number high level time idea framework called hierarchical memory uses memory based learning method reward across long decision sequences describe experimental study memory using framework task
goal many unsupervised learning two probability distributions into generative models such gaussian mixtures machines models such ica propose novel sample based error measure these classes models even maximum likelihood probability density estimation based cannot applied eg models nonlinear have furthermore our sample based error measure density function prove model our approach correct solution number samples expected solution our approach generative framework solution finally evaluate our approach via simulations linear nonlinear models mixture ica problems experiments show our approach
propose general bayesian framework independent component analysis ica ensemble learning response theory known statistical apply both discrete continuous sources continuous source case studied approach case linear response theory gives improved estimate efficient examples given sources without temporal correlations extended temporal correlations finally framework simple way generating new ica algorithms without define prior distribution sources explicitly
statistical learning its applications include em algorithm bayesian estimation bayesian inference simple lower bounds such latent per like maximization quite often ie learning upper bounds well derive prove efficient provides such variational upper bounds latent variable mixtures exponential family distributions thus wide range models discuss applications upper bounds including maximum conditional likelihood large margin models conditional bayesian inference convergence efficiency prediction results shown
learning complex task significantly agent learn between various abstract actions each solving task paper study hierarchical learning using framework take full advantage structure should perform state scale larger tasks state should algorithm automatically representations state feature space resulting algorithm using simple hierarchical task results suggest state approach making hierarchical learning systems more effective
data support temporal difference td model neuron activity cells provide global error signal reinforcement learning certain activity under td model stimuli address these cells information about including et additional role terms effects computational role
paper derive second order mean field theory graphical probability models using information shown function method direct approximation machines numerical example shown method first order mean field class graphical models single graphs second order method has complexity first order method belief networks method shown fast effective
paper develop method generalization error classifier terms its margin distribution introduced recent theory gaussian empirical processes allow us prove margin type most general functional classes complexity class being measured via so called gaussian complexity simple application our results obtain bounds generalization error improve results generalization error neural networks terms weights neurons furthermore under additional assumptions complexity class provide bounds case boosting improve results
result expectation error expectation ratio number support vectors number training examples extended class kernel machines class includes support vector soft margin classification regression regularization networks variety kernels cost functions show key result classification error margin error defined positive cost particular show true margin error empirical margin error equal sparse solutions kernel machines possible cost function
form filtering has been successfully used highly constrained active video sequences highly eg tracking hand computationally successfully approximate show algorithm used update set representing distribution over each video sequence compare method using video sequence requires highly show new algorithm performs better algorithm discuss method into active framework used shape
matrix has previously been shown useful decomposition data two different multi algorithms they factor used update rules algorithm shown minimize conventional least error while other generalized convergence both algorithms using used convergence expectation maximization algorithm algorithms gradient descent factor chosen convergence
introduce total length complexity measure circuit complexity sensory processing biological neural systems new complexity measure applied set basic computational problems need solved circuits sensory process exhibit new circuit design these new functions implemented within complexity bounds particular linear almost linear total length
present method bound function machine neural network order polynomial direct extension mean field bound first order show order bound better than mean field show bound belief networks numerical experiments error reduction factor two easily region based approximations useful
stimulus presented different retina visual tasks even those require many perceptual learning tasks show per inference discrimination face variance has different quality inference about fixed position stimuli particular quadratic rather than discrimination show advantage into account has discrimination suggest role recurrent area superior discrimination recurrent network propose learning feedforward recurrent neural connections these tasks fast components learning observed perceptual learning tasks
introduce novel kernel two text kernel product feature space length text weighted factor their full length text those close direct feature vector would amount computation even values dimension feature space paper describes fact product efficiently dynamic programming technique experimental comparison performance kernel compared word feature space kernel made showing results
paper presents novel technique constrained independent component analysis introduce constraints into classical ica solve constrained optimization problem using methods paper shows used order independent components manner matrix signal separation procedure experiments demonstrate use independent components while processes independent component analysis constrained independent component analysis constrained optimization methods
based statistical approach develop method computing average case learning curves gaussian process regression models approximation well large sample size limit arbitrary dimensionality input space explain approximation improved similar techniques applied general likelihood models
active set strategy applied simple standard quadratic linear support vector machine application fast new algorithm consists solving finite number linear equations typically large dimensionality equal number points making novel use much matrix order input space each step thus problem dimensional input space points required positive symmetric matrices size total time ii algorithm requires quadratic linear programming code but linear equation available
problem boosting algorithms studied present algorithm linear achieve error better than random distribution data while useful learning general show under conditions distribution yields dimensional problems simulations suggest similar behavior expected higher dimensions result recent theoretical bounds provide improved convergence rate bounds generalization error empirical error made small performance better than random
present new view image segmentation pairwise markov random study transition matrix interpretation shows spectral methods clustering segmentation have probabilistic particular prove method our framework finally framework provides method learning similarity function combination features
paper propose new based sequential sampling algorithm uses obtain distribution has two properties makes use available information have result algorithm standard other nonlinear methods experimental theoretical convergence algorithm algorithm includes markov chain monte carlo steps
investigate new kernel based classifier kernel programming formulation based average margin interesting original algorithm sparse find both proposed sparse probabilistic context furthermore show connections support vector machines relevance vector machines understanding able interesting kernel regression technique based upon algorithm simulations support use our approach
principal component analysis pca number principal components pca density estimation show use bayesian model selection true dimensionality data resulting estimate compute yet correct dimensionality given data estimate involves over difficult compute but after appropriate applying method rate practical estimator obtained simulations better than other proposed algorithms much faster
paper describes method steps steps based neural networks nonlinear least problems particular linear gradient method iterative algorithm solving normal equation algorithm takes steps without explicitly form matrix model our iterative algorithm reduce both memory space factor number comparison direct property useful problems
nonlinear support vector machines visual classification low resolution images face database performance shown superior traditional pattern classifiers linear quadratic linear well more techniques such radial basis function rbf classifiers large ensemble rbf networks furthermore svm performance error best result reported
paper new reinforcement learning explicitly takes into account input well errors use models quite both learning simulations online planning difference between model real environment lead often results based theory control consider differential agent make possible while control agent make best control input problem finding solution value function takes into account norm output norm derive online learning algorithms estimating value function best control value function tested call robust reinforcement learning task linear domain policy value learned online algorithms those derived analytically linear theory fully nonlinear up task control achieved robust performance against changes weight while standard control could such changes
paper framework recognition image sequences using observable stochastic equation models monte carlo sampling techniques used estimation sequence sequence likelihood network dynamics learned apply models sequence recognition tasks manner similar way hidden markov models hmms applied potential advantage over hmms use continuous state dynamics present results video sequence recognition task models provided performance compared hidden markov models
propose novel probabilistic framework video define probabilistic objects map features labels graphical network such scene text well between main novel application factor graph framework model network model between terms their well temporal between these within video using algorithm approximate exact inference these factor graph correct errors made during concept constraints results significant improvement detection performance
experimental data have shown synapses different synapses different sequences responses same spike train role synaptic dynamics role synaptic dynamics neural circuits well present methods make compute given known synaptic parameters spike train example sense sum responses our find most these spike common firing patterns specific types neurons discussed
experimental data show biological synapses quite synapses common artificial neural network models biological synapses dynamic ie their weight changes short time scale several input explore these synaptic dynamics computational power feedforward neural networks show gradient descent approximate given quadratic filter rather small neural system dynamic synapses compare our network model artificial neural net designed time series processing our numerical results theoretical analysis show even single hidden layer such networks approximate large large class nonlinear filters filters series result robust various changes model synaptic dynamics
work introduce parts model alternative hidden markov models hmms tested both models database online show hmms model have same average give results contrast hmms model modeling without increase computational complexity
show basis may best represent natural images terms sparse coefficients basis may either complete small number spatial functions across space combined so across scale these functions minimize estimated code length under model images linear sparse independent components natural images take different they orientation domain contrast standard used image basis set yields higher coding efficiency than standard
many approaches reinforcement learning neural net other parametric function form learning estimate value function markov decision process significant those resulting learning algorithms stable work present new approach reinforcement learning solution contrast existing algorithms our method shown consistent sense its converge optimal our focus learning framework practical optimal choice problem
present methods learning tracking human motion video estimate statistical model large set human motion data these data automatically into mean components computed using new algorithm missing information smooth between learned temporal model provides prior probability distribution over human used bayesian framework tracking human subjects complex video sequences their motion
present evidence several higher order statistical properties natural images signals stochastic model scale gaussian process discuss two interesting variety natural signals related through common model invariant random processes have property joint constructed dimensional second cases non assumption second order methods explicitly linear basis equivalent independent components obtained higher order methods demonstrated temporal components speech
representations key solving problems high level vision such face recognition coding present natural images basis their statistics have been account both properties early vision representations cortical processing here show codes derived natural objects such human but dimensionality show objects parts allows these codes have lower than sampling rates
present new algorithm solving support vector large training data sets new algorithm based iterative weighted least procedure used moreover novel sample selection strategy set presented randomly set among training samples do both optimization procedure sample selection strategy shown means computer experiments using well known data sets
study problem several different classifiers way provides inference constraints particular develop two general approaches structure first approach standard hmms allow use structure general classifiers model second extension constraint develop efficient combination algorithms under both study them experimentally context
bayesian gives other times large models perform well give simple examples both two complexity functions rather than used implement them analyze complexity functions linear parameter models equivalent gaussian processes find work
problem reinforcement learning large markov decision processes free energy product experts network network parameters learned online using algorithm pairs chosen based current value estimates current state sampling actions network using sampling algorithm tested task product experts model found perform small task perform well problem large representation
consider problem linear transformation features classifier such achieve minimum bayes error two first average between class second minimize bound range while both approaches similar performance practice they out perform standard features show relative improvement word error rate over features large speech recognition task
apply networks class learning rules synaptic weights change synaptic activity kernel spike time after resulting synaptic matrices have product form patterns represented complex vectors simple model even part response learned stimulus while part frequency our model cortex their associative input representations
problem neural coding sequences action spikes related sensory stimuli motor outputs question whether same coding rules used neurons corresponding neurons present formulation problem using information theory apply approach analysis experiments visual system individual structure code way temporal patterns spikes used information available spike rate other hand our ensemble exhibit high coding so every spike same amount information thus neural code has able mixture
method described like kernel support vector us generalize algorithms feature spaces usually related input space class kernels represented spaces out common kernel algorithms such kernel pca distance based algorithms class kernels well useful new into these algorithms work present work form basis new algorithms
many problems would natural reinforcement learning reward signal single value but has multiple examples such problems include multiple multiple single reward value multiple components information lead solutions describe multiple reward source problem discuss problems applying traditional learning present new algorithm finding solution results simulated
principle mutual information applied learning recurrent representations underlying model network input units larger number output units recurrent interactions limit zero noise network de mutual information related entropy output units entropy respect both forward connections well recurrent interactions results simple learning rules both sets parameters conventional independent components ica learning algorithm special case equal number output units recurrent application these new learning rules simple input example
present simple sparse technique approximate maximum estimate gaussian processes much improved scaling sample size particular computational cost prediction cost compute bounds show compute criterion give bounds approximation error show applications large scale problems
paper give necessary conditions under kernels product type condition thus may used support vector machines svm regularization networks gaussian processes particular show kernel ie series have give functional form feature map its
propose method approximate dynamic programming markov decision processes using decision produce value functions policies much lower time space than exact dynamic programming our method value functions generated during value iteration values values our method demonstrated class large up states compare results optimal value functions
control robot present novel vlsi chip relative similar pattern control chip time varying out small network characteristics output set input parameters between input parameters output computed analytically system practice true due off sets input parameters automatically system using unsupervised support vector learning algorithm introduced recently learning requires description desired output given machine learns labeled examples set parameters chip order obtain desired motor behavior
classification applications few available labeled examples examples improve performance present new algorithm examples classification achieved input vectors into feature vectors via both labeled examples resulting classification method kernel density estimate trained via em algorithm case both optimal solution provide addition formulation estimation problem maximum entropy framework demonstrate proposed requires few labeled examples high classification
analyze error probability direct sequence binary channel gaussian noise problem into problem analysis evaluate performance resulting include optimal map special cases approximate proposed using model approximation its performance analysis results per evaluation shows optimal compared conventional cases small information rate low noise level
novel noise scheme speech signals proposed based estimation local signal noise ratio frequency channels estimation input signal into so called amplitude modulation represent both spectral temporal characteristics analysis representation modulation higher auditory system neural network used patterns generated noisy speech estimates local noise achieved frequency channels according their noise algorithm recognition experiments compared noise spectral
describe unsupervised learning algorithm nonlinear generative model pairs face images same individual finding relative probability among pairs test image image whose known our method other methods generative model consists single layer nonlinear feature has property given data vector true posterior probability distribution over feature without iteration approximation weights feature learned correlations feature two network real data real data generated feature
use graphical models explore question learn causal relationships data two both estimating parameters fixed graph complete account causal should consider learn underlying causal graph structure propose model process bayesian inference our through three data sets
kernel principal component analysis pca nonlinear linear data analysis method kernel function de nonlinear transformation into feature space standard pca performed technique sparse components thus obtained terms kernels associated every training vector paper shows covariance matrix feature space reduced number example vectors using maximum likelihood approach may obtain highly sparse form kernel pca without loss
introduce new distance based clustering method method pairwise based method provide mean interpretation resulting clusters idea based distance matrix into markov process during process clusters structures using information method these clusters capture information about initial point most effective way method cluster data other bias makes assumption about underlying distribution
bayesian networks graphical representations probability distributions work learning these networks assumption presented data set randomly generated underlying distribution many have option active learning have sampling process certain types samples paper problem estimating parameters bayesian networks active learning setting provide theoretical framework problem algorithm active learning generate based model learned so far present experimental results showing our active learning algorithm significantly reduce need training data many
introduce mixture gaussian processes model useful applications optimal map input dependent derived mixture experts model used modeling general conditional probability discuss gaussian processes particular form gaussian process classification support vector machine model used graphical models
prior knowledge about video structure used both means improve performance analysis features allow classification introduce statistical models two important components structure activity demonstrate these models bayesian formulation segmentation problem new shown extend standard methods adaptive way improved segmentation accuracy
analyze codes simple model important between method probability algorithm find phase transition theoretical explain practical code performance terms
has been shown receptive fields simple cells optimal provided constraint finding suggests dependent optimal representation work used model noise here show more noise model neurons processes used does have constraint thus feature has but result optimal
present trees algorithm iterative technique estimation gaussian processes defined arbitrary graphs solving series problems trees conditional means efficiency better than other techniques other trees algorithm exact error error covariance computation most efficient graphs small number em tree context demonstrate sparse graphs provide significant increase modeling power trees increase estimation complexity
learning theory hierarchical learning machines such neural networks gaussian mixtures asymptotic does matrices paper form stochastic complexity based two problems studied prior positive stochastic complexity far than resulting generalization error than statistical models even true distribution parametric model prior free equal zero stochastic complexity has same form useful model selection but generalization
introduce method feature selection support vector machines method based upon finding those features minimize bounds error search efficiently performed via gradient descent resulting algorithms shown superior standard feature selection algorithms both data problems face recognition detection data
paper show kernel pca algorithm et al form metric scaling kernel function ie depends leads metric algorithm desired points found via solution rather than through iterative optimization objective function question kernel choice discussed
using statistical results learning curves average generalization error gaussian processes bayesian neural networks used regression applying results learning defined network directly compare bayesian learning find general requires training examples learn input features order input dimension learn task order number weights training examples considered results show even bayesian approach important limit complexity learning machine theoretical simulations learning mean field algorithm
introduce processing error codes image information stage using improve performance both mean analysis using method simulations show has advantage being robust against estimation
belief propagation work networks but well many applications networks including codes has been understanding algorithm nature solutions general graphs show converge point approximate free energy known free energy result makes connections variational approaches approximate inference more our analysis us made statistical approximation introduced have shown construct more free energy approximations approximation our analysis de generalized belief propagation these approximations these new algorithms significantly more accurate than complexity illustrate such new algorithm grid markov network show gives much more accurate probabilities than those found using
theory update has certain advantages over perceptron update many recently has been much perceptron using regularization class linear classification methods called support vector machines possible apply regularization idea algorithm gives call show resulting methods compare basic similar way support vector machine perceptron investigate learning properties derived methods experimental results provided illustrate different methods
large margin linear classification methods have been successfully many applications problem known under appropriate assumptions expected error computed optimal approaches zero rate inverse training sample size rate usually margin maximum norm input data paper another data distribution important role convergence behavior expected error based concept show large margin linear classification problem expected error may converge number training sample size
describe computer system provides bayesian network joint distribution times two parts through layer hidden variables network first using information network trained capture phase during learned distribution network combined analysis performed hidden markov model generate available sources knowledge provided
paper presents system automatically generating based more user uses gaussian process regression learn user function over function takes inputs paper further kernel method learning gaussian process kernel distribution functions learned function learns kernel large set learned kernel shown more effective than kernel
paper neural network architecture system similar approach scheme across various while simultaneously specific constraints optimization algorithm feedforward neural network underlying expected based error neural networks model error input evaluate their optimization implemented such constraints ii risk demonstrate our approach across different out our approach superior
number computing eg digital important many applications data structure example paper explore question optimal strategy such probabilistic models represent data structures model user objective functions respect demonstrate using two real world data sets user obtain more up information using our approach
introduce new type map space large text propose based space constant negative gaussian size point space provides more map complex information space language into spatial describe experiments showing successfully applied text tasks yields results other methods
present probabilistic generative model timing performance structure proposed model equivalent state space model two well known recognition problems tracking maximum map state estimation tasks out using sequential monte carlo techniques have derived novel algorithm subset hidden variables out resulting model tracking useful number applications such adaptive
investigate following data problem computational large data set find those target few iterations biological possible each iteration small target apply active learning techniques selection strategy examples maximum margin another many weight vectors over multiple data each weight vector its prediction examples prediction most between strategy note each example version space consistent weight vectors estimate both through version space labeled examples most even version space demonstrate two data sets provided three selection perform well much better than random
inputs out policy directly best policy depends current state current patterns problem because state space possible transitions set actions size present reinforcement learning formulation problem value function into many small value functions efficient action selection
estimating parameters sparse distributions important component many statistical learning tasks recent approaches have used uncertainty over distribution means present bayesian approach allows prior knowledge form small set approximate used improve resulting estimates demonstrate these applications text estimating distributions over words data
estimating data regression problem several large number variables many discrete shape noise distribution large few large values compare several machine learning methods estimating test them large data policies function approximation methods do loss like support vector machines regression do work well context compared methods include decision trees generalized linear models best results obtained mixture experts better least most allows reduce more most
report use reinforcement learning agent online our initial work et al provided ability statistics report them here describe application take actions complex environment behavior multiple sources human reward after training reward different learned number behavior based current state here describe state action spaces report statistical results learning experiment
algorithm used search results search into account link structure number times random would following equal probability propose improve using more probabilistic model relevance query efficient our algorithm query time made possible computing time thus terms experiments two large indicate our algorithm significantly quality while efficient used large search
present efficient planning algorithm dynamic systems feature our method between but derived directly system dynamics function approximation architecture view system single large markov decision process assume represented way using dynamic bayesian net work action space resulting joint action space set our approach based use linear value functions approximation joint value function value function allows their actions using natural scheme provide simple efficient method computing such approximate value function solving single linear whose size determined interaction between value function structure exponential state action space show our approach approaches based reward show our algorithm efficient more algorithms even single agent case
consider use two control methods reduce variance performance gradient estimates reinforcement learn problems first approach consider method function current state value estimate performance these methods use variance estimates based data derive function variance show sum optimal variance weighted distance optimal show used average value reward difference between reward its expectation second approach consider method uses approximate value function give bounds expected error its estimates show minimizing distance true value function general provide example true value function gives estimate positive variance but value function gives estimate zero variance our bounds suggest algorithms estimate gradient performance value functions present illustrate performance simple control problem
complex decision making problem world markov decision process whose representation designed process include time cost amount memory computational time policy value function representation about making best use available address problem estimating highly order improve expected performance resulting policy possible application reinforcement learning real world highly detection those areas state space need order improve policy another application approximation continuous state space stochastic control problems using adaptive techniques highly grid points high dimensionality these two problems under common framework given belief state over possible new thus uncertainty parameters transition probabilities most increase expected performance new policy do so use sampling techniques estimating each parameters probability distribution function expected loss using approximate policy such optimal policy most instead true but unknown policy
show convergence two deterministic used learning values large initial values policy respect values show setting initial value large optimal policy second new novel algorithm learning values actions taken show learning limit optimal policy our learning algorithm learning
paper presents reinforcement learning long short term memory recurrent neural network using advantage learning solve tasks relevant demonstrated task well difficult task
consider problem learning multiple dynamic unknown addition environment may varying elements related actions other nature problem stochastic markov between learning agent arbitrary reward function objective learning agent have its average reward vector given target set algorithm task based theory stochastic algorithm appropriate way finite set standard learning conditions given convergence learning algorithm general target set these results markov decision problem discussed well
address problem non convergence online reinforcement learning algorithms eg learning approach process function process our fit best algorithm between phase during trajectories generated optimal policy function phase during function best known states states advantage approach value function global process allows address function approximation cannot local online algorithms approach their algorithms show improve upon their work applying better process function procedure error advantage error measures into objective function results show improved performance several problems
address two theoretical policy gradient learning first using function represent state action value function theory showing linear function approximation representations rate convergence performance gradient estimates factor relative function approximation used number possible actions number basis functions function approximation representation use bias term estimating state action value function theory presented showing bias term improve rate convergence performance gradient estimates number possible actions evidence presented showing these theoretical results lead significant improvement convergence properties policy reinforcement learning algorithms
present three ways linear programming kernel value function approximations reinforcement learning formulation based svm regression second based equation good have advantage over minimize number support vectors while data experiments synthetic problem show three give performance but advantage formulation much train policy gradient methods kernel methods described here easily complexity function complexity value function
provide natural gradient method descent direction based underlying structure parameter space although gradient methods cannot make large changes values parameters show natural gradient moving optimal action rather than better action these optimal actions those would chosen under improvement step policy iteration approximate value functions sutton et al show performance simple more
propose new approach reinforcement learning least function approximation policy iteration our method off policy least temporal difference learning algorithm known its efficient use sample compared temporal difference algorithms prediction problems has application control problems moreover approximations learned distribution over states our new algorithm least policy iteration these result method use data source have tested several problems including learns goal efficiently relatively small number random
present simple approach computing policies markov decision processes optimal value function linear form our method based solving single linear best linear optimal value function applying constraint procedure obtain iterative solution method linear direct linear programming approach experimentally yields significant reduction computation time over approximate policy iteration methods several few quality solutions produced linear programming about approximation error same class speed advantage allows use larger approximation classes achieve similar error time
propose new classification learning algorithms each both their possible possible using classification algorithms including case propose improvement existing algorithms achieve average least long against
standard reinforcement learning view systems includes rather prediction sum future reward between actions based characteristics their states sense experiments into shows view many cases choice between many different actions given state but rather whether single response evidence suggests process underlying choice has neural properties underlying action choice describe model these systems consider way they
paper explore two approaches linear model based networks empirical data study fit models compared approaches other metric approaches future
present neural network model shows cortex sequence information activation based memory ie function may arbitrary information necessary tasks power language arbitrary information our model takes advantage class nature allows neural representations possible each sequential position make work suggest provide region update signal appropriate sequential coding demonstrate arbitrary novel sequences mechanism show model generalize novel sequences after training
computational modeling fully higher level domains such language processing methods developed construct representations used such models paper propose use clustering means binary representations objects using similarity data existing methods unsupervised learning clustering models do scale well large present new algorithm clustering based novel technique optimization algorithm than previous makes empirical both human synthetic data suggest more effective than previous methods scales better larger problems making clustering practical take significant step scaling connectionist models examples
unsupervised learning algorithms have been derived several statistical models but their computational complexity makes applying them large data sets paper presents probabilistic model much than conventional models but em training algorithm model based upon ie relationships between pairs words present results experiments model its ability generalize data its ability structure large text
temporal coding hypothesis suggests related temporal patterns stimuli into single memory representations concept using bayes estimation update parameters constrained hidden markov model approach allows us account temporal second order experiments et al other models explain
theory presented knowledge causal relationships between category features represented bayesian network theory theory objects category they have been produced category causal model view have models world lead them certain distribution features category eg correlations between feature pairs directly connected causal relationships consider good category they those these include feature interactions causal relationships research has problem learning new given observations category contrast view prior theoretical knowledge often their representations contrast models effects empirical observations have been few models developed account effects prior knowledge present model theory according knowledge many includes features but representation causal mechanisms link features many apply problem objects category standard view objects category they have features have often been observed category example object has most features eg trees few features other view models classification function similarity ie number features between representation category object models feature category independent presence other features contrast category theoretical knowledge features make category example have trees because they knowledge yet still trees might considered less than eg even has features whether knowledge fact feature make good category following experiment novel whose four binary features either figure category feature described three other features feature described being three represent causal knowledge such figure bayesian network nodes variables representing binary category features causal relationships representing presence probabilistic causal mechanisms between features feature present causal mechanism probability about presence effect feature allow effect features have potential explicitly represented network represented parameter probability effect present even its network finally each node has parameter probability feature present correlations correlations figure figure prediction object considered category its features have been generated causal mechanisms example table presents causal models figure generate possible each likelihood equation derived application simple example probability present being generated model probability present times probability about its times probability about its times probability about its probability present being generated model probability present times probability times probability about its note these assume causal mechanisms each model same probability other applications theoretical knowledge leads them certain distribution features category they use information category thus gain into performance predicted statistical properties category features generated causal model example figure represent features correlations generated causal figure would pairs features directly causal relationships correlated correlated its effects correlated its thus features evidence category they these expected correlations ie both effect present both against category they those correlations present other table equations observed predicted values common common effect control likelihood observed predicted likelihood observed predicted observed note causal networks predict pairwise correlations between directly connected features figure result causal relationships important between although three effects correlated more than directly connected features does three correlated between has been focus use these following experiment test whether sensitive pattern correlations between features causal those due causal relationships shown figure moreover show exhibit interactions among features than pairwise interactions shown figure method novel used description causal relationships between features effect feature two mechanism causal relationship example novel described four binary features eg high response causal relationships among those features eg high response signal because amount first studied several computer information about their category their first presented category four features condition causal relationships condition relationships test tested them knowledge they studied required test they errors performed classification task they scale category possible objects four binary features example those learn category high normal response normal weight order test each experiment they randomly equal three conditions experimental test over control conditions presented table presence causal knowledge large effect instance given lower conditions than control condition because these correlations effect features present even their contrast significantly higher conditions than control condition because both conditions correlations causal interactions between features multiple regression each four variables feature present additional variables interaction between pairs features those feature pairs connected causal relationship interaction terms represent whether causal relationship effect both present both present finally four interactions single interaction regression weights over presented figure function causal condition figure interaction terms corresponding those feature pairs causal relationships significantly positive weights both condition condition predicted figure better category expected correlations effect feature either both present both those correlations other present feature weight regression term common control predict predict control predicted control observed observed feature weight regression term common effect control predict predict control control predicted control observed observed figure addition shown figure because their three effect features correlated more than features consistent prediction condition three interaction terms between effect features than those interactions control condition contrast does three features correlated fact condition interactions between those control condition figure figure interactions among features condition weights interaction terms significantly different those control condition these interactions because requires feature explain presence common effect presents condition those test common effect present function number features present more
present model relationship information spatial domain eg above uses representations instead more temporal mechanisms temporal representations both efficiency ie units required ie resulting representations specific thus do support generalization novel these show our model uses far hidden units than number represented us distributed representations each unit has curve through space generalization novel inputs
hand human movements sequences several called movement units suggests system might efficiently control motor presence noise feedback delay another critical observation stochastic motor control problem makes optimal control policy different optimal control policy deterministic case use dynamic model address movements use reinforcement learning approximate optimal policy presence noise feedback delay using model show multiple optimal policy presence noise feedback delay optimal policy point close target fast apply few point into target region our simulations controller initial fast much like predictive observed number experiments
has been known after being generated knowledge able transfer knowledge inputs generated show second order recurrent neural network able transfer knowledge language generated finite state machine another language both representation knowledge network using linear analysis
data reward experiments shows property data time intervals into single curve data time called property timing here simple model neural presented shown give property model noisy linear spiking neurons analytically three parameters reinforcement learning procedure experiments both property pattern single
proposed human language human bayesian modeling process bayesian de trees paper extend model make further predictions about time given probability difference test model against time data experiment
partial information complete memory same time human memory information memory but context word memory present experiments demonstrate basic patterns human memory errors use cues word show short long cues more than length study factors lead behavior present novel computational model shows patterns errors human memory model between these together using markov model words allows memory simple feature set process compute probability distribution possible word manner similar models visual perceptual
describe multi chip vlsi neuronal system used spike based information processing models system consists retina chip whose neurons connected soft take architecture circuit multi neuron chip cortical neurons different computational properties connections set retina between different uses digital similar spikes neuronal system used multi chip spike based system orientation neurons using both feedforward model feedback model performance our analog hardware spiking model experimental observations digital simulations continuous neurons multi chip vlsi system has advantages over computer neuronal models real time computational time does scale size neuronal network
presented parallel product computation high dimensions efficient kernels image processing digital architecture analog array partial full digital resolution even random statistics analog binary random modulation scheme statistics even highly correlated inputs approach real image data experimental results analog array cmos
paper describes clustering algorithm vector using stochastic model new simple soft adaptation rule adaptation process same online clustering method random error evaluation process simulation results demonstrate new algorithm achieve efficient adaptation high neural algorithm reported most efficient clustering methods key random evaluation process each vector hardware process propose whose described circuit uses processes
experimental data has shown synaptic types biological neurons depends upon spike between spikes learning rules data have been proposed such learning rules analog vlsi implementation describe circuit weight spiking neuron according those learning rules test results circuit using cmos process given
learning curves gaussian process regression well model true data process derive approximations learning curves more case models find large input space dimensionality results exact learning curve transitions between exhibit many overfitting overfitting even estimates noise level lower dimensions learning curve dependent between even asymptotic limit large number training examples learn strong assumptions example standard radial basis function covariance function learn predictions simulations
study online learning domains using kernels feature equivalent using over basic demonstrate between computational efficiency these kernels computed generalization resulting classifier first describe several kernel functions capture either limited show these kernels used efficiently algorithm over exponential number prove using such kernels perceptron algorithm make exponential number even learning simple consider use kernel functions algorithm over feature space many while known upper bounds learn polynomial bound setting prove computationally behavior learning over such feature set thus such kernel functions efficiently
parameter space hierarchical models such information matrix does more classical model selection such cannot applied important study between generalization error training error present paper method these errors both maximum likelihood bayesian predictive distribution terms gaussian random fields using simple models
investigate generalization performance learning functional spaces introduce convergence estimated functional best underlying obtain estimate rate convergence estimate allows us derive generalization bounds learning
function machine above use bound means correlations networks small weights values these statistics regions ie subset experimental results show weight mean field generally give good results
report result analysis error belief propagation codes analysis based shows principal term error estimated full partial each takes single into account number code shown principal error term matrix code so sparse two than
paper show online algorithms classification used obtain good data dependent bounds their risk our results without they arbitrary online learning algorithms furthermore applied online algorithms our results bounds many cases better than best known bounds
propose method fast estimation large networks based linear response method empirical function simulation results show compared cross validation other techniques require matrix
derive between convex optimization problem showing difference between exponential loss used maximum likelihood exponential models requires model normal form conditional probability distribution over labels simple easily connection between two methods framework us derive new regularization boosting directly maximum likelihood experiments datasets support our theoretical give additional into relationship between boosting regression
recurrent neural networks analog units real functions study time complexity real general recurrent neural networks these have linear product units order nodes weights networks discrete time exhibit family functions high complexity derive almost bounds time required compute these functions thus evidence given computational analog recurrent neural networks
consider noisy problems random problems underlying structure sampling used compute average trajectories estimate underlying structure common procedure requires exact relationship between learning setting average trajectory used model construct solutions new same source experimental results show average trajectory fact estimate underlying structure over trajectory single instance
consider problem randomly sample points show these values estimated sum furthermore data into shown estimated random sample experiments presented theoretical results
give results about required complexity solve classification problems these results obtained kernel machines particular show decision trees normal special kernel risk margin derive number lower bounds required complexity using properties algorithms linear such perceptron learning
introduced its training have em work theory has been related useful algorithms here give new bound generalization error both use partial rules partial data use objective function our bounds apply case ie labels
give convergence analysis ensemble learning including eg regression algorithm regression these methods have common they call learning algorithm combined show these methods related method known numerical optimization state convergence results these methods our analysis includes norm cost functions general way ensemble learning
propose techniques up kernel principal component analysis three levels sampling matrix training kernel random kernel three cases give bounds accuracy obtained rather three techniques following idea kernel function kernel like expectation
introduce kernel measure similarity between two kernel functions between kernel target function degree between kernel given learning task has natural machine learning simple algorithms model selection learning its theoretical properties its expected value discuss its other standard measures performance finally describe algorithms obtained within framework experimental results showing kernel improve data test set improved accuracy approach provides method kernels
contrast standard statistical learning theory studies bounds expected error present framework learning algorithm used framework able training sample main previous approaches complexity measure rather than given hypothesis space necessary functions could have been learned using learning algorithm show resulting framework finally present application framework maximum margin algorithm linear results bound both margin distribution data feature space
study dynamics ica algorithm component gaussian back both online learning find large number examples required state close initial conditions signal least examples required data required signal
mutual information two random variables joint probabilities used learning bayesian nets well many other usually estimated empirical sampling frequency point estimate mutual information like consistent zero what probability true mutual information much larger than point estimate has point estimate bayesian framework these second order prior distribution prior information about prior compute posterior distribution mutual information derive approximations mean variance non mean give exact expression numerical range discussed
recent
cluster method class approximation methods containing approximations special cases derive two novel iteration schemes cluster method point iteration scheme gives improvement over mean methods graphical models other gradient based method converge shown give useful results random graphs methods practical value large inference problems
using methods statistical investigate role model complexity learning support vector machines show advantages using kernels complexity noisy target rules contrast common theoretical found achieve optimal generalization error although training error does converge generalization error moreover learning curves target rule but svm kernel
approach statistical approach analyze learning curves analytically apply method gaussian process regression main result derive between empirical error measures error posterior variance
belief propagation studied information belief network codes makes difficult obtain true belief characteristics algorithm its our study gives mechanism new framework analysis based framework basic properties
work introduce based term likelihood ratio classification method multiple classes under certain conditions term sufficient between true estimated likelihood ratio analyze gaussian case find new term classification results tested speech recognition tasks moreover addition term makes class therefore use several find further small obtained using find good measure classification confidence
important applying speech recognition ability variable length sequences paper presents standard scheme variable length data more useful mapping introduced based likelihood ratio space de mapping class conditional generative models directly into de space mapping appropriate schemes speaker independent task new mapping both hmms trained likelihood
units hidden layer feedforward neural network compute relative probability data point under two leads us consider other density models present architecture learning hidden markov models using network many small hmms experiments speech data show superior standard method training hmms
novel approach sequences observations using kernel demonstrated kernel derived using assumption sequence observations error training criterion use kernel classifier model size computation resulting model computation times our application computational advantages architecture based error train training using standard support vector machine gives accuracy significantly performance error training speaker recognition task
problem speech recognition speech signals highly noise approach noisy speech recognition automatically noise sequence speech previous work probability model trained speech probability model trained noise could combined estimating speech noisy speech iterative order vector series approximation could used probabilistic inference model many possible obtain examples noise without speech noise statistics may change during so estimating noise model paper show noise model learned even data speech particular noise model learned test used test approximate inference technique used approximate step generalized em algorithm learns parameters noise model test both data noise samples show new noise adaptive technique performs well better than non adaptive algorithm without need training set noise examples
model auditory described auditory attention key role model based upon correlation framework neural representing single perceptual representing other model suggests mechanism attention high low sequence addition perceptual complex
missing data approach speech recognition noise initial process spectral temporal regions speech source regions considered missing paper develop connectionist approach problem speech recognition missing data case using recurrent neural networks contrast methods based hidden markov models allow us make use time constraints make problems classification data missing values report results recognition task
applying unsupervised learning techniques like ica key question whether other words give error quality our separation use these show experimentally our proposed variance correlated error demonstrate estimation used appropriate separation performance most important components have application our approach
well known under noisy conditions speech much more suggests visual information task speech propose method visual cues speech separation under non noise single extend hmm based speech techniques signal noise models combined visual information novel signal hmms dynamics wide components model using simple approximate inference technique estimate signals mixture present evaluation approach using small visual database showing machine speech using visual information
present sequential monte carlo method applied noise robust speech recognition noise method set samples according prior distribution given speech models noise prior previous estimation model representing noise speech features used so extended kalman filter constructed each sample generating continuous state estimate estimation noise parameter likelihood each sample minimum mean error inference noise parameter out over these samples estimation samples their weights selection step step used improve experiments speech recognition simulated noise power highly noise experiments out observed method have recognition performance improvement over achieved noise noise assumption
cortical model motion depth complex cells visual cortex proposed model based time extension phase based techniques estimation consider computation total temporal time varying through combination responses energy units take into account model based cells resulting cortical units model show motion has been compared reported real cortical cells
combination suggest visual stimuli different patterns neural activity sensory areas brain but cannot measure such stimuli they would interesting two first could between stimuli used second difficult stimulus components measured neural activity top down components such those due stimuli stimulus without could measure activity here describe stimuli during stimulus classes class after change eye without changes images between these perceptual more sensory such
recent work has shown modeling clustering sets images objects similar these sets images object class show across individual eg images using representation based similarity because its particular components object representation detection object class those further model image set decomposition object class into component regions
present new simulation results computational model visual neurons simultaneously modulation spatial vision visual attention task human experiments new study our previous attention among early visual neurons within cortical hypothesis attention neurons two predictions increase gain attention while both have been observed single unit study has yet shown them simultaneously here explore whether our model could still predict our data attention might neuronal gain but do so non across neurons tasks investigate whether gain neurons best most about stimulus neurons but task dependent manner may account data these yields predictions hypothesis additional support our original
optimization pattern discrimination goal graph approaches often prior knowledge paper consider generative models labeled data spatial attention these constraints solution space condition constraints space smooth solutions method developed solve constrained demonstrate simple improve image segmentation results
nonlinear supervised learning model architecture described applied estimation human images consists several forward mapping functions inverse map function each function maps certain domains input space image features output space parameters key problems those learning domains mapping functions way well inference given inputs inverse function solutions these problems em algorithm conditional assumptions performance approach synthetic real video sequences human motion
locally linear nonlinear dimensionality reduction technique recently introduced data into study simultaneously data local each estimate upper bound dimension data set obtained automatically
paper new approach fast detection do distribution positive negative examples highly eg face detection database retrieval such domains simple classifiers each trained achieve high detection rates positive rates many able features including high detection rates low positive rates fast performance high detection rates rather than low error task typically machine learning al propose new mechanism training simple classifiers used experimental results domain face detection show training algorithm yields performance over conventional face detection system process per second over detection positive rate
most algorithms object detection require use spatial scale search such approaches object de means local features paper show including information object detection provides way down need search present results real images showing proposed scheme able predict object classes locations
describe neural network our work different previous work three important ways first like input provided our computation input second our network well defined function input based distribution random process even our computation implemented discrete network its output invariant continuous input pattern
describe algorithm automatically learning objects svm classifiers based image parts minimizing theoretical bounds error probability svm face classifiers combined second stage hierarchical svm classifier experimental results face classification show against depth suggest performance significantly better level than other face detection systems novel our approach algorithm learn classification experts their combination use models training maximum output each component classifier may relevant models visual recognition
describe factor probability distributions image features distributions images factor depends our choice features independent training image data illustrate factor parameters markov random field ie log linear probability models images learned data maximum likelihood estimation particular study models learn image distributions terms corresponding feature statistics entropy learning use our analysis factor determine features second show computed analytically factor demonstrate connection between approximation generalized iterative scaling algorithm due connection us use improve our approximation using approximations procedure support our analysis computer simulations
key question sensory stimuli such images studies response neurons early cortical areas propose scheme measures signal contrast uses instead local measures scheme structure signal represented set across regions paper focus representation strategy develop regularization approach image reconstruction measures demonstrate scheme signal structure present implementation computation uses local update rules results robust generalization ability local task pattern classification
paper presents unsupervised learning algorithm derive probabilistic structure parts object moving our examples automatically data part work based data ie training features include both useful parts between parts features unknown use graphs probabilistic parts but unsupervised technique limited type graph new approach data part taken hidden variables em applied algorithm developed parts search optimal structure based differential entropy these variables our algorithm demonstrated applying generate models human motion automatically real image sequences
investigate bayesian classical monte carlo methods bayesian monte carlo allows prior knowledge such into estimation simple problem show classical sampling method more computing statistical models functions model find bayesian monte carlo sampling although high dimensional problems problems may less advantage bayesian approach monte carlo samples distribution allows active design sample points so information gain
study parametric model information retrieval mean field methods applied analyze model derive efficient practical algorithms estimate parameters problem estimated fast approximate out cross validation procedure based method algorithm further several standard algorithms
many algorithms being given good metric over their inputs instance data often many ways clustering algorithm such means find user may user metric good clusters found these other applications good provide more way indicate what they consider similar instance may them provide examples paper present algorithm given examples similar desired pairs points learns distance metric over learning convex optimization problem allows us give efficient local free algorithms demonstrate learned used significantly improve clustering performance
paper consider multi class problems based generalized margin using output coding includes but standard multi class svm many previous approaches learn code well function illustrate lead formulation allows solving range problems instance many classes even missing classes our optimization problems propose algorithm capable solving them using classifiers similar boosting
prior knowledge form multiple sets each two introduced into linear support vector machine classifier resulting formulation leads linear solved efficiently real world examples demonstrate proposed method numerical results show improvement test set accuracy after prior knowledge into data based linear support vector machine classifiers experiment shows linear classifier based prior knowledge far direct application prior knowledge rules data use prior knowledge support vector machines linear programming
consider problem multi step prediction time series analysis using non parametric gaussian process model step discrete time non linear dynamic system performed step predictions state space model form prediction time per show using gaussian approximation uncertainty about values thus uncertainty current prediction based point estimates previous outputs
focus paper problem learning kernel empirical data kernel design problem accurate kernel simple less accurate kernels use boosting perform kernel process do so so kernel efficient simple kernels based generalized vector decomposition demonstrate our approach synthetic data performance perceptron algorithm learned kernels better than fixed rbf kernel
introduce family classifiers based system family called classifiers includes two best known support vector machines svm training example given location space classification function potential function training objective function energy framework provides novel interpretation existing algorithms their but suggests variety new methods including kernels between polynomial radial basis functions objective functions do require positive kernels regularization techniques allow optimal classifier space based framework propose novel perform simulation studies show they superior standard experiments include classification tasks data represented terms their pairwise classifier standard
paper algorithm relevance input variables support vector machines relevance measured scale factors input space metric feature selection performed zero weights variables metric automatically minimization standard svm empirical risk scale factors set parameters classifier feature selection achieved constraints scale factors resulting algorithm state feature selection its expression recognition problem
paper present new algorithm matching discrete objects such trees linear time thus dynamic programming quadratic time complexity furthermore prediction cost many cases reduced linear cost length sequence number support vectors improvement available algorithms makes kernels alternative
introduce generalized linear model statistical estimator features nonlinear regression factor analysis matrix into representation here low matrices while link functions include many useful models special cases including principal components analysis exponential family pca formulation independent components analysis linear regression generalized linear models they include new interesting special cases describe present iterative procedure parameters procedure well known algorithms special cases above other special cases new
propose framework data kernel based idea two points same cluster more have same label achieved kernel matrix experimental results approach
state networks novel approach recurrent neural network training consists large recurrent network desired output obtained training output connection weights optimal output weights linear task minimization basic describes online adaptation scheme based algorithm known adaptive linear systems example order system known algorithms over linear systems nonlinear convergence rate determined design time
introduce general family kernels based weighted kernels used analysis variable length sequences more generally weighted applications such computational speech recognition show kernels computed efficiently using general algorithm weighted general single source distance algorithm describe several general positive symmetric kernels these general kernels combined support vector machines form efficient techniques classification highly complex kernels design implement lead classification accuracy show kernels considered applications computational specific kernels
present framework sparse gaussian process methods uses forward selection based previously suggested active learning our goal learn rather than number training points but perform training under strong time memory scaling our method show prediction performance most large real world classification experiments support vector machine svm yet significantly faster training contrast svm our approximation estimates predictive probabilities error allows bayesian model selection less complex implementation
model selection model problem different models model parameters specific learning task supervised learning standard practical technique semi supervised unsupervised paper new model scheme introduced based stability stability measure yields upper bound cross validation supervised case but semi supervised unsupervised problems experimental part performance stability measure studied model order selection comparison standard techniques area
many approaches clustering but important feature selection ie data relevant clustering feature selection clustering difficult due class labels propose two approaches feature selection context gaussian mixture based clustering first instead making estimate feature expectation maximization em algorithm derived task second approach mutual feature relevance criterion unsupervised case feature selection out search scheme scheme mixture estimation layer performs feature selection experimental results synthetic real data show both methods have performance
paper show markov process leads kernels kernel view gives more into kernel suggests way statistics training furthermore approach suggests markov consider varying length rather than standard approach used kernel give procedure features generate finite state machine model used obtain kernel features way able obtain kernel finally experiments reported different kernels using standard words kernel
several have suggested boosting gradient descent search good fit function space apply gradient based boosting unsupervised learning problem density estimation show convergence properties algorithm prove property problem well illustrate potential approach through experiments boosting bayesian networks learn density models
present simple direct approach solving ica problem using density estimation maximum likelihood given model each using semi parametric density estimate based our estimates have two continuous easily second order search parameters our method performs compared state techniques
standard representation text words well known due its similarity between terms term similarity include latent use networks probabilistic methods paper propose two methods such similarity de word similarity based similarity system equations whose point use obtain similarity measure second method models means process graph de information both approaches produce kernel functions real number paper shows measure used successfully perform model selection over parameter combined use support vector machines obtain positive results
boosting algorithms applications classification regression learning problems but unsupervised learning propose sequential approach features random field model training them improve classification performance between data equal sample negative examples generated models current estimate data density training each boosting three first sample negative examples models current distribution next feature trained improve classification performance between data negative examples finally learned feature relative negative examples need generated learn each new feature approach demonstrated binary continuous synthetic data
propose new algorithm estimate dimension data sets method based properties data requires parametric assumptions data generating model input parameters set method compared similar algorithm same family techniques experiments show our method more robust terms data generating distribution more presence noise
using markov chain spectral clustering present algorithm automatically find number stable clusters markov spectral properties matrix transition probabilities derive along their describes probability due markov chain its its markov chain stable cluster zero key paper between clusters computing weights propose novel algorithm perform clustering these iterative
common objective learning model data its network structure while model parameters interest example may networks high data sources paper bayesian regularization using product independent over model parameters learned model structure domain discrete variables show small scale parameter often equivalent sample size prior leads strong regularization model structure sparse graph given large data set particular graph obtained limit scale parameter what may limit complete graph maximum likelihood estimate prior parameters expected scale parameter between parameters structure model demonstrate sense predictive accuracy
recently proposed algorithms nonlinear dimensionality reduction into two have different advantages global local locally linear present two advantages global approach what have previously been advantages local methods computational ability maps
application variable dynamic bayesian networks constrained complexity over latent variables either small latent dimensions gaussian latent conditional dependent states typically considered order inference suggest alternative approach latent variables using deterministic conditional probability has advantage inference even highly complex non gaussian conditional probability approach highly complex latent dynamics probabilistic model
propose probabilistic generative models called parametric mixture models multi labeled text problem binary classification approach has been whether text category binary classifier every category contrast our approach simultaneously multiple text using derive efficient learning prediction algorithms show our method could significantly conventional binary methods applied multi labeled text using real world wide
recently kernel used feature classification problems vector parameter probabilistic model paper gives theoretical analysis about class information space out consists few important dimensions class information many dimensions perform clustering means type methods because they make use dimensions so develop novel but simple clustering algorithm important dimensions algorithm successfully tested experiments artificial data real data sequences
propose paper probabilistic approach adaptive inference generalized nonlinear classification computational advantage parametric solution sequential sampling techniques parameters classifier latent states first order markov process propose algorithm variational generalization standard kalman filtering variational kalman filter based two novel lower bounds us use non distribution over adaptation rate empirical evaluation proposed method capable competitive classifiers both non although focus classification algorithm easily extended other generalized nonlinear models
introduce novel learning algorithm binary classification based pairs training points classes algorithm further extended nonlinear using kernel functions conditions ensemble simple learned means confidence version provides sound strategy through finite set experiments real world datasets generalization performance classifiers found classifiers furthermore computational cost classification time found similar better than svm kernel margin via contrast line learning machine kernel whose complexity number kernel directly off accuracy
sampling estimation technique variance standard sampling explicitly estimation objective previous work has demonstrated method technique both discrete continuous domains paper present sampling free parameters original estimator new regularization strategy further variance without resulting estimator shown effective difficult estimation problems markov random field inference particular achieved over standard distribution has multiple
problems novel should domain class examples these applications areas machine detection principle problem knowledge available class paper explain natural representations domain propose simple class classifier representations use linear programming efficient class description found based small number objects classifier made more robust compute using reduced representation set finally comparison class classifier given
regression problem minimum probability future predicted outputs regression model within bound true regression function our formulation obtain direct estimate lower probability bound proposed framework probability machine regression based recently described probability machine classification algorithm et al uses kernels obtain nonlinear regression models tested both real world data accuracy bound regression models
recent variational methods have approximate inference learning wide variety probabilistic models each new application necessary first derive variational update equations implement them application specific code each these steps both time error paper describe general inference called variational inference bayesian networks allows wide variety probabilistic models implemented solved without coding new models either through simple via graphical automatically variational equations illustrate power using examples bayesian mixture
new approach inference belief networks has been recently proposed based representation belief networks using functions according approach key computational question representing functions inference simple process such functions show here inference algorithms based special case approach sense use result new properties algorithms discuss its practical theoretical
constraint classification framework many classification including take classification classification present algorithm learning framework learns via single linear classifier high dimension discuss distribution independent well margin based generalization bounds present empirical theoretical evidence showing constraint classification over existing methods classification
introduce iterative local algorithm computing multi represented arbitrary graphs provide analysis experimental evidence performs well large graphical many often iterations graphs nodes tree algorithm et al similar belief propagation probabilistic inference thus recent work tree approach thus probabilistic inference have least two general approaches computation graphs
focus problem efficient learning trees well known given pairwise mutual information coefficients minimum weight tree algorithm problem polynomial time large data sets correlation matrix time have developed new tree algorithm capable partial knowledge about weights partial knowledge probabilistic confidence coefficients derive small sample data algorithm able need more data particular experimental results show time near constant number without significant loss accuracy generated trees our tree algorithm based rule generally considered performance
describe method computing exact maximum map estimates problems graphs basic idea represent original problem graph convex combination tree problems optimal value original problem ie log probability map upper combined optimal values tree problems prove upper bound tree problems optimal common important such map original problem next develop tree product algorithm find convex tree problems common give necessary sufficient conditions fixed point exact map estimate feature our analysis convex distributions
pairwise data empirical typically either due noise due estimates therefore analyze conventional machine learning paper therefore study ways work problem first present alternative multi dimensional scaling allows us apply variety classical machine learning signal processing algorithms class pairwise algorithms property invariant under procedure objects clusters based new representation methods applied second step both steps provide well pairwise data metric representation demonstrate practical our theoretical structure sequence data performance upon existing methods
similarity between objects many learning algorithms most non parametric methods take similarity fixed but much recent work has shown advantages learning particular local data capture non linear most data propose new non parametric kernel density estimation method local structure underlying through local covariance matrices experiments density estimation show significant respect density density used within bayes classifiers classification rates similar much superior classifier
describe probabilistic approach task objects described high dimensional vectors pairwise low dimensional space way neighbor gaussian each object high dimensional space under gaussian given used define probability distribution over potential object approximate distribution well possible same performed low dimensional images objects natural cost function sum per object leads simple gradient low dimensional images other dimensionality reduction methods probabilistic framework makes represent each object mixture low dimensional images allows objects like vector word have close images both without images close those
present procedure maps internal representations learned several local dimensionality reduction experts into single global system original data space our algorithm applied set experts each low dimensional local representation input recent such models their objective functions our algorithm after training efficient process trained models processing has local size system solve scales number local models rather than number original data points making more efficient than model free algorithms such
low approximation techniques pattern recognition research they include latent analysis probabilistic principal components pca generative model many analysis make use low dimensional data such techniques generally unsupervised allows them model data labels many practical problems prior knowledge available form context paper describe approach such information demonstrate its application pca based approximations several data sets
problem relevant data face multiple structures modeling complex data structure random variable relevant another variable has been recently via information method such variables often more information than required due structures task many other cases fact what than what task hand relevant structures thus improved minimizing information about another variable paper give general formulation problem derive its well solution its demonstrated synthetic example two real world problems context text face images while original information problem related rate theory measure relevant information relevant features while related rate information
show critical points likelihood function mixture type models they given critical point models less components sufficient condition critical line gives local points derived based fact component method proposed mixture gaussian components its through experiments
consider learning problem between general class objects another general class objects objects example vectors images trees graphs such task made possible similarity measures both input output spaces using kernel functions thus objects into vector spaces experimentally our approach several tasks mapping pattern recognition reconstruction partial images
missing data common real world datasets problem many estimation techniques have developed variational bayesian method perform independent component analysis ica high dimensional data containing missing missing data bayesian framework generative density model modeling distributions independent sources mixture allows sources estimated different variational bayesian method automatically dimensionality data yields accurate density model observed data without overfitting problems allows direct probability estimation missing values high dimensional space dimension reduction missing data
investigate problem learning classification task datasets described matrices these matrices objects objects may different sets matrix relationships between them matrix elements being produced unknown kernel object pairs show under assumptions these kernels unknown feature space minimizing bound generalization error linear classifier has been obtained using derive objective function model selection according principle risk minimization new objective function has advantage allows analysis matrices positive even symmetric consider case objects features suggest additional constraint objects show method used feature selection finally apply method data obtained objects samples objects matrix elements expression levels using standard classification support vector machines nearest after standard feature selection our new method sparse set provides superior classification results
paper study special learning problem each training instance given set distribution over class labels labels correct such problem eg information retrieval setting set words associated image classes labels propose novel approach class labels training examples experiments proposed approach over different datasets show our approach able find correct label among set labels achieve performance close case each training instance given single correct label contrast methods more introduced into labels
paper consider problem detection algorithm minimal region input space containing probability underlying data set single class probability machine distribution free case probability data point convex set given mean covariance matrix distribution making further assumptions present robust approach estimating mean covariance matrix within general two class setting show approach single class problem provide empirical results single class single class svm two class svm method
consider problem structure high dimensional data particular role distance metric use based statistical field scaling show use metric ie measure gives structure input data distribution provide theoretical observation
introduce new learning algorithm decision allow features constructed data allow between accuracy complexity bound its generalization error terms number errors size classifier training data compare its performance natural data sets set machine support vector machine
consider general problem both labeled labeled data improve classification accuracy under data high dimensional space develop framework labeled data set manner idea our approach classification functions defined question rather than total space using basis space functions such basis examples required basis training performed using labeled data set our algorithm models using graph data graph practical applications image text classification considered
discuss problem use large margin principle introduce two main approaches first fixed margin policy margin classes being out direct sum approach svm learning second approach allows shown reduce svm number classes approaches optimal size both total number training examples experiments performed visual classification filtering show both approaches existing regression algorithms applied multi class svm applied general multi class classification
describe new framework learning problems framework map both labels into common space space each instance label nearest analyze algorithm learning labeled data key analysis algorithm probabilistic output codes generalization error output codes furthermore method using shown instance demonstrate advantage over their performance problems
gaussian process regression allows simple exact bayesian inference has been found provide good performance yet scales number training data paper compare several approaches scaling gaussian processes regression large data sets subset method reduced approximation online gaussian processes bayesian machine furthermore provide theoretical into our experimental results found subset methods give good fast predictions data sets high noise levels complex low noise data sets bayesian machine significantly better accuracy yet higher computational cost
paper introduce determine structure class similar cost functions rate theory deterministic information information method introduce numerical algorithm uses form find point
paper boosting approach learning label sequences based sequence loss function proposed method many advantages boosting schemes dynamic programming methods both computationally addition discuss alternative approaches based loss label sequences sequence boosting algorithm interesting alternative methods based hmms more recently proposed conditional random fields applications areas presented technique range natural language processing information computational include experiments recognition part speech demonstrate our approach
propose framework classifier design based representation class conditional distributions way optimal classification set constrained maximization objective function measures average difference ie contrast between show maximization contrast equivalent minimization approximation bayes risk therefore using classes probability density functions resulting maximum contrast classifiers approximate bayes rule general case particular certain density functions obtain have same functional form well known support vector machines show training general requires nonlinear optimization but under certain conditions problem single linear indicate close between training particular show linear programming machines approximate experiments data sets shows competitive classification performance
upper error bound exponential function margin training set goal applications pattern classification minimum error rate other hand effective procedure learning classifiers difficult high dimensional data paper present novel procedure called learning better classifier uses mechanism after each iteration classifiers higher error rates resulting classifier consists classifiers yet lower error rates than both training test propose statistical model learning classifiers based approximation posterior using set features experimental provided through difficult classification problem face detection goal learn training examples highly nonlinear classifier between face patterns high dimensional space results demonstrate made over
paper consider relevance vector machine training strategy expectation maximization em algorithm call em subset active basis functions solution number basis functions computational complexity low introduce mean field approach classification model expected give good approximation exact bayesian inference approximation special case test algorithms two large data sets examples results indicate bayesian learning large data sets eg database
present class algorithms learning structure graphical models data algorithms based measure known kernel generalized variance allows us variables equal feature space obtained kernels thus able learn hybrid graphs discrete continuous variables arbitrary type explore computational properties our approach showing use kernel compute relevant statistics linear time illustrate our framework experiments discrete continuous data
propose model learn parts based representations data our key assumption dimensions data into several factors take values each other assume each factor has small number discrete states model using vector states each factor represent multiple input given set training examples our model learns data dimensions factors well states each inference learning out efficiently via variational algorithms present applications model problems image decomposition filtering text classification
classification labeled data requires using large number examples estimated further conditional few available labeled examples regularization approach conditional general way regularization measures information about labels over regions parametric assumptions required approach even continuous develop algorithms solving regularization problem finite differential equation behavior new regularization approach simple cases
gaussian processes provide approach allows combination function observations empirical model particular nonlinear dynamic systems experimental data allows us information associated uncertainty normal function observations into learning inference process information form data close allows multiple local linear models consistent manner consistent models constraints computational efficiency gaussian process models dynamic system large near data training set size problem gaussian process models
derive updates solving quadratic programming problem support vector machines updates have simple form prove they converge solution maximum margin updates proposed objective function they do such learning rate variables update each iteration they used quadratic programming variables parallel improvement each iteration analyze asymptotic convergence updates show coefficients non support vectors zero rate depends their practice updates converge good classifiers
given set hidden variables markov structure derive online algorithm updates posterior pairwise measurements between hidden variables available update performed using density filtering each pairwise compute optimal markov structure true posterior use prior next demonstrate resulting algorithm consistent trajectories robot along trajectory update trajectory length update takes conditional distributions linear gaussian algorithm kalman filter state covariance matrix after each
filters estimate state dynamical systems information many real time applications filters information significantly higher rate than update rate filter approach such update filter often possible information cannot time paper present real time filters make use information even filter update rate update rate achieved representing mixtures sample sets each mixture component observation during filter update weights mixture components set so minimize approximation error introduced mixture representation our approach computational samples information experiments using data robot show our approach yields strong over other approaches
present novel generative model natural language tree structures structures models provides component models level performance similar non models most other models model effective algorithm efficient exact inference
explore result predict particular context existing representation result problem show human data obtained probabilistic approach explicitly models generative structure language
standard view memory through various recent experimental idea transfer human memory its evaluation although independent evidence short transfer few theoretical what might suggest demonstrate two important computational associated
achieved movements their here show goal but dimensions optimal control strategy face uncertainty optimal feedback control motor tasks minimal principle average trajectory they task resulting behavior task constrained well among another empirical
present account human concept learning examples principle minimum description length support wide range two dimensional concept both highly theory give suggests concept description its structure number different have been explain manner learn has been underlying principle might objects decision bayesian inference while many these well been range experimental they have been concept types similar simple figure figure similar those previously represent equal moreover research has simple category types goal has been investigate performance distributions rather than present across range example has previously category similar concept well important they way range concept structures view dimensional space upon category may represented set space may considered potential category therefore natural whether such category principle more difficult learn than previous have considered range structures they have been position question paper present theory human based much better about both support theory present experiment human range types defined over continuous two dimensional feature space including both highly highly find our based theory gives good account learning these complexity various concept types tested previous category structure role structure has been fact structure has been quite work et human performance learning such structure recently have shown performance well predicted concept given length describes objects category result suggests principle minimization complexity might important role human category learning complexity analysis do generalize easily type feature spaces investigate required similar general but therefore complexity minimization technique such complexity defined over continuous features investigate complexity experiment while dimension experiment limited category structures within two dimensional feature feature space into feature space constraint possible category structure computation complexity feature values limited machine precision but features possible values range figure abstract used experiment particular abstract category structures experiment shown figure these considered interesting cross theoretical range available two each concept negative positive category represented regions corresponding negative category its note many cases these sense probabilistic given point feature space either positive negative during experiment each stimulus randomly feature space labeled region sampling used so figure have same rate experiment video required subjects between two classes each figure features cases shown figure these features randomly abstract feature space such experimental may abstract figure positive principle optimal bayesian inference while several bayesian algorithms have previously been proposed models human concept learning principle human learning have recently under relevant theory figure possible concept figure posterior data obtain log log log log problem thus problem log log constant its value does into hypothesis such minimize log log log us hypothesis what means hypothesis bayesian same hypothesis between learning theory investigate these compute first language about use table consists different grid each class particular grid four ie four suggests log each so therefore compute particular choice paper might such although have its ie class use value log rather log table show probability source given class corresponding class possible locations probability log log log log log log log log log log computing these requires probability function source subjects figure produced concept information source whose parameters unknown assumption source randomly class individual chosen class probability assumption class selection prior each class assumption within class sampling means order individual need consider class now individual class their within grid class equal probability associated individual class corresponding shown next these probabilities table description length particular hypothesis up hypothesis length second part two part description concept respect bayes likelihood several possible approaches computing hypothesis discuss up four regions computing therefore involves positive category within each hypothesis region same problem computing region interest fixed table minimum description abstract concept while regions procedure previous section compute appropriate function capture positive hypothesis region maximum four classes those size four minimum description applying above figure requires compute total description length corresponding each concept hypothesis corresponding total concept shown table along corresponding minimum observed while true positive almost concept information hypothesis true concept information distributed between hypothesis likelihood codes note general most minimum sum minimum results each ie each concept figure measure computed figure shows performance subjects function concept table linear statistical thus complexity across range shows highly significant complexity figure performance complexity subjects performance each concept mean each concept described here further make most approach prediction each new stimulus made based time stimulus observed correlation between subjects decision found highly significant concept types statistics given concept each figure behavior real time simulations variety sets found figure real time concept data size data set between hypothesis shown step two hypothesis shown step gives measure capacity ie independent criterion positive discussed above relationship bayesian inference basis theory data presented above suggest human much like principle construct corresponding two part code equation they related complexity minimization principle associated minimum human inference eg our suggest approach defined over continuous previously found approach well human performance research based between classification recognition probability density estimation bayesian modeling human concept processing systems optimal structure perceptual learning minimization complexity human concept learning nature modeling data
make causal data often few observations these bayesian over hypothesis space causal graphical models strong top down prior knowledge form present two case studies our approach including models human causal traditional up models inference
human generalization best bayesian framework rather than traditional models based similarity previous work bayesian concept learning unsupervised method hypothesis spaces propose version bayesian off over generalization these spaces analyze two data sets well results new study have out
but similar produced does action less less accurate information long term memory used simple model fit data effects study time word frequency both recognition memory simple model fit well et al more important within bayesian based modeling framework data consistent view less accurate rather than less information memory
current human causal learning focus long predictions two estimating parameters causal bayes nets different through learning paper short behavior dynamical these three their predictions real world
consider hypothesis systems learning visual may use designed during training four models trained estimate motion sequences visual images three models models sense nature their input during training they relatively visual input early training quality input improved training model used ie scale motion features early training scale features its input training another model used model used random model sense nature its input same training simulation results show model performed best account models superior performance designed sequences useful systems learning estimate motion idea visual development visual learning hypothesis need further study
according series models neurons signal reward prediction error using temporal difference td algorithm address problem solved these representation cues predict our new model uses td rule observable semi markov processes two features experiments hidden state temporal previous models predicted using delay line representation sensory inputs more active process inference about underlying state world system learn map these states reward predictions using td new model explain previously data responses neurons face temporal statistical model based learning td theory into about behavior previously been more abstract models
consider bayesian mixture approaches constructed weighted average space functions while such known lead optimal several cases accurate prior information available has been they perform prior assumptions paper data dependent bounds such previous approaches such algorithm fully bayesian setting finite sample work bayesian mixture approaches assumptions bayesian moreover bounds derived directly applied non bayesian mixture approaches such boosting
apply method statistical combined variational method approximate computation estimating generalization error demonstrate our approach regression gaussian processes compare our results obtained monte carlo sampling
information method information formulation clustering problems given joint distribution method about maximum likelihood mixture models standard statistical new variable over values approach clustering problems paper two methods related define simple mapping between problem problem mixture model show under mapping problems related fact input distribution over large sample size problems equivalent these cases every fixed point functional fixed point log likelihood moreover values fixed points equal under simple transformations result these cases every algorithm problems solution other
extend recent work connection between belief propagation free energy constrained minimization free energy into point problem both algorithms standard belief propagation solve point problem stability analysis leads us stable fixed points belief propagation local free energy need case fixed points illustrate example discuss
paper gives distribution free missing error rate rules negative methods used reduce these problems about independent although independent they highly such highly independent cannot using standard such bound theorem
classification trees most types classifiers implementation interpretation being among their features use classification trees theoretical analysis their performance paper show new family classification trees called classification trees near optimal sense range classification problems other schemes eg neural networks support vector machines cannot perform significantly better than many cases show near optimal performance linear number training data complexity algorithms moreover performance datasets standard generally more computationally does similar near properties our analysis theoretical results risk minimization rule based
paper analyze relationships between matrix kernel corresponding sample density corresponding continuous bound between two provide performance bound kernel pca
new family kernels statistical learning introduced structure statistical models based equation defined information metric information kernels generalize gaussian kernel space provide natural way generative statistical modeling non parametric learning special case kernels give new approach applying kernel based learning algorithms discrete data bounds new kernels using spectral theory differential experimental results presented text classification
population based learning shown require sensitive scaling its learning rate learning rate scale system size problem dependent way shown two problems learning rate system size smooth function learning rate like system size two methods proposed learning dynamics shown give consistent performance over range learning rates analog shown require learning rate scales inverse system size but problem independent
learning machines hidden variables used information have their parameter spaces information matrix resulting learning theory statistical models does recently true parameter bayes generalization error equal function information paper under condition true parameter almost but show two results dimension parameter inputs hidden units larger than three region true parameters generalization error larger than those models true parameter generalization error than those models generalization error training error does models general
investigate data based kernel learning support vector machines provide generalization error bounds estimating corresponding function classes particular obtain complexity bound function classes kernels given ie allow bound factor than complexity function class single kernel margin over such classes leads overfitting thus propose way class use efficient algorithm solve resulting optimization problem present experimental results compare them based approach
applied statistical inverse problem linear mapping investigate optimal used technique model demonstrate result rate function known theoretical limit criterion derived numerical study shows sparse model provide
distance based conditional model presented use classification model extension model classifier combination methods used several ensemble learning algorithms including error output codes discrete regression structure leads simple bayesian interpretation conditional model its special cases addition view framework suggests probabilistic interpretation error output codes extension binary coding scheme
show two related given consists weighted sum features large margin construct stochastic larger training error rate stochastic has future error rate bound depends margin distribution independent size hypothesis class new true error bound margin more data dependent than previous bounds
consider belief propagation approximate inference probabilistic graphical models standard algorithm computed graph introduce belief propagation belief propagation terms family approximate free includes free energy mean field free special cases using linear response scale parameters simulation results illustrate potential approach
although study clustering goal has been difficult develop framework about level approaches clustering research here suggest finding such form theorem set three simple properties show clustering function three these properties interesting work well studied clustering techniques such single sum pairs means
investigate generalization performance learning function spaces introduce concept scale sensitive effective data dimension show rate underlying learning problem using concept extend results parametric estimation problems finite dimensional spaces kernel learning methods de upper bounds generalization performance show resulting rates optimal under various
based algorithms used reduce computational complexity nearest classifiers paper discuss theoretical such algorithms theory present margin based generalization bounds suggest these classifiers more accurate rule furthermore derived training algorithm good set using large margin show learning vector algorithm our framework
work study information filtering model relevance labels associated sequence feature vectors unknown probabilistic linear function analysis version our model derive general filtering rule based margin regression estimator while our rule may label vector vector relevant experiments real world filtering problem show performance our rule close line classifier labels these empirical results theoretical analysis consider our rule prove its expected number much larger than optimal filtering rule hidden linear model
consider problem kernel estimation using gaussian process estimator support vector machine novel solution presented involves kernel space space kernels analog classical theorem problem kernel family kernels eg varying reduced statistical estimation problem problem minimizing risk functional various classical model kernel selection special cases our framework
comparison other sensory functional properties cells auditory cortex yet well recent obtain generalized description auditory cortical responses have often upon receptive field model function linear stimulus well such model account neural responses first auditory cortical processing question develop novel stimulus related response power population given type model use technique show auditory cortex models account more than stimulus related power neural responses
direct neural control such computer requires accurate neural activity representing continuous movement develop real time control system using spiking activity neurons array area motor cortex contrast previous work develop control approach explicitly models motion hand probabilistic relationship between motion mean firing rates cells focus control task randomly computer neural data achieved kalman filter has number advantages over previous linear filtering techniques particular kalman filter hand trajectories off line experiments more accurate than previously reported results model provides into nature neural coding movement
product often kernels statistical learning define mapping input space into feature space focus paper kernels cortical kernels derive map spike sequences into abstract vector space perform various prediction tasks discuss describe efficient algorithm computing their value two sequences neural population spike demonstrate our modeling approach using various standard kernels task hand movement cortical our experiments kernels tested standard product used regression best performance
do cortical neurons represent environment question often simple stimuli such such stimuli have advantage easily but have they may complex higher order neuronal response properties here alternative approach neuronal responses complex stimuli including have used whole cell methods auditory cortex potential these stimuli whole cell total synaptic input neuron other neurons circuit instead its output sparse binary spike train conventional single unit whole cell thus provides much source information about neurons response many neurons complex stimuli our ensemble here analyze linear component receptive field transformation sound represented its time varying neurons potential find has dynamical structure including regions general prediction simple curve find many cases much neurons response although related stimulus cannot predicted linear component presence yet nonlinear response properties
show two important properties visual cortex principle temporal applied natural image sequences properties simple cell like receptive fields complex cell like simple cell outputs apply two different approaches temporal first approach receptive fields whose outputs possible approach yields simple cell like receptive fields thus temporal alternative sparse coding modeling simple cell receptive fields second approach based two layer statistical generative model natural image sequences addition modeling temporal individual simple cells model includes cell temporal estimation model natural data yields both simple cell like receptive fields complex cell like simple cell outputs unsupervised learning both generative model estimated simultaneously significant improvement statistical models early vision layer has been learned have been fixed
consider statistical framework learning class networks spiking neurons our show optimal local learning rules derived neural dynamics desired neural have been contrast other models assume optimal learning rules within framework derive local rules learning temporal sequences model spiking neurons demonstrate its superior performance correlation based approaches further show include mechanisms such synaptic framework learning networks highly complex spiking neurons stochastic mechanism considered complexity learning discussed
inference adaptation noisy sensory variety specific experimental theoretical studies suggest these different different neural computational may reported different systems here our previous theory role cortical inference terms expected uncertainty theory terms uncertainty suggest up inputs top down inference plasticity illustrate using adaptive factor analysis model
single unit activity shows expected reward behavior present computational model neurons principal neurons hypothesis direct through activation reward neuron activity results key rate but temporal state models response thus correlated inputs
analyze convergence properties three spike data analysis techniques our results obtained setting linear nonlinear model stimulus neural activity exact rate convergence results common spike average technique next analyze spike covariance method have been recently successfully these first two methods conditions their convergence therefore introduce estimator model parameters designed consistent under general conditions provide algorithm computation estimator derive its rate convergence close efficiency these application data motor cortex
what hypothesis has minimize signal propagation while minimum show general cost function optimal fact speed scales power test available experimental data find
population neurons typically responses sensory inputs functional classification cells so most clusters rather than within clusters show made using information theory without need introduce metric space stimuli responses applied cells approach classical results but provides evidence those previously further find each cells even within same few spikes between cells
key neural modeling explain continuous multi input environment recurrent circuits neurons real time propose new computational model based high dimensional dynamical systems combination statistical learning theory implemented found recurrent
adaptation neural although basic form plasticity has computational theory main variety paper study adaptation factor analysis technique unsupervised learning use factor analysis standard view adaptation apply our new model recent data adaptation domain face discrimination
mapping patterns order their distribution may both structure training here properties such map obtained few steps discrete time dynamical system system called digital because recent studies structure system pattern properties well its average behavior function its few design parameters previous results furthermore technique parameters initial design order obtain noise behavior suggested our results demonstrated number simulations
cortical synaptic plasticity depends relative timing spikes temporal pattern spikes spikes study hypothesis cortical synaptic plasticity does individual spikes but rather whole firing depends these long they but possible timing individual spikes here present such study standard methods hidden markov models used define what firing estimating probability being such requires knowledge spikes but future spikes show construct causal learning rule depends spikes but firing future spikes show learning rule features synaptic plasticity visual cortex nature
dependent learning model has been shown account various rate based spike time dependent synaptic plasticity here investigate properties model multi neuron inputs different spike train statistics addition present form activity mechanism model neuron thus implemented stable selective receptive fields given various input statistics
dimensions neural responses natural signals theoretical neural new new new propose method allows statistical analysis neural responses natural stimuli non gaussian exhibit strong correlations have model neurons selective small number stimulus dimensions out high dimensional stimulus space but within responses nonlinear therefore mutual information between sequence neural responses ensemble stimuli has been stimulus space procedure number respect information those allow information between spikes full stimuli describe relevant dimensionality relevant much than stimulus space may experimentally map out neurons input output function even under fully natural stimulus conditions methods based correlations functions correlation spike covariance require stimulus statistics use them
cortex uses spike timing compute timing spikes robust based recent framework provides simple criterion determine whether spike sequence produced network sensitive initial conditions numerical simulations variety network architectures within set our model neuron sequences spike used computation under conditions typically found cortex
responses cortical sensory neurons variable number spikes stimuli varying significantly most often noise sensory system paper propose alternative view related uncertainty about world parameters sensory stimulus responses population neurons stochastic samples posterior distribution latent variable model addition theoretical such scheme provide simulations response might framework
data suggest temporal stimulus amplitude role perceptual particular detection signal significantly improved amplitude modulation spectral noise perceptual known temporal structure complex auditory scenes mechanisms auditory well known recent study has demonstrated cortical representation auditory signals noise our study these like response patterns auditory detection neuron shown simple neural model detection amplitude data et al but previous results variety related perceptual
framework introduced accuracy ability population neurons upon multiple stimuli minimal estimation errors obtained information analysis abstract space features stimuli even case linear responses gaussian space different those case single stimulus analysis allows description effects extended include neural such receptive fields
step understanding function sensory systems possible stimulus response function neurons process sensory information common experimental approach present varying complex stimulus while responses more neurons directly estimate functional transformation input neuronal firing estimation techniques usually such filtering other correlation based estimation kernels equivalent maximum likelihood estimation gaussian output noise regression model explore use bayesian evidence optimization techniques condition these estimates show learning control transfer function possible improve quality estimates measured their responses novel input
present method direct connections between two neurons common input other neurons computed spike times two neurons response noise stimulus although method based highly linear nonlinear approximation neural response demonstrate via simulation approach work more neuron model propose approach analysis may stimulus neural networks data experiments
certain simple images known input image sum two images first do more description two images rather than second given number ways sum two images do compute best decomposition here suggest system statistics natural scenes present probabilistic model images based statistics filters natural scenes use model find most decomposition novel image optimization performed using belief propagation show our model correct synthetic images discuss its application real images
goal work natural scenes using local image measurements features changes associated natural order information these features optimal way classifier trained using human labeled images present precision curves showing resulting existing approaches
dimensionality reduction techniques such principal component analysis factor analysis used linear mapping between high dimensional data samples points lower dimensional introduced mixture transformation invariant component account global transformations such perform clustering learn local dimensionality reduction due computational em algorithm learning model dimensionality data sample practical most applications paper demonstrate fast reduce computation order log show various applications tracking video clustering video sequences object recognition object detection images
present work recognition actions similar continuous speech words produced previous methods expression recognition images subjects often their recognition behavior requires methods out image here explore approach based images into performance approach expression recognition system using support vector machines hidden markov models system general learning mechanisms applied recognition movement system tested recognition set actions defined action coding system tracking machine learning techniques directly applied images expression recognition approach presented here information about movement dynamics out filters derived statistics images
single high quality image set images important problem such still images video approaches based use cross correlation images transformation unknown high resolution image observed low resolution images using regularization nature process paper develop bayesian resolution problem likelihood function image parameters based over unknown high resolution image approach allows us estimate unknown point function through
recent algorithms sparse coding independent component analysis ica have demonstrated features learned natural images these approaches do take image transformations into account result they produce image codes because same feature learned multiple locations describe algorithm sparse coding based generative model images explicitly modeling interaction between image features their transformations approach reduce image code provides basis vision present results sparse coding natural images explore extension model capture spatial relationships between independent features object new framework parts based object recognition
problem resolution involves generating higher resolution images eye given low resolution image might using simple filters out high resolution through applications prior information used images paper describe approach between two unsupervised method domains but simple methods what use dynamic tree like architecture model high resolution data approximate low resolution image achieved through mean field approach
introduced linear statistical model joint changes images due certain non parameters image scene another image same scene under different conditions here increase model coefficients according low order polynomial over image allows us better fit varying conditions well without our model much capacity show results image matching detection
accurate representation motion problem machine several tracking algorithms have been developed model human tree propose learning based method such models observations multiple paper model motion known our approach based finding maximum likelihood tree joint probability density function graphical model underlying demonstrate performance our algorithm both synthetic real motion capture data
neurons brain sensitive patterns generated during self motion study whether linear model these neurons used estimate self motion present theory estimator linear combination vectors prior knowledge both about distance distribution environment about noise self motion statistics estimator tested vision experiments show proposed approach leads accurate robust estimates rates estimates out less
describe method learning sparse image representations using sparse prior distribution over basis function coefficients prior consists mixture gaussian function thus coefficients have exact zero values coefficients image computed sampling resulting posterior distribution learned basis similar basis yields higher same number active coefficients using learned image model demonstrated standard test images results compare other methods
goal low level vision estimate underlying scene given observed image real world scenes eg complex high dimensional representations estimate propose low dimensional representation called scene image describe complex scene shape example these regression coefficients predict shape image data describe representation show two uses their properties improve shape estimates learning shape low resolution applying them full resolution shape information about use them segmentation
present algorithm uses multiple cues images single image using both information classifier trained scale patterns each image being change generalized belief propagation used information areas correct classification areas show results real images
address question feature selection context visual recognition shown efficient computational principle optimal minimum bayes error sense concept introduced principle feature selection principle maximum computational relationships between maximization family classification near optimal bayes error sense feature selection does require search family recent studies statistics natural images suggests visual recognition problems subset
propose model natural images probability image product probabilities filter outputs system find sparse features using distribution model each filter output distribution used model combined outputs sets filters system learns map orientation spatial frequency location filters change across map even maximum likelihood learning our model product form allows relatively efficient learning procedure well even highly sets filters model has been learned used prior derive filter images
present hierarchical bayesian model learning efficient codes higher order structure natural images model non linear generalization independent component analysis standard assumption joint distribution coefficients distribution variance structure coefficients efficient image basis novel description image structure provides way learn representations abstract image properties such object location scale
paper presents kernel method allows shape information based object recognition require de new common representation but use power kernels representations together manner these results achieved using results statistical combined markov random via kernel functions experiments show increase recognition rate up respect conventional
consider data images containing multiple objects our task learn about each objects present images task learning problem each image model each objects present correct parameters problem learning model number objects number need considered develop method object models data making use robust statistical method thus present results showing objects real images
problem product several gaussian mixture distributions number including belief propagation inference algorithm training product experts models paper two algorithms sampling product gaussian mixtures their performance existing methods first previously proposed monte carlo techniques theoretical but improved empirical convergence rates second makes use approximate kernel density evaluation methods construct fast approximate sample points within parameter their true probability compare both set computational examples significant over existing methods
provide generative representation sequential activity number within between individual specific global models paper linear time distributed model finite state sequences representing individual user activity making assumption user behavior may relatively small number common simple patterns may randomly user specific results empirical study three different sources user approach provides efficient representation scheme improved prediction performance well representations
address problem learning data model selection problem domain large possible trees use take bayesian approach generating appropriate prior via distribution process prior allows large factors data hierarchical model prior likelihood based hierarchical latent illustrate our approach simulated data application modeling
classification tasks function label single object kernel based approaches such support vector machines margin confidence classifier method choice many such tasks their both ability use high dimensional feature spaces their strong theoretical many real world tasks sequential spatial data multiple labels existing kernel based methods structure problem labels each object much useful information probabilistic graphical models such markov networks represent correlations between labels problem structure but cannot high dimensional feature spaces strong theoretical generalization paper present new framework advantages both approaches maximum margin markov networks both kernels efficiently high dimensional features ability capture correlations data present efficient algorithm learning networks based quadratic formulation provide new theoretical bound generalization domains experiments task recognition classification demonstrate significant over previous approaches
knowledge about local respect given pattern transformations improve accuracy classification previous approaches either based examples develop new framework learning linear classifiers under known transformations based programming present new learning algorithm programming machine able find maximum margin training examples polynomial trajectories instead single points solution found sparse variables allows identify those points trajectory minimal real output support vectors trajectories more than transformation parameter learning kernels discussed experiments use locally approximate images find over known methods
paper presents method learning distance metric relative comparison such than support vector machine svm approach develop algorithm provides way training data set constraints show such constraints lead convex quadratic programming problem solved standard methods svm training evaluate performance algorithm text
standard norm svm known its good performance paper consider norm svm norm svm may have advantage over standard norm svm noise features propose algorithm whole solution path norm svm adaptive selection parameter norm svm
common way image noisy image images made instance pca method even few noise update noisy linear solved efficiently apply directly moreover extend linear able prior knowledge often eg basic idea points points area able show property extended method use experimental results demonstrate power our approach
learning training data highly relevant many applications present new learning algorithm classification problems labels associated sets pattern instead individual patterns multiple instance learning special case our approach based generalization linear programming boosting uses results programming generate linear discrete non convex problem
class problem involves finding data set given set test points form problem has exponential computational complexity size set so far has been means programming techniques do scale problem local search paper present task based programming resulting convex optimization problem has polynomial complexity size data set results data sets cost still high large scale problems due high dimensional search space region approximation based solving approximation computational cost algorithm such problems more than points
propose novel method dimensionality reduction supervised learning given regression classification problem predict variable vector problem dimensionality reduction finding low dimensional effective statistical relationship between show problem terms conditional formulation into optimization problem conditional using covariance kernel spaces allows us derive contrast function estimation effective many conventional methods proposed method requires assumptions distribution parametric model conditional distribution
clustering hidden structure while problem finding clusters has been studied structures considered much problem paper present novel clustering algorithm problem two step procedure first data such way structures second step these new objects based criterion advantages method over related approaches properties based transfer problem structures model highly robust against objects ii kernel allows us clustering problem new method does free kernel polynomial approximation scheme generally contrast methods like spectral clustering mean clustering
new feature criterion maximum margin criterion proposed paper new criterion general sense combined constraint give most feature linear analysis derive new feature based using different constraint does within class matrix such sample size small nonlinear linear feature paper our experimental results face images demonstrate new feature efficient stable
probability machine classification framework et al classifiers minimizing maximum probability gives direct estimates probabilistic accuracy bound assumptions makes good estimates means covariance matrices classes support vector machines computationally requires cross validation experiments kernels kernel parameters give good performance paper address computational cost algorithm nonlinear sparse models basis functions ie kernels time next accuracy bound automatically both kernel parameters feature weights without using computationally cross validation therefore algorithm simultaneously problem kernel selection feature selection ie feature based accuracy bound experimental results indicate obtain bounds well test set state classification algorithms
propose method sequential bayesian kernel regression case relevance vector machine method automatically number locations kernels our algorithm computational related methods kernel regression non iterative requires single over data thus sequential data sets data sets algorithm based sampling allows design simple efficient distributions model parameters results two standard data sets show our algorithm compare existing estimation
new feature selection algorithms linear threshold functions described adaptive regularization method makes them classification expression data goal obtain accurate rules few our algorithms fast implement they large margin algorithm allows us linear quadratic higher order programming methods report experiments known datasets these experiments suggest large margin algorithms algorithms such svm feature selection tasks
consider question nonlinear time series kernel dynamical modeling new method based kernels proposed extension linear dynamical models kernel used first learn parameters model second compute time series predicted feature space means support vector regression our model shows strong connection kalman filter model kernel feature space hidden state space kernel dynamical modeling tested against two time series high quality predictions
principal components analysis pca most used techniques machine learning data components analysis less well known but important role presence constraints data distribution paper present probabilistic model components analysis maximum likelihood solution optimal combination principal components given number components log likelihood model larger equal than probabilistic models pca describe efficient algorithm solve optimal solution log convex prove solution consists principal components while log solution consists components general solution combination both experiments explore properties synthetic real world datasets
linear dimensionality reduction semi parametric estimation problem us study its asymptotic behavior generalize problem gaussian noise unknown noise non models
many problems information processing form dimensionality reduction paper introduce these linear maps solving variational problem structure data set should alternative principal component analysis pca classical linear technique data along variance high dimensional data low dimensional space obtained finding optimal linear approximations result many data representation properties nonlinear techniques such locally linear yet linear more defined space rather than training data points out examples high dimensional data sets
search has its algorithm global rather than local structure using random here propose simple algorithm data space such text image data idea our method data respect structure amount data experimental results synthetic image text data illustrate our method
several unsupervised learning algorithms based provide either clustering given training points extension out sample examples short paper provides framework local linear multi dimensional scaling dimensionality reduction well spectral clustering framework based these algorithms learning data dependent kernel numerical experiments show performed have level error algorithms due choice training data
significant clustering has been achieved algorithms based pairwise between particular spectral clustering methods have advantage being able clusters based efficient spectral methods probabilistic interpretation makes difficult automatically set parameters using training data paper use previously proposed framework pairwise clustering show between inference graphical model show clustering problems exact inference may still possible more datasets show belief propagation generalized belief propagation give results clustering problems use graphical models derive learning algorithm matrices based labeled data
approximation structure important role inference graphs structure tree approximations have been variational method sequential method et al belief propagation each factor graph product single node paper belief propagation extended represent factors tree approximations way expectation propagation framework each factor pairs nodes tree structure result more accurate more convergence than belief propagation lower cost than variational trees algorithms
information over noisy channels common generally computationally difficult problem approach computing mutual information noisy channels using variational approximation resulting algorithm em algorithm yet mutual information likelihood apply method several practical examples including linear population
online gradient backpropagation algorithm considered method solving large scale neural network learning problems contrast show implemented iterative learning method much faster example three times faster classification problem outputs data parameters two hidden layer perceptron times faster nonlinear regression problem prediction outputs data parameters network three principal our algorithm following first use region regularization iteration solve associated nonlinear least problem iteration performs method second sparse matrix vector algorithm construct used solve update matrices resulting many outputs
consider training data computing designed online learning algorithms learning algorithm both theoretical experimental presented
online algorithms classification often require memory computation time kernel functions paper describe analyze simple approach reduction number examples used prediction experiments performed real datasets show using proposed approach single competitive support vector machine svm although being algorithm each training example multiple times
work presents architecture based structures online learning algorithm train together recognition strategy learning two filtering layer search space layer optimal structure provide recognition based feedback rule each local function its errors global point view allows train them together online problem recognition state results advantages our global training method over each function locally
paper sparse representation data matrix first discussed basis matrix estimated using means method have estimated basis matrix sparse solution matrix minimum norm probability obtained using linear programming algorithm norm solution norm solution presented used analysis source separation next apply sparse matrix approach case generally sources sparse perform separation time frequency domain after observed data using transformation eeg experimental data analysis example presented illustrate proposed approach demonstrate its performance two almost independent components obtained sparse representation method phase analysis their significant phase found related tasks finally approach state areas require further study
recently relevance vector machines have been sparse bayesian learning framework perform supervised learning using weight prior representation additional set prior each weight specific approximation full over weights its empirical particular approximation available address demonstrate application variational approximation full model prior form formulation leads natural achieved practice
describe bayesian approach few labeled examples larger set objects assumption latent tree structure domain tree distribution over trees may using data prior over generated process trees allows efficient computation optimal bayesian classification function labeled examples test our approach real world datasets
paper about non approximate high dimensional such nearest neighbor classifiers prediction phase support vector machine classifiers fact even exact usually do need explicitly find close query but need about properties about set small amount computational investigate much paper classification prediction phase introduce new tree algorithms real world datasets give up compared against highly traditional tree based these results include datasets up dimensions show non while exact
introduce class covariance functions gaussian process regression covariance functions allow model functions whose inputs class includes version covariance regression function parameter experiments regression model performs well input space two three dimensions neural network model bayesian free models competitive bayesian neural network but dimension state bayesian free model model non gaussian data use computational methods may allow implementation method larger datasets
clustering right number clusters use often automatically problem paper present improved algorithm learning while clustering means algorithm based statistical test hypothesis subset data gaussian distribution means means hierarchical test hypothesis data each means gaussian two key advantages hypothesis test does limit covariance data does compute full covariance matrix means requires parameter standard statistical level present results experiments showing algorithm well better than recent method based model complexity these experiments show function does models complexity
belief propagation has been successfully used number difficult graphical models find most hidden variables applications image analysis would like find best but rather top while problem has been solved using tree many real world problems size tree large work address problem finding best exact inference new exact inference algorithm best uses approximate inference using product generalized show algorithm approximate best graphs variables
propose non linear correlation analysis method mixtures linear models same way idea pca our work recent methods non linear dimensionality reduction case multiple same underlying low dimensional observed each different high dimensional show special case our method applied single algorithm previous schemes mixture models have been estimated parameters our model estimated form without local learning experimental results illustrate approach non linear extension
spectral clustering class techniques similarity matrix points into clusters points same cluster high similarity points different clusters low similarity paper derive new cost function spectral clustering based measure error between given solution spectral minimum problem minimizing cost function respect leads new spectral clustering algorithm minimizing respect similarity matrix leads algorithm learning similarity matrix develop approximation our cost function based power method computing
consider general problem learning labeled data often called semi supervised learning inference approach semi supervised learning design function smooth respect structure known labeled points present simple algorithm obtain such smooth solution our method yields experimental results number classification problems effective use data
paper introduce new underlying probabilistic model principal component analysis pca our formulation pca particular gaussian process prior mapping latent space observed data space show covariance function linear model equivalent pca extend model less covariance functions allow non linear more general gaussian process latent variable model approach high dimensional data three different data sets our non linear algorithm further kernel pca mapping between feature spaces
gaussian process framework regression learning nonlinear transformation outputs allows non gaussian processes non gaussian noise learning algorithm nonlinear transformation such data well including transformation part probabilistic problem rather than step demonstrate several real regression problems learning transformation lead significantly better performance than using fixed transformation
novel algorithm presented while traditional algorithms predict our approach statistical between pairs our empirical results provide strong evidence type moreover best so new idea critical parameters context learning
discuss expectation maximization em algorithm maximum likelihood learning bayesian networks belief propagation algorithms approximate inference propose step belief propagation algorithms step em algorithm yields approximate em algorithm still important advantage converge simulations illustrate such approach
belief propagation graphs efficient algorithm computing approximate probability distributions over single nodes nodes graph paper propose two new algorithms joint probabilities arbitrary pairs nodes prove number properties these estimates first algorithm propagation algorithm shown converge belief propagation stable fixed point second algorithm based matrix experiments compare number methods
present new method approximate probability distributions defined graphs based gaussian entropy bound combined bound combination leads log maximization problem solved efficient point methods approximation its problem taken approximations exact contrast approaches our variational problem convex so has global additional feature value optimal solution provide upper bound log function experimental performance log better than sum product algorithm margin certain problem classes finally zero limit our log class well known programming eg
consider question well given distribution probabilistic graphical models introduce new parameter effective degree between accuracy complexity approximation present simple approach threshold behavior graph properties provide experimental results support approach
paper problem hidden graphs set noisy present model observed graph includes degree based structure hidden graphs exact inference model present efficient approximate inference algorithm compute evaluate our model algorithm biological graph inference problem
present analysis expectation bayesian networks use generalized linear models local conditional probabilities framework wide variety probability distributions including both discrete continuous random variables large analysis method evaluate class approximate inference algorithms bayesian networks have superior asymptotic error bounds fast computation time
describe markov chain method sampling distribution hidden state sequence non linear dynamical system given sequence observations method updates states sequence simultaneously using hidden markov model hmm update states each time define hmm whose states within these using forward dynamic programming algorithm efficiently state sequence appropriate probabilities large number state sequences through states these illustrate method simple dimensional example example showing hmm used effect state space without error compare hmm more problem human motion
applying hidden markov models analysis data often necessary use reduced set states due large part fact basic hmm estimation algorithms have quadratic size state set present algorithms reduce computational linear near linear time states underlying grid parameters type state representation many domains particular show application analysis high
models define probabilities via maximum likelihood learning typically involves using markov chain monte carlo sample models distribution markov chain data distribution learning often well even chain few time steps but data distribution regions low density different have correct relative because cannot another show improve long range suggested data distribution model correct these long range have rate
approximation technique probabilistic inference exact inference sampling useful models variables inference problem solved paper presents sample propagation efficient implementation approximate inference large class models sample propagation sampling tree its simple structure clusters tree sampling current clusters variables its discuss application sample propagation conditional gaussian inference problems such linear dynamical systems
discrete other related methods have been due fast many fast without complete data would paper algorithm belief network allows set coefficients furthermore efficient belief propagation methods between clusters four nodes coefficients missing data estimated near log time total given missing data points method compared number common approaches such setting missing data zero interpolation tested generated data analysis signal
present novel method approximate inference bayesian models risk based propagation mean variance derived approximation conditional probabilities distributions much expectation propagation normal case belief propagation general case provides optimization strategy containing support vector bayes machine gaussian process special cases
consider problem patterns feature map learning algorithms using kernels kernel space their solutions terms input points into introduce technique based kernel principal component analysis regression corresponding patterns input space images its performance several applications images introduced technique difficult numerical optimization implement previous methods computation images discrete input spaces
present version perceptron learning algorithm polynomial time algorithm based following three observations linear many linear constraints ii every linear solved sequence constraint problems linear constraints general perceptron learning algorithm constraint problem linear constraints many updates probabilistic algorithm average size region results probabilistic algorithm solving polynomial time present results demonstrate algorithm but competitive state point methods
density estimation gaussian mixture models generative technique used clustering develop framework information form constraints into model estimation procedure constraints defined pairs data points whether points same source positive constraints different sources negative constraints such constraints automatically learning problems natural form estimation model parameters present form em procedure positive constraints generalized em procedure using markov net negative constraints using available data sets demonstrate such information lead improvement clustering tasks our algorithm two other suggested methods using same type information
novel approach clustering feature selection presented strategy feature selection sense features directly power used algorithm present efficient optimization algorithm local convergence property free parameter method based stability analysis experiments real world datasets demonstrate our method able both features
describe procedure hierarchical clustering cost function use hierarchical extension means cost our local tree node show these efficiently special properties using techniques algorithms
propose information clustering approach known data identify common clusters across given standard clustering setting clusters single source feature information factor additional bias features they correlated known resulting framework applied successfully synthetic data well text based cross
label task total order over set labels each given instance present general framework learning label functions supervised data assume each instance training data associated over label set do assume either complete consistent us variety problems contrast general form our goal learn function total order over set labels special cases our setting hierarchical classification present general boosting based learning algorithm label problem prove lower bound each boosting iteration our approach demonstrated set experiments large scale text
most machine learning perform experiments estimate generalization error compare algorithm order important estimate uncertainty such estimates paper studies estimation uncertainty cross validation estimator main theorem shows estimator variance cross validation analysis based covariance matrix errors better nature problem shows may variance numerical experiments
has method model structure uncertainty our experiments artificial data demonstrate graphs learned samples complex graphical models bias eg model uncertainty find bias well known order bias model complexity demonstrate effect simple bias our experiments bias bias estimator entropy well difference between expected test training errors graphical model rather than
pairwise multi class classification method together pairwise each classes paper presents two approaches class probabilities both methods reduced linear systems implement show experimentally proposed approaches more stable than two existing methods
pattern classification tasks errors introduced because between true model obtained via model estimation using likelihood ratio based classification possible correct finding class specific terms likelihood ratio directly make class relationships work introduce new makes necessary likelihood ratio those necessary achieve classification but likelihood ratio new while than previously reported such analytically they functions therefore several approximations test number these new schemes speech recognition task well machine learning data sets results show using bias terms new way classification accuracy improve over both over our previous results
although trained classifiers usually more accurate labeled training data previous work has shown training data limited generative classifiers out perform them paper describes hybrid model high dimensional subset parameters trained generative likelihood another small subset parameters trained conditional likelihood give sample complexity bound showing order fit parameters well number training examples required depends number feature feature set size experimental results show hybrid models provide lower test error produce better curves than either their generative discuss several advantages hybrid models further work area
propose approach learning images allows us automatically image images based text do using models images assume every image into regions each described continuous feature vector given training set images compute joint probabilistic model image features words allow us predict probability generating word given image regions may used automatically images given word query experiments show our model significantly best previously reported results tasks image retrieval
paper fast sparse scaling large graph similarity represent represent similarity between those locations space locations used generate large sparse graphs performed family algorithms called algorithms these algorithms distance matrix constant number times two algorithms compared uses approximation perform new algorithm called fast sparse uses these algorithms compare both terms speed quality
present novel approach solving problem networks goal estimate position based measurements signal network our solution gaussian process models distribution signal obtained series measurements stage position estimated likelihood signal respect position investigate accuracy proposed approach data obtained within large network
present architecture system mapping capable consistent maps large many represented markov random space maps local range used identify using search our system has been three two has maps accuracy
key supervised classification representation input sequences recent work using kernels data has achieved state classification performance such representations based labeled data examples known structures into classes while practice data far more work develop simple cluster kernel techniques data into representation sequences show our methods improve classification performance kernels standard approaches using data such close positive examples training data achieve equal superior performance previously presented cluster kernel methods while far computational efficiency
present novel strategy automatically given data user our goal those features most correlated defined function has demonstrate able various types real
use hidden markov hidden semi markov models automatically into its features used generate representation signal more appropriate show state standard hidden markov model those real features investigate use hidden semi markov models improved state
part observation system information dynamics changes these response critical data have identify early minimize data loss development classifiers examples solve these problems take detection approach model these identify its time human experts real time during produced yet field these initial through our have amount useful data
paper present generative latent variable model based filtering called user model generative process designed produce complete user each each user our model each user mixture user distributed according random variable each generated user according pattern associated related several models including mixture model model but has advantages over each
classification detection they robot environment show method class classification support vector machines applied solve these tasks using limited hardware capacity experimental evaluation shows improvement over our previous methods classification statistical approach used detection
paper novel kernel function natural language data field natural language processing feature consists following two steps data ie representing results discrete structures such trees graphs part speech high dimensional numerical feature vectors discrete structures new kernels called hierarchical graph kernels directly whose nodes data structures fully structures natural language data have paper define kernel function show efficient experiments demonstrate proposed kernels superior existing kernel functions eg sequence kernels tree kernels words kernels
given grid each has underlying population our goal find region density its density measure dependent total total population region used example each number cases use spatial find most significant spatial cluster approach finding maximum density region requires time generally computationally present novel algorithm grid into regions bounds maximum each region regions cannot maximum density region regions method maximum density region optimal time practice resulting significant
many real world domains nature set objects related each other complex ways paper type between such domains apply markov network framework et al define joint probabilistic model over link graph application algorithm task requires probabilistic patterns over structures apply method two new datasets other network show classification approach
accurate spectral decomposition analysis paper present first system decomposition compare performance our system data report results
propose unsupervised using independent component analysis ica cluster data based ica mixture model expression patterns linear nonlinear ica components specific certain biological processes exhibit significant up down within each component into clusters test statistical within each cluster ica based clustering other methods clusters various datasets result our model expression data effect independent biological processes comparison clustering performance among various ica algorithms including kernel based nonlinear ica algorithm shows nonlinear ica performed best small datasets natural gradient maximization likelihood well datasets
propose functional mixture model clustering sets curves measured discrete time grid model expression time data each functional cluster nonlinear combination solutions simple linear differential equation describes change individual levels rates constant mixture continuous time parametric functional allows account observed time estimating real time capture experiment noisy mean curves derive em algorithm estimating parameters model apply proposed approach set experiments show consistent improvement predictive power within cluster variance compared gaussian mixtures
existing source location algorithms used generally assume source activity different brain locations independent correlation structure known local field show strong correlations activity over significant stimulus activity would correlated time different brain areas here present through simulations new approach source reconstruction correlation between sources estimated explicitly variational bayesian methods accurate source locations time their activation
brain mechanisms reward prediction different time scales developed markov decision task requires prediction both future subjects brain using functional estimated time reward prediction reward prediction error different time scales subjects performance data used them variables analysis found maps different time scales cortex result suggests different reward prediction different time scales
consider learning states human subjects based their brain activity observed via functional problem important because such classifiers hidden states may useful research applications recent work et al have demonstrated training such classifiers individual human subjects eg whether whether they here extend line research train classifiers applied across multiple human subjects including subjects training classifier describe design several machine learning approaches training multiple classifiers report experimental results these methods learning cross classifiers two different data sets
nonlinear filtering solve complex problems but typically time here show filters constructed rbf network gaussian basis functions decomposition into linear filters computed efficiently frequency domain improvement speed present application idea image processing images synaptic containing should labeled automatically use hand labels provided human experts learn rbf filter using support vector regression gaussian kernels show resulting nonlinear filter task degree accuracy close what achieved human experts allows time task data evaluation efficiently
paper presents energy method reduce system errors brain computer energy has two system performance first increase class separation between active eeg data second system signal amplitude four subjects study performance improvement range while non accuracy performance change
brain computer interesting develop effective human into control signal like human output like most activity research finding features algorithms increase information transfer rates present paper studies using more classes eg left right hand theoretical study showing under assumptions useful more than three four classes two common spatial pattern algorithm based eeg experiments our theoretical show improved
describe system single accuracy noisy measurements real time its perceptron trained map signals position location including position previous need each training generated mapping randomly chosen through model noise real after training average error few iterations using output its initial improved accuracy above statistical accuracy noise applied these methods single sources components source separation compared estimated locations those generated standard
useful properties gaussian process regression models reinforcement learning continuous state spaces discrete time demonstrate model allows evaluation value function form resulting policy iteration algorithm demonstrated simple problem two dimensional state space further ability models distributions functions would allow method capture instead has been focus much reinforcement learning
recent grid based point based approximation algorithms have improved planning these approaches sets belief points learning value function each point belief points highly metric but current algorithms do property paper presents new metric tree algorithm used context planning belief points perform fast value function updates over points present results showing approach reduce computation point based algorithms wide range problems
real world planning problems time often limited well these problems they find solution work time out paper propose search its performance bound based available search time finding solution using bound bound time allows given time optimal solution while its bound previous search result significantly more efficient than other search methods addition our theoretical analysis demonstrate practical experiments simulated robot dynamic path planning problem
recent research has demonstrated useful solutions do require belief space extend idea temporal present explore new reinforcement learning algorithm over grid points belief space uses actions monte carlo updates values apply algorithm large scale robot task demonstrate temporal consider even part belief space learn policies faster do information more efficiently
robot world large amount sensory data uncertainty its action almost interesting sequential decision making domains large state spaces large stochastic action sets investigate way possible domains finding complete policy would take long time approach planning large noisy problems along two first domain instead allows problem structure dynamics small set probabilistic rules second based approach planning agent within part full state space its
online mechanism design problem implement desired system wide systems self their arrival times addition information about their value different consider problem total value system self interest online problem markov decision process solved used implement optimal policies bayesian
control problem complex noisy dynamics paper describe application reinforcement learning first fit stochastic nonlinear model dynamics use model learn number taken
large partial design good learning algorithms provide simple efficient algorithm part uses linear system model world single limited takes advantage kalman filtering allow agent construct good training signal learn effective policy
so called experts algorithms actions both choice action unknown current state environment experts algorithm has set experts each may action algorithm learns individual experts so long fixed sequence states environment does well best would have relative same sequence may states environment depends chosen actions usually case example non zero sum new experts algorithm presented context shown under certain conditions performs well best available algorithm quite different previously proposed experts algorithms minimization optimization long term effect actions actions environment demonstrated fact algorithm capable previous experts algorithms converge non
describe new approximation algorithm solving observable our policy iteration approach through space size stochastic finite state several advantages gradient efficiency search through controller space policy iteration less local
consider policy search approach reinforcement learning show distribution given often good policy each state derive policy search algorithm finite number steps provide non performance demonstrate algorithm several grid world robot problem
optimal solutions markov decision problems sensitive respect state transition probabilities many practical problems estimation those probabilities far accurate estimation errors factors applying problems propose algorithm solving finite state finite action solution robust respect estimation errors state transition probabilities our algorithm involves accurate yet efficient representation uncertainty via bounds case complexity robust algorithm same original computing cost
explore approximate policy iteration learning step learning step policy space give policy language solution large markov decision processes previous technique solve particular high quality domain specific classical planning domains both deterministic stochastic solving such domains large
predictive state representations use predictions set represent state dynamical systems representation alternative observable markov decision processes models dynamical systems may much more than models empirical work has linear have relative introduce new allows us define new type nonlinear general allows exponential deterministic dynamical systems these new called related used their work representation but our their representation particular its potential larger than equivalent
study learn optimal multiple may have different among focus non interest do structure up noisy design efficient near optimal algorithms both their joint actions
recent multi agent learning require knowledge other functions assume times other paper different approach learning values rather than actions learned other estimated observed actions via bayesian inference may effective against many different types adaptive even they dynamic against certain adaptation may converge exact optimal time varying policies using paper learns significantly gradient well policy analysis against presented
design multi robot systems highly active research area two research particular have generated interest solution large design implementation architectures propose new algorithm together these two research class our algorithm automatically architecture multi robot system converge consistent policy show policy same would produced particular planning algorithm demonstrate new algorithm three simulation examples multi robot multi robot path planning limited
develop dynamic behavior network simple components such network network network requires local simple distributed among large networks example discuss problem optimization power delay network our approach policy gradient methods optimization markov decision processes extension policy gradient methods context performance through distributed computation dynamics approximate solution differential equation gradient performance objective
approximate linear programming has recently most methods solving complex finite state spaces work show solutions limited finite state spaces but they applied successfully continuous state show based approximation such model contrast existing solution methods approach robust alternative solving high dimensional continuous state space problems point experiments three problems continuous state factors
visual classification using both machine learning techniques human used classification task human subjects their time confidence several learning algorithms used same classification task using principal components shape representation classification performance learning algorithms estimated using face database true labels estimated subjects correlated human responses distance stimuli learning algorithms our results suggest human classification algorithms feature space used classification brain more processing stimuli close than those further
sensory way they paper show sensory well designed self supervised cross learning using minimizing algorithm unsupervised speech task visual moving auditory sound signal inputs show auditory dimensions performance visual network better them than consider them part visual input explain finding terms statistical structure sensory inputs
show temporal temporal knowledge represented artificial neural networks present algorithm temporal rules neural networks show networks compute fixed point rules apply has been used distributed multi agent systems provide complete solution use simple neural networks capable about time knowledge through learning
present connectionist architecture learn model between actions use model behavior planning state representations learned layer directly motor layer knowledge about possible state transitions connectivity motor signals connectivity dynamic field layer planning process mechanisms local adaptation based model continuous action time domain
connectionist models their performance often difficult evaluate approach statistical model selection introduce similar method global behavior connectionist model number types response patterns markov chain monte carlo based algorithm constructed these patterns efficiently demonstrate approach using two network models speech
way algorithm unknown information about world case space example way algorithm its three dimensional world possible algorithm line more do these make sense given algorithm has high dimensional data its sensory inputs motor outputs demonstrate these given positive show possible make algorithm its motor outputs its sensory inputs information about structure world present results simulations way motor resulting movements structure world
explore case study understanding structure noise present account based statistical problem model selection given stimulus whether process generated random given complexity terms finite controller different memory find binary sequences upon identify these about processes different
describe pattern algorithm learns unsupervised representation structures natural language paper learning knowledge large scale natural language data set generalization text implemented algorithm graph whose words parts words significant patterns determined context sensitive statistical inference form new represented trees significant patterns their associated classes input allows algorithm standard test second language results model level performance considered been trained containing speech small
present novel connectionist model simple language through real robot focus human language ability combination words much attention robot means robot should its sensory motor system representation self generalized between patterns through simple experiments robot corresponding between learned
develop framework based bayesian model explain uncertainty about classical experiments traditional fit parameters within fixed generative model uncertainty over model structure considered apply theory explain relationship between second order two similar result according theory second order results limited leads world model correlations results more complex model additional
have designed tested single chip analog vlsi design chip based model proposed explain extension behavior during approaches new motion circuit developed measure circuit models nature large cells visual system array motion standard cmos process chip power addition wide able complex real world scenes
synapses critical spike based neural computation role computation many different circuit function different computational paper describe new cmos design current synaptic gain time constant circuit part used model synaptic show theoretical analysis experimental data available cmos process
paper presents vlsi circuits continuous probabilistic noise into each computing noisy neurons continuous machine has shown performance noisy data learning algorithm implemented vlsi noisy neurons parameters chip
most neural networks have over problem train networks computing different classical computing training should propose simple neural network training method shown algorithm systems results several real world data sets show algorithm train proposed neural networks has advantages over classical learning algorithms
present test results spike timing correlation learning experiments out neurons spike timing dependent plasticity synapses weight change scheme synapses set either weight independent weight dependent present results learning implemented both presented spike different types neurons develop weight distributions show network spiking neurons synapses perform hierarchical detection
signal image filtering vlsi has been developed real time based image vectors robust image recognition four stage detection architecture based analog digital signal circuits has been introduced determine threshold value detection key processing parameter vector result fully processing threshold detection feature map has been chip designed three layer cmos concept chip chip dimension feature vector scale image every about times faster than computation making real time image recognition system
have constructed second chip capable generating necessary timing control machine demonstrate over previous chip moving significantly more includes larger number neurons more neurons including dependent relative neural networks chip basic results achieved previous chip its self controller
relative depth objects small left right these objects called here describe implementation selective complex cell using energy model has been proposed model response selective cells visual cortex our system consists two containing spiking neurons type spatial receptive fields circuits spike outputs compute selective complex cell response cell both position phase between both used our system performs better phase because relative responses neurons different phase better than responses neurons position
decision functions constructed support vector machines usually subset training set so called support vectors derive lower upper bounds number support vectors several standard types particular show gaussian rbf kernel support vectors bayes risk svm probability noise svm svm
paper investigate sample properties risk minimization based multi category classification methods these methods considered natural binary large margin classification conditions sample classifiers obtained risk minimization framework examples provided two specific general formulation extend number known methods using these examples show risk minimization used obtain conditional probability estimates underlying problem such conditional probability information useful statistical tasks classification consider binary classification problem predict label based observation most significant binary classification machine learning large margin methods include support vector machines boosting algorithms based set observations large margin classification algorithm decision function minimizing loss function often convex upper bound binary classification error function given binary decision rule predict predict decision rule important following form large margin binary classification often minimize empirical risk associated convex function chosen function class such scheme computational associated direct classification error minimization often leads problem current view statistical such methods algorithms obtain conditional probability estimates example see related studies point view allows show various large margin methods large sample limit obtained classifiers achieve optimal bayes error rate example see learning method property may good classification method should consistent large sample limit although statistical properties binary classification algorithms based risk minimization formulation quite well due many recent such those above much studies risk minimization based problems binary large margin method complexity possible may another may estimate conditional probability multi category problem using binary classification formulation each category category estimated conditional probability still useful whether more natural what risk minimization formulation used consistent classifiers large sample limit important step direction has recently been taken proposed multi category extension support vector machine bayes consistent note number consistent paper generalize their so include much class risk minimization lead consistent classifiers sample limit see structure risk minimization based multi category classification multi category large margin methods have more attention recently example learning bounds multi category convex risk minimization methods obtained although study possible bayes consistent multi category classification consider following class classification problem would like predict label input vector paper consider classification loss have loss correct prediction loss prediction binary classification class label determined using decision function generalized class classification problem consider decision functions predict label vector function note two more components achieve same maximum value may them framework often function category correlated category compared classification error given note relative compared important particular decision rule given does change same numerical each component allows us constraint vector degree component vector approach often called machine learning another main multi category classification problem into binary classification problems such schemes difficult analyze discuss them example binary classification case represented decision rule equivalent leads binary classification rule
paper learning although task than have been many useful algorithms bounds present error bounds derive general technique bounds within setting technique applied derive error bounds schemes such algorithms based clustering
consider online learning make predictions basis fixed set experts derive upper lower relative loss bounds class learning algorithms dynamics over choice experts basis performance bounds provide optimal learning parameter dynamics demonstrate new algorithm context networks
order dynamics its ability derive associated nonlinear map analyze its behavior low dimensional cases find stable these cases explicitly used solve output dynamical system able prove may converge margin combined classifier given learning algorithm known descent method but other known algorithms explicitly margin such consider function maximum margin solution make simple approximation derive new boosting algorithm whose updates more than those
investigate fact ie either its positive negative predictions correct particular set labeled examples consistent case consistent hypothesis using log iterations other hand set algorithm consistent hypothesis size log our question whether simple boosting algorithm performs well set first show proposed different does perform well set algorithm show requires log iterations learning achieve well simple experiments based artificial data further give called case given examples have same label showing used produce small well
paper family computationally practical classifiers converge bayes error near optimal rates variety distributions classifiers based classification trees feature space key their spatial local rather than global decision our risk analysis involves spatial decomposition adaptive data dependent criterion distribution whose bayes decision locally like smooth function show error bayes error rate within factor optimal rate study polynomial classification rules each show their errors converge bayes error rate parametric rate other practical provide similar rate convergence fast algorithms tree discussed
many different generalization error bounds classification each these bounds improvement over certain our goal these different into single bound particular bayes approach introduced interesting classifiers optimal bound provided technique developed combination quite natural based measures considered set classifiers such bayesian setting
problem probability goal output given training set new object probability measure possible values new objects label line algorithm probability well probabilities outputs observed give natural well study under assumption pairs independent distributed out although probability algorithm automatically well our sense wide class algorithms such algorithms output set probability measures property call algorithms class probability machines our experimental results demonstrate nearest neighbor probability machine performs well standard data set our theoretical results simple probability machine approaches true conditional probabilities without knowledge true probability measure generating examples
non negative matrix problem finding data points positive show under certain conditions data across positive such give examples synthetic image these conditions these require support sampling such generative model terms parts parts show our theoretical results predictive performance code algorithms our synthetic image
paper obtain convergence bounds bayesian posterior distributions true distribution using novel method previous results based analysis introduce generalized family bayesian show convergence behavior these generalized determined local prior structure true distribution important property does standard bayesian posterior may prior structures even far true distribution
general linear response method improved estimates correlations variational bayes framework presented three applications given discussed use linear response general principle mean field approximations
deterministic algorithms clustering derived more general information approach cluster data points information about their location set optimal solutions but equations define optimal solution iterative algorithm set smooth initial conditions solutions desired properties addition approach more efficient robust than algorithms
many classification algorithms including support vector machine boosting regression minimum contrast methods minimize convex loss function statistical using such general relationship between risk using loss risk using loss function show relationship gives bounds under possible condition loss function form classification relationship based variational transformation loss function compute many applications present version result case low noise finally present applications our results estimation convergence rates general setting function classes finite dimensional class
derive form sample covariance matrices produced non data analysis standard pca study case data has variance along small number depends signals parameter ratio sample size data dimension results derived limit large data dimension while fixed transitions functions upper corresponding data bias corresponding kernel pca covariance matrix feature space may structure even data components distributed equal variance show examples phase transition pca results case
compute approximate support vector classification using combination method statistical approach approximate inference test our method few datasets compare exact obtained monte carlo sampling
gradient following learning methods problems implementation many applications stochastic used these derive learning curves three online training methods used linear perceptron direct gradient descent node weight maximum learning rate stochastic methods scales first power dimensionality noise into system small learning rate three methods give learning curves these results suggest these stochastic methods limited their architectures they effective
what optimal interpretation noisy data more than interpretation data bayesian model learning framework depends prior dynamics model parameter data local time constraints interpretation over another other hand time constraints noise shown learning specific model parameter even many data transition mapping model estimation problem system use statistical methods transition model learning
problem relevant data through information method soft clustering variable while information about another relevance variable interesting question current work extension these obtain continuous representations relevant information rather than discrete clusters give general continuous problem obtain solution optimal representation important case gaussian variables obtained optimal representation noisy linear correlation matrix basis obtained correlation analysis gaussian parameter dimension well scale each novel interpretation solutions different level our analysis provides expression optimal information curve terms
address paper question knowledge distribution learning algorithm suggest three theoretical methods into account distribution regularization provide existing graph based semi supervised learning algorithms propose practical
present view online classification regression problems view leads single framework three problems prove case loss bounds various algorithms both case non case our main online algorithm setting learning discussed result new algorithms loss bounds loss
margin properties important role analysis models such boosting support vector machines margin maximization interesting because generalization error analysis interesting because presents interpretation models being prove condition solutions loss functions converge margin regularization condition loss svm exponential loss regression loss generalize multi class problems present margin regression support vector machines
network leads constraints memory models previous work here show these constraints pattern each pattern model principle both global between average local between activity given time principle applied networks cell high capacity associative memory number possible patterns limited constraint out within specific model limit cell network best our knowledge first time such high memory demonstrated state models spiking neurons
efficient method using bayesian linear classifiers dynamics information high dimensional states cortical models shown such recurrent circuits spiking neurons have out complex spike patterns information order spike arrival previously context information
signal networks biological information processing systems individual cells neurons their introduce model single its capacity channel cell cell interaction nonlinear channel non gaussian noise model channel study its response input signals different order estimate its channel capacity stochastic effects introduced both process interaction give channel low characteristics estimate channel capacity using noise gaussian channel
two classes effect neural activity cortex memory direct cortex contrast neurons associated stimuli makes neurons modulation output neurons cortex so memory noise existing models have other structure have memory effects paper these mechanisms explore their joint effect model memory task illustrate actions lead memory selective input has
connectivity system has been described but analysis neuronal basis behavior system here used optimization algorithm search patterns connectivity sufficient compute transformation underlying simple form spatial orientation behavior probability rate change optimization produced networks feedback among neurons further analysis feedback between sensory input behavior common patterns connectivity between model biological networks suggest new functions previously connections system
significant plasticity sensory cortical representations either tasks sensory stimuli reinforcement experiments sensory input direct but usually sensory stimuli presented learning have focus unsupervised mechanisms may significant role but role reinforcement plasticity contrast theoretical reinforcement learning has generally optimal policies action world rather than sensory representations paper framework learning relative unsupervised cortical effects reinforcement way
paper neural mechanisms brain non through specific cortical functions high temporal resolution due these advantages has been experimental various fields neural mechanisms underlying still unknown theoretical basis has been developed paper provides computational evidence interactions neural population single neuron critical role neural
discuss idea data relatively efficient manner our point view bayesian information given input such way mutual information between unknown state system stochastic output given prior information including data previous prove theorem strategy give few examples performance adaptive technique more experimental design example able explicitly asymptotic relative efficiency method research demonstrate efficiency form function underlying output responses
learn new motor have both our task sensory uncertainty reduced using information about distribution previously tasks here distribution novel task sensory feedback show subjects represent both distribution task well their sensory uncertainty moreover they these two sources information way predicted optimal bayesian processing further analyze subjects represent distributions such mixtures results show probabilistic models during learning even
model higher order functions such learning memory face neural hidden variables sensory motor signals dynamics network here propose novel method estimating hidden variables learning agent such connection weights sequences observable variables bayesian estimation method estimate posterior probability hidden variables observable data sequence using dynamic model hidden observable variables paper apply filter estimating internal parameters reinforcement learning model method using both artificial data real data
spike timing plasticity special form synaptic plasticity relative timing activity change synaptic weight active spikes role spike timing dependent plasticity temporal change potential weight change related activation channels therefore analytically change synaptic weight potential activity channel thus variables cell result shows weight change curve measurements positive part weight change curve determined activation negative part weight change curve determined potential change therefore weight change curve should change its shape distance cell find weight change close symmetric weight change
capable using auditory information neural basis behavior auditory neurons spatial receptive fields provide description performed auditory input signals representation auditory space develop our model first sound problem solved statistical estimation problem implementation solution constrained known
strategy allows us amount information neurons provide about certain visual scene study develop method based bayesian sequential filtering algorithm activity neurons our method use kernels filter high dimensional space parametric bayesian scheme compared optimal linear shown work better than linear optimal our results suggest real time spike few independent but similar neurons would sufficient critical scene variable particular class visual stimuli variable predict neural activity about well signal respect kernels
report compare performance different learning algorithms based data cortical task predict orientation visual stimuli activity population simultaneously neurons compare several ways coding input ie spike data well output ie orientation report results obtained using different kernel algorithms
recent area significant speaker recognition use high level features structure speaker has sound but uses language manner large speech data available recent allow long term statistics patterns word patterns individual propose use support vector machines term frequency analysis sequences model given speaker explore techniques text applied problem derive new kernel based upon likelihood ratio introduce new based svm speaker recognition approach error rate conventional based approaches
over significant have been made develop kernels applied sequence data such text speech video images kernel similar have been suggested good ways underlying generative model feature space classifiers such paper suggest alternative procedure kernel finding kernel functions variable length sequence data domains particular domains such speech images explore use kernel functions take full advantage well known probabilistic models such gaussian mixtures single full covariance gaussian models derive kernel distance based between generative models effect our approach best both generative methods standard svm kernels perform experiments speaker image classification tasks show these new kernels have best performance speaker kernel based generative classifiers speaker image classification
many techniques complex speech processing such multiple speaker separation multiple analysis sequences short time power representation often well these tasks significant problem algorithms output does include phase component time domain signal has good perceptual quality here describe generative model time domain speech signals their show efficient used find maximum speech signal given contrast techniques between estimating phase consistent signal our technique directly speech signal thus phase consistent signal compare our technique standard method using signal noise but provide improvement perceptual quality our technique
speaker adaptation has been shown effective small amount adaptation data available method principal component analysis pca find most important paper nonlinear pca particular kernel pca may even more effective map feature space back observation space so state observation computed during estimation weights our solution compute kernel pca using kernels call our new method kernel speaker adaptation found compared speaker independent model our kernel adaptation method reduce word error rate while standard approach performance speaker independent model
speech algorithms up metric human previous methods such used speech account effects highly nonlinear transfer function therefore propose neural estimates speech neural spike rate over time produced signal auditory neural model using well developed model auditory detection theory show human perceptual discrimination spike rates auditory highly frequency transfer conditions prediction error prediction error
speech view example robust speech recognition real world still problem using single although techniques have been they cannot speech signals because their assumptions speech signals propose new principle based property speech signals present methods learn filter speech data prior knowledge data achieve high quality speech time long
single filter out other perceptual ability paper describes novel supervised learning approach speech target speech signal using spatial location cues time auditory effect time frequency binary target than local time frequency unit within frequency relative target source respect changes estimated given spatial interaction clustering feature space perform pattern classification order estimate binary evaluation terms signal noise ratio well speech recognition performance shows resulting system close binary comparison shows our model yields significant improvement performance over existing approach furthermore under certain conditions model large speech normal
local phase neural new new able visual images but mechanism they do so known traditional view image because reduction energy high local phase more important factor first demonstrate image its high frequency energy reduced but local phase much than image its high frequency energy but local phase show features such step result strong local phase structures across scale space complex domain loss such phase propose technique phase prediction coefficients such predictions highly effective natural images phase image features phase relationship images thus new theory perceptual estimation well variety algorithms images
according view neurons visual stimuli linear evidence responses linear account propose model more than research field model neurons have linear receptive field nonlinear field field local contrast test model responses estimate model parameters basic set measurements show model predict responses novel stimuli model might new standard model responses visual processing involves both linear filtering gain control
studies suggest component motion patterns radial consistent visual motion properties cells superior temporal area non human here use constrained model visual motion processing performance two motion pattern tasks computational mechanisms associated processing motion patterns during self motion both tasks discrimination significantly type motion pattern presented perceptual motion bias reported through model demonstrate while motion pattern units capable information relevant visual motion tasks equivalent performance achieved using neural non units these results suggest performance may part recurrent connections within motion pattern areas whose structure function similarity motion patterns receptive field locations between units
paper ability human target image curves target curves generative model local properties curve performs bayesian inference generative model using map estimation varying probability model curve us investigate whether human performance best target curves specific shape statistics particular those observed natural experiments performed data both our results show human performance approaches general conditions target curve similar natural statistics curves suggests bias human curves natural statistics
recent eye tracking studies natural tasks suggest link between eye movements goal motor actions most existing models human eye movements provide up account visual attention visual scene paper introduce new model human eye movements directly eye movements behavior basic idea eye movements reduce uncertainty about variables task relevant value eye movement estimating expected cost uncertainty result movement made several eye movements expected value chosen model using figure environment simulations show our superior simple mechanism
even under human eye under motion dynamic theory vision states eye movements improve according theory eye movements variable spatial patterns grid allow better theory using model retina responses moving eye performance simulated cells task analysis find retina eye have effect performance here eye improve performance based analysis our predictions experiments
current view independent representation space cells they out view dependent visual representations show here investigate whether recently proposed visual scheme called temporal population code provide such representations our analysis based behavior simulated robot environment containing specific visual cues our results show temporal population code provides account fields
present test novel approach free form object represented range data contrast traditional based systems use specific objects introduced representation our approach abstract description shape classes using ensemble classifiers learn object class parts their corresponding relationships set used our classification series large scale discrimination experiments two well defined classes many common features experimental results suggest our method traditional based
standard approaches object detection focus local image them propose use scene context image whole source global information local present conditional random field solving tasks object detection scene classification
problem structure motion problem vision given locations certain points motion points under models problem matrix into product two low matrices each matrix position point particular image elements observed problem solved using but many elements matrix missing observed have different uncertainty under these conditions most existing algorithms while human relatively paper use well known em algorithm factor analysis perform allows us easily missing data uncertainty more allows us prior temporal trajectory latent variables position show prior gives significant improvement performance image sequences
mutual boosting method information object detection multiple objects parts trained parallel using object might use set method efficient features suggested thus information inference between parts objects our experiments eye face trained using mutual boosting framework results show method applications information suggest step human like detection
face detection example detection problem target patterns much lower frequency than out face input image example few typically face recently proposed architecture face detection successfully nature task part their method feature selection algorithm based present novel learning algorithm based forward feature selection two faster than approach yields classifiers equivalent quality faster method could used more classification tasks such line learning
paper present random fields framework classification natural image regions spatial labels well observed data proposed model local models allows assumption conditional observed data given labels used markov random field framework parameters model learned using maximum likelihood method furthermore form model allows map inference binary classification problems using graph algorithms performance model synthetic well real world images model model experiments
detection estimation images video made human complexity natural scenes high dimensionality models these problems represent human graphical model relationships between parts represented conditional probability distributions estimation problem probabilistic inference over graphical model random variables individual parameters position orientation because described dimensional vectors space random variables our model approximate belief propagation such graph recently introduced generalization filter framework model low level cues robust parts scene
paper describes system video sequence description each view representation activity while view system does require fixed system tracking using motion capture motion sequence matching motion capture data off line using class structure describes allows motion may while example computed video real show method accurate
paper presents algorithm learning time varying shape non object tracking data model shape motion component combined non reconstruction arbitrary problem object shape each time gaussian distribution based assumption algorithm simultaneously estimates shape motion each time learns parameters gaussian missing data points extend algorithm model temporal object shape thus cases missing data
computer dimension human computer interaction us new ways about could used face face real time process time scale less than second paper present perceptual automatically video code them respect dimensions real time face feature trained boosting techniques expression novel combination generalization performance new subjects way choice correct two available datasets outputs classifier change function time representation code expression dynamics fully manner system field application human robot interaction
paper presents novel graph approach ratio set noisy real images defined using paper first graph two different sets weights measure local between most optimal graph minimum average weight proposed approach global without related region area length variety images proposed approach results
present approach statistical shape analysis curves images basic idea space curves given constraints differential space solve optimization inference problems demonstrate approach computing statistics observed ii learning parametric probability model shape space binary hypothesis test space
resolution produce high resolution image set more low resolution images high frequency image approaches high resolution image using several images usually prior over high resolution image space other methods use training data learn low high resolution have been highly even single input image case here present domain specific image prior form based upon images show certain types resolution problems sample based prior gives significant improvement over other common multiple image resolution techniques
present bayesian approach probabilistic model image process parameters model estimated directly image set small number additional parameters chosen using cross validation algorithm shown exhibit error lower than other algorithms based model estimating set test images demonstrated via direct performance comparison available set real world test images code
consider number moving points each point joint human image presence other such true even points missing eg because points ability machine present detection scheme probabilistic framework our method based representing joint probability density points graphical model using belief propagation interpretation scene furthermore introduce global variable representing experiments motion sequence suggest our scheme accuracy previous approach based graphical models few parts improvement due both more general graph structure use more significantly
learning system problem due two key factors first other simultaneously learning environment thus convergence second learning often other may able particular dynamics case could result performance than agent learning these two most common evaluation learning algorithms convergence algorithms convergence paper address both single algorithm learning algorithm prove algorithm most zero average while algorithm many self prove convergence limited setting give empirical results variety these results suggest new learning criterion convergence call negative non convergence
among important feature structures here develop new methods prediction connectivity first large data set containing use dimensional neural networks predict probabilities between pairs these probabilities lead weighted graph matching problem efficiently show method better results than previous approaches same validation data addition method easily arbitrary therefore previous approaches predictions containing more than method applied both state each known unknown case state predicted precision method yields estimate total number each chain
paper propose efficient algorithm large mixture into mixture while still component structure original model achieved clustering components method new easily computed distance measure between two gaussian mixtures stochastic model iterations algorithm use model parameters need demonstrate method hierarchical clustering images
environment actions agent rather than experts algorithms experts more than addition more value required general experts method presented along value method shown perform well best available several including explore constant frequency constant size complexity performance bounds
consider problem class size independent generalization bounds multi category classification methods particular obtain expected generalization bound standard formulation multi category support vector machines based theoretical result formulation over error theory may lead generalization performance based generalization multi category regression conditional maximum entropy proposed its theoretical properties
propose new method estimating dimension derived applying principle maximum likelihood between close derive estimator process approximation its bias variance simulations apply number simulated real datasets show has best performance compared two other dimension
belief propagation method approximate inference arbitrary graphical models times even further approximations required whether other representations stochastic approximation methods such errors into has potential solution obtained analyze effect respect particular measure error show bounds errors system leads both convergence conditions error bounds traditional approximate
consider problem image large amount video data image problem terms finding image each spatial location reconstruction task learning problem such image compute present new technique estimate global our technique through convex problem recent techniques
assume grid data each cell grid has our goal find spatial regions dimensional significantly higher than expected given focus two applications detection clusters cases data over regions brain activity corresponding given tasks data each these problems solved using spatial compute maximum likelihood ratio over spatial regions find region computing spatial regions generally computationally so introduce novel fast spatial algorithm algorithm arbitrary dimensions our new algorithm allows us find spatial clusters up faster than spatial without loss accuracy
paper presents general family positive similarity functions over spaces matrices varying represent local regions image images have varying number local parts images image sequence motion trajectories motion so family set kernels derive based invariant product parameters provide possible similarity measures over sets varying our approach set kernels visual recognition using local parts representations
paper propose novel method learning distance measure used classification algorithm algorithm directly stochastic out training set learn low dimensional linear labeled data used data fast classification other methods our classification model non parametric making assumptions about shape class distributions between them performance method demonstrated several data sets both metric learning linear dimensionality reduction
study problem hierarchical classification labels corresponding partial multiple underlying introduce new hierarchical loss function loss simple additional class should based probabilistic data model introduced work derive bayes optimal classifier loss compare two approximations bayes optimal classifier svm classifier classifiers obtained using hierarchical perceptron svm algorithms experiments show our approximation bayes optimal classifier performs after training well hierarchical svm classifier performs best same algorithm derive loss bound showing data generated our probabilistic data model fast convergence loss hierarchical classifier based true model parameters
learning observable domain may need problem perceptual ie different states similar but require different responses problem noisy ie may produce different observations same state show many well known reinforcement learning methods designed perceptual such memory finite size memory do noisy well suggest new algorithm noisy memory based uses weighted classification observed trajectories compare above methods show more robust noise
propose soft learning algorithm small simple threshold functions called defined single real propose bayes risk bound classifiers non between number used margin each finally test soft algorithm four array data sets
experiment dynamical kernel based system tracking hand movements neural activity state system hand location while systems input spike rates systems state dynamics defined combination linear mapping previous estimated state kernel based mapping modeling neural contrast generative models activity state mapping learned using methods minimizing noise robust loss function use approach predict hand trajectories basis neural activity motor cortex find proposed approach more accurate than both approach based support vector regression kalman filter
present extension model allows transformations extension allows object simultaneously learning object shape learning out applying variational inference algorithm includes global search over space local correct convergence use up cues space possible transformations present results number video sequences show model extended object whose changes sequence
present semi parametric latent variable model based technique density dimensionality reduction previous methods estimate latent distribution non us model data generated underlying low dimensional distribution addition allow components latent variable models exponential family makes method special data types example binary data simulations real binary data show comparison other related schemes both terms different generalization samples
show detection binary classification problem using interpretation propose support vector machine svm detection present theoretical results include learning rates finally experimentally compare our svm standard class svm
learning rates bayes risk support vector machines loss particular gaussian rbf kernels propose condition distributions used determine approximation properties these kernels finally compare our methods recent paper et al
paper approximate nearest neighbor algorithms have important high dimensional areas such computer vision recent much due new approximate nearest neighbor approach called sensitive paper question spatial data structure approaches exact nearest neighbor such metric trees provide approximate so introduce new metric tree allows certain may both introduce new approximate search algorithms structure show these structures should able same based approximations but algorithm efficiency provide empirical evaluation large high dimensional datasets show up over result true approximation levels
describe algorithm support vector machines svm efficiently scales large problems training vectors instead whole training set optimization step data into multiple partial results combined global svm over multiple minimal requires far less memory kernel matrices much than svm convergence global multiple through but single provides good generalization single faster than svm problems vectors implemented single parallel cluster tested over vectors class problems two while svm over
feature selection provided datasets different application domains called classification results using minimal number features over research make line validation test sets performance validation set being presented performance test set presented total made validation sets during development test sets used combination bayesian neural networks trees other top used variety methods feature selection combined filters methods using random kernel methods neural networks classification results including predictions made features they available available further research
paper new learning model input data noise present general statistical framework problem based statistical propose novel formulation support vector classification allows uncertainty input data derive interpretation proposed formulation develop algorithms efficiently solve empirical results show method superior standard svm problems noisy input
mechanisms important role visual recognition performed scenes propose computational existing models discrimination particular given visual class defined features best discrimination between class other classes recognition interest shown leads algorithms low complexity large recognition problems existing models early biological vision experimental results context recognition problems presented
graph based prior proposed parametric semi supervised classification prior both data features multiple given sample eg multiple thus bayesian form training em algorithm training classifier automatically between data data training information active label query selection performed using mutual information based criterion explicitly uses data training information results presented measured data single multiple
linear analysis well known scheme feature dimension reduction has been used many applications high dimensional data such face recognition image retrieval classical so called problem matrices well known approach problem apply dimension reduction stage using principal component analysis pca algorithm called used face recognition has high time space due need decomposition matrices paper propose novel algorithm dimensional linear analysis problem while efficiency key difference between classical model data representation classical representations data while algorithm data matrix representation further reduce dimension combination classical studied proposed algorithms applied face recognition compared experiments show achieve competitive recognition accuracy while being much more efficient
linear analysis well known method feature dimension reduction has been used many applications such face recognition recently novel algorithm based decomposition has been proposed competitive terms classification accuracy other algorithms but has much lower time space based linear may data nonlinear structure paper first algorithm called algorithm nonlinear data using kernel efficient approximation called proposed experiments face image data show classification accuracy both competitive generalized analysis general kernel analysis algorithm while has much lower time space
gaussian processes usually terms their covariance functions makes difficult multiple outputs because covariance matrix positive alternative formulation gaussian processes noise sources kernels kernel instead using extend gaussian processes multiple outputs
two neural networks trained their mutual output time weight vector novel used key using channel several models system have been suggested have been tested their under different most models networks process mutual learning described analytically using statistical methods
address problem specific class set images class although cannot model particular instance may provided training example use information other class task learning problem given image pairs labeled matching image features most consistent matching explore based representation model distributions similarity measurements defined finally describe algorithm most based mutual information criterion algorithm performs well our images after matching few well chosen
paper propose probabilistic model online clustering use non parametric process prior model number clusters use prior general language model distribution novel clusters furthermore cluster uncertainty bayesian distribution use empirical bayes method estimate based our probabilistic model applied detection task detection tracking compared existing approaches
experimental studies have observed synaptic neuron neuron synaptic neuron after synaptic modulation timing two action known spike timing dependent plasticity derive simple computational principle synapses so minimize neurons given input neurons output more face noise using entropy minimization objective function spike response model experiments obtain curve along other including reduction synaptic plasticity synaptic compare our account other derive computational our account provides most thus neural response face noise may key goal cortical adaptation
paper address problem statistical learning text whose goal relevant label given set proposed algorithm margin possible labels independent classes learns multi class classifier multi class problem data number possible labels prior knowledge about label margin criterion novel way experiments multi show existing learning algorithms including support vector machines multi text paper problem learning multi text whose goal relevant text given set multiple may relevant single text thus call set label text label almost previous text studies eg label predicted each relevance text decomposition approach features specific label important features approach may result learning explain following example problem computing multi label computer example words specific computing such efficient should use such words label decomposition approach these words they specific small whole many more than computing therefore features either unit information real computing but other vector set label binary representation set possible labels training samples table parametric mixture model another approach multi generated mixture specific word distributions its decision each has problem multi specific features such have such features given mixture process these problems multi specific features assumptions between labels explicitly made existing methods solve these problems propose margin labels independent classes learns multi class classifier multi class problem paper first discuss multi class classifiers cannot directly applied section propose section address implementation section section experimentally compared existing methods using multi paper section solving multi class discuss existing multi class classifiers do work multi class classifier proposed use given table multi class classifier object into class whose vector objects feature vector label class classifier product vector label following similar vectors learned solving following margin problem st matrix whose vectors matrix norm note eq eq training samples labels but possible labels because labels training samples may relevant test samples eq margin constraints other hand margin constraint each training sample approach leads optimization problem without constraints see eq much solve than multi class problems such labels number labels generally large eg our datasets has labels table labels often thus necessary consider possible labels eq eq labels present test samples two problems eq eq first problem they vectors labels without prior knowledge about vectors should obtain appropriate vectors such labels second problem these equations computationally they maximization over possible labels whose number quite large example number datasets used our experiments address first problem section second problem section margin section prior knowledge about location vectors into eq eq propose novel learning algorithm margin prior knowledge assume vectors similar labels should close each other based assumption first eq product basis classifier eq two step process first step map vector into second step find image generally non vectors whose label similarity more use vectors condition product vector space kernel similarity measure between labels call vector space classifier linear map solution following problem st note eq eq scale factor thus eq eq natural multi class classifier call classifier eq eq margin figure margin product eq margin distance image training sample between correct label label linear map so margin between training samples possible labels along case samples into margin margin form numerical computation following form eq more its due space st variables corresponding first constraints eq note eq does through label similarity therefore kernel using solution eq classifier eq label similarity examples label similarity use two similarity measures measure measure measure measure efficient implementation approximation learning following easily extended include case both although do discuss case due space eq sum over possible labels number problem approximate sum over possible labels eq partial sum over set other zero approximation quite number reduced reduction many approximation first note variable corresponding first constraint margin constraint eq thus non zero margin between assume margin close ie assumption well proposed approximation sum lead good approximation exact solution polynomial time algorithms classification classification eq involves maximization over possible labels so computationally process efficient classification algorithms available either measure measure used label similarity eq into number label used used here computational cost eq number non zero eq log thus total cost classification eq log other hand under approximation described above therefore classification within computational steps significant reduction case search used eq experiments section report experiments compared svm using used linear kernel svm real used experimental datasets used our experiment represent used table through top each svm classifier trained predict whether relevant positive negative input text label size frequency table datasets text number number ie features number number labels label size frequency relative frequency each label size label size number label method svm feature type binary parameter model model table feature types learning parameters number parameters evaluation test data into datasets top category each labeled second level thus our term see more about into three types feature vectors binary vectors each feature presence term vectors each feature number term term frequency vectors each feature product term frequency inverse frequency best feature types learning parameters such trained feature parameter table measure development data achieve best measures table used following experiments evaluation measures used three measures evaluate performance measure exact ratio retrieval measure following mean predicted labels true labels measure measure average performance while partial into account measure exact ratio retrieval measure table performance comparison measure left exact ratio retrieval measure right best among methods second best represent svm exact ratio exact ratio exact between predicted label true label true true retrieval measure real tasks important evaluate retrieval performance ie classifiers find relevant given retrieval measure measures average retrieval performance over results first trained classifiers randomly chosen samples three evaluation measures other randomly chosen samples process times resulting values shown table table shows measure other methods measure exact ratio show best performance retrieval although other methods large observed measure exact ratio note classifier measure good three measures example shows high measures but its performance rather retrieval measure second experiment classifiers trained training samples same test samples figure shows each measure over datasets observed show high generalization even training data small interesting point measure rather high measures retrieval measure training data size such high does trained larger data called average measures text learning curve measure left exact ratio retrieval measure right mean same table paper proposed novel learning algorithm multi text algorithm margin labels sets into vector space learns large margin classifier space computational cost provide approximation method learning efficient classification algorithms experiments other methods including svm better generalization would like codes datasets text support vector machines learning many relevant features line machine learning number boosting based system text machine learning mixture models multi text neural information processing systems implementation kernel based vector machines machine learning research
spike involves clustering spike according source neuron problem requires human due non nature data propose technique clustering non gaussian sources bayesian framework first search stage data into short time data mixture computed each second stage transition probabilities between mixtures computed optimal clustering found map solution resulting probabilistic model transition probabilities computed using local assumptions based gaussian version method applied several performance almost wide range including movement clusters
similarity neural networks networks digital circuits each other their study work propose simple system whose architecture whose components allow implementation arbitrary circuits use two addition develop rate equation networks derive general neural network rate equations principle associative memory task feedforward network computation shown simulation difference between neural network models global rate equations through lead global feedback thus simple network without mutual perform take computation thus full complexity cell necessary computation wide range functional achieved small set components
standard approach classification objects consider examples independent distributed many real world assumption because relationship between objects consider special case image segmentation objects underlying grid introduce classification method uses measured feature information but label within due resulting between labels classification set necessary propose new method called support vector machine based kernel self consistent solution label shown equivalent recurrent neural network performance algorithm compared conventional svm cell image segmentation task
present probabilistic approach learning gaussian process classifier presence data our approach involves category noise model noise models noise model assumption data density lower between class conditional illustrate our approach problem present results semi supervised classification
paper generalization learning algorithm studies their relationship maximum likelihood estimation causal parameters prove parameters two causal models same generalized linear algorithm provided conditions apply fixed points these algorithms about them input set samples fixed unknown distribution describe determine convergence conditions convergence rates algorithms under these conditions
paper algorithm learning statistical parameters algorithm stochastic approximation us conditions under algorithm converge optimal solution probability includes necessary sufficient conditions solution
propose convex optimization based strategy uncertainty observations classification problem assume instead sample distribution over particular derive robust formulation distribution given normal distribution leads second order programming formulation our method applied problem missing data direct
describe used data set train hidden markov models using probabilistic framework allows us system learns examples new make comparison our systems performance against models provide example
paper linear ica proposed independent components quite high dimensional observed signals such large size natural scenes two each layer mapping phase dimensional mapping stochastic gradient algorithm makes more non independent signals another local ica phase each neighbor highly correlated signals mapping algorithm because highly correlated pairs instead independent components quite efficiently appropriate observed signals addition numerical experiments quite efficient effective large size natural image processing
prediction trees provide effective tasks such classification language modeling paper take decision view task sequence prediction margin present online learning algorithm derive loss bound depth generated algorithm scales length input describe self our learning algorithm automatically depth prove bound self algorithm result efficient algorithm assumptions shape depth target does require parameters our knowledge first correct learning algorithm depth while being competitive fixed determined
important clustering algorithms whether constructed finite samples converge useful clustering whole data space sample size paper question spectral clustering algorithm convergence spectral clustering more difficult than case even recently first results convergence spectral clustering have been obtained case have develop new approach numerical spectral theory probability out while case spectral clustering usually data space case same under strong additional assumptions our analysis gives strong evidence spectral clustering provides basis future other based methods
computation without stable states computing different has been demonstrated various types simulated neural networks hardware implemented neural network results implementation showing performance network dynamics computing approach well analog computing such used vlsi neural network
consider problem reconstruction several images using learned shape models while shape information inverse problem has out difficult perform automatically introduce framework based level set reconstruction shape models goal through obtain efficient robust method object category interest shape model includes cues such point curve features based active shape models show both these features multi view context complete obtained level set fit features addition model used solution particular features sparse experiments demonstrated database real face images
paper show possible model sensory about task function maps object into consider way their about presented same therefore use special svm polynomial kernel training data set used experts provided different weights gain into used feature subset selection result most important
problem objects classical robust statistics recently has been proposed address problem means class svm classifiers main most class approaches sense they expected has method presented paper problem class classification gaussian density estimation feature space possible identify objects their gaussian model rbf kernels shown gaussian model sense provides estimator true density order model selection problem cross likelihood criterion free model parameters applied
bound ensemble method classification based entropy weights margin constraints bound same general bound weighted algorithm similar bounds other prove more bound leads optimal algorithm learning based maximum entropy principle describe line maximum entropy method after each iteration margin constraints single linear algorithm takes similar form same bounds
provide case analysis selective sampling algorithms learning linear threshold functions algorithms considered paper perceptron like algorithms ie algorithms efficiently kernel space our algorithms simple margin based rule whether query current label obtain selective sampling algorithms average same bounds those their deterministic but using much labels our theoretical empirical comparison two text tasks these experiments predicted our theoretical results our selective sampling algorithms perform good algorithms true label after each classification while practice labels
describe framework learning object classifier single example goal achieved relevant dimensions classification using available examples related classes learning objects single training example often due overfitting effects instance representation provides distance between each two same class than distance between two different classes nearest neighbor classifier could achieve performance single training example therefore suggest two stage strategy first learn metric over distance criterion above available examples other related classes using single examples define nearest neighbor classifier distance learned class relevance metric finding metric relevant dimensions classification might possible linear therefore make use kernel based metric learning algorithm our setting object sets based appropriate image kernel class relevance metric learning proposed framework learning single example demonstrated synthetic setting classification task
what makes neural computationally more could explain better particular family computational tasks than another propose measures computational power generalization neural apply them neural models different distributions proposed measures their prediction direct computational performance these models procedure applied first models spatial range synaptic connections scale synaptic circuit models level input level noise potential neurons case proposed method allows us computational power generalization circuits different dynamic down states have been demonstrated through
paper present framework using multi layer perceptron networks nonlinear generative models trained variational bayesian learning using hidden neurons yields accurate approximation cases large posterior variance method used derive nonlinear linear algorithms such factor analysis independent analysis state space models demonstrated nonlinear factor analysis experiment even sources estimated real world speech data set
auditory scene sources complex object whose parts individual sources known important auditory scene analysis paper goal human describe real time system identify presence more compute their signal processing based frequency estimation method tracking speech while pattern matching back based matrix unsupervised algorithm learning parts complex objects while framework analyze auditory scenes our system real time state performance speech
log important property context optimization approximation sampling bayesian methods based gaussian process have quite recently classification regression density estimation point process estimation here prove predictive corresponding each these applications log given observed data prove likelihood log mean function gaussian prior density point process estimation cases mean covariance observation noise parameters classification regression cases result leads useful these large class corresponding maximum problem log
present algorithm based convex optimization kernels semi supervised learning kernel matrices derived spectral decomposition graph labeled data previous work using kernels gaussian random field kernels kernel approach presented order constraints during optimization results kernels need among different parametric our approach constrained quadratic computationally large datasets evaluate kernels real datasets using support vector machines results
has been development object classifiers images example here address problem eg test images have explicitly been training data variational classifier algorithm models field binary variables strong spatial prior variational inference used over obtain robust classification way approach kernel classifier data into without specific training
model comparison has been many areas propose generalized version individual extended introduce simple algorithm convergence solve model obtain individual useful application multi class probability estimates using error codes demonstrated
regularization role analysis data non lead over models both prediction interpretation consider design algorithms solutions regularization these approaches often result methods both efficient highly suggest general path following algorithm based second order approximations prove under conditions close path optimal solutions illustrate examples
present algorithm local problem estimating parameters mixture models existing approaches both em robust algorithm give data stochastic learning scheme minimal data points sufficient parameters model new regions high likelihood using em bias sampling solutions algorithm computationally efficient well effective local compare alternative methods including em both synthetic data computer vision problem
computation classical higher order statistics such higher order difficult images due number terms estimated propose alternative approach interactions described series estimated via polynomial kernels associated classical higher order statistics first results show image structures such predicted interactions up order important role natural images most interesting structure natural image its higher order statistics instance cannot described pairwise statistics such power function point line cannot predict its would require knowledge second point line ie have consider order statistics describe interactions between points prediction least order statistics so terms analysis higher order image structures such described phase ie phase correlations between several components image phase interactions measured higher order estimation these high dimensional signals such images involves estimation interpretation number terms instance order image coefficients about would have estimated considered first estimating higher order structure natural images therefore global measures such order here propose alternative approach models interactions image points series functional order those image components predicted interaction image points contrast higher order estimation model does require estimation number terms computed polynomial kernels allows us image into components interactions given order next section introduce discuss its modeling higher order interactions estimation method described examples use results possible modeling interactions our analysis prediction framework given image predict its value values interactions different prediction our basic assumption value its series discrete here have into vector discrete order functional linear combination order elements coefficients provide way interactions image points functional order input order terms higher order statistics means control order statistics used order series leads between each other ie input distribution functional order generally leads additional lower order interactions result output functional components lower order instance output second order functional gaussian input generally has mean different zero estimate order component image ie constant component without interactions constant component second order interactions general series achieved into new series ie respect input resulting linear up order they computed original series procedure shown finite degree mean error between true system output its series model condition functional order component image interaction contrast general functional lower order so far have compared classical estimation higher order order functional same number terms term functional respect gaussian input here term used arbitrary input distributions corresponding order functional same order has even higher number coefficients consists lower order next section introduce representation series using polynomial kernels allows efficient computation estimating series regression series linear order functional weighted sum order input vector evaluation functional given input map defined such maps input into vector containing degree using order functional eq product coefficients into vector same idea applied order series maps into single map mapping into dimensionality order series product show terms training points reduce number parameters have estimate procedure because space order has special property has structure kernel space product computed positive kernel function easily show eg generated direct sum single spaces associated product sum thus have shown series linear functional linear regression our prediction problem property series leads efficient solution part due so called theorem eg states following given observations similar approach has been taken using polynomial kernel kernel map into same space but weights applying theorem function arbitrary cost function function norm associated kernel minimize objective function over functions optimal solution other words although over including functions defined arbitrary input points out solution terms observations optimization problem over large number coefficients eq into over variables us consider special case cost function mean error zero solution computed setting respect vector equal zero takes form matrix defined series estimation above degree order series error into regression framework finite series represented linear functional corresponding find order series error linear regression degree series other series has property obtain following series matrix vector computed using kernel eq note series represented using representation sum training points thus dimensionality ie need compute large number coefficients explicitly eq terms containing desired order them up individual order series degree given term constant zero order functional vector functional obtained conditions solution see note different approach used zero resulting series different series they respect input inverse kernels obtained design matrix individual applying regression procedure degree functional have compute solution kernels functional obtained difference two results corresponding order degree functional computed resulting condition its form states degree functional input lower order prove following theorem obtained eq condition expectation over input distribution arbitrary show least fit linear set basis functions form case basis functions components error minimum expected quadratic loss respect given means set basis functions minimizing error error basis functions used now us assume series mean error system up degree approximation error given sum higher order so part error expectation eq order less than difference both equations yields so lower order basis functions order than experiments examples our first experiment whether our about higher order statistics described
new distance measure between probability density functions introduced distance distance connection kernel based learning theory via technique density estimation kernel feature space defined data matrix distance shown measure between cluster mean vectors data matrix its obtained automatically based data hand optimal selection show distance has interesting interpretation risk function connected probability error
many interesting problems general framework label defined given set classes evaluation such generally given terms number order constraints between classes paper propose learning model framework model solve large class problems large margin addition original kernel based method proposed state results
paper presents application boosting labeled graphs general structures modeling number real world data such natural language sequences consists decision use features ii boosting algorithm based decision used discuss between our algorithm kernels two experiments using natural language data show our method even better performance than kernels well efficiency
sets new graph concept has relevant pairwise data clustering problems such image segmentation they generalize graphs have non connections continuous quadratic optimization spectral based address problem out sample examples after clustering process has taken may either reduce computational associated processing large data sets efficiently dynamic data sets need show set simple efficient way numerical experiments various problems show approach
de task research while methods de still problem current approaches precision paper present novel method de based hidden markov model experiments demonstrate new method significantly standard approaches matching quality
paper analyze relationship between computational randomly connected networks threshold domain their dynamical properties particular propose complexity measure find assume its values near ie transition dynamics furthermore show proposed complexity measure computational well near such networks able perform complex time series simple synaptic scaling rule self presented
propose examples training set using probabilistic estimates related algorithms procedure distribution training examples minimal position decision linear between number number training examples complexity during both training prediction
prove generalization error bounds observed matrix observed low matrix analysis approach take obtain bounds present example class functions finite such functions class have
training method labeled data examples containing two sets features has number practical yet previous theoretical have strong assumptions data practice paper propose much assumption underlying data distribution prove sufficient iterative given strong learning algorithms each feature set necessary well assumption fact iterative nature original training algorithm assumptions such given label allow training analyze effect performance noise data predicted behavior synthetic experiments graphs
learning algorithms have control tasks problems time varying dynamics online learning methods have automatically tracking critical applications such these algorithms has been significantly their such stability rather than show difficult stability specific learning methods paper propose method suggested learning algorithm online prove even arbitrary online learning method used our algorithm control linear dynamical system resulting system stable
propose new set learning algorithms multi agent systems more better than previous proposed our apply most average three against class class parameter criterion algorithm approaches best response against other algorithms least approach level value these algorithm achieve close optimal self furthermore require these average achieved present novel algorithm show these new particular parameter class class finally show algorithm effective theory but using recently introduced test show algorithm almost previous learning algorithms
describe semi markov conditional random fields semi trained version semi markov input sequence outputs segmentation labels ie rather than individual elements features semi measure properties transitions within non additional power exact learning inference algorithms semi polynomial time often small constant factor than conventional experiments recognition problems semi generally conventional
give fast scheme based image demonstrate example face detection instead detection step focus step show our method simple fast learned thus making processing step standard machine learning classifiers such neural networks bayes classifiers svm face images into regions similar behavior over image set relationships between mean variance image used form over image thus small image full scale classifier moreover training time our method much less than standard shape features ie image use data they compute they form low dimensional feature space search best features
paper method computing fast approximations support vector decision functions field object detection present approach existing algorithm set support vectors so called reduced set input space points contrast existing method reduced set via optimization constraint synthetic points such resulting approximations via filters applications require large images computational complexity significant amount experimental results show face detection approximations times faster than reduced set systems
introduce novel active learning user work learning algorithm identify useful these traditional statistical points our user make two additional assumptions first few useful down within second both useful may within classes similar thus identify category noisy set form class labels human has small they propose technique mixture model fit data but makes assumptions particular form mixture components property wide real various statistical models give several alternative methods their empirical analysis show our method set containing few points
computation memory required kernel machines training samples least such complexity significant even size problems large datasets present approximation technique based improved fast reduce computation give error bound approximation provide experimental results datasets
novel linear feature selection algorithm presented based global minimization data dependent generalization error bound feature selection scaling algorithms often lead non convex optimization problems many previous approaches through gradient descent convergence local minimum propose alternative approach global solution non convex optimization problem derived via equivalent optimization problem moreover convex optimization task reduced quadratic programming problem efficient available highly competitive numerical results both artificial real world data sets reported
during has been interest development brain computer field has been few most human based eeg reported rates still low low signal noise ratio eeg based alternative paper present method examples eeg three motor cortex movements two eg movements analyze data using support vector machines channel
describe methods computing model given finite sampling methods work mapping sample points into kernel space regions terms
develop family upper lower bounds case expected loss estimating discrete distribution finite number points given samples our upper bounds similar recent bounds estimating discrete entropy lower bounds bayesian based loss under distributions upper bounds convex their parameters thus descent methods provide low case error lower bounds dimensional parameter thus easily asymptotic analysis bounds wide class shows estimator consistent contrast entropy estimation moreover bounds shown within factor two finally sparse data limit find bayes constant estimator parameter scaling like both upper lower bounds optimal choice constant parameter
paper propose two boosting learning hand improve knowledge structure data into classifier design selection other hand use efficient learning mechanism significantly improve supervised semi supervised algorithms proposed context learning specific based resulting algorithm boosting large family learning algorithms
propose based distributed algorithm gaussian mixture learning em algorithm network each node local other nodes arbitrary point point main difference between em standard em algorithm step our case implemented manner random pairs nodes their local parameter estimates them weighted provide theoretical evidence demonstrate experimentally under nodes converge fast correct estimates each step em algorithm
capture position specific probabilities biological sequences than individual sequences much more computationally than discrete making many large datasets furthermore because they such representation difficult these problems propose using representing individual but common using extension information constraints class distributions find optimal yields representation sequences between these sequences while accurate full computed almost those between individual sequences full pairwise would take using but less than using discrete discrete range sequence problems information applied
problem graph inference part graph known supervised learning problem propose algorithm solve method involves learning mapping space graph optimization problem kernel space report results problem network reconstruction data
paper explore use random language model uses information next word based words goal work construct randomly decision trees using information investigate performance speech recognition developed classifiers combination decision tree classifiers each tree based random training data same distribution trees random selection possible each node decision tree our approach original idea data problem language modeling have been studied context language modeling have been shown generalize well data show paper using information achieve better performance both word error rate large speech recognition system compared uses
visual action recognition important problem computer vision paper propose new method model actions objects such hand image sequences our method consists three levels representation low level first feature vector invariant scale using spatial spectral obtain initial clustering clustering using temporal constraint gaussian mixture model based clustering density estimation linear analysis applied image feature vectors obtain level representation finally high level temporal model each action clustering weights images action discuss high level representation extended achieve temporal scaling include multi transition information both image clustering action results given show our three representation
high retrieval precision based image retrieval relevance feedback mechanisms these mechanisms require user quality results query images being either relevant search information search better present proposed relevance feedback mechanisms terms search model has such optimization involves search parameters so nearest neighbor query vector number relevant images paper different approach relevance feedback proposed after user provides first feedback following based search but computation relevance each image database computed function two distance nearest non relevant image distance nearest relevant images according top images reported results three image data sets show proposed mechanism other state relevance feedback mechanisms large number based image retrieval systems vector representation images feature space representing low level image characteristics eg shape based often visual examples order database images similar examples retrieval often nearest neighbor retrieval see based image retrieval systems depends choice set visual features choice metric used model image similarity choice image used query database typically allow different images given query non relevant different images relevant need mechanisms system response based feedback user interesting note while relevance feedback mechanisms have been first introduced information retrieval field they more attention field relevance feedback techniques proposed based values search parameters better represent concept user search parameters computed function relevance values user images so far example relevance feedback often terms query vector terms adaptive similarity recently pattern classification such have been proposed feedback thus used model concept relevant images search concept modeling may difficult account distribution relevant images feature space domain image allows good features so images similar clusters other hand domain such image used those made up images more difficult cluster because high these cases low level non features image retrieval better terms search problem rather concept modeling present paper original direction rather modeling concept relevance user feedback used each image database relevance such depends two computed against images user set relevant images set non relevant images its computational mechanism allows state relevance feedback mechanisms both domain domain paper section idea proposed mechanism provides basic assumptions section proposed relevance feedback mechanism results three image data sets presented section other relevance feedback mechanisms compared section st proposed mechanism has been classification techniques based nearest case nearest case theory provided mechanism compute each image sets relevant non relevant images ratio between nearest relevant image nearest non relevant image has been used compute degree relevance each image database present section use nearest case us assume each image database has been represented number low level features measure has been defined so between pairs images similarity other words chosen feature space similarity metric least number search image usually performed most similar images respect given query dimension usually small large number images time values between relevant images user may fit similarity metric designed search user may other regions feature space user subset relevant images out usually such relevance feedback used perform new search search parameters ie position query point similarity metric other parameters recent proposed use support vector machine learn distribution relevant images these techniques require assumption about general form distribution relevant images feature space difficult make assumption about such distribution domain propose information about relevance images so far nearest neighbor nearest neighbor techniques used statistical pattern recognition case based instance based learning effective applications difficult produce high level generalization class objects relevance learning image retrieval may well fit into difficult provide general model represent different similarity addition number available cases may small estimate optimal set parameters such general model other hand more effective use each relevant image well each non relevant image cases against images database should compared assume image much relevant much its nearest relevant image small image much non relevant much its nearest non relevant image small according previous section each image database thus degree relevance degree non relevance according nearest relevant image nearest non relevant image should these should because relevant images represent concept while non relevant images may represent number other different interest other words while degree relevance degree class relevant images same does apply degree non relevance propose use degree non relevance weight degree relevance us subset related set relevant images so far original query relevant subset related set non relevant images so far each image database according nearest neighbor rule us compute nearest image nearest image us these value used measure degree relevance image small values related relevant images other hand hypothesis image relevant query high value defined relevance relevance formulation easily terms estimation posterior probability image relevant nearest made up nearest relevant image nearest image while weights computed inverse distance nearest relevance computed according equation used images first presented user order test proposed method compare other methods described three image have been used database database subset database these used relevance feedback techniques database database images have been into classes each these images has been into non images data set images filters used these images so each image represented dimensional feature vector database consists images images into data classes path spatial features each image reported database available used subset made up images into classes each image four sets features available paper report results related features features feature sets each distance metric has been used linear procedure has been performed so each feature takes values range between first two each image used query while database images have been randomly used query so classes represented each retrieval iteration images relevance feedback performed images same class query relevant other images non relevant query set relevant images experimental set up objective comparison among different methods used many results term retrieval precision over considered precision measured relevant images top images first two domain type while domain type experimental set up proposed technique comparison retrieval obtained two methods recently described reported query vector similarity metric account features relevance bayes bayesian query based query these two methods have been because they easily implemented their compared those provided large number relevance feedback techniques proposed see example results presented results presented different cannot directly compared each other because they related common experimental set up they related same data sets similar experimental set up us performance two above techniques quite close other results experiments database database considered domain type images different types addition feature space measure similarity figure show proposed relevance feedback mechanism those two techniques used comparison precision relevance bayes feedback figure retrieval database terms average retrieval precision after first feedback iteration graph each relevance feedback mechanism able improve average precision first retrieval more than proposed mechanism better than desired user typically allows few iterations user better search additional feedback iteration bayes able additional information they provide after second feedback iteration other hand proposed mechanism provides further improvement precision number iteration these small first feedback provides high precision value near experiments database database considered domain type images data classes features have been precision relevance bayes feedback figure retrieval data set terms average retrieval precision figure show database retrieval precision high after first feedback each considered mechanism able relevance feedback bayes improvement while proposed mechanism improvement example shows proposed technique precision after second iteration further iterations allow precision other hand bayes further feedback iteration precision after iterations while does improve precision after first iteration user typically allows few feedback iterations proposed mechanism domain allows precision close experiments show two feature sets database database domain type images represent large number feature sets represent similarity between pairs images reported results show proposed mechanism us note retrieval precision after first search graphs quite small good feature space represent similarity between pairs images domain database using bayes they allow retrieval precision according number iteration according feature space us both bayes perform query movement order perform more region feature space other hand proposed mechanism based images database according relevance provided higher precision after first feedback but allow improve significantly retrieval precision number iteration initial precision quite small user may have more perform further iterations proposed mechanism allows new relevant images figure retrieval data set feature set terms average retrieval precision figure retrieval data set feature set terms average retrieval precision paper proposed novel relevance feedback technique based image retrieval while relevance feedback mechanisms modeling concept relevance based available labeled samples proposed mechanism based images according relevance nearest relevant non relevant images our choice same case based instance based learning nearest neighbor pattern classification these techniques provide good number available training samples small use statistical techniques case relevance feedback use classification models should require formulation order small sample problems reported results proposed mechanism large made up images related many different addition while many relevance feedback techniques require parameters exhibit high computational complexity proposed mechanism does require parameter exhibit low computational complexity number techniques available speed up distance based image retrieval early pattern analysis machine
particular problems develop uses auditory stimuli describe allows user make binary decision attention two auditory stimulus sequences using support vector machine classification channel independent components show eeg data high level accuracy suggests possible eeg signals single direction attention well useful
statistical language models estimate probability word given context most common language models discrete predictive eg capture statistical across these paper show learn hierarchical distributed representations word predictive value statistical language model representations unsupervised algorithms linear nonlinear dimensionality reduction input into hierarchical mixture experts each distribution over predicted words while distributed representations our model neural probabilistic language model et al our particular architecture us work significantly larger training example large scale modeling task word training three demonstrate consistent improvement over class based models discuss our approach
discuss framework noisy speech mixtures based generative model explicitly time varying noise model number latent sources observed through noisy mixtures parameters including source signals sources filters noise statistics estimated maximum likelihood using em algorithm exact over hidden sources obtained using kalman show estimation source separation performed simultaneously estimates compared measurements artificial real mixtures used demonstrate approach speech signals estimated models
provide method analysis database containing experiments database labels used individual experiments eg according function consistent pattern experiments within determined method each experiments via kernel density estimation probability density values probability density compared hypothesis distributions generated set experiments used across experiments allows analysis most between brain areas labels furthermore method used functional
paper propose new method parametric estimated over mixture model simultaneously both objects their classes low dimensional space takes input set class posterior vectors given data points posterior structure space minimizing sum under assumption samples generated gaussian mixture equal space has many potential uses source input data into classifiers behavior supervised semi supervised unsupervised algorithm has computational advantage over conventional methods based pairwise object its complexity scales product number objects number classes demonstrate supervised semi supervised words latent found unsupervised algorithm latent
abstract out search problem active learning schemes better adaptive improve sample complexity give various upper lower bounds number labels need prove active learning rule good other strategy minimizing number labels
neuron visual cortex most inputs other cortical neurons similar stimulus does inputs allow efficient sensory information target cortical neuron address using simple neuronal population activity information find efficient synaptic information requires curve neurons wide stimulus neurons target neuron analysis data found case cortical inputs neurons visual cortex suggest cortical synaptic inputs allows optimal information
consider semi supervised learning problem decision rule learned labeled data framework minimum entropy regularization data standard supervised learning our approach includes other approaches semi supervised problem particular cases series experiments proposed solution data method mixture models data distribution class generative model minimum entropy regularization generative models data provides cluster assumption finally illustrate method far superior learning high dimension spaces
alternative important step expression allows single multiple biological processes mechanisms well have developed levels large scale present here generative model array demonstrate its levels different learning performed using variational expectation maximization algorithm parameters shown capture expected comparison results obtained well but low through experimental method demonstrate levels obtained highly predictive levels biological through alternative current estimates number human small number has number cannot account complexity cell higher ie complexity achieved through use alternative single used code information required cell information using corresponding four make up what known into cell information generally both information cell out estimated human figure four types represent represent possible single single alternative alternative other alternative alternative both but may alternative two alternative may but both may different called alternative four types shown figure many multi may more than alternative resulting many possible single addition single code more than has been shown critical processes its specific work presented here inference single levels figure based data obtained expression known data set alternative although possible directly analyze cell often more instead measure present expression has been studied using low techniques such limited few sequences time making large scale analysis early method capable expression sequences simultaneously sequences interest size small form cell back into sample over sample array measured each generally measure related cell over wide dynamic range significant recent data still presents analysis low measurements have low signal noise ratio often sequences similar but they designed process figure each alternative studied using chosen measure expression levels each three used target each two would while would exhibit varying efficiency sequences exhibit varying efficiency design our data sets sequence strong analysis provided potential design samples type brain each has target chosen regions shown figure unsupervised alternative alternative figure measure sequences both example while sequence designed measure sequence found therefore assume measured each result certain amount both due generally linear relationship between measured model measured weighted sum two assumption single consistent both across would estimate individual each studied across our current number small resulting two first number parameters large compared number data point using model second do exhibit specific alternative within our small set while first could using parameter estimation second cannot generative model alternative array using described above expression vector containing measurements real linear combination two represented real vector noise noise weight matrix containing figure graphical model alternative each observed expression generated either using scale factor linear combination randomly model description model see text two across note may have negative amount given presence measured expression so both constrained positive expression levels measured have previously been expression dependent noise address above formulation scale factor zero mean distributed random variable covariance matrix prior distribution given normal distribution function such need account observations eg due model complete model shown figure observations either applying equation model cases results number considered each may two constraint node figure distribution conditional latent variables random variable result model model parameters model set mean variance data variational learning model posterior distribution over while same time learning model parameters use variational expectation maximization algorithm em em log likelihood data estimating posterior distribution model given data expectation step log likelihood respect parameters while posterior fixed maximization step variational em used case exact posterior variational em free energy model defined between joint distribution latent observed variables approximation posterior under model parameters approximate true posterior using distribution given st st constant constrained computational efficiency finite set probability variational free energy given st variational em free energy distributions td parameters step model parameters step resulting updates long shown context paper discussed few particular points step here log prior full normal distribution would need variational approach exact em possible normal distribution cannot analytically case constraint note full covariance matrix equation would true posterior could find sufficient statistics matrix elements furthermore easily shown optimal normal distribution full covariance mean optimal optimal case equation still true equation does optimal cannot found analytically our experiments found using equation still free energy every step significantly more efficient than using example gradient method compute optimal matrix optimal weight matrix figure set weights based biological would see while learned set weights cross between model original data model prediction figure three examples data cases their predictions data does our single but level predicted model predict other two model still levels making biological predictions about alternative results presented paper obtained using two learning first step weight matrix learned subset data quality two selection used data used those cases high confidence other present figure sets high expression determined set negative second selection criterion common assumption low measurements quality see section second step fixed introduce additional constraint noise learn data set constraint noise introduced model using subset making set predictions show learned set weights figure weights fit well our what they should capture presence two moreover learned weights account specific data examples model prediction based data shown figure due nature data do good criterion each based its fit model given two input vectors equivalent up scale factor map equal up same scale factor would like their criterion used therefore correlation positive rate table model performance various using measurements able predict models performance various two evaluation used correlation between models predictions measurements positive rate prediction considered positive more than map used criterion sum noise signal estimated using two values given observation models best prediction observation relative amount most interest need use distribution obtain estimate relative levels should do have measurements us see figure using top fit three parameters such present given map estimation map estimation used target parameters using gradient descent least error evaluation criterion used two evaluate quality model predictions correlation used evaluate ability model estimate data invariant transformation so independent transformation parameters discussed above while parameter found effect above top two predictions second evaluation criterion used positive rate prediction considered positive more than allows us example prediction within top within levels designed novel model inference relative two measurements unsupervised learning model performed using variational em algorithm underlying structure data suggested its biological nature model presented here used learn type simple multiple types predictions obtained model being used various about role functional identify sequences model predictions model prediction measurements model prediction figure sample cell sample through field being further through than resulting two corresponding two showing measurements compared model predictions shows available measurements better model presented single weight matrix data cases view data current work being out specific expression due low dimensionality problem per taken overfitting would like their generating data set work part research et al wide human alternative et al understanding nature et al global features alternative using cell et al alternative specific human
vlsi accuracy analog circuits learning performance large scale neural networks implemented show low power chip techniques our techniques large scale analog vlsi neural networks learning performance order demonstrate our techniques linear perceptron learning least mean algorithm cmos process
analysis known uncertainty difficult important problem natural language processing matching many other tasks paper several conditional probability models analysis examples graphical models many approaches models presented here they do assume pairwise should made each other other models generative conditional model here variety features input without about their advantages conditional random fields over hidden markov models present positive results two standard text data sets
recent probabilistic generative models networks classical statistical structure such networks global such our mixture analysis simulation experiments data set
decision trees adaptive three important they automatically conditions near bayes decision focus data distributed lower dimensional features paper decision tree based each these conditions achieve optimal rates convergence proposed classifier first known achieve these optimal rates while being practical
given graph nodes labeled investigate question link structure graph labels nodes propose regularization framework functions defined over nodes graph classification function change yet computationally simple classification algorithm derived within proposed framework experimental evaluation real world classification problems results our approach
generative probabilistic model objects images presented object consists features feature scene images generated set objects given database random image study case features same object common moreover parameters shape across features previous work probabilistic models features each other each feature model have different statistics these two allow us models containing features well train each model single example our model may probabilistic model propose efficient entropy minimization inference algorithm best interpretation scene objects test our experiments two image compare algorithm demonstrate better performance particular presence large
address problem learning symmetric positive matrix design parameter updates positive our updates rather than most general case focus two key applications our methods line learning simple loss finding symmetric positive matrix symmetric linear constraints updates generalize gradient eg update parameter now symmetric positive matrix instead probability vector context positive matrix generalized updates use matrix positive most show analysis each algorithm non case apply both new algorithms called matrix gradient update learn kernel matrix distance measurements
most existing tracking algorithms construct representation target object prior tracking task invariant features target view change paper present efficient effective online algorithm learns low dimensional representation changes target tracking task furthermore our method updates sample mean existing update methods fact sample mean over time tracking problem state inference problem within markov chain monte carlo framework filter sample distributions over time experiments demonstrate proposed tracking algorithm target objects large changes
study number spectral clustering appropriate scale analysis ii multi scale data clustering finding automatically number first propose local scale should used compute between each points local scaling leads better clustering data includes multiple scales clusters within further suggest structure automatically number leads new algorithm randomly means stage
paper presents adaptive generative model conventional linear algorithm probabilistic interpretation within context object tracking find generative model best target present computationally efficient algorithm update model time while most tracking algorithms object condition does significantly change time our method generative model target tracking task experiments show our method able learn generative model tracking target objects large changes
present unsupervised algorithm object significant our algorithm does need does assume prior knowledge about object shape dynamics its algorithm two joint probabilistic model over point between them model local well more global constraints capture distance between corresponding point pairs algorithm even range thus used automatically partial even those previously different evaluate algorithm several real world datasets demonstrate good results presence significant movement parts non finally show output algorithm used computer tasks such interpolation between two non object object models
introduce computationally efficient method estimate method function graph connectivity network size present numerical results demonstrate our estimates random model real world network although method interactions local evidence zero binary variables its predictions capture inference map estimation arbitrary graphical models using approach find performs better than large networks degree distributions such scale free networks out significantly
paper choice svm cost parameter critical derive algorithm fit path svm solutions every value cost parameter same computational cost svm model
complex objects often represented finite sets components such images sets words study class positive kernels two such objects function their sets components prove general representation such kernels present two particular examples them leads kernel sets points space positive kernel provide experimental results experiment image classification illustrate approach
present novel approach prediction using low norm instead low approach has strong connections large margin linear discrimination show learn low norm solving semi discuss generalization error bounds them
paper computational synaptic plasticity individual model neurons new plasticity mechanism continuous activation model neuron based low order neurons firing rate distribution goal plasticity mechanism sparse distribution neurons activity level learning neurons synapses neuron shown sparse input
motor control depends sensory feedback multiple different paper consider within framework reinforcement learning different sensory combined real time optimal movement control propose architecture multiple whose output combined using function tested our architecture simulation sequential task visual feedback long our learning scheme agent feedback hand near trajectory simulations different visual feedback found agent more feedback
consider semi supervised learning label sampling mechanism depends true response well features suggest method estimating stochastic using data useful two input supervised learning procedure used de bias its results using labeled data interesting learning task present several examples illustrate practical our method
context provides cues associated image obtain face images using face images automatically link obtained using these simple clustering method produce results improve these results significantly clustering process model probability individual given its context procedure over have labeled set model each individual natural language model produce accurate results
describe novel method real time multi view face detection estimation method network map face images points non face images points far network trained loss function three variables image face label test resulting system single three standard data sets find its performance each set previous multi view face form show experimentally systems accuracy both face detection estimation improved training two tasks together
recently have been several machine learning pattern recognition learning algorithms construct nonlinear low dimensional sample data points high dimensional spaces paper develop algorithms address two key learning adaptive selection better local structure account its sampling density data set illustrate our methods synthetic data sets
propose probabilistic generative account learning classical learning experiments generalize between patterns simultaneously presented stimuli such predictive reinforcement previous models these have been more than level they experimental but provide basis understanding they do present theory arbitrary previous models while set data key patterns data eg patterns varying shown statistical inference
evidence studies brain bayesian inference decision making important question bayesian inference arbitrary graphical models implemented networks spiking neurons paper show recurrent networks noisy neurons perform approximate bayesian inference dynamic hierarchical graphical models potential dynamics neurons used implement belief propagation log domain spiking probability neuron shown approximate posterior probability state neuron given inputs illustrate model using two examples motion detection network spiking probability direction selective neuron posterior probability motion direction two level hierarchical network effects similar those observed visual cortical areas hierarchical model new bayesian interpretation modulation
study neural coding selective attention perceptual decision making hierarchical neural architecture proposed bayesian noisy sensory input sound perceptual discrimination model experimentally observed modulation prior information stimulus feature location have independent feature orientation networks levels representation known properties visual cortical neurons model possible cortical representations uncertainty
consider problem classification task predict label input has internal structure our framework includes supervised training markov random fields weighted context free special cases describe algorithm large margin optimization problem defined using exponential family distribution representation objects algorithm efficient even cases number labels exponential size provided certain under distributions efficiently method labels more general result application gradient updates quadratic
investigate approach simultaneously multiple each extended action semi markov decision process each activity define set solutions set optimal policies those policies optimal function associated them generated them such way solutions set solutions superior present our theoretical results evaluate our approach simulated domain
present algorithm perform speech separation our algorithm mixtures speech without modeling individual instead problem speech separation problem signal into two more sets feature sets our using classical cues speech these features into matrices take advantage fact generate training examples segmentation signals thus parameters matrices using recent work learning spectral clustering yields adaptive speech specific segmentation algorithm successfully speech mixtures
algorithms search low dimensional structure complex data but most algorithms objects single type pairwise paper describes method objects different types such images text into single common space based their statistics joint distributions low dimensional space problem convex optimization over positive matrices local structure our statistical correlations via random space performance our method two text datasets show significantly standard methods statistical modeling such scaling analysis
learning way probabilistic predictive action models includes methods finding using hidden state make predictions more accurate extend original mechanism arbitrary discrete improve original learning domains better hidden state using predictions these show large improvement over original mechanism several achieve low prediction error difficult speech modeling task further compare extended learning recently introduced predictive state representations find their predictions next step action effects equal accuracy work based system learning planning
derive optimal learning rule sense mutual information maximization spiking neuron model under assumption small input find spike timing dependent plasticity function depends time function neuron show function has both positive negative positive phase related shape while negative phase neuronal
many have shown strong connections learning examples regularization techniques inverse problems now evidence learning examples could inverse problem theoretical results learning theory could derived using regularization theory paper provide positive both loss learning problem language regularization theory show results optimal regularization parameter choice derived corresponding inverse problem
statistical approaches language learning typically focus either short range long range between words present generative model uses both used simultaneously find classes representation statistical model competitive tasks like part speech classification models use long range
problem norm sense positive symmetric matrix matrix upper bound its problem decomposition covariance matrix into sparse factors has wide applications use classical variational representation symmetric matrix constrained derive programming based our problem
have constructed system uses array spiking neurons fast digital memory implement network neurons system designed spiking neural networks require high address hardware arbitrary network implemented address specific internal according memory based field mapping system demonstrated three stage network input address regions image performs spatial modulation high resolution location
application reinforcement learning algorithms often involves hand necessary non linear features reduce complexity value functions convergence algorithm contrast human brain complex features provided sufficient training recent work machine learning has demonstrated role cortex reinforcement learning paper new reinforcement learning algorithms evidence provides potential new approaches feature problem algorithms compared task
investigate problem complexity graphical model finding chosen class such optimal respect do first decomposition tree representation related tree representation give algorithm uses representation compute optimal have used graph separation properties solve several optimization problems size minimal graph present extension technique important even size minimal large particular problems such finding optimal model over tree graphical model over tree arbitrary optimal model constant respect solved time polynomial using formulation
bayesian regularization proposed estimating time signals filter coefficients using norm regularization probabilistic generative model used simultaneously estimate regularization parameters filter coefficients signal data iterative update rules derived under bayesian framework using expectation maximization procedure resulting time delay estimation algorithm demonstrated noisy data
paper use method policy improvement analyze version version called has but rules strategy using about many average human does
describe approach brain computer based graphical models probabilistic inference learning show dynamic bayesian network used probability distributions over states during planning actions learned directly observed data allows measured signals such eeg terms internal states such activity movement traditional classification based approaches proposed approach allows continuous tracking prediction internal states over time control signals based probability distribution over states rather than binary present results state estimation using eeg signals during self hand movement task
paper effect kernel principal component analysis within classification framework regularization properties dimensionality reduction method has been previously used processing step applying svm but point out method regularization point view propose new algorithm called kernel machine based statistical framework regression gaussian noise model experimental results show algorithm same svm
areas brain various memory exhibit patterns neural activity quite those computational models show use well bayesian probabilistic derive neuronal dynamics models together appropriate values parameters such time constant explicitly two cases standard learning rule involves activity patterns firing rates other spike timing dependent learning rule involves patterns phase spike times relative local field potential our model new more complete understanding neural dynamics may support
existing algorithms discrete observable markov decision processes best solve problems few states due two important sources dimensionality policy space complexity paper describes new algorithm both sources value technique policy iteration demonstrated synthetic network problems up states
introduce new algorithm based linear programming differential value function average cost markov decision process via linear combination basis functions algorithm out form cost version error error bound scales number states without strong condition required its propose path following method selection important algorithm parameters represent state relevance weights studied
online mechanism design problem sequential decision making stochastic environment multiple self goal make value self interest previous work presented markov decision process based approach large scale problem domains practice underlying solve large mechanism consider approximations may able approximation gain sparse sampling based algorithms implement efficient policies approximate our approach context dynamic connectivity
area under curve has been evaluation criterion problem study large properties particular derive distribution free large bound bound expected accuracy function terms its empirical independent test sequence comparison our result corresponding large result classification error rate suggests test sample size required obtain accurate estimate expected accuracy function confidence larger than required obtain accurate estimate expected error rate classification function same confidence simple application bound allows large bound extended learned functions chosen finite function classes
present effect large class learning algorithms local kernel learning algorithms dimensionality dimension true underlying observation suggests explore non local learning algorithms structure different criterion such algorithm proposed experiments estimating prediction function presented showing its advantages respect local learning algorithms able generalize far training data learning image local non parametric method
analog system chip kernel based pattern classification sequence estimation presented state transition probabilities input data generated support vector machine product based kernels support vector coefficients implemented analog circuits probabilities using threshold current circuits input state support vector forward kernel machine chip cmos experiments trained speaker sequence estimation demonstrate real time recognition accuracy point power
both objects images both local image data well information introduce random fields uses boosting learn graph structure local evidence conditional random field graph structure learned graph model connections between individual but using graphs information large regions image models support efficient inference show information other objects improve detection performance both terms accuracy speed using computational apply our system scenes
propose novel framework approximations probabilistic models framework based free energy negative log likelihood generalization adaptive expectation propagation free energy constructed two distributions different model such single node constraints consistent chosen set test framework difficult problem binary variables fully connected graphs grid graphs find good performance using sets either nodes tree nodes approximation approximation gives results even
clustering prediction sets curves important problem many areas often case curves each other continuous manner either space across measurements time develop probabilistic framework allows joint clustering continuous sets curves curve space fixed dimensional space proposed new probabilistic models model based curve clustering algorithms probabilistic approach allows consistent em learning algorithms joint clustering problem experimental results shown human data joint clustering expression time data
present graphical model tracking using probabilistic graphical model allows us local information global constraints manner evaluate our model set difficult examples achieve results using fast tree algorithm graphical model inference our system less time than being
study method optimal data classifiers convex combination upper bounds its risk respect convex loss function under assumption solution optimal problem sparse use boosting type algorithm optimal develop classifiers activation patterns based locally trained svm classifiers coefficients used design boosting map brain identify regions most significant classification
call behavior its rather than step solving specific problem practical value but what learn during behavior our development able efficiently solve wide range practical problems they paper present initial results computational study reinforcement learning artificial construct extend
graphical models layer observed random variables more hidden random variables have been many research fields although approach has causal these models make difficult posterior distribution over hidden variables paper propose alternative two layer model based exponential family distributions models inference these exponential family fast while learning performed minimizing family studied alternative probabilistic model latent experiments shown they perform well retrieval tasks provide solution
many sequential prediction tasks patterns sequences generative probabilistic language models such hidden markov models hmms have been successfully applied many these tasks these models they cannot cases pattern arbitrary ways present alternative approach based conditional markov networks represent elements show efficiently train perform inference these models experimental results domain show our models more accurate patterns than models based hmms
whose complexity has suggest using probability bayesian sense model uncertainty complexity tree present simple conditional markov random field model model spatial structure describe version process sampling model during learning apply belief propagation inference prediction model trained several our experimental results indicate model successfully learns predict its
has been suggested goal sensory system represent input such way reduce high degree given noisy neural representation reduce effects noise here propose model best reduction representation like previous models our model structure simple cells but different population noisy limited capacity units optimal representation multi scale representation compared previous models data these results new number neurons retina provide theoretical model useful into efficient neural representations
bias images important problem image processing most previous approaches have used maximum likelihood method increase likelihood single image estimating unknown image bias field defined either terms existing model non terms images values both cases specific location image used suggest new approach simultaneously bias set images same but different use statistics same location across different images rather than within image bias fields images simultaneously method multi resolution non parametric model image location while bias fields associated original image set present experiments both synthetic real data sets present other methods
propose hierarchical process bayesian model clustering problems multiple data each data mixture number components being automatically model further components across across well generalization new such clustering problems often practice eg problem report experimental results three text showing effective superior performance over previous models
present novel method learning gaussian process regression hierarchical bayesian framework first step kernel matrices fixed set input points learned data using simple efficient em algorithm step does require parametric form covariance function second step kernel functions approximate learned covariance matrix using generalized method results complex data kernel evaluate our approach images proposed hierarchical bayesian method leads prediction performance
various problems machine learning statistics pairwise among set objects often these properties metric applications metric data useful include clustering classification metric based approximation algorithms various graph problems paper presents metric problem given matrix find nearest matrix measures paper efficient algorithms compute optimal solutions structure problem algorithms have time linear number constraints methods easily additional speed
context binary classification define measure often two trained models their classification data explore use error estimation model selection call procedure validation two models another results data assume relatively compared labeled data show per instance estimate variance error instance show provides lower bound prediction generalization error upper bound variance prediction error variance average error across variance measured across training sets present experimental results several data sets validation error estimation model selection procedure effective active learning training sets random cross validation error
problem learning sparse combination kernel functions kernel matrices classification regression achieved via regularization norm paper present algorithm regularization path these problems path obtained using numerical techniques involves time complexity constant times complexity solving problem value regularization parameter setting kernel linear regression kernel regression show effect norm regularization non norm regularization used variable selection regularization path particular value case
consider setting reward function change during each time step manner yet dynamics fixed similar experts setting address question well agent do compared reward achieved under best policy over time provide efficient algorithms have bounds size state space instead these bounds certain time process number actions show case dynamics change over time problem computationally
many machine learning algorithms clustering dimensionality reduction take input points space construct graph input data points graph clustering used metric information dimensionality reduction has been much recent work new methods graph based clustering dimensionality reduction but much graph graphs typically used include graph local fixed grid graph image segmentation nearest neighbor graph suggest graph should locally structure data achieved graph ensemble multiple minimum trees each fit version data set show such graph ensemble usually better representation data than standard methods provides clustering dimensionality reduction algorithm based graph
study discrimination human using combination classification discrimination experiments together methods machine learning reduce dimensionality set face images using principal component analysis train set linear classifiers reduced representation linear support vector machines relevance vector machines linear classifiers using human classification data because linear linear classifiers system linear classifier us decision image corresponding normal vector each classifier predict transition along normal vector classifiers human classification svm should faster than transition along other direction discrimination experiment using decision images stimuli consistent prediction
spike patterns have often been taken evidence chain stable spike through feedforward network spike intervals represent spike pattern propagation speed spike between propagation speed network structure well while propagation speed depends might related spike patterns analyze feedforward network connectivity using equation show both spike stable certain parameter region demonstrate propagation speed depends firing patterns same network
propagation technique statistical has been applied solve problem both principle practice give using probability common propagation belief propagation several interesting hybrid methods present numerical experiments use used random based complexity function their parameters both randomly generated after propagation properties have previously been reported make its mean cost number variables ratio variables its behavior underlying structure solution space has been predicted analysis between various methods search shows far more than has been suggests interesting new practical algorithm development
paper provides multi task learning using kernel spaces vector functions setting kernel matrix function examples described our results particular classes kernels linear product invariant type discuss these kernels used model between tasks present linear multi task learning algorithms finally present novel theorem regularization functional based minimal norm interpolation
present part based approach recognition object classes scenes objects parts local observations found interest each object class probability given parts local features conditional random field propose extension framework hidden variables class conditional into framework part based object recognition parameters estimated maximum likelihood framework recognition finding most class under our model main advantage proposed framework allows us assumption conditional observed data ie local features often used generative approaches assumption might number object classes
consider multi agent systems whose environment reinforcement learning policies they policies introduced random initial their policies explain provide evidence agent important these mechanisms simulations over data
finding minimum norm representation signal given basis vectors important problem many application domains required optimization problem often because increase number local number basis vectors has most instead minimize measures such norm lead more computational methods procedure have now introduced between our goal our objective function paper demonstrate sparse bayesian learning based method minimizing norm while number local moreover derive necessary conditions local via approach demonstrate typically many general problems interest
present competitive analysis bayesian learning algorithms online learning setting show many simple bayesian algorithms such gaussian linear regression bayesian regression perform compared single best model model class analysis does assume bayesian algorithms modeling assumptions correct our bounds even data chosen gaussian linear regression using our error bounds best bounds online learning provide lower bound showing gaussian linear regression optimal certain case sense give bounds used maximum map estimation algorithms including regression
multi problem online algorithm set sequence so minimize total cost chosen while upper lower bounds known case strategy set finite much less known strategy set here consider case set subset cost functions continuous case improve best known upper lower bounds factor consider case cost functions convex recent online convex optimization algorithm feedback model multi problem
representation signals wide range auditory tasks require both time frequency demonstrated many filtering properties could terms efficient coding natural model account properties such phase sound could terms action here extend theoretical approach algorithm learning efficient auditory codes using spiking population code here propose algorithm learning efficient auditory codes using theoretical model coding sound terms spikes model each spike time position time varying kernel function kernel functions statistics natural show compared conventional signal representations spike code far coding efficiency furthermore kernels show both measured filters similar frequency
propose new method clustering based finding maximum margin through data problem terms matrix problem convex although still yields difficult computational problem clustering constraints soft clustering formulation solved our clustering technique depends data through kernel matrix easily achieve nonlinear same manner spectral clustering experimental results show our maximum margin clustering technique often more accurate results than conventional clustering methods real our approach leads semi supervised training method support vector machines margin simultaneously labeled training data achieve state performance using single learning principle
describe way using multiple different types similarity relationship learn low dimensional our method different representations similarity dimensions common underlying latent space applied single similarity based between input data points method simple dimensionality reduction additional information available about about use information up improve demonstrate potential form semi supervised dimensionality reduction simple examples
propose family kernels based theorem its extension includes special cases known kernels derived framework processes kernels kernels graphs kernels sets approach many these kernels new kernel functions leads new special cases application apply new class kernels problem clustering video sequences results
choice based analysis models over our main goal machine learning solve problem more efficiently thus propose two algorithms estimate
provide principle semi supervised learning based rate labels points information information terms sets points regions labels each region same resulting regularization objective convex has solution solution found local propagation graphs regions analyze properties algorithm demonstrate its performance classification tasks
interactions typically interaction more small two these important design paper propose computational method based probabilistic model address task using high interaction data set short sequence learn model using em algorithm bound algorithm approximate inference step our method whose presence explain their observed interaction determine pairs have high therefore lead interaction show our method more accurate than new interactions more solved structures find predicted active interaction
while clustering usually unsupervised varying should same cluster while should would like such pairwise cluster out sample data manner consistent prior knowledge training set our point probabilistic clustering based gaussian mixture models data distribution clustering prior distribution over data points clusters prior cluster according degree they fit model parameters em experiments variety data sets show improve clustering results
have recently proposed extension regression uses paper extend theoretical results obtained boosting its first extend recent results efficient margin show algorithm converge maximum margin within precision finite number steps provide confidence type bounds generalization error
describe three dimensional hand model visual tracking applications constraints models have probabilistic structure well described graphical model inference model many well image measurements use belief propagation develop tracking algorithm graphs structure control complexity while while constraints have local structure process lead complex based likelihood functions show local structure may binary hidden variables state each algorithm these variables distributed analytically over them produce hand position estimates account provide simulations showing may used model well hand motion through extended image sequences
such provide source knowledge natural language processing applications but extend problem automatically such paper present new algorithm automatically learning text our method work using small hand expression patterns identify pairs using path features trees introduce general generalization these patterns given training set text containing known pairs our algorithm automatically useful them new identify novel pairs our evaluation task whether two relationship our automatically database both higher precision higher than
first order markov models have been successfully applied many problems example modeling sequential data using markov modeling control problems using markov decision processes first order markov models parameters estimated data standard maximum likelihood estimator first order single step transitions but many problems conditional assumptions result higher order transition probabilities may problem learning parameters control propose algorithm learning first order markov model explicitly takes into account higher order interactions during training our algorithm uses optimization criterion different maximum likelihood allows us learn models capture range effects but without up using first order markov models our experimental results show new algorithm conventional maximum likelihood estimation number control problems parameters estimated data
consider problem set together set eg hand unknown times unknown locations propose solution problem under far field approximation defined value decomposition structure problem define low dimensional optimization techniques solution into further techniques locations times approach useful networks
type models usually because their other hand model basis most theoretical studies spiking neuron models here develop sequential procedure evaluate equivalent type model based cortical neurons find resulting effective model sufficient predict spike train real neuron high accuracy like predicted almost significant part spikes predicted correct timing processes like spike frequency adaptation shown key feature context they necessary model between different
training learning algorithm task goal active learning reduce cost paper introduce new algorithm capable learning large scale problems using selective sampling algorithm sampling step well known query algorithm low dimensional space use kernels simple way non linear sampling low dimension space using random demonstrate novel algorithm applying both artificial real world problems
analog array has been developed filtering perform kernel steps simple analog processing developed line parallel processing scheme nearest neighbor architecture has simple implementation concept chip cmos filtering rate has been experimentally demonstrated
paper presents based probabilistic interpretation spectral clustering dimensionality reduction algorithms use graph given pairwise matrix points define distance between two data points show low dimensional representation data first few corresponding markov matrix optimal under certain mean error criterion furthermore data points random samples density identify these discrete approximations potential conditions finally applying known results continuous provide spectral clustering dimensional reduction algorithms based these first few analysis terms characteristics processes many empirical spectral clustering algorithms algorithms architectures learning theory
paper presents representation contrast visual scenes terms both objects natural scenes objects include while human graphical include other abstract our analysis both natural graphical domains basic problem interactions among local image contrast such natural constraints among these visual scenes sparse markov random field framework define set interpretation nodes functions among them minimum energy found belief propagation shown human interpretation across wide range examples including important such well more difficult examples practical terms approach correct hand low computational cost
based large scale spiking neuron model input identify neural mechanisms observed contrast dependent receptive field size cells variety mechanisms analyze them based relative gain synaptic inputs average spatial low contrast predicted models models our simulation results suggest sufficient necessary explain
paper neuronal population responses time dependent inputs role synapses neural information processing have derived equation potential density function synaptic obtain computing response rate through analysis several inputs important role information processing temporal detection role synapses temporal important neural information processing spatial distribution synapses spatial temporal inputs input frequency response amplitude phase delay
paper present our design experiments robot under neuronal control goal study neuronal mechanisms obtain fast speed line learning circuit parameters our controller motor neuron models including local position trajectory tracking control algorithm instead controller allows its natural dynamics during critical its our knowledge first time dynamic achieved using controller addition structure allows using policy gradient reinforcement learning algorithm parameters controller real time during way relative speed per second after few online learning faster than other robot relative speed human addition stability domain stable quite large design strategy
define probability distribution over classes binary matrices finite number number distribution use prior probabilistic models represent objects using array features identify simple generative process results same distribution over classes call process illustrate use distribution prior latent feature model markov chain monte carlo algorithm inference model applying algorithm image
prove known bound risk ensemble generated learning algorithm training data our result based techniques different standard risk analysis based convergence
consider least gaussian kernel prove gaussian while regularization parameter solution polynomial whose order rates solution order polynomial minimal empirical error illustrate result example
supervised learning feature selection has been studied features unsupervised learning much problem due class labels would search relevant information almost previous unsupervised feature selection methods techniques require learning algorithm evaluate feature paper propose filter method feature selection independent learning algorithm our method performed either supervised unsupervised proposed method based observation many real world classification problems data same class often close each other feature its power compare our method data variance unsupervised supervised two data sets experimental results demonstrate efficiency our algorithm
propose mean field approximation computational complexity solving stochastic dynamic provide conditions our method number derive performance bound well approximation performs given number apply our method important class problems applied show numerical experiments able set problems computationally
given basis vectors our goal find sparse representations signals previously have sparse bayesian learning framework well task showing has far local than other bayesian paper provide further evidence condition based distribution generating model weights solution equal sparse representation prove these weights approximate prior probability our condition finally case demonstrate still better than most used sparse representation algorithms these include basis based convex norm matching simple strategy basis vectors most current
variational bayesian framework has been used approximate bayesian learning various applications has provided computational good generalization performance paper discuss variational bayesian learning mixture exponential provide additional theoretical support asymptotic form stochastic complexity stochastic complexity minimum free energy lower bound likelihood key model selection us discuss effect accuracy variational bayesian approach approximation true bayesian learning
considered distribution intervals statistical model neuronal spike model parameters time dependent firing rate shape parameter spiking individual neurons because environment changes time observed data generated time dependent firing rate unknown function statistical model unknown function called model problem statistics generally difficult solve used novel method estimating functions information estimate shape parameter without estimating unknown function analytically obtained optimal estimating function shape parameter independent functional form firing rate estimation efficient without information loss better than maximum likelihood estimation
multiple visual cues used visual system analyze scene cues include contrast motion have shown visual cortex neurons scene structure eg orientation type information paper shows invariant response properties complex type cells learned natural image data unsupervised manner order do extend previous model so applied model complex cell responses our results invariant response properties natural image statistics showing statistical modeling approach used model processing response properties visual neurons work learn natural image data more feature than those based changes mean way new data approaches image processing computer vision
fast well studied models research has proposed take best strategy decision making limited take good cues features task objects compared investigate complexity problem optimal show efficient algorithm approximate within constant factor further consider approach derive bounds performance ratio new simple algorithm algorithm perform better than take best
recent experimental results suggest back spikes synaptic plasticity different ways study investigate these signals could plasticity properties local clusters similar previous study differential plasticity rule spike timing dependent plasticity use back spikes synaptic signals learning rule investigate their interaction plasticity analyze plasticity characteristics change time type synaptic activity synapses local spikes process spike process fast synaptic changes much spike now plasticity rule way take mechanism two stage process best correlated inputs these results suggest synaptic plasticity temporal process computational properties complete neurons
present competitive analysis non parametric bayesian algorithms case online learning setting probabilistic assumptions about data made consider models use gaussian process prior over space functions provide bounds under log loss used non parametric bayesian algorithms including gaussian regression regression show these algorithms perform under rather general conditions these bounds explicitly dimensionality these non parametric classes natural way make connections minimum description length framework here show bayesian gaussian regression strategy
consider problem estimator finite class functions convex risk functional under constraint propose stochastic procedure descent performs gradient descent space generated estimates specific weights descent algorithms have been developed different they known efficient high dimensional problems moreover their implementation online setting main result paper upper bound convergence rate generalization error
separation signals interesting but difficult problem many other such analysis paper new signal separation method proposed based structure modeling main idea structure modeling structure signal stable so signal represented structure model corresponding separation algorithm proposed main idea learn structure model each signal mixture signals using these models structures different signals experimental results show algorithm signals obtain high noise ratio but rather good quality
natural world selection relevant visual cues attention investigate whether our visual system cues search optimal manner obtain optimal selection strategy signal noise ratio between search target optimal strategy successfully several visual search behavior including effect target uncertainty features linear furthermore theory new prediction through experiments human subjects our results provide direct experimental evidence visual cues so between
present non linear simple yet effective feature subset selection method regression use cortical neural activity our algorithm involves feature weighted version nearest neighbor algorithm able capture complex target function its input makes use out error natural regularization explain characteristics our algorithm synthetic problems use context hand spikes motor cortex applying feature selection able improve prediction quality suggest novel way neural data
images represent important source data understanding their statistical structure has important applications such image paper propose particular probabilistic model model describe structure images develop practical algorithm based single show state performance images
perceptron algorithm its often performs well online classification tasks perceptron effective used kernels common kernel based online algorithms amount memory required online hypothesis may paper present analyze algorithm kernel based online learning fixed memory our knowledge first online learning algorithm hand limit number examples while other hand relative bound addition results present experiments real datasets our approach
present new connectionist model use neural networks represent show each corresponding neural network ensemble provides parallel model sets scene knowledge representation learning neural networks networks ensemble trained examples using standard neural learning algorithms
matrix approximation recent technique dimensionality reduction data analysis yields parts based sparse representation input data has found wide variety applications including text analysis clustering recognition language modeling speech processing many these applications development computing factors has been relatively paper makes modeling solving using updates new generalized problems minimize between input matrix its approximation update work special case our algorithms addition paper shows use functions constraints other than into problem further interesting use link functions modeling nonlinear relationships discussed
spectral clustering its both data clustering learning but most spectral clustering algorithms cannot multi class clustering problems directly additional extend spectral clustering algorithms multi class clustering problems furthermore most spectral clustering algorithms cluster local paper present new spectral clustering algorithm soft algorithm soft efficiently computed using bound optimization algorithm our experiments variety datasets have shown performance proposed clustering algorithm
propose probabilistic model based independent component analysis learning multiple related tasks our model task parameters generated independent sources account tasks use distributions model hidden sources makes possible identify hidden independent components instead modeling correlations furthermore our model property makes both robust propose efficient algorithms both empirical bayes method point estimation our experimental results two multi label text classification data sets show proposed approach
paper presents new framework based graph analysis inference gaussian graphical models key idea correlations between variables sum over between those variables graph weight each given product partial correlations provide sum interpretation gaussian belief propagation trees approximate method belief propagation graphs leads better understanding gaussian belief propagation its convergence graphs
kernel methods make relatively define complex feature spaces question identify relevant particular learning task two same available kernel correlation analysis has been shown effective step improve performance classification algorithms such support vector machine svm paper takes observation its method two stage learning svm into single svm present both experimental theoretical analysis approach showing results
propose algorithm uses gaussian process regression learn common hidden structure between corresponding sets observations observation spaces via single reduced dimensionality latent variable space present results two datasets ability novel data learned first show method learn nonlinear mapping between corresponding objects missing data novel show method learn mapping between human robot human motion capture data
present method regression performs selection variable selection simultaneously approach based technique gradient estimator respect large unknown function condition our approach dimensionality optimal rate convergence up factors relevant variables known method called regularization expectation sequence hypothesis implement version soft sequence problems
study statistical convergence boosting methods samples independent distributed but empirical processes sequences technique sequence independent close distribution original samples prove classifiers resulting regularization achieved norm classifiers weights compared case nature sampling result through generalization original condition regularization parameter
given graphical model binary hidden nodes real noisy observations consider upon maximum map maximum posterior under each node its single present variational formulation processing rules local nodes loss expected map performance such online constraints approach leads novel algorithm observations performance loss rules manner global statistics provide examples ii assumptions convergence efficiency connections active research areas
long motor learning different experimental results suggest either learns task memory dynamical system approach mechanism memory generated so called learning rule cell contrast numerical models our model simple but predictions experimental features trajectories phase space synaptic weights without parameter
study problem maximum entropy density estimation presence known sample selection bias propose three bias approaches first takes advantage sufficient statistics obtained samples second estimates distribution factors bias out second using samples sampling distribution provide first two approaches evaluate performance three approaches synthetic experiments real data modeling has been successfully applied sample selection bias significant problem
paper presents new filter online data problems high dimensional spaces key representation data posterior information form objects numerical these requires linear time compared exponential time required computing exact posterior probabilities paper algorithm provides results using data obtained real world array large scale network simulation
previous work has demonstrated image many objects human particular under variable low dimensional linear spaces linear learning algorithms include principal component analysis pca linear analysis these methods consider image high dimensional vector while image represented matrix paper propose new algorithm called analysis image second order two vector spaces relationship between vectors image matrix between vectors local structure space learning lower dimensional compare our proposed approach pca methods two standard experimental results demonstrate better recognition rate while being much more efficient
propose propagation distributed across network convergence convergence rate graphs demonstrate better scaling properties than pairwise alternative has much recent attention propagation special case belief propagation our results belief propagation particular connected graphs few classes relevant problems belief propagation known converge
investigate learning object single image instead using large number object use labeled database other objects learn noise knowledge used predict two new objects do training same object propose scheme called address task random binary training set chosen together images given object those extended complete image space simple learning algorithm given two images responses combined bayesian rule into posterior probability similarity experiments database database compare our method classical learning several examples positive class direct learning similarity
linear analysis sensitive problem data robust problem explicitly model data uncertainty classification problem case under model main paper show general convex uncertainty models problem data robust out using convex optimization certain type product form uncertainty model robust out cost standard method demonstrated numerical examples finally show extend these results robust kernel analysis ie robust high dimensional feature space
present generalization temporal difference networks include abstract question network temporal difference td networks have been proposed way representing learning wide variety predictions about interaction between agent its environment these predictions their defined terms other predictions they about what would action sequence actions taken conventional td networks related predictions time steps single action here generalize them extended time intervals whole ways our generalization based framework temporal paper introduce new algorithm option learning td networks function approximation present empirical examples our algorithms td networks feature temporal difference td networks sutton they general learning learning predictive being agent learning problem such what see step forward right see perceptual might set predictions about what would certain actions taken about what would down what would like various predict thus make prediction about set other predictions target prediction sense first prediction each other predictions td networks first framework representing predictive learning machine form each node td network individual question predicted has associated value representing question prediction represented set between nodes node node node question node question its value prediction about node prediction higher level predictions several ways lower representation language learning structure human thus agent its learning algorithm network these question network set between nodes used compute values predictions associated each node these network computation network conventional way node values computed other node values td networks should apply well feature td networks predictions node values each time used representation state world time way they instance idea predictive state representations introduced sutton representing state its predictions strategy state et al note used previous work defined terms actions observations other predictions they sense td network have discussed so far they conditional certain way predict what would see step forward right conventional td networks but they conditional actions sequences actions conventional natural generalize have examples above conditional extended ways example complex high level action hand like would see would require temporal addition state framework sutton way about extended ways about predictions their paper extend framework so applied td networks significant original framework novel features our option extended td networks they predict components option rather than full probability distributions learn according first option method use see sutton include whose policies several actions framework section present elements framework sutton need our extension td networks framework agent environment discrete time steps each state st agent action next state st action way time step framework us about extended ways individual option consists three parts first set subset states option second component option its policy agent although framework includes them here because prediction control option finally function option probability state option thus defined conventional td networks section present structure learning algorithm td networks introduced sutton td networks address prediction problem agent may have direct state environment instead each time step agent observation dependent state thus consists sequence actions observations td network consists set nodes each representing single prediction question networks suggested previously network nodes vector predictions time step predictions estimates expected value typically case they estimates probabilities predictions each time step according vector function parameter often taken linear form vector features matrix whose elements weights vector form either function function feature vector arbitrary vector function example case feature vector unit basis vector location current state observable environment feature vector may combination action observations predictions previous time step update network question network consists set target functions condition functions define target prediction define condition time learning algorithm each component positive step size parameter note here functions observation predictions time step conditions functions single action what makes algorithm learning about step td relationships together multiple nodes sutton used predict steps various particular values predict specific action sequences eg et al et al now consider extension abstract actions option extended td networks section present our option learning algorithm td networks suggested each nodes link question almost same them here difference weights step out compared ie equation now option applying over many steps policy nodes option condition function option each action taken whether option being agent option policy values possible agent option policy option has more than action consistent option significant generalization original idea actions state option cannot thus cannot here take set states least action set option option function td networks each node given corresponding function probability time option has time has values soft stochastic conditions option target but option without nodes next value should target function two mixture two used produce form td error each node ii ii our option extended algorithm see sutton short term memory variables matrix weight matrix effect each weight could have each nodes prediction during time agent has been nodes option components matrix parameter td learning algorithm because factor nodes zero agent nodes policy agent policy option does gradient way policy option does zero following time step new finally our algorithm updates weights each time step fully observable experiment experiment designed test algorithm simple state observable applied extended td network problem learning predict observations interaction environment shown left figure indicate spaces agent shown figure indicate agent each time step agent environment representing first experiment provided other directly complete state environment orientation fact option depends current predictions action observation means markov test world left question network right used experiments world location orientation agent labeled representing note left but right shows full question network corresponding structure but shown other four non actions forward three possible actions actions according fixed stochastic policy independent state probability actions agent left right agent probability same probability probability called probability forward movement would agent into agent does experiment used addition these actions provided two abstract forward forward option takes action every state agent policy option same agent probability probability used question network shown right figure predictions nodes estimates probability would observed corresponding action taken node prediction whether agent see upon option taken node probability given forward option nodes represent predictions action forward option nodes take step further they represent predictions forward option action taken forward option applied our algorithm learn parameter network question network step size parameter parameter initial each agent state figure left experiment function each value time steps each time step error each nodes prediction computed over nodes nodes corresponding option average because their correct predictions average fully observable error observable error steps steps figure learning curves fully observable experiment each probability left observable experiment right over time steps produce learning curves shown left figure probabilities error predictions almost zero after agent made almost predictions cases learning higher probabilities these results show our td network able make complete abstract model world observable experiment our second experiment observation available agent experiment provides more test our algorithm model environment well td network construct representation state sparse information fact accurate prediction possible problem our question network experiment input vector three components each total action first components set node values observation other components action next components same way first zero action technique network function represent class functions linear form than would possible experiment function probability our performance measure used error first experiment predictions actions nodes these predictions accurate because agent space error over time step produce learning curve shown right figure error zero node figure prediction agent forward corresponding nodes other predictions other upon forward make these predictions agent even many steps has learn space figure learned after time steps agent state shown first relative steps agent shows prediction node each question network predictions shown each observation forward option agent forward option would result other over steps see predictions agent fact its observation same even after steps agent way while agent after forward but up figure predicted shows prediction node each question network these nodes sequence forward forward time agent forward forward forward predictions made node each step sequence correct these results show agent able its long term predictions without directly sensory much larger would td network have same question network size problem same even network across varying other experiments training larger problems have shown same td network used here learn make long term predictions version used here st figure part what agent learns observable environment second sequence states relative time given first sequence generated agent steps agent trajectory after shown line state show values nodes corresponding figure each observation our experiments show option extended td networks learn they learn about their conventional td networks other method learning models world our option learning algorithm off policy learning method function approximation learning predictions combination these three known produce convergence problems methods see sutton they may here sound solution may require sampling see sutton paper have considered option over time within option but across sutton have proposed method option could combined our option paper
classical bayes rule posterior model probability prior probability data likelihood generalize rule case prior density matrix symmetric positive data likelihood covariance matrix classical bayes rule special case matrices classical setting probability data expected likelihood expectation over prior distribution generalized setting expected variance variance computed along prior density matrix expectation over density matrix form probability vector along direction determined covariance matrix expected variance variance matrix prior density matrix mixture state both classical generalized bayes rule minimum relative entropy principle version gives classical bayes rule relative entropy new bayes rule density matrices
show learn distance metric nearest neighbor classification programming metric trained goal nearest same class while examples different classes large margin data sets varying size find trained way lead significant classification example test error rate support vector machines learning problem convex optimization based loss learning our framework requires extension problems binary classification
functional has into active brain between functional brain regions still studied paper novel framework modeling interactions between multiple active brain regions using dynamic bayesian networks generative models brain activation patterns framework applied modeling neuronal circuits associated reward our framework machine learning use brain connectivity such models derived data through classification task compare four different types parallel hidden markov models hidden markov models fully hidden markov models hmms hmm moreover propose compare two schemes learning hmms experimental results show using classification performed even constructed few brain regions demonstrate using proposed learning algorithms different structures subjects control subjects finding provides independent test effect brain function general demonstrate computer into functional studies provides novel approach human brain function
layer vision whose components spike using address demonstrated system includes retina chip two take chip delay line chip learning classifier chip set computer address space components use mixture analog digital computation learn trajectories moving object complete experimental measurements results shown
paper provide general theorem between loss functions classification family moreover provide given loss finding loss functions given next introduce among loss functions corresponding provide necessary sufficient conditions these have applications classification problems component experiment design particular our results prove procedure learning classifier under
introduce technique dimensionality estimation based dimension asymptotic optimal error probability distribution its dimension dimension yields family estimation algorithms whose case equivalent recent method based using high rate vector address statistical analyze behavior our scheme presence noise
active learning problem supervised learning design locations training input points so generalization error existing active learning methods often assume model used learning ie learning target function model hand many practical assumption may paper first show existing active learning method under condition model does have but models out condition still practice problem propose alternative active learning method class models thus proposed method has range applications than existing method numerical studies show proposed active learning method robust against models thus
analyze classification error cases ie cases different those training set standard generalization error off training set error may significantly empirical error high probability even large sample derive bound difference between off training set standard generalization error our result based new bound missing small samples than existing bounds based good demonstrate data sets our bound gives generalization many practical cases these results show certain made free
propose new linear method dimension reduction identify components high dimensional data our method non gaussian component analysis uses general semi parametric framework contrast existing methods define what gaussian out estimate relevant non gaussian show estimation error finding non gaussian components zero parametric rate components various tasks applied data analysis process like data clustering classification numerical study our method
present novel approach complex sensory neurons main sensory neurons dimensions stimulus space neurons highly sensitive large neural responses dimensions stimulus space neuronal response invariant response problem learning stimulus space neural responses distance between stimuli should large responses they different small responses they similar here show successfully train such distance functions using rather limited amount information data responses neurons auditory cortex stimuli derived natural each neuron subset pairs stimuli such responses two stimuli either similar distance function trained fit these constraints resulting distance functions generalized predict between responses test stimulus trained stimuli
paper provides system level analysis distributed model our system model data data each their noisy observations original binary sequence their data sequences data combined rate limited use independent rate codes show system performance given finite number analysis shows optimal strategy distributed problem changes critical values data rate noise level
paper show loss log likelihood semi parametric model posterior probabilities point view represent parametric component semi parametric model maximum estimation procedure connection derive mapping svm estimated posterior probabilities previous suggested mapping set posterior probabilities each svm framework new way svm optimization problem classification result experiments show over state
brain computer systems novel channel brain output conventional motor output therefore they could provide new control option based techniques classification single brain signals here present novel technique allows optimization spatial spectral filter multi channel eeg single evaluation experiments different subjects proposed algorithm classification spatial spectral filter determined algorithm used further analysis data eg source brain
given set points set representing them graph whose points problem yet been framework statistical learning theory work propose generative model based graph algorithm learn parameters work first step model set points statistics
while kernel correlation analysis kernel has been applied many problems asymptotic convergence functions estimated finite sample true functions has yet been paper gives statistical convergence kernel related method provides theoretical these methods result gives sufficient condition regularization methods convergence
they produce underlying has been studied depth showing auditory system complex problem manner present large scale circuit model process show results circuit simulation what known auditory system now being extended use robot along previously neural better complete understanding out complex tasks design simple sensory systems often have into filters highly specific data environment particular problem directly need further processing examples include uses vision other estimate self thus its because few time difference two small even they about low directly neural spikes because significantly than difference low information uses phase determine direction possible because almost its information action auditory system four inputs channel directly through two sound inputs has phase delay reduction gain sound making each input system auditory system well system see figure uses sound four inputs two two such response near amplitude firing rate auditory neurons them sound source different inputs out phase outputs two sound inputs symmetric respect sound source sound frequency off phase signals better into signal other allows sound source see figure example version auditory system using two inputs implemented hardware simple neuron network required direct robot out specific simple model auditory system figure different data et al used together average values paper simulation figure shows model internal auditory system sound inputs through down auditory model up inputs well sound results used system different gain better understanding its response effect movements complex due sound chip designed implement same model both more complex experiments such movements experiments real world model auditory system used implementation shown these experiments circuits being those more present paper present circuits used implementation circuits chip figure two delay filters three gain circuits second order filter first order wide filter first order high filter well including single chip chip thus includes necessary model complete auditory system complete model auditory system obtained using two connected two delay filters need implemented instead three suggested figure because relative delay between three node delay circuits implemented fully differential filters order extend frequency range delay first order delay circuit second order delay circuit resulting addition first order delay second order delay delay response delay frequency first order filter delay second order filter its frequency figure shows second order delay circuit two these used based data presented designed way bias current figure standard includes common feedback necessary fully differential figure simple differential pairs ii ii ii ii ii ii figure first order delay circuit left second order delay right differential output delay circuits into current variable gain implemented shown figure gain cell includes differential source via source current three gain cells implemented have set input high bias through value correct chip explore other gain current cell figure allows gain digital means current takes input current figure into current ie first gives second so these used together digital low setting gain set output each three gain cells set via single output three gain circuits current domain involves three together therefore natural option filters use current domain filters our case have chosen implement log domain filters using figure shows basic filters cell cell showing these connected necessary filtering cell log domain filter has response out factor bias current figure input cell used second order filter cell out out cell particular responses along corresponding equations high frequency filter figure implemented high filter figure frequency low frequency filter into two parts biological filters response see example figure well into second order filter frequency wide filter made first order high filter frequency first order low filter frequency these filters together biological filter filters responses via their bias allows due processing matching errors figure gain cell above used differential input delay cells into single current output gain each cell via current cell chip bias used necessary current chip main gain cells filters have their chip bias through chip chip using designed using design methods chip tested using sound generated computer through chip responses chip back computer given output gain circuits current current sense circuit discrete components used output figure circuit log domain filter cell along three filters used model initial experiments performed after taken frequency responses generated computer each chip input moving sound appropriate amount time much solution than using moving them using results chip tested measure its successfully appropriate values chip compared simulation system result test frequency shown figure amplitude signal response circuit similar expected because circuit has real world noise simulated version has signals examples gain frequency response two log domain filters shown figure note filter significantly above frequency but observed real well
investigate under what conditions neuron learn experimentally rules spike timing dependent plasticity predict arrival times strong inputs same neuron out contrast perceptron convergence theorem convergence perceptron learning rule neuron model stable solution strong convergence given spiking neurons but derive criterion statistical structure input spike learning converge average simple model spiking neuron criterion linear criterion perceptron convergence theorem but here correlation matrix related spike inputs addition show through computer simulations more neuron models resulting analytically predicted positive learning results common interpretation changes weights synapses but more interpretation suggested experimental data initial probability dynamic synapses
standard statistical models language capture most properties natural power distribution word present framework statistical models produce power standard generative models appropriate pattern show particular stochastic process process type natural language performance model unsupervised learning
present model learns markov within proposed model dynamic bayesian network two level structure individual level level individual level models actions each level models actions whole experiments synthetic multi multi show proposed model
paper derive algorithm solution path support vector regression same computational cost model propose estimate model allows selection regularization parameter
discuss method subjects behavior context under assumption behavior optimal bayesian method sense do assume prior fixed class distributions eg gaussian method relatively simple implement being based case linear programming algorithm more generally maximum likelihood maximum formulation out convex optimization problem non global local many important cases addition develop methods uncertainty these estimates demonstrate accuracy method simple simulated setting particular method able subjects posterior distribution more more data observed close interesting connection recent models neural population coding
present efficient algorithm learning function domain into regions function above given threshold develop experiment selection methods based entropy rate variance their show they perform number data sets show these algorithms used determine simultaneously confidence intervals parameters shows algorithm computation necessary parameter estimation problem order
while classical experiments spike timing dependent plasticity synaptic changes function timing pairs spikes more recent experiments point effect spike here develop framework allows us timing based learning rules moreover identify learning rule variables free parameters variety experimental data including upon firing rule well timing based rules discussed
problem sparse graphs real variables studied using methods statistical efficient distributed algorithm basis analysis using numerical simulations showing performance full theoretical results
our understanding input output function single cells has been accurate multi models large number parameters hand these models has their here propose simple well method estimation many these key parameters spatial distribution channel cells pattern synaptic input channels noise level each assume experimental signal eg via sensitive techniques approximate description channels synapses present each part neuron under key observation given data parameters may simultaneously version constrained linear regression regression efficiently solved using standard algorithms without local problems large number parameters complex dynamics noise level may estimated standard techniques demonstrate methods accuracy several model datasets describe techniques uncertainty our estimates
network neurons brain feedback connections but computational function these feedback connections unknown present computational theory gain computational power achieved through feedback dynamical systems memory many such systems through feedback computational analog computing non memory particular show feedback such systems process time varying input ways according rules implemented through internal states dynamical system contrast previous based computational models neural networks these internal states high dimensional circuit dynamics still allow circuit state new information online input way novel models memory evidence reward expectation cortical circuits show they circuits based neurons high levels noise experimental data conditions
objects many clustering them basis relatively small random subset these capture information well moreover show under conditions clustering objects basis such random subset performs almost well clustering full set prove finite sample generalization novel learning scheme results supervised learning setting scheme demonstrated filtering
long distance language modeling important speech recognition machine but high dimensional discrete sequence modeling general problem context length has almost been so far words has been natural language processing contrast paper view within text latent stochastic process give probabilistic generative model has partial propose online inference algorithm using filters most appropriate length context automatically experiments consistent improvement over previous methods order
motor eeg over these amplitude changes most successfully method common spatial patterns used methods based amplitude information have phase dynamics eeg study method based phase rate computed phase value describes number discrete within statistical show significant between types motor classifiers trained demonstrate results subjects further observed subjects phase more than amplitude first suggests phase has potential information transfer rate
visual attention early parallel processes features such contrast motion visual field these features combined into map attention most regions first top down control achieved different feature types map key source data control studies effect recent perform perceptual discrimination task eg what shape object robust finding features recent eg target performance view adaptation statistical structure environment propose probabilistic model environment after each under assumption control so make performance more efficient more states obtain data four different experiments further our model provides control short
present series theoretical large class learning algorithms prior similarity between examples local kernel sensitive dimensionality more target our supervised unsupervised learning algorithms these algorithms found local sense properties learned function training set makes them sensitive dimensionality well studied classical non parametric statistical learning show case gaussian kernel function learned has many these algorithms require number training examples number could large even may short target function ie their complexity may low suggests non local learning algorithms least have potential learn about such but complex functions because locally they have many while using specific prior domain knowledge
study learning multiple sources limited data each may different rate develop complete theory data sources should used two problems estimating bias learning classifier presence label noise both cases efficient algorithms provided computing optimal subset data
design new learning algorithm set machine bayes propose bayes risk bound classifiers non margin off
paper consider problem finding sets points given underlying model within noisy set observations problem task efficiently but range spatial current tree based approaches showing off between single tree multiple tree algorithms present new type multiple tree algorithm uses variable number trees advantages both approaches show algorithm performs well using both simulated data
present method inference large datasets our algorithm based gaussian processes effective kernel matrix its inverse vector computed fast instance certain graph kernels achieved variational inference over data constraint
under natural conditions small movements eye direction known stimuli they retina several whether self motion image visual during natural visual study statistics visual input retina structure neural activity early visual system input signals presence natural images spatial correlations these input neural activity model they cell responses even contrast functions simulated cells power natural images neural activity has been proposed statistical input signals might therefore efficient representations natural stimuli
paper propose new basis selection criterion sparse regression models provides accuracy well efficiency over previous methods our algorithm much faster than while generalization information gain approach proposed et al quality predictive distributions
present conditional temporal probabilistic framework human motion video based image observations computational efficiency visual inference low dimensional kernel non linear state spaces our kernel pca based non linear dimensionality reduction conditional bayesian mixture experts order learn complex between observations model hidden states necessary accurate inverse visual several solutions due noise uncertainty low dimensional models appropriate because many visual processes exhibit strong non linear correlations both image observations target hidden state variables learned combined within conditional graphical model order allow propagation uncertainty study several show proposed algorithm techniques based regression kernel estimation pca gives results competitive those high dimensional mixture their computational cost show method successfully complex motion real video sequences
present new kernel method between natural language text based generalization kernels kernel uses three types patterns typically natural language relationships between two experiments interactions top level demonstrate advantages approach
dynamic video model video sample temporal stochastic process linear dynamical system problem associated dynamic cannot model video multiple regions motion work introduce dynamic model problem introduce model present em algorithm learning each models finally demonstrate proposed model tasks segmentation video
propose fast learning algorithm based domain decomposition set sample points into two develop solution problem two into whole domain provide analysis errors produced process using matrix theory numerical examples given illustrate efficiency proposed methods
experimental data indicate attention previously considered function system time scale suggested signals global uncertainty changes known stimuli tasks here extend our uncertainty based detection state uncertainty within task role through neural
although non parametric have been proposed statistical non standard measures different classification error less often used paper these compare more classical various conditions more using large estimate whole population behavior several statistical test varying class compared models performance measure sample size main result evaluation sets non parametric relatively conditions
sample complexity active learning problems terms parameter takes into account distribution over input space specific target hypothesis desired accuracy
paper presents non asymptotic statistical analysis kernel pca focus different proposed previous work here instead reconstruction error approximation error bounds prove upper bound between but dimensionality allows stability results these estimated spaces
describe based kernels multiple biological sequences process regions kernels more information most complex kernel multiple regions tree prior knowledge relevant sequence patterns these kernels used presence known factor de over given length classifier such kernel given class regions but effect simultaneously relevant sequence demonstrate based multiple kernels using regions classes cell data available
neurons have spike train statistics underlying network state estimate time such state dynamics multiple neuron have developed algorithm likelihood observed spike state state conditional distributions our algorithm free time spike problems has computational complexity state markov model state sequence length equal total number spikes example fit two state model neurons find two state conditional functions highly similar measured during
investigate problem automatically efficient representations basis functions value functions based structure state space particular two novel approaches value function approximation based automatically basis functions state spaces represented graphs approach uses effect global analysis graph second approach based generalize classical graphs using random graph together these approaches form new methods solving large markov decision processes underlying representation policies simultaneously learned
consider framework semi supervised learning using spectral decomposition based supervised kernel design approach class previously proposed semi supervised learning methods data graphs various theoretical properties such methods particular derive generalization performance bound obtain optimal kernel design minimizing bound based theoretical analysis able demonstrate spectral kernel design based methods often improve predictive performance experiments used illustrate main our analysis
propose new bayesian method spatial cluster detection bayesian spatial compare method standard approach demonstrate bayesian has several advantages over approach including power clusters much faster evaluate bayesian methods task spatial clusters cases resulting demonstrate our bayesian methods while number low
given probability measure measure often minimum measure set measure least minimum sets type regions probability useful confidence regions paper problem estimating minimum sets based independent samples distributed according other than these samples other information available but measure known introduce rules estimating minimum sets parallel empirical risk minimization risk minimization classification classification show our rate convergence empirical true probabilities over class estimator thus obtain finite sample size performance bounds terms dimension related demonstrate strong based illustrate proposed rules
recurrent networks perform take computation have been studied although these studies include spiking networks they consider analog input rates present results take computation network neurons spike inputs show connectivity network so after determined number input spikes discuss spiking inputs both distributed rates computation tested take network analog vlsi array neurons have variance their parameters
consider problem joint parameter estimation prediction markov random field ie model parameters estimated basis initial set data model used perform prediction eg interpolation new noisy observation computation limited setting analyze joint method same convex variational used construct estimator parameters perform approximate prediction step key result paper computation limited setting using parameter estimator ie estimator model even data limit resulting errors errors made using approximate prediction technique result analyze asymptotic properties based convex variational stability property class variational methods show joint based sum product algorithm used based sum product markov random fields variational method algorithms sum product belief propagation parameter estimation learning
reinforcement learning models have long computational neural behavior data free experiments fast work reinforcement existing reinforcement learning models about these tasks because they they thus address simple observation work well such their even such here develop framework free behavior subjects perform actions states such these factors effects response rates well many other finally suggest levels may computation state optimal complex related effects
brain eg measurements what parts cortex each other order more accurate models brain activity common techniques like source separation estimate brain sources single out using underlying assumption source signal interesting brain sources typically so them sources signals due effects work these effects new technique proposed uses cross correlation matrices resulting decomposition consists brain sources interaction our new concept source analysis successfully demonstrated data
two power empirical inverse non linear relationship between hand speed its trajectory during motion invariant upper movement has been shown even demonstrated motion prediction has various empirical relationship these generally either joint space result mechanisms noise motor system produce smooth trajectories human motion show here gaussian noise power analysis signal noise shows trajectories power power after combination low levels noise furthermore noise types non power trajectories power these results suggest experiments power its underlying without analysis noise our results could suggest power might derived mechanisms noise our motor system but rather correlated noise motor system
dimensionality learn non local functions sense value shape learned function using examples may far objective present non local non parametric density estimator upon previously proposed gaussian mixture models covariance matrices take into account local shape upon recent work non local able generalize training data traditional local non parametric models
present new gaussian process regression model whose covariance locations input points learn gradient based optimization take number real data points obtain sparse regression method has training cost prediction cost per test case find covariance function same joint optimization method bayesian regression model particular input dependent noise method out related several other sparse approaches discuss finally demonstrate its performance large data sets make direct comparison other sparse methods show our method full performance small ie sparse solutions significantly other approaches
describe hierarchical system objects images objects represented graphical models algorithm uses hierarchical tree tree full object lower level elements tree features algorithm simple up down tree method under second images demonstrate approach method presence our approach more traditional methods such dynamic programming belief propagation
standard method obtain stochastic models time series train state hidden markov models hmms algorithm based observable models few number novel learning algorithms similar have been developed two efficiency algorithm statistical efficiency sequence constrained gradient descent estimator transition hmms hmms give these algorithms compare them learning synthetic real data
paper gaussian process dynamical models nonlinear time series analysis low dimensional latent space associated dynamics map latent space observation space out model parameters form using gaussian process both dynamics observation results model dynamical systems uncertainty model demonstrate approach human motion capture data each dimensional use small data sets learns effective representation nonlinear dynamics these spaces
have been many graph based approaches semi supervised classification problem learning performance depends similarity graph transformation graph noise model present bayesian framework learning graph based classification given labeled data labels semi supervised classification inference problem over unknown labels expectation propagation used approximate inference mean posterior used classification learned using em evidence maximization show posterior mean terms kernel matrix bayesian classifier new points synthetic real datasets show cases significant performance over existing approaches
online learning algorithms typically fast memory efficient simple implement many common learning problems fit more learning setting power online learning algorithms using online techniques new algorithm existing online algorithm first give three existing online techniques do use training data process upon these data independent derive analyze data our find small risk explicitly minimizing generalization bounds experimentally demonstrate our approach particular show data data independent
present novel spectral clustering method prior knowledge size clusters into clustering process cost function size defined sum cluster similarity regularization term relative size two clusters finding data set minimize complete approximation algorithm proposed solve version optimization problem problem over different data sets demonstrate method sensitive performs better than
derive bayesian motion solving problem obtain model approximation our experiments show human performance similar bayesian but human performance far investigate ways bayesian but show even do approach human performance instead propose perform motion tasks using general models motion perform more experiments consistent using smooth model rule out alternative model using
propose simple information approach soft clustering based mutual information between unknown cluster labels training patterns respect parameters constrained distributions constraints chosen such patterns they close specific unknown vectors feature space method may applied learning optimal matrix learning parameters procedure does require matrices makes clustering large data sets
show linear perform maximum likelihood estimation parameters generative models causal our approach involves variables similar model our results assumptions distributions these assumptions example causal power theory show linear estimate parameters model up nonlinear moreover nonlinear able estimate parameters directly within arbitrary accuracy previous results used determine convergence estimate convergence rates
well known difficult online setting arbitrary sequences examples labeled time setting examples distribution show result direction give efficient algorithm online uses future data between what efficiently model online model
has recently attention machine learning has been many learning algorithms such multi layer artificial neural networks show training multi layer neural networks number hidden units learned convex optimization problem problem involves number variables but solved hidden unit time each time finding linear classifier weighted sum errors
paper statistical relationship between natural images their underlying range depth images relationship changes over scale information used low resolution range data using full resolution image based our propose extension existing technique known shape two methods compared using images real scenes our extension shown provide two improvement over current method furthermore demonstrate linear shape filters learned natural scenes may derive even more cues than traditional linear cues
present improvement algorithm mapping multiple about maps full map per filter time linear significant algorithm parameters takes constant time per iteration means asymptotic complexity algorithm than algorithm using single map same number present hierarchical extension uses two level filter models filtering process hierarchical approach results using finite number filter use more domains while linear time asymptotic complexity
determine asymptotic limit function computed support vector machines svm related algorithms minimize empirical convex loss function kernel space gaussian rbf kernel number examples gaussian kernel regularization parameter fixed non asymptotic convergence bounds limit sense provided together upper bounds classification error shown converge bayes risk therefore bayes variety methods although regularization term does these results relevant class svm regularization shown first time consistent density level set estimator
good image object detection algorithm accurate fast does require exact locations objects training set such object architecture training new boosting call uses cost functions multiple instance learning combined framework feature selection criterion performance experiments show detection rate up times better using detection rate shows advantage simultaneously learning locations scales objects training set along parameters classifier
probabilistic modeling correlated neural population firing activity understanding neural code practical algorithms parametric models modeling correlated neural data high dimensional nature data makes fully non parametric methods address these problems propose energy based model joint probability neural activity represented using learned functions data parameters model learned using optimization procedure finding appropriate evaluate method using real data population motor cortical neurons particular model joint probability population spiking times hand position show likelihood test data under our model significantly higher than under other models these results suggest our model correlations firing activity our probabilistic model neural population activity step both correlations neural coding improved population activity
observed dynamics many possible factors including state kalman filter used presence such factors sequence observations estimate true values these observations have been apply model time series data show effective number patterns
hybrid circuits cmos simple two extend exponential development into range network architectures future neural cell implemented cmos used while used synapses have shown may trained perform pattern classification hardware estimates have shown may cells per times faster than biological neural networks power discuss possible short term long term applications
general analysis distribution neural network functions performed non gaussian show symmetric stable output weights more generally weights distributed normal domain stable variable neural functions converge distribution stable processes conditions under gaussian do weights independent but distributed classes stable distributions learning such processes
field based small linear sparse signal information reconstruction paper introduce new theory distributed new distributed coding algorithms multi signal both signal correlation structures theory new concept term joint signal ensemble study three simple models sparse signals propose algorithms joint multiple signals number measurements per required accurate reconstruction sense framework distributed sources memory has problem information theory time range problems networks
paper presents statistical analysis active learning significantly classical learning active learning algorithms able make sample locations online results previous leads significantly faster rates error than those possible classical learning nature these performance active learning two function classes addition theoretical potential active learning paper describes practical algorithm capable active setting upon classical techniques our active learning theory methods show number applications including field estimation using networks line detection
predictive state representations method modeling dynamical systems using observable data such actions observations describe their model use predictions about future system state best existing techniques learning use monte carlo approach explicitly estimate these probabilities paper present new algorithm learning uses gradient descent approach compute predictions current state algorithm takes advantage large amount structure prediction matrix its predictions furthermore algorithm used online agent improve its prediction quality current state learning algorithms do give empirical results show our constrained gradient algorithm able using small data larger data compute accurate predictions system dynamics
introduce method automatically improve models without use using minimum specific training data show use words identify whose using those regions our prediction model improve our search retrieval performance words
develop approach estimation gaussian markov processes prior while instead information between nodes graph study posterior distribution hidden nodes whole graph show resulting computation forward neurons moreover using matrix matrix inverse without iteration same computational simulation results illustrate approach
linear efficient coding hypothesis such independent component analysis ica sparse coding models have provided functional properties simple cells these models non linear behavior neurons individual population properties neural receptive fields but important ways hierarchical models including gaussian scale mixtures other generative statistical models capture higher order natural images explain nonlinear neural processing such context effects previously been lower level representation independent been fixed training these models here optimal lower level representations derived context hierarchical model find resulting representations different those based linear models basis functions filters learned ica sparse coding these functions more simple cell receptive fields range spatial scales our work several related approaches observations about natural image structure suggests hierarchical models might better representations image structure
extend radial basis function rbf networks multiple correlated tasks learned simultaneously present corresponding learning algorithms develop algorithms learning network structure either supervised unsupervised manner training data may improve networks generalization test data experimental results based real data demonstrate advantage proposed algorithms support our
propose simple clustering framework graphs pairwise data similarity based methods approach data clusters probabilistic way more hierarchical clustering derived framework lower level clusters into higher level random analysis algorithm clustering structures various ie higher level models term graphs thus more global clustering structure finally provide experimental results
paper propose general framework study generalization properties binary classifiers trained data may dependent but generated upon sample independent examples provides generalization bounds binary classification cases problems relationship between these learning tasks
has been interest learning non linear models approximate high dimensional data both computational complexity generalization desired feature such models usually means dimensionality reduction estimating dimension but mean subset data use important because many existing algorithms have quadratic complexity number observations paper presents algorithm based regression well known sparse approximations because uses regularization norm continuous based found experimental results synthetic real data illustrate algorithm
present computational model human eye movements object class detection task model state computer vision object class detection methods features trained using model human eye movement produce sequence simulated target model its behavior behavior human object class detection task among complex objects found between model human data multiple eye movement measures including number probability target distance
sparse pca approximate sparse whose capture variance data constrained non convex optimization problem wide range applied fields recent has continuous approximation convex constraint contrast consider alternative discrete spectral formulation based variational bounds provide effective strategy well optimal solutions using bound search moreover exact used simple step approximate solutions obtained continuous method resulting performance gain discrete algorithms demonstrated real world data monte carlo evaluation
regression zero weights most features technique feature selection its solutions linear models kernel machines feature scaling techniques have been studied feature selection non linear models such approaches require solve non convex optimization problems paper new approach feature vector machine standard regression into form svm form easily extended feature selection non linear models kernels defined feature vectors sparse solutions nonlinear feature space much more compared feature scaling kernel machines our experiments simulated data show results small number features non correlated response task standard complete
experimental evidence cortical neurons show activity firing being distributed power present extension neural network power distribution wide range connectivity parameters
address problem robust computationally efficient design biological experiments classical optimal experiment design methods have been biological practice part because resulting parameter estimates model part because computational constraints present method robust experiment design based programming present application method design experiments complex signal have found parameter estimates obtained robust design better than those obtained optimal design
number requires statistical analysis high dimensional data sets instance behavior neural firing artificial brain brain machine linear analysis techniques such cases but classical linear regression approaches often high dimensions paper address question whether data movements linear approaches neural activity motor cortex achieve robust data analysis develop full bayesian approach linear regression automatically features data against overfitting comparison least regression partial least regression search most predictive input features data demonstrate new bayesian method superior mixture characteristics terms regularization against overfitting computational efficiency use its potential other linear regression techniques results our demonstrate data well predicted neurons further path possible real time between machines
show algorithm minimizing symmetric functions used clustering variety different objective functions two specific consider paper single minimum description length first criterion minimum distance between elements different clusters known optimal into clusters given polynomial time criterion computed second criterion minimize description length clusters given probabilistic generative model show optimal into clusters approximate within factor optimal more clusters computed best our knowledge first time algorithm finding optimal clustering respect criterion clusters has been given result criterion paper show same algorithm used class used many application specific criterion efficient algorithm known
consider scaling number examples necessary achieve good performance distributed multi agent reinforcement learning function number prove lower bound showing algorithms global reward signal learn policies limit they require number real world examples scales number interest large number demonstrate class algorithms advantage local reward signals large distributed markov decision processes able good performance number samples scales makes them even large number
learning new actions has been observed simple movements based paper show problem goal based actions using learned probabilistic graphical model environment first describe algorithms planning actions achieve goal state using probabilistic inference describe planning used learning goal dependent policies feedback environment resulting graphical model shown allow goal based using simple task illustrate agent observed even
paper propose new digital focus application gaussian processes detection code multiple systems solve near far problem reduce other same frequency while approaches minimize mean error user interest same but design nonlinear optimal solution known nonlinear performance novel method furthermore based even short training sequences include experiments illustrate other nonlinear such those based support vector machines exhibit performance
make optimal perceptual noisy conditions underlying such optimal behavior have been shown probabilistic inference according generative models whose structure usually taken known bayesian model selection similar even more complex model structures find experiments learn statistical properties visual scenes unsupervised manner show these well bayesian model learning within class models explain observed variables independent hidden
between variables many graphical models eg active learning analysis previously pairwise information gain has cost quadratic network size work show perform similar computation cost linear network size loss function allows form computation dynamic programming algorithm results described empirical results demonstrate large without accuracy cost sensitive domains superior accuracy achieved
while classical kernel based learning algorithms based single kernel practice often use multiple kernels et al considered kernel matrices classification convex constraint quadratic show semi linear efficiently solved standard svm moreover generalize formulation our method larger class problems including regression class classification experimental results show proposed algorithm model selection learning result examples kernels combined
paper presents novel technique data obtained using stimulus experimental technique based probabilistic graphical model describes data terms underlying sources explicitly models stimulus variational bayesian em algorithm model data sources activity individual brain sources new algorithm existing techniques two real datasets well simulated data
most systems information about stimuli activity large neuronal networks activity often sequences action multiple now standard research important have measure such network wide information multiple neural spike train data propose new measures much better unit predicted dynamical state another measure information superior traditional pairwise measures correlation find dynamical states use recently introduced algorithm effective state spaces stochastic time series extend pairwise measure analysis network estimating network multi information illustrate our method model transition much most important information neural systems over multiple neurons cortical areas such population codes distributed representations time scales neural information temporal patterns activity therefore information between neurons brain regions between sequences neural spikes furthermore neural systems regions brain often require neural activity perform important functions requires multiple neurons cortical areas information thus measure dynamic network wide behavior neurons test about them need practical methods associated information across multiple neural units these would useful about particular distributed coding eg current techniques analyze among spike pairs neurons so further need method analyze network system region whole here propose new measure information based dynamical state section behavior neural systems often measures correlation sensitive nonlinear stochastic predictive relationships section mutual information between dynamical states two systems states rather than out section right states section describes effective state spaces data section gives about approximate global information network section our method model system based model our results those more second order statistics interest space full existing minimal here paper now most idea information activity across neural units specific activity units should same eg spiking same time measure close units being eg variance spike times point view over other neuron spiking after another relationship two simultaneously spiking but such stable phase approaches exact nature neural code uses extended patterns activity so information should those patterns rather than activity three common ways cross correlation related second order statistics mutual information generalized cross correlation function covariance function includes present joint time most measures efficiently observable series statistical well deterministic relationships between processes variable problem phase transformation covariance function yields cross gives spectral correlation between components over spectral measures degree linear cross two series spectral neural activity such second order statistics linear relationships neural processes known nonlinear these statistics measure neural systems mutual information because both nonlinear stochastic relationships has natural interpretation often practice being small even between signals known neural codes use patterns activity over time rather than many different actions approach these extended patterns consider two neurons other spike after does neuron spiking every these but whether first neuron time information about what second neuron its spiking but its spiking most time mutual information direct observations spike second neuron its spike here mutual information could find used but work general take two rate coding neurons line firing rates stimulus other spiking rates thus information but whether neuron about what other neuron generalized based idea relationships between states various units state here taken sense dynamics control theory state time variable distribution times system state allows us predict well possible system two systems exhibit generalized state system given mapping state other applications data reconstruction state according smooth dimensional deterministic dynamics function space time delay vectors various generalized between state spaces but they equivalent another phase based thus these measures nonlinear relationships neural systems have deterministic dynamics experimentally levels much less deterministic relationships among such states different units what but these provides measures predictive relationships among states but allows those relationships nonlinear stochastic next section such measure call states mutual information between sequences observations described capture units phase rate estimate their phase rate mutual information between those variables see units patterns activity rates do neural patterns more general common scheme most general pattern activity dynamical state system sense above now information information state variable mutual information between well known use mutual state information scale between joint distribution product their distributions error between mutual information between predictive dynamical states thus error two systems independent ie much predictions could improve into account measures amount relevant information two systems value degree two systems have patterns behavior although uses directly observable reconstruction estimation effective state spaces state space deterministic dynamical system sequence observations main experimental nonlinear dynamics but assumption almost interesting neural system while classical state space reconstruction work stochastic processes such processes do have state space representations special case discrete time series ways state space here use algorithm introduced code available causal state models stochastic capable optimal nonlinear prediction state machine minimal sufficient future observable process basic idea form set states should sufficient statistics next observable have deterministic transitions theory sense algorithm minimal state model whether these properties means hypothesis they model generally but more states new model each state model distribution over future ie statistical pattern behavior under conditions do prior knowledge state space probability causal state model data generating process practice quite fast linear data size least well training hidden markov models em algorithm using cross validation selection standard advantage causal state approach classical state space reconstruction state estimation general case nonlinear state estimation necessary form stochastic dynamics state space observation function but their parametric values distribution observation estimating state observable time series computationally application rule due way causal states statistics data probability finite time causal state time certain degree belief confidence because way states constructed process other state time causal state has been ie causal state time function causal state time observation causal state model automatically therefore into finite state observation time series outputs corresponding series states our implementation filters its training data automatically result new time series states non predictive components have been out estimating our algorithm estimating matrix each unit causal state model filter observable time series produce series causal states each neurons construct joint causal state models have same power observable models predictive state representations power than variable length markov models figure neuronal spike times network neurons shown during first current connections among cells left those connections active right state distribution estimate mutual information between states single unit state gives symmetric matrix values even two systems independent their estimated average positive because while they should have zero mutual information empirical estimate mutual information non negative thus values against hypothesis system way do so take state models two systems them forward another generate large number simulated state sequences these values procedure approximate sampling distribution under model dynamics each system but their interaction find values them here space network multi information networks should analysis pairs neurons over pairs analysis information network would over structure statistical between various units complete joint probability distribution states would allow us instance multi information between joint distribution product distributions pairwise mutual information over predictive states multi information would give total amount dynamical information system mutual information its maximum possible value its maximum sum distribution over high dimensional space so estimate well without strong parametric constraints thus consider approximations order approximation units independent distribution step up tree distributions global distribution function joint distributions pairs units every units into such distribution every unit part tree distribution tree units whose interactions into global probability trees determine tree distributions et set pairs has distributions distributions estimated empirical distributions now et so best true global distribution natural approach minimize between its tree approximation maximum weight tree gives minimizing distribution weight mutual information between variables three advantages using approximation estimating empirical probabilities gives consistent maximum likelihood estimator tree rates convergence so known even cannot efficient algorithms maximum weight trees such algorithm time log thus approximation computationally distribution gives lower bound network multi information bound sum mutual along tree even eq would useful alternative directly log many natural higher order approximations eg using three way interactions into pairwise interactions but do so because finding optimal approximation such interactions like eq generally do therefore approximation here example model use simulated data test case instead empirical multiple allows us method system over neurons compare measure against expected results model taken designed study system often transition between them more studied those model two neuron neurons defined based equations simulations out network cells each cell neuron basic spiking applied current gaussian input noise first simulation neurons made spike via applied current figure maps network measured zero cross correlation top left right through maximum obtained recurrent connections result during after current current during due activation used during cells during subset fig fig zero cross correlation second order method states simulation could have states model neurons directly rather than them but our method relationships fig but instance phase between cells mutual information shown gives similar results has two presence dynamical noise state reconstruction average low neurons tree estimate global multi information global right analysis stage average tree estimate global multi information estimated global because low neurons now active global information but over pattern more noisy fig so expected total information higher but across network lower provides measure neural information activity nonlinear stochastic relationships between extended patterns spiking robust dynamical noise leads measure global across networks regions applied data multi should about distributed neural representation function support under neural codes distributed representations nature probabilistic models brain practice data analysis up et al statistical dynamics sutton neural information processing systems nonlinear time series analysis up elements information theory et al probability uncertainty artificial statistical neural computation machine learning statistics linear nonlinear filtering world upper still information theory et al
consider task depth estimation single image take supervised learning approach problem training set images include trees their corresponding apply supervised learning predict function image depth estimation problem local features estimate depth point consider global context image our model uses trained markov random field global image features models both individual points well between different points show even scenes our algorithm able accurate
probabilistic temporal planning find good policies domains tasks multiple limited these domains typically markov decision problems solved using dynamic programming methods paper application reinforcement learning form policy gradient method these domains our large domains dynamic programming our approach construct simple policies each planning task result general probabilistic temporal policy gradient tasks probability use
present family approximation techniques probabilistic graphical models based use graphical developed computing our framework yields upper lower bounds probabilities log function graphical models using non iterative have low time complexity mean field approaches approximations upon problem distribution parameters approximate inference terms well studied linear systems problem good matrix experiments presented compare new approximation schemes variational methods
non method brain neuronal here show allows neuronal use variational framework model multiple component model signal variational regularization mechanism order reduce free estimate free each variational framework applied data conventional parameters containing using variational framework able highly results show able find found
paper describes highly application problem generating high resolution range images new range capture low resolution range images high resolution images paper fact range generate high resolution low noise range images images into range data show using such improve over existing range
describe novel method learning recognition objects generative model multiple object parts respect object system these parts generate image features complexity model number features low our model much more efficient train than methods moreover variational approximation introduced allows learning faster than previous approaches while many more features results both accuracy our model has been tested standard datasets compare number recent models particular demonstrate state results detection
sets consider problem concept cluster given query few cluster bayesian inference problem describe simple algorithm solving our algorithm uses concept cluster using probability each cluster containing query exponential family models probability simple function sufficient statistics focus sparse binary data show our using single sparse matrix making possible apply our algorithm large datasets evaluate our algorithm three datasets finding sets finding sets words compare sets show bayesian sets gives set
category visual stimuli has been patterns neural activity visual cortex has yet whether object activity present data responses human cortex set object images use simple take classifier using data each training set evaluate object across approach sensitive noisy describe two methods data object method each within data while another estimates mutual information each stimulus set find both identify data object even noisy measurements data mutual information metric less efficient task due constraints data
demonstrate first fully hardware implementation self neural map retina into correlated spike population automatically mapping sources spikes pattern different cell types self maps
sampling new monte carlo method general bayesian computation sampling provides robust alternative based methods computing generate estimates other such posterior key ability samples prior constraint likelihood provide model graphical model
linear text classification algorithms work computing product between test vector parameter vector many such algorithms including bayes most parameters determined simple form function training set statistics call mapping mapping statistics parameters parameter function much research text classification over few has identify better parameter functions paper propose algorithm automatically learning function related classification problems parameter function found our algorithm new learning algorithm text classification apply novel classification tasks find our learned classifier existing methods variety text classification tasks
paper two network modeling first generalize model relationships into dynamic model over time second show make learn such models data even number large generalized model each point dimensional latent space points time but large latent space observed between more close latent space show make such model number use appropriate kernel functions similarity latent space use low dimensional trees new efficient dynamic adaptation scaling first approximate into latent space efficient gradient update rule non linear local optimization time per during update use both synthetic real world data indicate linear scaling computation time improved performance over four alternative approaches illustrate system data present version work
investigate top down td up information weighted human search behavior td components based model model artificial retina neuronal population code component based td component defined feature target representation compared models behavior different mixtures td components eye movement behavior human search task found td model provides much human behavior than mixture model using information biological constraints eg retina mixture model approximate human behavior
many real world classification problems prediction multiple dependent variables recent machine learning has supervised classification such variables paper investigate classification semi supervised setting present approach input patterns data points derive maximum margin formulation semi supervised learning variables algorithms our formulation new test points
paper algorithm stage stochastic decision problem continuous state space sequence supervised learning problems optimization problem associated trajectory tree random trajectory methods solved using method algorithm reinforcement learning problem into sequence single stage reinforcement learning each solved via exact reduction weighted classification problem solved using off self methods thus algorithm reinforcement learning problem into supervised learning shown method finite number steps solution cannot further improved optimization proposed algorithm classification methods applied find policies reinforcement learning problem
present model region using conditional random field over scale invariant representation images multiple cues our model includes capture low level similarity level high level object shape maximum likelihood parameters model learned human labeled large images using belief propagation using out test data information level cues high level shape
biological sensory systems problem high sensory signal population noisy low neurons problem information terms coding multi dimensional analog signal over set noisy channels previously have shown robust codes learned minimizing reconstruction error constraint channel capacity here present theoretical analysis optimal linear data analysis allows arbitrary number coding units thus including both over complete representations provides number important into optimal coding particular show form code number coding units different data noise conditions achieve report numerical solutions robust coding image data show these codes more robust compared against other image codes such ica
describe vision based system off system trained map input images trained supervised predict provided human during training wide variety conditions conditions types robot off two computer processes video robot via learning system large layer network whose input single low resolution images robot ability them real time
highly complex such them yet unknown based same may present paper control problem using online reinforcement learning algorithm based bayesian approach policy evaluation known gaussian process temporal difference learning our real computer simulation dimensional model even model state space face high dimensional apply algorithm domain demonstrate its several learning tasks varying
propose efficient algorithms learning functions order constraints between sets ie classes training samples our algorithms may used generalized partial classes special cases include area under curve binary classification its generalization regression experiments indicate proposed algorithm least accurate current state computationally several faster current methods easily able even large datasets over samples
introduce new model large input into short sequence small set short sequences probability distributions many representation has been used modeling real signals such images discrete sequence model introduce paper applications multiple inference our experiments modeling natural model relatively small large number system known our experiments show includes more than other similar length including tree observed discuss take into account uncertainty about cross our experiments find optimization robust these
paper new approach feature selection based statistical feature technique sequence tree kernels natural language data take discrete structures kernels such sequence tree kernels both concept accuracy many natural language processing tasks experiments have shown best results achieved limited small structures these kernels paper kernels statistical feature selection us use larger structures proposed method order efficiently into original kernel process using structure algorithms experiments real tasks problem conventional method compare performance conventional method proposed method
paper numerical computation machine learning domains based similarity such kernel methods spectral techniques gaussian processes presents general solution strategy based iteration fast learning methods experiments show significant computation datasets image segmentation object detection dimensionality reduction paper presents theoretical bounds stability these methods
although value iteration have been proposed finding correlated general sum markov these have been shown effective general paper demonstrate existing value iteration cannot find policies arbitrary general sum markov instead propose alternative interpretation output value iteration based new non concept call prove value iteration class find demonstrate value iteration examples random distribution markov
learning patterns human behavior data important high level activity inference show label significant data contrast existing techniques our approach simultaneously significant locations takes context into account our system uses markov networks represent hierarchical activity model complex among significant apply based perform efficient over large nodes networks present experiments show significant over existing techniques
models such latent useful statistical analysis other discrete data model words each mixture each distribution over model correlation even example about more about than use distribution model among paper develop correlated model exhibit correlation via normal distribution derive mean field variational inference algorithm approximate posterior inference model fact normal gives better fit than furthermore provides natural way other data sets
problem learning objects minimal develop hierarchical probabilistic model spatial structure visual scenes contrast most existing models our approach explicitly uncertainty number object given image our scene model based process novel extension hierarchical set mixture components between multiple data visual scenes mixture components describe spatial structure visual features object while transformations model object particular image learning inference has many potential applications computer vision based effective applied labeled scenes show spatial structure detection performance labeled training images
present mixture model each component gaussian distribution over input space gaussian process model over output space our model able non covariance functions output signals work similar use full generative model over input output space rather than conditional model allows us data perform inference over inverse functional well regression leads more consistent bayesian effective network different experts
clustering problem machine learning has been many ways two general quite different approaches include mixture model eg using em together pairs training cases have high eg using spectral methods clustering algorithms need compute sufficient statistics solutions directly similar examples same cluster many applications require each cluster data described model so based clustering its cannot directly describe technique called propagation advantages both approaches method learns mixture model data demonstrate propagation problems clustering image image segmentation learning mixtures expression models data find propagation better solutions than mixtures algorithm spectral clustering hierarchical clustering both able find number clusters able automatically determine number clusters propagation belief propagation graphical model pairwise training case likelihood functions cluster
paper presents new sampling algorithm functions variables graphical models arbitrary connectivity pairwise well estimating difficult function graph algorithm into framework sequential monte carlo methods rather than more used sequence distributions desired while idea using known construct novel sequence target distributions rather than global parameter individual pairs variables tree variables present experimental results inference estimation function sparse connected graphs
consider variational representations non gaussian latent variables derive variational em algorithms general form general among convex methods evidence based methods ensemble bayes methods has previously been demonstrated particular cases
problem semi supervised learning graph underlying data propose use method number constructed graphs each these graphs basic graph kernel compute optimal combined kernel kernel extended regularization problem requires joint minimization over both data set graph kernels present results different tasks optimal combined kernel computed graphs constructed variety functions nearest
present probabilistic generative model relationships their simultaneously among among corresponding models relationship data have been studied network analysis time here simultaneously cluster several here words associated certain relationships significantly joint inference allows present experimental results two large data sets us their corresponding text similar data show comparison traditional latent variable models words models joint inference more improved
spiking activity experiments often dynamics neural these dynamics may important features neural computation during example activity cortex neurons during delay movement target motor planning show dynamics underlying activity non linear dynamical systems model underlying recurrent structure stochastic point process output present latent variable methods simultaneously estimate system parameters dynamical trajectories these methods applied dynamics data array while perform tasks
present bayesian framework about predict actions agent based its behavior action understanding problem probabilistic generative model order achieve their given constraints their environment simple world domain show model used goal agent predict agent novel constraints change model provides account several have been shown perform predictions make new experiment
consider problem modeling dynamics based state action trajectories paper two first consider linear models such learned standard show linear makes certain properties dynamical systems such difficult capture propose alternative based does learned efficiently data second markov decision process model dynamics would explicitly model step transitions but often models predictive performance over paper present efficient algorithm minimizing prediction error over long time scales present empirical results two different although work problem modeling presented here general applied modeling large classes dynamics
reinforcement learning direct policy gradient estimation theory but practice leads optimization problems improve its speed convergence stochastic descent gain vector adaptation method fast vector our experiments resulting algorithms previously online stochastic natural policy gradient methods
problem computing estimate reconstruction error pca inference problem method using expectation consistent approximation inference problem solved efficiently using two variational parameters result computed alternative presented
present signal vlsi hardware real time separation sources gradient representation signals over array four yields observations time sources independent component analysis ica gradient ica each measure cmos power sampling rate experiments demonstrate separation two speech sources presented through array table analysis shows they direct path
present simple algorithm large margin estimation models including important class markov networks models estimation problem convex point problem apply method algorithm linear convergence using simple gradient step solved using algorithms cost quadratic makes approach efficient alternative based quadratic present experiments two different prediction tasks image segmentation word scaling properties our algorithm
multiple information sources significant successfully learning tasks many studies have information supervised learning present approach multiple information sources form similarity data unsupervised learning based similarity information clustering task non negative matrix problem mixture similarity measurements between data sources their mixture entropy based mechanism model selection stability based approach selection most self consistent hypothesis experiments demonstrate performance method well real world data sets
use decomposition develop algorithms analysis large scale complex networks decomposition based least connected allows hierarchical structure networks their using strategy develop general algorithm used compare properties various networks their hierarchical structure low computational complexity algorithm size network number makes large sparse networks show proposed allows find specific networks
